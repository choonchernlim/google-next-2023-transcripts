{
    "title": "Common business use cases for generative AI",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML110"
    ],
    "video_id": "c4dwJlTzgdI",
    "time": "Aug 30 12:30 PM - 01:15 PM CDT",
    "transcript": "foreign[Music]let's get started hey everyone uhwelcome to this session on commonbusiness use cases for general of AI Iam Nema dakiniko I'm a product managerat Google for our gender of AI portfoliobut I will turn it over to our esteemedguests here who can introduce themselvesbecause we do have a very packed paneland we're going to start with you hieverybody I'm Ignacio Garcia I'm theglobal director of data analytics and AIfor both of them and I'm also the CIO ofVodafone Italyeveryone arvind Christian here I hadengineering at Blue Core so I runengineering data science and oursolution architecture teamshi I'm Donna I lead the TechnicalSolutions management team for generativeAI at Google cloud and together with thesolution architecture teams with Kevin'steam we identify design and build AISolutionsforeignSolutions and we also do mlinfrastructure as wellvery cool uh okay so let's start firstby talking about top business use casesand Don I'm going to start with you onthis one but I really want to understandmany people here are like look Jenaifantastic this is great I'm sold butwhat are those top use cases well how doyou prioritize them how to get startedsure yeah so um I can start withprioritization and then go into a fewuse cases so we really in ourprioritization we focus on our customerswhat will really add value to them whereare they seeing friction points and thenthe Techno technical implementation ofthat we also look internally to some ofour research teams and think about howcan we take those Innovations and thenbring those to our customers so oneexample that we worked on around one anda half years agowas Alpha fold on Google Cloud sodeepmind had this amazing research andmaybe to give a little bit of context onthe protein folding problem scientistshave long been interested in solving theprotein folding problem because once aprotein's structure within a cell isunderstood then scientists are able todevelop drugs that can modulate itsfunctionbut for our Healthcare organizations inorder to be able to actually leveragethat they need additional requirementsso for example reproducibilityscalability it has to be cost effectiveum and so we took their their amazingresearch and we operationalized it onGoogle Cloud through a solutionsome other areas more recent where we'reseeing traction or for example productcataloging so being able to categorizewhen there's a new product label it forsearch and then also create the websitecopy and arvind and his team have donesome amazing work in this space andcustomer service operations and it's notjust a conversational agent which youmay have experienced on a website that'sanswering questions but also internallyfor example supporting SRE teams withpost-mortem search and summarizationwhich we've done some work on but alsosupporting support agents withsummarization and next steps and Ignacioand his team have done some some greatwork herewhat are some of the use cases andprioritizations that your organizationdoes yeahum before I jump into a use case maybejust a little bit step back and what weblew core do so we can connect the dotsso we are an identification and acustomer Movement platform so we workwith large Enterprise retailers toidentify and then convert Shoppers touh repeat customersso we've used traditional Ai and createdover 20 retail models using first partydata so Shopper informationbehavioral data and then productinformationso these models are baked into ourplatform so marketer can use thesemodels to create campaign campaigns andaudiencesso the content that needs to begeneratedthe channels in which to deliver theseuh the the content and finally thetiming when to deliver are allpersonalized on a per Shopper basiswith the Advent of gen AI we looked at acouple of areas you know one is how canwe improve uh our features on ourplatform we looked at internalefficiencies as well and optionopportunities to better serve ourcustomersso um the the problem that she wasreferring to uh is core to our valueproposition so taking unstructureduh product catalog data and mapping itto Google's product taxonomyso for exampleum a retailer could call this a t-shirtanother retailer could call it acategorize it as a true cut T-shirt andso on and so forth but if youstandardize it in the Google's taxonomythis is probably labeled as a t-shirtwhich is under categorized under a shirtwhich is apparel and so on so there area number of uh advantages tostandardizing product catalog one is wewill improve our models and our wrecksour customers will be able to nowanalyze performance within their productcatalog and finally we will be able todeliver Trends within verticals acrossthe retail spaceso using gen AIwe were not very successful usingtraditional AI so with Gen AI we wereable to solve this specific problem verycool absolutely I love the phonehopefully people are a little bit morefamiliar with it in terms of what you dobut love to understand your use casesand prioritizations oh thank you I thinkthat I still will take a couple ofminutes just to explain the thecomplexity that we have and that contextmaybe help to understand how are weusing what we're using so we are atelecommunication company we do mobileswe dotelevisions we do fixed lines and we doiot so the whole package across theworld we have more than 300 millioncustomers we have billions of iotdevices so I'm just talking about thescale and then it's in Europe and inAsia and in other areas so languages arecompletely diverse and this is anotherpoint that is very important on the onhow we're using and the type of problemsthat we need to resolve probably a bitof background as well is we have beenvery focused on partnership with Googleon cloud and data so Google is ourpartner on the data domain and we havebeen very focused on making sure thatour data is in the right place is safefor our customers we have theanonymization we have all theregulations that we have in Europearound privacy and we're super focusedon that and we have been using Ai and wehave been using Google tooling and formany of our normal operations so if I goit will be strong models analysis ontrying to understand why the customersare going up next best offered modelsthat is on the customer side but then ifyou go to the network we we do analysisin where to deploy the network so capexefficiency which is super important orand we call it a predictive maintenanceso trying to understand what is going tobreak and and be sure that we canreplace the components and and that wassuccessful but then with gnai we havebeen now experimenting and and it's acompletely different dimension forexample the use case that you you aresaying with it implemented in Italy sowe are getting all the calls that ourcustomers are making to the call centersWe're translating them into text andthen we're getting a summarization ofthe problems what was the originalintention to reduce the risk that thecustomers are calling us and to driveautomatically the Deep detractors so theamount us is the attractors this is onlypossible now that we have large languagemodels available and we were able to doit very fast because we have been veryconsistent on creating the datastructures to combine combine the themodels with our data in a good way butthis use case in particular so we'retaking these 50 000 calls translatingthem into text summarizing and gettingthe the reason of the problems and it'sa complete Game Changer because then weunderstand what the customers are reallysaying we don't need to do surveys andget high level data we're really gettingto the actual details on why are theycalling us and then we can intervene onthat and then that data that was aregional reason and then that data hasbecome key to do other things tounderstand behaviors and understandpotential upselling and other areas andthe other important thing on that is weneed to replicate that across all thecountries so replicability and scale isfundamental it's not only doing and whatis a use case is can we do it fast andwith it secure and with it across a wallin a in a way that we can repeat and wewill talk later about vertex Ai anddifferent components on Google haveallow us or is allowing us to usabsolutely it's interesting I think bothwe actually spoke about data and liketaxonomies and data structures so thisgoes into our second question around howdo you actually technically design theseSolutions and Kevin I'll start with youum okay so Donna's team and my team haveworked on a number of different uhbusiness use cases applying to an AI anduh what's interesting is to see a fewtechnical patterns kind of surface up orjust kind of permeates across thedifferent use cases right so the firstone is how do I get data that's outsideof the llm right into my applicationright so that use case is very pertinentto you know customer support right forexample so uh one of the very uh one ofthe very common technical patterns is touseum like a embedding model to processyour unstructured data and then index itwith a vector database you know somatching engine are now called a vectorsearch right yeah is a very popularoption and now we also have lodb with PGVector as well right so there are a lotof options for that yeah and after youindex that then you can very quicklyretrieve your unstructured data imagesand text and so forth the other type ofdata received we're now seeing right isto use a coding model like code togenerate the SQL right to action toaccess your relational database or togenerate Cipher to access neo4j right sothat's that's kind of another kind of upand coming type you know pattern thatwe're seeing and another area that we'reseeing is around application of these uhlanguage or you know these Transformermodels to non-image non-text use casesright so one of the partners that we'reworking with full story we're helpingthem build a sequence model to analyzeand predict user events right andfinally with the Donna mentioned Alphafault right well allothold actually is aTransformer model it's very interestingyes so instead of generating language orimage it generates protein structures sowe took deepminds researchwe broke the inference pipeline which isactually a multi-step pipeline right sowe applied uh different types of computeto the different processes the earlierparts has a lot of data retrieval so weuse high uh IOP CPU nodes for the latercompute stages which is extremelycompute intensive we use Nvidia a100gpus right so that's how we can optimizeright going from research to productionto production we also need to make surethat we're we we have reproducibilityright and experiment tracking and forthat we use vertex metadata right and tokind of stitch it all together we usevertex pipelines to automate the processso adaptation is another veryinteresting area that we're seeing amore customer uh demandsvery good you can also I'll go to youfirst what are those technicalconsiderations that you have to havewhen you're trying to deploy this aroundthe world essentially uh the first thingand again is escape scalability and andreplicability of what we are doingbecause we have to secure the data wehave a lot of local regulations uh aboutgdprs in different countries have theirown flavors and we have to to create orwe have created policies around andmaking sure that there are no bias inthe model oh making sure that we candetect those buyers is very regulatedthe world in Europe probably verydifferent to America but there we wehave to complain with a lot of thingsand you can do these things what takes alot of times and by the time that youdeploy then your data signs are going tokill themselves because they have inspending 99 of their time in activitiesthat are not related to the model soarchitecturally what we have done istake out the problem of data transportso making sure that their data arrivedto the right place is something that wedo and we do in with your andEngineering that we have created for allthe data Logistics that allow us tomonitor to make sure that the data isencrypted the data is anonymized and ifwe change anything on the policies thatapplies for all the the data pipelinesthat we have across so that that hasbeen designed and then we have theprocess inside which is a bigquerystandard and then in the top and here iswhere vertex and and your product isfundamental we we have in a very earlyadopter so vertex AI we createdsomething that we call the AI boosterbased on vertex AI these are ouradaptation but that is where we receivethe models and where we then exchangeand make sure that we can do what youare saying which is running models withyour own data and data that is subsideso architecturally we have dataLogistics we have all the where we havepolicies security encryption andmonitoring all the good stuff then wehave the engine that runs all thequeries which is our real Nerf systemsif you want to call it like this andthen in the top we have created withvertex AI the interface to run all themodels and to co-create what is thatallowing us that now our data scienceare now working on encryption dataengineering uh all the all thebureaucracy and equally we can sharemodels across the market so the dataEngineering in Italy that have createdthis model are now just passing theinformation and the the guys in Germanythat are going to run it I can do it inweeks rather than in months which wasum the previous setup so it's very veryimportant for us to take itand spend that time on making sure thatwe have the foundation right then inparallel we allow a lot ofexperimentation because very importantthat the people can experiment and seethe power in a safe environment wherethey can play and they see and they seethat the model is right but thedeployment is very automatic toautomatized and and it's very securethat's excellent so it's a lot ofengineering behind to to allow us to runproperly Auburn can you double clickinto the technical aspects of yours sureumso the team came up with a reallyingenious uh two-step process so on theone hand we have thousands of productcatalog in our database and then theGoogle product taxonomy has aroundroughly around 5500 classes insubclassesso what what the team did was first useuh gecko to create the embeddings and tosort of reduce and narrow down theoptions and then pass that along tocreate a prompt and pass that throughtext bison to create the final resultsvery cool very cool um okay so this is alittle bit of a self-serving questionbut why did you choose Google cloud andit can't be Donna and Kevin so so that'snot on the table but um for us was aproper processor like five six years agoand we were defining our Cloud strategyfirst and and we did a very sort ofanalysis and the three reasons I wouldsay is your header teaching data so youyou have that the The Innovation androadmap that you were proposing and theapproach and the ways of working and itwas very refreshing to see that it was arelation on co-innovation and trying totackle problems together rather thanthis is a price list and just consumethese products and services and we havedone that and in we have been very goodpartners so far I always always have tomake sure so farum so blue core is natively built on gcpand so the team is very very comfortableusing the tools and technology andGoogle has done a fairly good jobbuilding the Gen AI Technologiesalongside the existing Technologies theother things which you mentioned arounddata governance security are importantto us and a lot of those are also bakedinto the jnai technologyso I think that's the first the secondone is we actually started this projectonGPT 3.5 and we got really good resultsand then we elevated and moved on togpd4 and we got really good results aswell as well and then when Googlereleased Palm 2 we decided to try it outand so far the results have definitelybeen better than what we've seen withopen Eis models absolutely Okay so we'vetalked about use cases we've talkedabout like technical you know Solutionsbut at the end of the day it's all aboutthat business value right like how doyou actually see those business resultsDonna like I want to talk to you aboutthis like start with youhow do we see those business results andcan you give me some examples becausewithout them it's kind of pointlessright like you want to see those resultsso I'm goodyeah um so let me start with Alpha foldum so in the case of alpha folds the thecustomers were able to conductexperiments much faster get much quickerinsights and also minimize the highratio of failures from more traditionalmethods and I mean the impact was reallyincredible to see and it's also one ofthe reasons why I'm in this fieldbecause they were able to accelerate thedrug Discovery process both biotech andpharmaceutical companies alikeum more generally I would say within thegenerative AI space we see customersgetting benefits in terms of employeeproductivity allowing them to focus onmore value-added tasks we see moreintuitive experiences being built withgenerative Ai and also better userexperiences and then also new insightsor new ideas that were impossible beforebut I think arvin's and Ignacio willhave great input here Armin we had twooverarching goals for this specificproject so the first one was obviouslythe accuracy of the data and the resultsand thenthe cost ofbuilding and maintaining this featureand what we've foundwas using llm and gen AI we achievedboth goals so sort of to step back weattempted to solve this problem lastyear using traditional AI techniques andlike I mentioned you know you're talkingof thousands of product catalogs we havearound 5000 Plus classes in the Googletaxonomy and trying to build a modelusing that is extremely difficult andnow to scale that across multipleverticals within the retail space makesit even more challenging so for usit was extremely expensive both from ahuman time perspectivecomputational resources and you know theamount of data we needed to train andbuild those models and a lot of thosewere solved with Jin AI absolutelyall right I think that I will I willtalk about three dimensions of benefitsfirst I will go to the use case and thereason why I'm here which is thatsummarization and the the understandingon on what the customers are calling usand then I will go to the three areaswhere we are working on generative AIbecause that's one use case but really Imean we are going ahead in in many areasand finally from technology point ofview the benefits about velocity andcost of building because that is whatI'm responsible for in order to learnmore on the on the recent side so thethese particular use case which is thesummarization on all the calls and whypeople is calling to our call centers isvery simple we were not able to do itbefore so it's a paradigm change in thepast that was impossible to dosimple as thatum and now we can do it and thatinformation has changed completely ourunderstanding and our relation andproximity with our customers because wewere doing surveys and getting scoresand getting some comments and then itwas a team trying to understand whatdoes that means and then we were crossuh Crossing that data with technicalproblems that we have and then makinginterpretations and you you should seethe debates that we had in our customerboards that we create to try tounderstand and be better and now we havethree really really granular informationthat is precise is what they are sayingit's not what we think that they'resaying so that is a paradigm change Icannot put money on that but we aretrying to reduce 30 percent our leaddetractors and we are in in that trackso he's doing very well then if I go tothe second one which are the differentareas I would say we are working on allthe checkbox and interaction with thecustomers it's early days we see anincredible opportunity in there so wehave checkbox but we have to invest alot of money and time and training thedifferent languages and hence theexplanation about the fact that we weoperate in a multi-language is isexpensive it's not precise theexperience for the customer is notcorrect and our early tests are showingthat this can be again a paradigm changein comparison with what we were doingbefore so one big area by the differentdomains of customers operations all thedifferent call centers that we have isis a chat box the second one is what wecall copilot so it's making sure thatthe people can really do their jobbetter and that imply a lot of areas sowe're talking aboutif you are in my team in the in thetechnical team coding yeah and we seeproductivity that's 10 to one incomparison with no use in it I stillexperimental I'm no I'm not talkingaboutdetails butlegacies so we grow through mergers andAcquisitions so we have a lot oflegacies with documentation that is notexistence and knowledge that isdisappearing of therewe are testing how to get that thosesystem documented and that change againour ability to to run operations in adifferent way or to maintain systemsthat were not possible to maintain so weare experimenting in what we callcopilot and you can add every differentbusiness area and we are doingexperiments on that and then it'sKnowledge Management we're a massivecompany we have a lot of informationmanaging knowledge is is a big problemfor us and doing it well can changecompletely how our customers arereceiving our services and that is acertain area so the the first benefitwas in the in the proper bit the secondis in in these three areas and finallyfrom me something like vertex Ai and allthe engineering is the velocity so thefact that we were able to do in in weeksthe real application that is working andfor taking all the calls in a fullcountry is just because the tools arethere and the cost and the velocity ofthe plane is is helping us to to reallyget the value yeahI really like this framing of again it'sit's what are you what are you changinghow much does it cost how effective isit and then can you measure that rightbecause otherwise it's just a boondoggleyou're spending money and who knowswhat's happening but then you can proveit you can double down on it and buildon top of it absolutely Uh Kevin uh canyou talk a little bit about what youlearned along the way of this magicalgenie Journeyum in short I learned that we have tocontinue learning I mean there's just somuch to learn I mean think about wherewe were six months ago right look atwhere we are today you can imaginewhat's like six months from now right soit's a new normal The New Normal isyou're gonna really have to keep thelearning upum but then the good news isaccessibility right imagine think abouta year ago how could you get your handson to llms right you have to spin upyour own VMS spin up there you know justset it all up and download someframework install it yourself before youcan even prompt it all right and youprobably have to troubleshoot a bunch oflibraries and stuff like that along theway I mean we've gone through that soyeahum today it's available everywhere allthe cloud vendors have it we have coherewe have anthropic it's there's really noexcuse to not have that hands-onexperience right so go for it you knowand there are all these you know if yousign for free and try it out right sodefinitely try it out and we haveFrameworks like Lang chain to help youbuild up these applications as wellright so go Hands-On I think the lastthing also is we used to say read themanual read the manual right I think youknow in this world we may still want towant to start saying read the papersread the papers papers as in researchpapers right so you'll get a lot ofinsight of what's going on right so thisa lot of this started with a Transformerpaper back in 2017. it's still a reallygood paper to read right so there aregood papersum if you don't have time read theabstract all right but I think that'swhere you could really get up to speedon what's coming down the pipe I wouldused to go to the Google AI blog andjust read all the papers they werepublishing because I was like listen ifGoogle's publishing it it's probablystate of the art so yeah that's that'show I used to cheat sheet my way throughyeah exactly the papers or you could runit through an llm to summarize get asummarization right yeahumI think for a subset of problems likethe one that I mentioned I think llmsprovide a phenomenal Foundation becausethere is so much information encoded inthese models because there's craned onso much relevant data it makes the liftfor us a lot easier right like Imentioned we tried this with traditionalAi and it was really not sustainable forus to scale this and what uh gen AI isnow able to provide or the tools for usto be to not only solve but able toscale problems such as the one Imentionedfor me three things one is is reallytransformational everybody can see itdon't try to centralize it in Ito and inany area let the people experiment somake sure that you create a safeenvironment for experimentation and youcan measure that to then decide whereyou're going to invest but let thepeople play because the people need toplay don't don't restrict in the otherhand investing in Foundation because itis the only reason or the only way toget real value is combining the LLmodels with your own data so investingfoundation invests on getting the rightarchitecture because then you can gosuper fast when the experiment showsthat these are use case is worth 2xscale so that that is my my learningthing and sorry one more stick with yourCEO make sure that they they understandthe potential the value and they are noum bombarded by vendors telling themthat is abullet point a silver bullet to resolveevery single problem so invest ineducation in based on bringing the thewhole company and do not stop do notcentralize it because then you kill it II've heard so many customers say theboard of directors the CEO have told mewe need to do this ASAP and so yeah it'sin every single boardroom every singleyou know CEO officeum okay one last question and then we'llopen it up to q a so you know get readythere are mics here in case you want toask questions but last question adviceany other pieces of nuggets of wisdomthat you have for the audience here interms of business use casesum sure yeah so I would say and I thinkwe've all touched on this already but isexperiment and iterate so generative AItruly has the potential to transformeach industry we're living in a veryexciting time but nothing reallysubstitutes hands-on experience right tounderstand what the value isspecifically for your business and alsoto understand the limitations so I wouldlook within an organization andcustomers that we've seen be successfuldo this is really look at who's excitedto Pioneer this which domain experts andwhich machine learning experts get themtogether to identify what does successlook like to work on the use case and wedid this as well so we actually workedwith an SRE team to on the postmortemsearch and summarization use case wherewe worked with experts that reallyhelped Define what success looks like ifour outputs are good we started with avery small set of experts we graduallyexpanded to a trusted tester group westarted with a small data set of 100postmortems we expanded to a thousandpostmortems and now we're rolling thisout more broadly and so um that thatwould be my advice is just get startedumso I I consider uh gen AI or llm asbeing yet another tool in your toolboxright so as you go through buildingfeatures I'm sure you have some successmetrics and if Jin AI is going to helpyou reach those metrics and those goalsthen yes that's the right tool right sothat's the first thing and given as youmentioned Kevin like how rapidly thingsare changing uh pick use cases that hasa tolerance for getting it wrong so forexample pick use cases that are internalfacing or pick use cases that have ahuman in the middle so you can Rectifyif there are issues uh the last one Iwould say isinvest in tooling and technology andplatform what I mean by that is today werun 20 plus models we have customersasking us questions about theperformance the output of the models weuh our teams have to debug fix issues sowe've built a lot of tooling to be ableto observe and scale the systems so Ikeep him for uh reminding my team ifyou're gonna build a ship be preparedfor a shipwreck right so while you'reyes focused on llm engine AI ensure youhave enough tooling and platforms tosupport thatI'm sorry nothing else to add I think isI I already mentioned everybody is ifthat is precisely that I think my pieceof advice is if anyone tells you whatthey know what channel is going to bedoing in five years they're lying to youso you know stay humble stay stayattached to the actual you knowshort-term use cases because it's I'msure it's gonna be crazy in five yearsbut but we're we're to your point we'reall just like wait what did we announceso absolutely all right uh we are out oftime uh love it if you uh you know giveus feedback here and I think we'll bearound if you have any other questionsas well thank you everyoneforeign"
}