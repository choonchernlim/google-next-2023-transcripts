{
    "title": "The future of databases with generative AI",
    "presentation_type": "Breakout",
    "categories": [
        "Database Professionals",
        "DBS301"
    ],
    "video_id": "aU0AJjC50os",
    "time": "Aug 29 02:15 PM - 03:00 PM CDT",
    "transcript": "foreign[Music]the future of databases for generativeAI a topic for the time certainly helloeveryone my name is Shaileshkrishnamurthy I'm VP engineering fordatabases at Google cloud and I couldn'tbe more excited to be with all of youhere again in person at Google nextthank you all for coming we arefortunate to have two amazing industryleaders today to share the stage GilPerez who's the chief Innovation officerof Deutsche Bank and Mohit saxenaco-founder and group CTO of inmobi Gilland Mohit will share their very ownunique perspective on this importanttopicso with the Advent of gen AI we areseeing perhaps what's the biggest andthe fastest reimagination andreinvention of Enterprise apps in recentmemory so the first topic will be aboutthe specific and unique challenges thatthese applications must surmount inorder to be successfulnow the heart of every application isactually an operational database andtransactional database so the secondtopic will be how your oltp databasesare the critical ingredient the secretingredient to success for Enterprise genAI applicationsand we are not just advancing databasesand empowering our customers we're alsoeating our own dog food so we'll getinto how we at Google are leveraging genAI in order to improve all our managedproducts and in particular we're reallylooking to fundamentally simplify datamanagementso let's get started with theseEnterprise dnai challengesnow the last year has been fascinatingwe've all seen a whole bunch of reallyinteresting user experiences with Gen AIyou know we've had text and imagegeneration immersive collaboration we'vehad magical search experiences nowalthough we've experienced all of thisin the consumer space I think what'sinteresting is that Enterprise spaceGenia is poised to fundamentallytransform customer experiences andincrease productivityso what's really fascinating is thatgenei is heralding a new post-trainingera large language models llms aredemocratizing Ai and they are making itfundamentally accessible to applicationdevelopers application developers do notanymore need to learn how to train deeplearning models they don't need tobecome proficient in linear algebrasling matrices around applicationdevelopers are already positioned todrive Innovation today with generativeAIand according to the Bureau of LaborStatistics in the U.S there are over 10times the number of software developersas compared to data scientists that's anorder of magnitude more Innovationpotential that software developers canbring to the table with generative AInow our heroes uh you know applicationdevelopers are looking to use the powerof llms to weave new genii drivenexperiences in their existing and newapplicationsbut that's a challenge LMS by themselvesare not enough that's because EnterpriseGeneral applications need to you knowprovide the most accurate and up-to-dateinformation they need to offer relevantcontext sensitive user experiences andmost of all they need to be easy and apleasure to develop build and operateand you know this is where databasesenter the chat so to speak but memesaside we believe that databases withVector indexing support can bridge thegap between your llms and your geneiapplicationshere's how first databases provide themost accurate the most real time themost current information so your old DPdatabases can be used to retrieveinformation to augment your llm promptsand what that lets you do is ground yourllms for accuracy and relevance so appEnterprise generate applications thatcombine llms with operational databasescan provide the most accurate answersbased on real-time dataseconddatabase is stored in addition tostructured data lots and lots ofunstructured data these could includethings like product descriptions cataloginformation images help desk ticketssupport cases you know chat messagesusage and related content you name itand llms have risen to very powerfulembedding models that can be used toencode the semantic meaning ofunstructured data in Vector in numericVector representation now you can storeand index these vectors right in yourdatabase you can query them withapproximate nearest neighbor predicatesfor semantic search based queries andmost powerful of all you can combineboth regular predicates on structureddata with the semantic search predicateson unstructured data that lets you builda whole new kind of application you canyou can certainly build immersivesemantic search applicationsbut you can also find the most relevantsubset of your information to send yourllms and that lets you really build verymagical history based conversations sothere are a lot of very interestingthings that can be done with Vectorindexing especially when that Vectorindexing is right in your database whenyou don't have to deal with a whole newdata stackand finally you can do all of this withthe data that's right in your databaseyour databases are your most trusteddata store they are you know at theheart of your mission critical line ofbusiness applications they provide foryou Best in Class availabilityreliability scalability safety dataProtection security performance latencyit's what you've come to expect it'swhat you need it's not something you cancompromise with and for your applicationdevelopers databases are at the heart ofa thriving and robust ecosystem you knowyour developers love your visual IDEexperiences you have idiomatic clientLibrary bindings in the languages ofyour choice and and of course you haveorm tools and the list goes on and bestof all your application developers andyour operational Engineers they are allintimately familiar with databasesalready they don't need to try out a newuntested untried stack and figure outhow to populate the data there andhydrate that data you know you don'tneed to figure out another set of slosyou can do it right there in the systemsthat you already know and love and so weare bringing this technology across ourmanaged databases portfolio startingwith alloy DB AI which is an awesomedatabase built for Enterprise gen AIapplications a low ADB AI provides youknow high performance PG VectorcompatibleVector indexing and search which is 10times faster than standard postgresprovides easy to use and highlyefficient embedding generation rightfrom within your database and it workswith the vertex AI ecosystem and themuch wider open source genetic gen AIecosystem so we are extremely excitedabout our idbnow I want to welcome my colleague GillPerez who's the chief Innovation officerof deutschebag Gail and his team havebeen advancing AIML for over three yearsyou're well ahead of the code wellbefore the dnai hype it's a fascinatingstory and you're going to love it thankyouthank you everybody and great to be hereumlet me start off with a quick overviewof our journey which actually started in2020 with a strategic partnership thatif you want to think about it a yearbefore that we went through a strategyof trying to consolidate our view of howdo we go from what we call before aprivate Cloud to the public Cloud so webasically had a whole transformation ofdeciding our path forward the strategythat ended up with with selecting Googleas our provider and signing a 10 and ahalf year partnership with themand in essence that started our Cloudjourney in more Earnest which continuesall the way to today and and willcontinue in the following years butwhile we were doing that the first yearended up being uh 2021 ended up beingthe year what we call Regulatory andcontrol Frameworks as a regulatedindustry we cannot just move things tothe cloudwe have to actually get more than 46Regulators to approve to validate andonly when all of that is ticked andapproved can we start moving any kind ofworkload to the cloud so you can imagineall of the uh back and forth with allthose entities it took us about a yearto get our MVP of that and that'sobviously an evolving element becauseregulations change new requirements comeup and so it's a constant Evolution aswell so thank think of that as a basicfoundations that we need to deal with asa regulated entityand while we were doing all of thatwe have a term called NBT next big thingand while we were doing this Foundationwe said we have to also focus on thenext big thing and in 2021 we decidedthat it's going to be AIML and at thetime we also identified another partnerthat were were extremely delighted tosee them here today on on on stage withThomas but we are identified at the timeNvidia as a key partner and beganworking actually uh quite closely withJensen and with his team on how would Aiand gen AI at the time it wasTransformers spinformers all kinds ofother things that just basic uh no NLPhow did they come into the world offinancial regulated Industriesand we in essence began that in 20212022 was the year that we've actuallyengaged our businessesand went out to all of our business andstarted Gathering use cases I can saythat that year was you know the thereception that we we received was not ohthis is amazing let's change the worldit was lukewarm it was like oh this isgreat this is some kind of cooltechnology nobody really uh reallyunderstood uh the potential that allchanged obviously when chat GPTentered the scene and from basically theend of 2020 uh two we've seen a hugechange in the reaction of the businessand if you think about you know we'rehere in a developer concerts conferencewe're talking about all kinds ofdifferent things but the most importantthing that has happened regenerative AIis really the fact that businesses wantto transform their practices they'rewilling to engage in redefining the waythey do their business which is afundamental difference than trying tosay hey I've got a technology it couldit does things better faster trying toconvince the business and obviously withthat kind of excitement from thebusiness and all the way to the top ofour companyour AI mL of 2023 was launchedumandthis is really a a short overview of thedifferent things that we're doing but ififthere's obviously an ongoing discoverythat we're doing with all of thebusinesses and it's very important toensure that this kind of Discoverybecomes a a standard practice into theorganization because we look atgenerative AI as really in re in theearly phases we're going to learn a lotnew use cases are going to pop up allthe time you really need to get theorganizationand specifically the business engagewith you there's all kinds of othertopics I like to jump really to thebottom there which is from myperspective really important we've alsoengaged onengaging with the with the users on howto useAI in the organization what does it meanresponsible Ai and we we embarked on asummer of AI which was a huge effortthroughout all of DB ended up with a24-hour hackathon with 1700 teams sorry1700 participants about 210 teams whichwe got a huge amount of of Engagementand lots of ideas and and really all ofthat together is is nurturing our ourcollaboration with the business but moreimportant we also while we did all thatwe also went top downand the top down view was looking at theskill sets that from each one of the usecases that we have so let let me takeand you'll probably go and and see ourshowcase on on the show floorum code generation uh code writing duetAI we've actually looked at each one ofour use cases and broke it down toskills we then map those skills to ourHR taxonomy to the job descriptions andin essence created a heat map of wheredo we see the most the groups that wouldbe impacted the most by these kind ofchanges so in essence we went andcreated a top view of the organizationand we have a very clear understandingof the areas one of them is obviouslythe code generation where we have 8 000people 8 000 developers that are rightnow working day in and day out and weobviously believe that uh that use casewill be fundamentally changed usmoreover if it does continue forward weobviously believe that it will have aprofound impact onthe business developers because we dosee the the natural progression of thedevelopment tools and making them andthe citizen we call them the citizen genAI developer will become a part of thefabric of our organization last but notleast I wanted to put this uh and toshare this with youum this is at a high level R kind ofview or stack of generative Ai and Iwanted to focus on the orchestrationlayer because that is the layer thatwe're spending a whole lot of time onthat is where the Lang chain uh comes inthat's where we we get the prompt or thequery from the end user break it up tosometimes going to a database sometimesgoing to a search obviously going to anllm creating the prompt that goes downto theum to the llm coming back reconstructingtheum the result and then serving it up itback so that entire orchestration layeris extremely uh powerful and we'respending a lot of our time on itobviously there's different layers tothe bottom uh including the the largelanguage models and the data but we'reright now starting first of all to tryto optimize that level withouttrying to do the training we're gettingto the limitations but with every newlarge language model that we're tryingwe're seeing new capabilities obviouslywe were mentioned today over a hundredlarge language models are now availableI think we're going to have a veryinterestingnext year or so two years of figuringout what is the optimal size of largelanguage models do you go with anall-purpose one do you go with smallerones how do you construct them do you gowhen and in the orchestration layerFederate to a distributed a largelanguage query to multiple largelanguage models bring them up backtogether go back again there's all kindsof techniques that are are evolving andI think that it's going to be a veryinteresting area I think that thatorchestration layer is going to be a lotof ipn let's not forget thatorchestration layer is also verydependent on your data and the structuresolast but not least I I want to end upwith with one commentum and that's another uh Insight that wehave that we view prompting as IPintellectual propertyand so I think thatum just doing a mindset for theorganization that everything that goesinto the uh to this kind of a stack andcomes out you should think about it asyour own IP is is uh the right thing todo because that really captures a lot ofthe the knowledge and the capabilitiesthat you have you could use all of thatdata later on to making recommendationsof promptsum you can figure out which prompts areare applicable for certain people youcan also use it with lifecyclemanagement of of uh machine of largelanguage models so there's a whole lotof things that could be derived fromthat but againthe entire prompting as an IP andcapturing it is super important and withthat uh back to you[Applause]peace I think our friends in SandhillRoad are already writing checks it's astartup idea right there uh but butthank you Gail I think one of the mostimportant things as engineering leadersis balancing Innovation for the futureand paying our bills so it's reallygreat to see see how Tasha bank has donethatum I I want to move to the next sectionof the top and talk about how databasesare uh you know critical part ofbuilding these applications and Gil justmentioned orchestration and I thinkthat's where I'm going to focus now soin in this new world of gen AIapplications uh you have to orchestratebetween many different things you haveyour embedding models that providenumeric Vector representations of uhyour unstructured data you have theseembedding models are much more efficientthan large language models which areactually trained on large internetcorpora and you know they can predictfuture words based on on a prompt and ofcourse our very own Superstars rightoperational databases real-timeoperational databases relational andnon-relational databasesso I'm going to talk about three kindsof orchestration scenarios one where youonly have embedding models you don'teven have llaps we think these arereally valid gen AI applicationsorchestration scenarios where you onlyhave llms and one and finally when youhave both embedding models and llms sothe context for uh what I'm what we'regoing to walk through is uh simple gamesa hypothetical uh online B2B SAS gamingplatform for whose customers are variousindie game studios uh they they host uhconsumer games on this platform for uhyou know people on on the web and on themobile ecosystemsso let's start with the first scenarioso in this case we are trying to help asupport engineer triage a support caseand identified duplicates so you knowlet's take you know a support case comesin someone is complaining that a givengame is is really you know slow onStartup and what what we're what theengineers trying to do is figure outquickly is this a known issue or is thisa new issue and you really need toleverage the current state of the systemso the first step is you call anembedding model and you generate avector representation of uh you know ofof the issue then you go probe that yourdatabase and you probe it with a simplestraightforward SQL query where you'reComputing this approximate nearestneighbor you're trying to find the mostsimilar uh bugs that exist in the systembut note the the predicate that's inblue b dot status equals open you'retrying to limit the search to the actualopen bugs so this gets the power ofgoing against the real-time system youhave your operational system you havethe current state of your system youknow what your current bugs are and youare now trying to find which are themost relevant Buffs and you get that setof results you know from the system andnow uh the support engineer can eyeballthat list and try to figure out if thisis a known bug maybe they add anannotation in that and otherwise theycreate a new bugso let's recap what did we see in thisscenario we saw the use of similaritysearch in an integrated fashion alongwith in many ways it's similar to fulltext search which databases have had butthe real Power is coming because you'reintegrating the information in yourstructured data you're looking at thelatest and greatest data you're lookingat the current state of the system it'svery hard to to have this kind of userexperience if you are a vector indexingis happening somewhere else so theintegration is is one big part thesecond big part is the power ofembeddings because of llms embeddingshave become this extremely powerful toolI think this is going to be transmittedfor the database industry it's going togo beyond unstructured data in thefuture I predict we'll be talking aboutembeddings for structured data I thinkwhen you think about entity relationshipmodeling you'll start to think aboutembeddings as almost the Primitive forevery entity I think it's really goingto change our world so we should keepour eye on itnow let's move to the next scenariowhere we're only going to use largelanguage models so in this case thescenario is to help a support engineergenerate an email to a customer byleveraging what we know about incidentreports so we start with an instructionabout writing an email and all we haveis a given incident ID now in order toactually write that email you need toget more information so the first stepis you programmatically build a promptand the prompt includes you know theinstruction to the llm so note that thisprompt is not generated by a user it'sactually a programmer an engineer anapplication developer who has writtenthis up front but this prompt has abunch of parameters that's why it's atemplate and it needs to know the youknow incident description when itstarted when it ended the impactedresources and how we do how do we getthat by running a query on ourSuperstars the operational database soyou run a standard SQL query you fetchall of the information you need and youaugment The Prompt template and now youare having the recipe for the llm youtell the llm generator user facingimpact statement omit internal technicaldetails provide all of the additionaldetails and just like magic the llmgenerates the email right it sayssomething like your game ABC thatinvolves this set of resources was downfrom 6 AM to 8 AM because of a networkconnectivity issue nowlet's face it this is not an RCA this isjust uh you know just an email and maybethat's a good thing right we don't wantthe AI to take all our jobs we have somejob security right writing a good RCA sobut it's a stack this is where you knowthe the AI helps us and of course wemight want to save all of thiscommunication history in a databasepresumably we'll create a vector indexuh on the message and we'll talk aboutthat in the in the final use case sowhat did we do here uh we had thesethree steps we had retrieval where youfetch data from the databaseaugmentation where you augmented ThePrompt and finally generation where thellm you know generated text rag the rackpattern it's a new hotness the way thisindustry is going we'll probably have 10more new patterns in the next two monthsbut for now rag is it but I want to talkabout something else hereum you know I know I'm dating myself butwhat this what I'm reflecting when Ilook at this pattern is I go back intime a quarter Century back uh you knowmany of us in the room we're buildingdatabase backed web applications youknow uh can anyone say Java server Pagesactive server pages so what what were wedoing then we built programmatically webuilt HTML templates we query thedatabase we stack those values in thoseHTML templates and we returned HTML tothe clients what we are doing is notthat different we're building prompttemplates programmatically uh you knowaugmenting them with data retrieved fromthe database and we are sending them totheir lab yes we are doing something newbut we're also doing something that usthis community that builds you knowdatabase backed applications we know howto do this llms are not some crazy ideanow we've got this we know how to buildthese applications so you know we shouldlook forward to embracing llms indatabase backed applicationsso the final scenario I'm going to talkabout where you combine both embeddingmodels and lnms in this scenario we areyou know saying we want to support helpsupport Engineers respond to chatmessages in real time and we want toleverage the past history so you get achat message customers complaining heythis game is slow is it the same as thenetworking issue from the past now whatwe want to do is again as before buildthat prompt template programmaticallybut what you want to do is get the priorcontext and this is where the accuracythe relevance comes in if I just includeall the chat messages from the past forthat particular customer it may be toomuch we will overwhelm the llm in anavalanche of data so what we want to dois find the most relevant chat messagesfrom the past history and we do thatwith a vector query you have a query thesame idea you take you map that the theuser information into Vectorrepresentation using an embedding modelwe probe the database and you find youknow the set of similar queries and inthis case you add an extra predicate andlimited to the last month but you couldmaybe look at the last year or the lastweek as you choose and then you haveanother query an independent query whereyou find this current set of openincidents you take all of that youpackage that into the prompt templateand you send it to the llm right and nowthe llm actually responds like magic andit actually says something like we arecurrently dealing with two openincidents a capacity stock issue and atail latency spike in in storage butnone of these issues seem relevant to toyour networking issue that youexperienced you experience in August28th so this is personalized you havegrounded it and you also given the llmrelevanceso let's recap again what we are seeinghere is a pattern which we calllong-term memory for large languagemodelsand you know there's always thestraight-off you can you know tune thellms you can train them but you need toget the most relevant information andyou want to get that private informationfrom your database and you know one ofthe the challenges when you deal withllms is that they have prompt limits youcan't send uh you know problems whichare of unlimited length and the secondissue especially there's some veryrecent research is llms tend to look atthe early part of the prompt more so thesmaller the prompt the better you shouldavoid sending too much information andso that's why the vector indexing isreally key and that's what people meanwhen they talk about long-term memoryso finally thus far I gave a verydatabase-centric view of orchestrationbut that's another view right there's aview not that you're coming in from adatabase back tab there's a view whereI'm actually coming into the llm firstand so then the question is how is thatllm going to ground itself uh and youknow we are announcing uh vertex AI isannouncing an extensions modelextensions really are a standard way foran llm to create queries for an externalAPI databases just another external APIand what we are announcing is a databasespecific retrieval plugin retrievalextension for Alloy DB and what thiswill let you do is in this world the llmwill be prompted with the description ofthe API it generates query parameterssends it to the query service which runsa query sends the results back for thenext step in your chain uh the nicething in all of this is the frameworkwill support built-in robust identityand authentication to enable secureaccess to private data and with thatit's my distinct pleasure and honor toinvite my friend Mohit Mohit saxena asthe co-founder and group CTO of in Mobibut today he's going to talk aboutglance which is a startup that's takenin the world by storm I guess you're nota startup anymore right yeah all rightthanksthank you guysum I think it's a privilege to be hererepresenting uh in Moby group and glanceand in fact I have my co-founder andteam member here also who have their ownsubsequent session uh so before I beginlet me introduce you to uh in Bobbygroup and uhwe arefounded in 2000through our various product our reach isaround 2.4 billion smartphone uh somenumber as you can see we are globallyvery dispersed from Europe us and NorthAmerica and uh even in Asiawe are backed by some of the Marqueecustomer and Google is one of themSoftBank shall follow and some of thegnomes names that are very familiar toyou guys but for this session I'll Focusmy conversation around glance which isour b2c offering uh and glances arebasically uh in the business ofRevolution revolutionizing uh smartsurfaces as we know it todayso grants has also making some biginroad in2022 we have made big uh you know growthin Asia and in 2023 we are making a roadtowards the westward from Europe and inNorth America uh we have roughly 450million devices uh on this product uhdaily active user is somewhere around200 million users enormous 20 plusminute engagement time from user androughly 60 percent of the user uh arewith us with the NIT time Horizon whichis a significant number if you know theb2c context here uh so what the way weuse a Smart surface today only as aconduit to accessing some app you knowmost of the things are restrictedanything you want to do utility and allyou just click and you go over therewhat we are trying to Envision in glassis can this surface be used to basicallyhave completely different line andanticipatory Discovery a totalSerendipity that you know which is builtaround you and that is what reallytrying to do so the three main surfacesthat we are talking about is obviouslylock screen home screen which is thescreen that you go in after unlockingyour phone and the last one is fodawhere your information is organized incertain categories you know like Financeshopping Etcin glass what we are trying to do is asnackable glanceable information thatthat that is Meaningful to you you knowwhat is happening when is rain going tohappen you know when the rain is goingto stop and you know something youfollow San Francisco uh Niners and youknow what is happening on their score isthere a touchdown there is somethinglive event happening you know maybe EdSheeran is in the town and he's doingsomething so all the information thatyou know that you care about andsomething that is you know has asignificant value just in time uh youknow you can actually use this surfaceuh to uh pop that out and interact withthat so that is really what glass istrying to do bringing live internet uhto you on the three surfaces that I wastalking aboutand we are not stopping a removalbecause you know the surface is aSurface even glass even TV is like alarge smartphone so why can't you knowthat dull wallpaper can bring to youknow we can why can't we bring thatwallpaper into life and it gives youimportant information that you careabout same thing in all utility gamesyou snippet that basically you know youreally care about so that's the visionuh and for engineers in this room thisis how the stat looks like you know youknow there is an odm there is a OS thereis a chipset and then so far you knowthe ecosystem on top of it which isvarious app possibly you will be usingin your life as well and we see it rightin between them as a link where we uhintegrate between the app and the thingsthat are happening at a lowerprogramming level so it's a really youknow a bridge that is bringing all thenative utilities and Native features toyou in form of uh you know theseapplications without downloading thoseapplication on your three smart surfacesso what is glass and what is glassdatabase you know if you are in thebusiness of delivering happiness to Userit's it's not easy job it's really hardyou know making user happy is is ittakes a lot of work and if you thinkabout it we have been using databases tobasically deliver that value andhappiness out there but database have along Evolution cycle you know it startedwith rdbms storing transaction and thenwe got into media we got into other kindof documents and this has become veryfragmented you know for every kind ofasset you have a different databasewhere you store all those kind of thingsso the bigger challenges in Mobile whereeverything has to be time-bound andeverything has to be you know at a veryhigh throughput lot of computationhappen at the runtime where you have topull multiple assets and figure out whatis the most important and relevant thingfor for us and that is lot ofcomputation and that is really you knowuh what the what the challenge glancefaces on day-to-day basis because yourhappiness or your relevant content couldbe an Edgeit could be a gaming it could be a liveit could be shoppingit could be live content it could beshort videos it could be news it couldbe anythingand we have to figure out what are thosethree four five ten things that that aremost relevant around you so what we aredoing is basically running multiplemodels browsing through all these assetsand then doing Federated ranking on topof that so that you can we can deliverto you what makes uh most meaning uh umwhich is most meaningful to you so thatis really the challenge that we arefacing at the glanceandwe moved all some of our Legacy systeminto spanner most recently and and ourrequirement always is availabilityscalability and consistency and you youcan see some of the throughput that wedeal with is roughly 3000 requests persecond and this migration was soastounding in terms of saving andperformance that my colleague ispresenting a session on the migrationitself I think Google next uh but afterthat our North Star is basically weshouldn't be doing so much computationon top of it if my database canunderstand the semantics and it can itcan put that semantic context along withthe asset then a huge step is going togo out from our life and we can justfocus on what we do best deliveringhappiness to our user you know what isit could be three images two shortvideos five news article whatever it isyou know the context should beunderstood by the system and everythingthe information is Right stored in thereso that is really what we are trying togo after this is a pretty interestingimage and there is a story to it I thinkyou have seen in the image that Shaileshwas showing and when I was talking tohim about the session I didn't see hisimage and and my Engineers came up withthis image and basically two things gotvery clear to me number one great mindthinks alike so we were building asimilar image what he was thinking andthe second thing is this is this was soreal to the problem that we weregrappling you know this is really whatour design is we have operational databasis on one side and we were trying tofigure out the semantic and contextualrelevancy around it and then llm runningon top of it so imagine basically if thevector emerging Vector databases uh andin assets and core information is storedtogether a huge step from our life willgo away immediately and we can startfocusing focusing on what we do bestwhich is making our user Happy by havingthis discovery and and showing them theinformation that matter to them intimely mannerwith that I think shalish I will handyou over that[Applause]thank you so much Mohit that was uh thatwas that was really fascinating uh youknow what a ride I think it's it's we'veenjoyed working together I think we'vebrought a massive production system uhyou you know that migration story isreally awesome totally encourage you alluh to go attend it and and I think weare also learning so much from yourexperiences so thank you for thepartnershipuh I I want to now uh spend the rest ofthe time talking about how we at GoogleCloud are also eating our own dog fooduh we are an application toostar uh services and you know ourmanaged uh Cloud databases we have acontrol plane we have a data plane wefor offer apis and so we can alsoleverage jnai in our own applicationsand uh dramatically simplify datamanagementand we're doing that using duet AI uh inGoogle Cloud it's the AI powered alwayson collaborator uh and in Duet Ai anddatabases in particular has you knowthree big things the first is a chatinterface a natural language chatinterface let's write in the consolethat's providing the information youneed in the context that you needed youcan ask specific questions based onwhere you are the second is an assistiveprogramming interface right in the cloudconsole that is going to you knowprovide a SQL based code generation andcode completion we'll have we'll extendit to other models uh you know it's it'sgoing to be an experience which is whichis going to be delightful and and helphelp programmers and help developers andthe third is really help for automateddatabase migration uh you know the inparticular it's going to focus on thelast mile assistance to help you allmigrate from Legacy commercial databasesso let's talk about a couple of thesethings uh first duet Ai and Cloudspanner we'll also be following so thisI think we're going to be brandedSpanish Studio it's in preview we'll befollowing this in Cloud SQL and in inother systems uh but the basic userexperience is right in your console in acomment you can start having uh you knownatural language description it's goingto give you uh Auto generation Autocompletion fix it and a lot of coolthings I think this particular exampleon screen uh you're trying to ask aboutuh some churn analysis or something likethat and you know you put in the commentit you know provides the text it'sreally cool I mean you know you're goingto love it I was playing with it theother day you know I put in you knowjust for fun comment that said you knowcreate a table uh to model restaurantsyou know it came up with a bunch ofinteresting things Cuisine and otherthings then I said you know populatethis table with a bunch of with 10 dummyrows and it you know does a whole bunchof interesting things it only pickedfast food chains but then to be fair Ididn't ask her to pick Commission StarRestaurant so you know it actually worksreally well it's really fun uh you knowto see to see that actually in practiceuh and and the interesting thing againis it didn't take a lot of work for usto build this this is where it is againwhat I'm trying to say we didn't have todo training we have past training we'rejust able to Leverage The llms anddeliver you know that value right thereso super exciting uh and and then thedatabase migration service so DMS isthis amazing service that we are usinguh our customers are telling us how theyhate uh operating in the Legacycommercial databases were it's painfulthey want to come to you know the highperformance High scale vibrant uhpostgres ecosystem and so we are helpingthem on that Journey database migrationservice you know already takes care ofmany of the very hard things you have todo schema conversion you have to movethe data to replicate the data but youknow one real bug bear is storedprocedures any of you who are in Legacyshops will see you know you know tens ofthousands of lines hundreds of thousandsof lines we have customers who have fouror five million lines of code in storeprocedures you need to move all of thatand so we are providing you know thisthese built-in tools to move them wellone of the big challenges is this lastmile problem uh you know as best as thetools are they don't solve all theproblems that's where a human beingenters the loop and what is really cooland how we've used duet AI here is asyou're going and fixing these problemsthe llm like magic will come and say heyI see you made this change there's 200other changes that are very similarshall we make them for you boom you'rein business right so I'm incrediblyexcited about database migration serviceand in fact about all of our duet AI weare just getting started there's youknow a whole host of interestingInnovation we're going to keepdelivering it and you know we it's it ithelps us learn the patterns how we'redoing it I think will also help you alluh you know not just make benefit fromhow we are simplifying data managementbut we are excited at sharing thesepatterns so that you can all use them inbuilding your own you know your ownapplicationsso uh where do we go from here firstagain I want to reiterate the immensepotential in generative AI I know we'veall looked at the chat Bots and otherexperiences but I think you know for usuh as Engineers I think the big value isto Leverage The real-time data that's inyour operational database to put it alltogether with Google's history andInnovation AI we have an amazingFoundation I like to paraphrase Newtonif we can see farther it's because westand on the shoulder of Giants and andthat's that's what Google'sinfrastructure give for gives for us wehave you know the world's bestoperational database the best analyticssystems and really amazing and vibrantuh AI ecosystem all of that can be puttogether to really build a unified dataand AI platform for the next generationof applicationsyou know I encourage you all to getstarted uh you know we have a lot ofresources in how you can learn andworkshops that you can use uh if youhave interesting ideas I think everytime I speak with a new customer in thisworld we're getting 10 new ideasum you know everything that I said in myscenarios they all came from customersreal customers whom I talk to right Imean I kind of paraphrase this into oursimple games example but it really camewith engagement so I value theengagement it's a gift for us uh and youknow if you know if you have ideasplease come and find me I'd love to chatuh and of course you know also with ouraccount teams uh you know please youknow reach out to our ProfessionalServices Partners you can start buildingum and you know first again thank youall to my co-presenters first you knowyou know amazing job thank you so muchand thank you all you've been an amazingand wonderful audience I'm glad we'reall back in person uh please uh send usyour feedbackthank you"
}