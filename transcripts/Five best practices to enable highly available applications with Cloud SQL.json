{
    "title": "Five best practices to enable highly available applications with Cloud SQL",
    "presentation_type": "Breakout",
    "categories": [
        "Database Professionals",
        "DBS303"
    ],
    "video_id": "LvOEQVIfbns",
    "time": "Aug 31 01:30 PM - 02:15 PM CDT",
    "transcript": "foreign[Music]good morning welcome everyone to thesession on cloud SQL best practicesfor availabilityum I hope all of you had a productiveand fun conference and you have had afew takeaways that you can take backhome and to your work and business wehave an exciting session for you and weare hoping that by the end of thesession you will have a few moretakeaways that will allow you to runyour Cloud SQL instances with maximumavailability and if you're new to CloudSQL I'm hoping that this will get youexcited to use cloud SQLmy name is gopal Ashok I'm a groupproduct manager for cloud SQL I'm joinedby a few folks uh Rahul Deshmukh who isa cloud SQL PM for availability and weare super excited to have two of ourvalued customersum everflow and Cape analytics and Ijust wanted to thank Jonathan blay anduh Jason Erickson who will be joining uson stage and you'll be hearing from themin just a little bitall right let's um get started so todayI'm gonna basically kick off the sessionwith an overview of cloud SQL and talkabout some of the exciting things thatwe shipped over you know in the pastmonth or so and then Rahul will come upand talk about uh the available the bestpractices he'll talk about thecapabilities and you know the thingsthat you should really care about to runyour Cloud SQL instances with maximumavailability uh Jonathan will followthat talk about everflow's architectureand the best practices that they've beenusing and then we'll wrap it uh up withuh Json and keypad analytics and Q aso before I get startedum just a quick pull how many of you arecurrently using Cloud SQL in any formohand how many of you are using Cloud SQLto run your mission criticalapplicationsall rightso that's quite a few folks here sohopefully you will find the sessionsuper usefulum by the end of it so let me justquickly start with a quick overview ofwhat cloud SQL is looks like most of youare using it you know and if you haveattended the postgres or MySQL sessionyou're probably seeing the pitch but Ijust wanted to emphasize a few thingsum so when you look at Cloud SQL it's afully managed relational databaseservice for postgres MySQL and SQLserver and the the beauty of cloud SQLis that it is fully compatible withmySQL and postgres and what that meansfor you which you probably already knowis that if you're migrating yourapplications from self-managed MySQL orpostgres and you want to get thebenefits of a fully managed service youcan very easily do that with Cloud SQLbecause we are fully compatible and whenwe talk about fully managed what we'retalking about is giving you somethingthat you know is easy to deploy easy tomanage and easy to uh operate and one ofthe things that we try to do and to makelife easier for you running Enterpriseapplications is to automate a lot ofthings and make it easy to do thingslike higher availability for exampleand the other key thing I'm sure all ofyou care about quite a bit is tobasically run your application in a verysecure environment so from as a managedservice Cloud SQL provides a lot ofbuilt-in capabilities securitycapabilities compliance capabilitiesthat gives you the Peace of Mind interms of you know managing yourenvironmentand lastly we make it very developerfriendly and what that means is that weprovide a developer orapplication-centric observabilitycapabilities using things like queryinside systems inside Etc we providesupport for terraform and we also have avery rich API that we provide whichallows you from a developer perspectiveto manage Cloud SQL as infrastructure ascode integrate with your CI CD pipelinesEtcso what does this all mean what thismeans is that cloud SQL is extremelypopular service so more than 95 percentof our top 100 customers actually usecloud SQLbutwhat we are seeing is that customers aredemanding more and rightfully so andwhat are customers asking for what theywant to do essentially is and most andmost likely you're also looking for thesame things is that you want to run moreand more critical applications on cloudSQL so what does that mean you wantbetter performance you want betteravailability and you want better dataprotectionand we've been listening to that and I'msuper excited and you've probably seenthis in other sessions but I just wantto re-emphasize uh we have launchedCloud SQL Enterprise Plus Edition andthere are two Dimensions that we arereally differentiating cloud SQLEnterprise Plus Edition compared to whatwe have today which is the EnterpriseEdition and that is performance andbusiness continuity and quickly on theperformance side uh with Cloud SQLEnterprise Plus Edition you can have 3xmore performance compared to what youhave today you get better compute andmemory ratios for example we support 183memory ratio compared to one is a 6.5 inEnterprise Edition and lastly we providea lot of software and Hardwareoptimizations that allows us to dealwith the kind of performance that youneed and on the business continuity sidewhich is what Raul is going to reallydeep dive into just a quick a couple ofquick call outs with Enterprise PlusEdition you get four lines ofavailability compared to three and ahalf lines of SLA on Enterprise Editionuh we are really worked hard to reduceplan down time and Rahul will be youknow diving deep into that and lastly onthe data protection side we support uhmore than up to 35 days of bitrretention so overall if you haven'tlooked at Enterprise Plus Edition pleasetake a look at it it might suit some ofyour applications with all theInnovations and capabilities that we aredelivering thereso with that I am going to hand it overto Rahul who's going to Deep dive intothe available deepest practicesit's the year 2023 uh we have comepretty far from the days of squirrelschewing through the cables in a DataCenter and just taking it downhowever availability is still a verycritical aspect of a business our usersare you know are spreading around theglobe demanding 24x7 availability infact availability is such a key topicthat even though it's standing betweenyou a nice lunch and a flight back homeso many of you decided to show up forthis session so thank youso today what we are going to do is talkabout how you can leverage the existingCloud SQL features and functionalitiesto maximize the availability that youcan get for your most criticalapplications let's Dive Inso how do you actually get maximumavailability you do it by minimizing thedowntimeand you can think about downtime in insort of two different groups there isthe plan downtime and the unplanneddowntime within the plan downtime youcan think about the plan maintenance orthe plant activities which are necessaryto actually keep your service safesecure and improve its performance andreliabilityand then you have the otherconfiguration changes which you as auser perform to make sure that yourdatabase instance actually fits thechanging needs of your applicationthen on the unplanned downtime side whatyou have is essentially a different kindof failures and how you recover fromthose the failures could be scope 2within a Zone across multiple zones orwithin a region or it could be somethingthat is created because of a a humanerrorso let's dive into how you can sort ofoptimize this downtime by looking at theplan downtime first and then moving onto the unplanned downtimetaking a step back Cloud SQL performsmaintenance on your instances typicallyonce every three months the maintenancecomprises of updates to your databaseengine updates to the underlyingoperating system and then other servicechanges or service updates which giveyou our newer featuresour goal is to minimize this downtimethat's why we pack it up and do it onceevery quarterso we'll we'll talk more about Cloudsql's industry leading maintenancecapabilities and how you can sort ofLeverage thoseare maintenance experience isessentially Guided by three differentprinciples the first is flexibilityflexibility is essentially giving youthe surface area that you can tweak toget to make sure that the maintenanceessentially happens at a time that ismost convenient for your applicationthe second one is control which isessentially you saying that while theegg while the automatic maintenanceexperience is great and it works formost of my fleet for some of myapplications I actually need even morecontroland then you have the uptime whichessentially focuses on just reducing themaintenance downtime as much as possibleso starting with flexibility Cloud SQLmaintenance is fully flexible it givesyou so many different controls for youto decide exactly when and how you wantthe maintenance to happen let's gothrough some of those optionsso the first is the maintenance windowthis is an option where you get tospecify the day of the week and the hourof the day so that when Cloud SQLessentially starts the quarterlymaintenance rollout it performs themaintenance on your instance when itreaches that particular week it performsit on that day and hour of your choicethis is something that you can update aswell and Cloud SQL essentially honorsthe the changesthe second option is actually quiteinteresting and I don't think a lot ofcustomers actually understand the thevalue of this this is called the orderof update you can set this value toearlier or later now let's say that youhave some Dev test instances what youwould do is sit there order of update tobe earlier and for your productioninstances you would set the value tolater what that does is thatboth the the instance with the value setto earlier gets patched a week beforethe one for which the value is set tolater so what you can do is using thesevalues you can essentially accept themaintenance on your Dev test instancesfirst certified with your applicationmake sure that it worksand then a week later you can accept iton your production instances and you canthereby significantly reduce any riskthat you know uh the the new maintenanceversion May pose to your specificapplicationobviously if you are going to getmaintenance on your instance you wouldwant to know about it so you can sign upfor maintenance notification and youtypically receive the notificationeither seven days in advance if it isset to earlier or 14 days in advance ifthe order of update is set to laternow if you have set a maintenance windowand when Cloud SQL is ready to performthat maintenance you will see that thereis a maintenance update that's going tohappen and what you can do is eitheraccept it immediately if that's moreconvenient or you can let it happen atthe time it's going to happen based onyour maintenance window or you canactually defer the maintenance becauseyou may want to take some more timecertifying the the maintenance updatewith your lower environment or you mayhave other long running jobs runningthat you don't want to disrupt by takingmaintenance in that way Cloud SQL givesyou ability to actually defer thismaintenance by up to 28 days and withthis additional maintenance notificationyou can essentially stretch this to fiveto six weeks of duration to to make surethat you are receiving the maintenanceon your production instance exactly whenyou want itnow all this is great but let's say thatyou're uh an online retailer and you'rerunning into October and you have BlackFriday Cyber Monday and and the holidaysort of uh shopping season upon you andwhat the business is telling you is thatfor the next couple of months we aregoing to be in a code freeze and thatalso means that your Cloud SQL instancesshould not be maintainednow in this case the 20-day differencewould not help so what doesCloud SQL gives you the ability tospecify a deny maintenance period up to1 to 90 days so once you specify thisdeny maintenance period Cloud SQLessentially says that we will notperform any maintenance on your instanceuntil this deny period is overas I said Cloud SQL maintenance isextremely flexible and we have been hardat work improving this flexibility evenfurther let's take a quick look at someof the new features that we havelaunched in the in the recent ones thefirst one as I already mentioned is thatthe maintenance referral is now up to 28days which used to be earlier seven daysthe second one is that replicas are nowpatched within the primary's maintenancewindow what this means is for yourproduction instance if you have someread replicasall you need to do is remember to setthe maintenance window for your primaryinstance and when the maintenance windowcomes your replicas get patched first ingroups to ensure that you always have atleast two thirds of your read capacityonline and ready to serve the workloadsand once all the replicas are patchedthen we go and Patch your primaryinstance so all of this is happeningwithin that 60 Minute maintenance windowand you don't have to worry aboutthinking about setting maintenancewindows for your read replicasthe third option is default maintenanceWindows now it is very much possiblethat you do not want to actually gothrough all this hassle for your lowerenvironments or for or in some caseswhat may also happen is that you mayhave a production instance and you mayhave just forgotten to set themaintenance window on that instanceto be safe and secure by default we havelaunched default maintenance Windowswhere what we do is if your instancedoes not have a maintenance window thatyou have specified the only patch itduring off P cars so that's typically 10pm to 6 AM during Monday to Friday andand all weekend which typically workswell for most of the businessesso this is how we come to our first bestpractice of five which is you shouldconsider setting up a maintenance windowwith the relative order of update foryour production Cloud SQL instancesall right so we talked about flexibilitylet's talk about controlso let's consider a scenario you work ina regulated industry where your Chief'sinformation security officer tells youthat you need to accept the and applyany recent security fixes to yourinstance within 30 days of the releaselet's take another scenario you actuallyare running a critical application wherethe uptime is so important to thebusiness that even taking fourmaintenance events in a year is not goodenough and the business would like toactually reduce that that frequencyfurther downon let's take a third example where youwould not want to actually wait for thetoday morning maintenance window toaccept the maintenance on your primaryand all your replicas you may want toget the replica maintenance out of theway first and then just let the primarymaintenance happen at that off becausefor all of these scenarios the answerthat we have is self-service maintenancecell service maintenance is somethingwhere we essentially create newmaintenance versions every 30 to 60 daysand we release their information insomething we call the maintenance changelock which is publicly available so youcan go to the maintenance stage log youcan see which specific security fixes wehave deployed as part of thatmaintenance version and if those arerelevant to you you can actually just goand applyclicking on view updates and justapplying the update immediatelythis is also helpful in fullycontrolling your maintenance experienceby saying that I want to perform cellservice maintenance on my replicas firstthen I will go do it on my primaryinstancein fact for customers who are looking toyou know have the maximum availabilityand reduce the maintenancemaintenance occurrence as much aspossible what they do is they basicallychange the deny maintenance period sothey take a 90-day deny maintenance andthey just sort of take another one afterthat another one after that and thenwithin those periods they actually goand use self-service maintenance to takethis maintenance update themselves at atime of their choosingthere are a couple of caveats to keep inmind with self-service maintenance thatI'll call out quickly first one is thatas soon as we release a new cell servicemaintenance version we make all theolder ones uh obsoleteso if you are actually trying to applycell service maintenance on your primaryand replicas you want to do it in a waythat they're all passed to the samemaintenance version around the same timethe other thing to keep in mind is thatwhile you can change your denymaintenance period at the end of the dayyou should always consider being safeand taking a maintenance on yourinstances to make sure that they'regetting the security patches that theyneedso this is our second best practicewhich is to use cell service maintenanceif the default maintenance controls thatyou get with Cloud SQL are not enoughfor some of your instancesmoving on so the we talked aboutflexibility and control now we come uponuptimegreat that cloud SQL provides you all ofthese options to perform maintenance youcan take it on a weekend you can sort ofdefer it you can deny it you can do allof that but it's still a downtime it'sstill A disruption what if there was away to actually reduce the downtime somuch that at one point the maintenanceevent itself essentially becomesuneventful unremarkable and just simplyboringso that's exactly what we are trying todo here by reducing the maintenancedowntime significantly and we have donethat with Cloud SQL Enterprise Pluswhere the maintenance downtime is nowless than 10 secondsnow just to set some contextfor cloud SQL Enterprise Edition wealready offer a pretty low planmaintenance downtime of less than 30seconds for postgresless than 60 seconds for MySQL and lessthan 120 seconds for SQL Serverbut with Enterprise Plus both MySQL andpostgres now have the maintenancedowntime of less than 10 secondsinstead ofdetaching the underlying storage fromthe primary instance and attaching it toa cold VM and starting that up andtaking that longer downtime under thehood we are essentially performing arolling upgrade which makes this processsignificantly better and reduces thedowntime quite a bit and while stillmaintaining your IP address and all yourinstance configurationsand we have seen fantastic customerfeedback on this you can see a code fromone of our customers who saw over an 80percent reduction in plan downtime whenthey tested Cloud SQL Enterprise Plusif you're interested in looking at howthis feature actually works in action Iwould encourage you to check out theMySQL and postgres sessions because theydid a demo on this very featureso that brings us to our third bestpractice which is that you want to ifyou want to run your instances with thehighest availability possible considerrunning those on cloud SQL EnterprisePlusagain this may not be the requirementfor your entire fleet you may have evensome production instances where you donot actually need such low downtime butfor the ones that you really doEnterprise Plus is a fantastic choiceso we talked a lot about the plandowntimeand again you can sort of configure ityou can move it from here to there butnow we come upon the unplanned downtimenow no one and I mean no one likes that2AM page which just results in anxietyand and frustration and stressbut then how do you actually plan thatis something by definition unplannedlet's see howso when you're thinking about planningfor the unplanned downtime you want tofirst start by defining your RTO and RPOgoals now just as a refresher RTO isyour recovery time objective whichbasically tells you the amount ofdowntime your application can acceptRPO on the other hand is the maximumamount of data loss which is alsomeasured in time that your applicationcan acceptonce you define your business continuityneeds based on the RTO and RPO then itbecomes a question of optimizing thatbusiness continuity and how much priceyou're willing to pay for itso with this framework in mind where ifyou want to if you want higher businesscontinuity it typically comes withredundant Hardware which results in ahigher price and so you want to makesure that you are optimizing andunderstanding all your options andmaking your choices based on what youwant to you know what what is moreimportant for you so with this frameworkin mind let's actually talk about youknow the different categories of theunplanned downtime and how Cloud SQLhelps you thereso we talked about zonal failure whichis essentially a failure scope to a zonenow this could be your database servicethe database engine going down your VMhaving a failure underlying this havinga failure or the the Rack or the Zoneitself just going downfor these Cloud SQL makes it very easyfor you to protect your instance usingour high availability featureso when you have a high availabilitywhen you enable a high availabilityfeature on your instance what weessentially do is we create a standbyinstance in a different Zone which inthis case is Zone Band then we create a underlying Regionalpersistent disk which does synchronouszero data loss storage replicationacross these zoneswe also end up deploying a load balancerendpoint so that your instances IPaddress Remains the Same throughout yourfailover and failback and yourapplication doesn't have to worry aboutthis change happening which typicallytakes about 60 secondsso if Zone a goes down Cloud SQL detectsthat zone a is unavailable and it failsover the instance to Zone B in less than60 seconds and after that Interruptionyour application essentially reconnectsto the same IP and the and the and itcan resumeso this is our fourth best practicewhich is that for highest availabilityin case of a zonal failure youdefinitely want to make sure that you'reconfiguring your instance with with hewhich is our high availabilityconfigurationokay let's talk about Regional failureso Regional failure is anything whereessentially it could either be multiplezones having an issue or it could be anetwork issue that spans acrossdifferent zones or a whole region or itcould be some sort of a natural uhdisaster phenomenon happening that justspans a large geographic areafor this what youcannot do is rely on resources deployedwithin the same region so you have tothink multi-region for that how doescloud SQL helpwhat cloud SQL offers you is the conceptof a cross region read replicafor a cloud SQL primary instance you cancreate a read replica in multipledifferent regionsnow let's see that you create this crossregion read replica and in case of thefailure of region one you promote thisreplica you make it a primary instancebut now that it's a primary instance ourearlier best practice said that youshould enable ha on this instance butthat's going to actually result in someadditional downtime so how do you avoidthe downtime and optimize your RTOyou can do that by configuring thereplica itself as an h a replica so weoffer the option for you to configureyour read replica as a highly availableread replicanow let's also say that in your primaryregion you're running some critical readworkloads that you're offloading to aregional read replicaafter the region has gone down yoursecondary region is up you areessentially promoting that across regionreplica it has become a primary but nowyou need to also offload the same readworkload within this region you canalways go and create a new read replicain that case but what cloud SQL alsoallows you to do is create what we callas a cascading read replica so this issimilar to any other read replica theonly difference is that its primary isanother replica itselfso in this case when you promote thatcross region read replica not only doyou have an instance up and running in adifferent region you also have haenabled on it and you also have its ownsame Regional read replica that you canstart offloading the read workloads toso that's our fifth best practice whichis that for highest availability duringa regional failure you should considerconfiguring a cross Regional readreplica with high availabilitynow we did say in the session title thatthere are going to be five bestpractices but seeing as all of you arehere I'm going to throw in a sixth oneso let's talk aboutuser error so let's say thatthat performs some a correct datadefinition or data modification query onthe database or you know performs theapp has a bug and it performs someincorrect changes to the database andyou need to actually recover from thoseto do that cloud SQL offers you multipledifferent optionswe have different types of backups theyare called automated backups and on andon demand backups automated backup issomething that cloud SQL performs onyour instance once a day and you candefine a retention period for thisbackup between 1 and 365 dayson demand backup on the other hand issomething that you perform yourself andit doesn't have an expiration periodCloud SQL also allows you to performpoint in time recovery on your instanceby storing the locks for your for yourinstance this feature is available alongwith the backup features across allthree of our enginesas you can see here you can essentiallyspecify a date and point in time and youcan recover back to it now point in timeis so critical uh for a productiondatabase that we have investedsignificantly in it over the last fewmonths let's take a look at some of ourrecent launchesthe first one is that as gopal mentionedCloud SQL Enterprise Plus offers you 35days of point in time recovery which isa five times higher retention periodthan what you get with the EnterpriseEditionnow this additional retention actuallydoes not come at an additional cost toyou because Cloud SQL now supportsstoring your logs to Google CloudStorage bucket for MySQL as well asposter SQL we launched this proposal SQLa while ago it's now also available forMySQLthis is great but what if your instanceis actually downfor your post to SQL instances if yourinstance is down you can now performpoint in time recovery so with arecovery Point objective of five minutesor fewer because we typically store thelog backups to the GCS bucket every fiveminutesbut what if the Zone in which yourinstance was running and that you'retrying to perform this point in timerecovery 2 is also unavailable now forcloud SQL point in time recovery foroffline poster SQL instances can also bedone to a different Zone within the sameregion this gives you one other greatway to to protect your instance from anyzone of failure with that five minuteRPOso that brings us to our sixth and lastbest practice which is you should alwaysenable automated daily backups and pointin time recovery with a retention periodof that that fits your needs and saveyour instance from user errors and othercatastrophic eventsso I talked about a bunch of differentthings it's great I'm a PM that's my jobbut it you know what would be moreinteresting is to actually hear fromcustomers like yourself who are usingthese features and who are maximizingtheir availability so let's do that solet's welcome Jonathanum so it's a pleasure to be on stage somy name is Jonathan I'm the co-founderand city of everflow Technologyum so we've been using gcp for quite awhile so we've been through the Journeyso I'll try to like bring some colors tolike what Raul and gopal saidum so funded in 2016 soso we're a partner marketing platform sowe we help Brands and agency track theirmarketing campaignsum so we've been using gcp like I saidsince day one uh we leverage likemultiple products such as big querybigtable Pub sub but like also likeCloud SQL and most precisely MySQL whichis the backbone of the environmentso like I said we've been through theJourney so I want to just spend like afew minutes with you to kind of tell youwhat we did what when well what did notgo well also because I think this isimportant for you guys in the room tounderstand thatso when they first asked me to like jointhe session ask myself why should I dothat I mean we're just like in the citywith a small startup like there'sbunch of people in the room like we allhave different strategies like differentlike use cases different budget too butlike we all have one common goal witheveryone no one wants to get like apager at 1am on a Sunday morning becauseyour app is not able to connect to likethe database so we all want the bestavailability so I'll try to like Expressthat with what we didum so the first one is as you see likeasrael mentioned like we do like weleverage the zones quite a bit so wehave like our Master our failover and abunch of read replicas in differentzonesum we never want to have everything inthe same Zone because if the Zone goesdown well at the same point at the sametime like your app is going to go downso that's one thing we doumalso likethe sorry the theum this oh I mentioned this step bysorry uh so the other thing is that isimportant for us like is the themaintenance and this is quite a HotTopic at everflow I know like there's abunch of improvements that are comingbut I'll be very transparent with youanytime we get like an email about anupcoming maintenance on a masterinstance like this is never something weenjoy because we know that in our casethat's multiple minutes of downtime sowe're using 5.7 sothis is something that has been going onfor a while and we did a POC with likeEnterprise Plus so that went frommultiple minutes to like seconds so likelike this is like a true use case thisis not like an infomercial this is uslike trying this feature in it or itworked really well[Music]umso ezrael also mentioned there's a bunchof control so you should take the timeto look at these controls and make surelike you use them to minimize your yourdowntimeum and like couple that with EnterprisePlus I think you'll be in a good spotsothe other aspect is disaster recovery asyou can see there like we do usemultiple regions so like we have a readreplica in a different region like canwe do that for all our different shardsthe reality is you need to like look atlike the activity on your master becauseone thing we notice is yes if yourmaster is super busy right with rightswhat could happen is you'll see areplica like your lag on the riptica inthe other region so this is somethingyou need to carefully look at likealways ensure that your master is in agood State and you're not just writinglike crazy because you're going to seelike an impact on the cross Regionalwith replicaumum yeahsorryI'm not doing that every day I can tellyou thatall right sorry about thatanother another thing we do is like werun manual backups yes like the the logretention is going to 35 days that'sawesome right but one thing we do islike we run our own backup that weexport to GCS with multi-region becauseyou never know right if you if you needto look at something from 60 days ago auser did something like there's an auditso that's something we do and if you dosomething like that make sure you youtest the Integrity of your backupbecause you could be taking backups formonths and years if you never test themthey might just be faulty so somethingthat you should you should considerumnow let's just focus a bit like on thethe diagram so one thing we do is we'redeployed on gke so all so we're usinglike a micro Services environment soeverything we do is through gkey andlike top left that's a pod right so youhave your app Cloud SQL proxy h a proxysowhat's important for us is like we don'twant to have like let's say read replicagoes down we don't want to have tomanually okay like change the config andall that so all pods are using aha proxywith all their read replicas so if onegoes down automatically it's going to beother read requests will be routed tothe appropriate read replicas and if itcomes back up automatically it's goingto be added back to the pool so that'ssomething you should consider if you'reusing multiple read replicas I'm notsaying you're using gkey but like youneed to have this layer between your appand Cloud SQL for like haum the other thing I want to point outis like this is like the current stateof our infrastructure well in 2016 itwas much simpler right like one MasterOne read replica and we started to likeadd more customers into scale so what wewere doing is like changing the specs ofthe machine make it bigger and biggerand bigger at some point we kind of Hitthe limit and we add to Shard so that'swhat you see like we have like multipleshards and the way we Scout horizontallyis much like now we have the controlit's much more seamless than trying tojust change like and make the machinebigger and bigger so something likedepending on your app and your use caseyou should consider like also shardingmore machine more money I get it but atsome point if you need to scale that'sone way that worked for usum another aspect is when you set upyour cluster always think about likehaving n plus one read replicas if yourworkload is like super tight based onyour current read replicas if one goesdown you want to be able to absorb thisworkload again more money I get it butyou need to have that for like a missioncritical app you need to think aboutthese thingsum another aspect I would recommend islike when you start using Cloud SQL it'smanaged all right it's beautiful butlike make sure you understand like theunderlying like the metrics how it worksbecause as you're going to be scalingyou want to make sure that you're ableto act on it so if you don't know likeif you just think this is a manageeverything's gonna happen magically it'snot make sure you get control on thatinstanceum yeah one last aspect on theapplication so this is again veryspecific to usum what we're trying to do is anythingthat could be done asynchronously likewe try to do it so we have like our APIlike this one okay all right sometimesit needs to write to the master so ifwe're down for multiple minutes we'redown but everything we can doasynchronously we use a pub sub a lot soyou should try to decouple like yourdifferent services so that everythingthat runs in the back end if your masteris down well at least you can pause thatthat part so you're not going to be likespinning your wheels and like trying totalk to your master while it's down soyou can dig up all your environment likethat again that's very much so likerelated to us but something you shouldconsider because like when you'rerunning at scales with that many schemasand tables downtime are taking longer sosomething to considerso quick final word sorry it went fastbut likelike for us like the a plus andclassical 8.0 is going to be a gamechanger for us because like the downtimeis going to be like much more minimaland I'm not sure I'm not sure if you sawthat but there's also the data cache interms of performance we noticed like 3to 12x improvements so that's going tobe very interestingum and yeah looking forward to it[Applause]thank you Joe thank you Jonathanum really really great to see all thethings that you're using with Cloud SQLand really great to hear about all thebenefits you're getting from EnterprisePlus uh now we'd like to welcome Jasononto stage for a quick conversationabout what Cape analytics is doing withCloud SQLgreat I'm happy to meet everybody herefantastic to see so many peopleinterested in databases uh a surprise tosee that but excited nonetheless so I'mJason Erickson VP of platform at Capeanalytics at Cape we have built machinelearning models that are able to processaerial and satellite imagery andgenerate accurate objectivecharacteristics about those propertiesand we use we work with our InsurancePartners to provide them the informationthat they need to accurately understandthe risk about each property thatthey're planning on insuring we werefounded in 2015 we've been a postgrescompany from the very beginning bothFord's Enterprise support but mostspecifically because it has Richgeospatial features at Cape we deal withReal World objects so being able tostore and query parcel outlines andbuilding outlines directly in thedatabase is incredibly important to uswe're actually also a recent convert togcp having migrated in May of 2023and we're very happy so farand today we serve over 1.5 billionspatial objects through Cloud SQL andpostgres with subsequent latencies forour clients that's awesome to hear andwelcome to Google Cloud thank you allrightso let's talk a little bit moreum Rahul do you want to yeahyeahum one of the I think interesting thingsthat I think I think everyone in theroom would be would want to know moreabout is your migration so I think youyou mentioned that you sort of migratedover from AWS Aurora to Cloud SQL couldyou talk a little bit more about thatand how that experience has been andwhat best practices sort of you learnedyeah absolutely so we migrated ourentire infrastructure over from AWSto gcp we set ambitious goals forourselves we aim to complete migrationin less than four months and with zerodowntime for our clients so we had a lota lot of non-starts but a lot of thingslearnings thatallowed us to complete successfully sofirst take time for data transfer wehave over 30 terabytes of informationthat we needed to copy and we used acombination of Google's databasemigration Service as well as PG dump andPG restore to move that data overregardless it still takes time to movethat much data so plan for that secondthing make sure you test againstproduction equivalent workloadsthe same instance type on a differentservice might not perform the same sowhen we loaded our data into Cloud SQLwe tested uh very thoroughly and we wereable to identify issues you know usingumquery insights and tune our instancesand we're actually faster on cloud SQLthan we were on Aurora and then finallythe last but most important thing have afantastic team it was a group effort byall the engineering team at Capeanalytics with also support from Googleand that's the reason why we're able toget this done so quickly with nodowntime for our clientsthat's awesome to hear the amount oftime that you took to just migrate towhere it seems um that looks like agreat experience so I'm pretty sure thenavailability and Disaster Recovery allthese are super important for youum so what are some of the principlesand approaches that you took uh when itcame to you know available DN DisasterRecovery yeah um so I mean we we selldata to insurance companies who are bydefinition some of the most risk-awarecompanies uh in the world it's in theirDNA so from the very beginning they hadvery strict Dr and availabilityrequirements for us the first principleis Leverage The built-in tools that areavailable to you um on the cloud andespecially gcp we just saw a tremendousamount of work by a lot of people thatenable companies like us to turn on highavailability with the click of a buttonenable backups another click even set upacross region replicas very easily sodon't reinvent the wheel use what'savailable to you save timeand then the second thing design yourbackups and disaster recovery for yourserviceswe have one database that we need toback up via a read replica because wehave a very tight uh recovery Pointobjective but a lot of our otherdatabases that we control primarily aregeospatial ones we can hit ourobjectives simply through a multi-regionbackup and they're restored into anotherregion if necessary awesomeall right soum thank you both for being here pleasegive it up for you know Jason andJonathan uh for being hereforeign"
}