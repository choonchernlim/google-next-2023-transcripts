{
    "title": "Enterprise readiness for generative AI",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML109"
    ],
    "video_id": "WyhxAPhsK-8",
    "time": "Aug 30 03:00 PM - 03:45 PM CDT",
    "transcript": "[Music]hi I'm meline I lead up Cloud'sresponsible AI team and I'm here with mycolleague Nema and an amazing customerDoug English co-founder and CTO ofcultureamp and we want to begin by with you ourcustomers we got a start with thecustomer needs and concerns and thinkabout that in the context of how theindustry is evolving and continues toevolve we've seen huge opportunity inthe generative AI space it's an excitingtime I feel like the the energy at theconference right now is is simplyphenomenal there is it's trulyexhilarating and there's a tremendousamount ofopportunity at the sametime there's a tremendous amount ofconcern there's scrutiny fromgovernments and regulators and policymakers and journalists but also we'rehearing concerns questions about thetypes of risks being raised fromcustomers our customers customerscreators fans maybe you heard about thebacklash uh against Marvel using AIgenerated opening credits or maybeyou're keeping track of the growingnumber of lawsuits that AI thatgenerative AI is engendering it's achallenging nav it's a Challen allinglandscape tonavigate there's a lot of questions andwe know that to grow your business andImplement generative AI effectively andsuccessfully you need a clear paththrough the risks and concerns andthat's where our approach to EnterpriseReadiness comes we have built ourEnterprise Readiness around four keypillars based on questions that you'reseeing for instance we hear you say saythat my data is my differentiator buthow can I protect my IP whilecustomizing Foundationmodels we hear you say I want to be anAI everywhere organization but how do Ideploy AI to every employee and in everylocation while keeping everything safesecure andcompliant and I also want to scale up tomeet the moment but how can I scale upwith generative AI specificinfrastructure cost effectively sustainsustainably andreliably and last but certainly notleast I want to be effective safe andresponsible how do I make gen generativeAI work for every end user in all thedifferent types of use cases whilemitigating potential harms and negativeimpacts how does Google Cloud addressthese concerns well I'm going to hand itover to my colleague Nema to take youthrough some more detailsthank youmeline the answer is EnterpriseReadiness all right we're done we can gohome all right now so what do we mean byEnterprise Readiness well uh EnterpriseReadiness is at the core of all we dogener of AI all the pieces we build howwe've built them and how we take it toMarket is Enterprise ready nowEnterprise R in particular when we talkabout it there are four different piecesto this one is around data governanceand privacy two is around security andcompliance support three is aroundinfrastructure reliability andsustainability and then finallyresponsible AI now we're going to gothrough these four pillars one by onewe're also going to tie them back tothose questions we were asking earlierin thepresentation so my data is mydifferentiator I want to use my data tocustomize these Foundation models but Iwant to keep my data private and securethis is data governance and privacy sofirst off your data is your data GoogleCloud will never use your data to trainour Foundation models now when I say theword data that means not just your dataon storage or you know in in in GCS oror bit query but it's also the promptsit's also the logs the metadata we willnever use these to train any of ourfoundational models we make that promiseto you additionally uh it's important tounderstand that while gen is new theGoogle Cloud platform has been aroundfor many many years and we havecommitments to security and privacyand we stand by these commitments thatwe've made whether that's gdpr whetherthat's transparency accessibilityprivacy they are built into the platformand then when you build gen becauseyou're building on top of the platformyou inherit these protections andsecurities and commitments aswell now when we talk about privacy it'simportant to understand that privacy isbuilt in by Design and by default intoour entire stack what I mean what I meanby that is we assume you don't want yourdata to be seen we assume you don't wantGoogle to access your data we but that'sby default you have to actively opt infor us to be able to do anything if I'mtrying to help you troubleshoot a safetyfilter issue I don't know what yourprompts were and I don't know what theresponses were you're going to have totell me right as a PM I have to do thatadditionally it's important tounderstand that we have tools andservices that are built on top of AI tohelp you with your privacy things likedata loss prevention uh or also tools tokeep your data private to be able tomask the information make sure the piiis not in there uh also transparency andaccess of understanding for example if agoogler or anyone else is accessing yourinformation you can see those logs youcan actually understand who's doing whatin your systems and then also tools likeuh impact assessments as well again ifthere is an incident if something occursyou have those tools they've existed youinherit them as part of generativeAI now you might be asking yourself okaythat's fine that's Dandy but how do Icustomize my Foundation modelswith my data but keep this informationsafe that's where these adapter layerscome into play you can also be calledadapter models adapter weights as wellsame thing essentially when you aretraining parameter efficient tuning yourmodel when you are reinforcementlearning when you're doing anything uhof that nature all of your changesaccumulate in the adapter layer now thefoundation model is fro Frozen at timeof inference at the time of the requestit's an API that occurs inside of yourproject and then the adapter layerswhich are inside of your securityperimeter I'll get to that in a secondsits on top of the API and when you makea prompt request the prompt and theadapter layers all get encrypted andsecured and whatever and then they getsent to the model so all of your dataessentially sits in the adapter layerand by the way that is customer IP uhthe terms of service make that clear aswell so the adapter layer is yours toown to keep to delete do whatever youwant with it it and that is how you cancustomize while protecting your uhIP all right so that was Data governanceand privacy now I want to be able todeploy AI everywhere uh all across theworld every user every uh employee but Iwant to keep myself safe and be incompliance all around the world this iswhere security and compliance supportcome intoplay again Google cloud has been aroundfor few years we take security veryseriously and has been built into ourinfrastructure into our platform sosecurity by Design this is important youhave multiple layers of encryptionthroughout the entire stack you haverigorous controls you have supply chainaudits to make sure that the pieces thatare building that infrastructure hasbeen audited and made sure to be secureyou have ongoing security testing andthreat analysis as well all of theseinherited by your gener of AI models youhave security by default you have thingslike cryptographic secured identity forzero trust models essentially again whatthat basically means is I don't trustanybody you have to prove to me who youare before I can give you access to anyof this information uh you also haveagain default encryption at rest yourinformation is encrypted and secured andyou hold the key Google can access itand then of course security anddeployment we have things likesuspicious activity monitoring we havemalware identification we haveencryption at rest and in transit aswell all of the are not New Gen is newyou inherit all of the security andprivacy andsafety all right let's talk a little bitmore about security controls inparticular uh first you havevpcc this makes sure to understand who'saccessing what who gets access uh whowho can access your security perimeterand how is that's defined you havecustomer manage encryption Keys againyou as the customer hold the encryptionkey Google cannot access your databecause you actually have the encryptionkey uh you also have access transparencythe ability to understand who isaccessing what if a googler for somereason is going in and looking at yoursystem you can see that in the accesstransparency aswell all right this is my favorite slideuh very pretty gone through so manylegal reviews all right let's start atthe let's start at the outside the bluebox right here is your securityparameter the reason you have the vpccthe CMAC the DRZ the axt all of thosethings that we just talked about theyall apply to every everything right soeven the large Foundation model that APIwere talking about your securityparameter applies to all of it rightokay so that's that then as we talkedabout before you have the foundationmodel it's an API it is instantiatedinside of your project right it's frozenat time of inference it does it canchange over time right like their newmodels we just announced one yesterdaybut at time of inference it's frozenthen you have the adapter layers wetalked about this again all of your IPchanges all of the parameter efficienttunings you're doing the Lowa tuningsthe reinforcement learnings allaccumulated in the adapter layer thatsits inside your project again all thesecurity is there and then everything isencrypted in transit either at rest orin transit and when you again when youmake that request your prompt plus theadapter layer are sent together to theAPI we only hold your prompt for as longas it's necessary to do the transitionto do the transaction and then we sendit back and delete everything uh I havenever had as many conversations withlawyers in my life in the past sixmonths and essentially it's this chartright here but it's important tounderstand right so again if you havequestions this is how we are doingit all right so it's not just securityit's also compliance support now this isan ey chart on purpose because it wantsto show you the breadth of compliancethat vertex has across our platform wehave uh over what was it three 2 millioncontrol senses audited annually by Thirdparties now one thing I want to pointout here this is not the chart for allof gen right gen it's brand spanking newwhen you have compliance when you havethese pieces you have to actually gothrough and get them audited and and uhapproved for compliance so for exampleHippa was in June uh we just achieved afew of these as well so be careful thisgives you a sense for the entireplatform right the different pieces andcompliance pieces but again talk to yourcustomer rep to understand I don't knowif you're in Malaysia and you want Idon't know brm or something like this dowe support that yet where is it on theroad map to be able to achieve that kindof piece of compliance but this is veryvery important uh we are working veryhard in Q4 to hit many of thesecompliance Milestones you know the theproducts are have been built now we cango and get them all certified and andcompli oopssorryokay you want to be able to scale upyour infrastructure to to meet themoment but you want to do it in a waythat can scale up scale out not cost anarm and a leg can do it with low latencyand also not kill the planet whileyou're doing it this is where the ourworldclass infrastructure comes intoplay all right another pretty chart Ilike this one as well I had to changethat number it says 38 down there it was37 last week it became 38 because Ithink a second data center went up inGermany so just FYI again this gives youa sense for the breadth ofinfrastructure and data centers andnotes that Google cloud has now againit's important to understand there's adifference between gen and there's adifference between our overallinfrastructure can you in can you traingenerative AI models in every singledata center no there are tpus gpus thereare specific pieces everyone needs to beable to deploy those it's it's a it's adifficult piece to do but this gives youan understanding of as we are rollingout across the world for gen specificwhere we are going and how we are doingthis now it's important to understandthat Google Cloud's infrastructure waspurpose built for large models thetensor chip right that was purpose builtto run large tensor models which justhappens to be gener of AI so when youare looking for the best-in-classinfastructure both from a TPU or a GPUperspective doesn't matter you have thatchoice you have that ability you want tobe able to run that on Google Cloud youhave that optionality additionally it'simportant to understand it's the speedand the performance and that fastinference often times you will the uhhow how quickly you can get thoseresponses are important in a Genera ofisetting so having those low latenciesthose those abilties to have the quickresponses very very importantadditionally it's all well and good if Ihave the greatest infrastructure in theworld but it's going to be super supercost costly right so price toPerformance ratios look at at those aswell compare the gpus the tpus what'sright for you you can get that with yourlarge language models on ourinfrastructure uh and then of course theability to scale up to meet the momentto be able to have those capacities andthen scale up and scale down asnecessary and of course all built on anopen source platform now it's alsoimportant to understand that it issustainable Google cloud is the cleanestCloud we can make that commitment wehave those statistics so if you or yourcustomers want want to you know makesure that you're not killing the planetwhile we training these massive modelsyou want to run your workloads on GoogleCloud all right now my last pillar isresponsible Ai and with that I am goingto turn it back over tomeline there's so much more too um soyeah I'm really really excited to behere and talk to you all aboutresponsible AI because this is what I doevery day day this is what I and my teamwork through and we're meeting the needof knowing that our customers want thesenew systems to be effective andresponsible andsafe so you may know that in 2018 Googlewas one of the first companies toannounce a set of AI principles theseprinciples put beneficial use users anduser safety and avoidance of harms asessential business considerations thesedo not happen after product developmentthey happen during before anditeratively throughout um theseprinciples are they truly are the kindof blueprint for how we develop Ai andthis is also like Nemo was sayinginherited generative AI is inheritedthese principles sorry um so principlesare only as good as they are whenthey're put into practice so since 2018and these principles have been announcedwe have iteratively been develop dedeveloping Frameworks and processes toput these principles into practice andin Google Cloud we look at our work inresponsible AI not only in how wedevelop our Cloud products but also howwe enable our customers to develop andinnovate responsibly so with this dualfocus in mind we think think about ourwork along three primary Dimensions onewhich I'm going to walk you through oneis along product and data governanceprocesses these are repeatable scalableprocesses that ensure during developmentthat our products align to our AIprinciples and our data commitments in aconsistent repeatable way the secondcategory focuses on tooling and supportfor our customers after we've launchedproducts when our customers need todeploy and and then third we also aim toadvance the industry we want to shareresearch education and best practices tohelp us all move forward in implementingAIresponsibly so I want to take youthrough what what an example of one ofthese governance processes look like sowe begin by identifying potential harmsthen we assess the risk level and thenfinally we develop mitigation plansthese mitigation plans are essentialbecause we want to think through notonly what might be potential harms oropportunities but how do we ensure thatthose harms don't come to pass so what'san example well we do this for our Cloudproducts as well as products that arebuilt custom built with our ProfessionalServices organization so for instancethere was a customer that wanted toanalyze images on their website thatwould flag content that might beoffensive to users to enable bettereditorial decisions and just enablebetter ads targeting this is a great usecase this also has the potential toexacerbate bias or create new forms ofuser harm and so as part of thedevelopment process we worked with thecustomer to identify potential harmsboth based on their business experienceas well as Google's business experienceand set out particular sets ofevaluations and ultimately policies tolimit or mitigate potential bias in theimage classified wedeveloped um ultimately this thiscollaborative process with eitherproduct teams or with our customersresults in a better experience for usersand it creates a longer lasting valuefor AI when it's out in theworld we've also developed manyTechnical mitigations and I want to walkyou through some of these these end upbeing a lot of the mitigations that wethat we articulate in as as part of ourresponsible reviewfor instance we've created a set ofsafety filters for instance the Palmcontent that is processed by the PalmAPI is assessed against what we call alist of safety attributes which includethings like harmful categories thingsthat may be toxic or um overtly sexualtopics that may be considered sensitiveand as a customer you can leverage thesesafety filters and Define confidencethresholds that meet your business needsbecause what we've also learned over theyears of working on responsible AI isthat details and context matter and soit's really really important to know thespecifics of your your usecase with these safety filters you asthe customer can take comprehensivemeasures to detect specific content thatyou're concerned about to protect yourusers and to better better manage brandrisk with these technical guard rails wewe want to be able we we want to provideprovide some kind of peace of mind butalso want to emphasize that this is acontinually evolving space and so weconstantly have to um update these kindsof uh filters and continually look fornew forms of mitigation as new forms ofharm of new forms of harmarise I also want to talk to you aboutthe kinds of technical guardrails we putin place around copyright protection wehave taken a multi-layer approach so forinstance we have made this happens atthe model level first and foremost wehave made a tremendous amount of effortto keep the training data of our modelsfree and clear of Ip and copyrightedmaterial second we've developed citationchecks on the model outputs so we havein the model and then the model outputsum these these uh citation checks wecall them um scan for known sources ofIp both your own data as well asexternal sources and then third andfinally our terms of service providecustomers with third-partyindemnification against any issuesarising from training data this is thisis really remarkable and so again we aimto give you confidence and peace of mindthat you can use generative AI not in ajust a pilot setting but really out inthe world in use inproduction and finally we continue todraw on not only our experience in Cloudbut also across Google with Googleresearch and other product areas likeYouTube and search to continue todevelop um best practices and learningsuh and sharing learnings with customersso for instance there are many playbooksthat you can find on our website thatwere developed by our uh researchPartners we also have specializedtrainings for different audiences fromdata scientists to ux researchersthere's even a speci specialized courseuh for customers and partners on skillsboost about how to set up your owngovernanceprocess so we're continually updatingour guidance and best practices we knowthis is an emerging field and we bringboth our years of experience inimplementing Ai and also some of thebest cuttingedge research around what wedo in this new field we'll be continuingto update the kinds of um both technicalguard rails as well as practices that weshare throughout the next weeks actuallyum months and I think over the comingyears so with that I want to hand itback to Nema the full expert here togive a a summary of Where we've[Applause]been h no all right there it is allright cool this is my Encore uh okay uhso in summary we had those fourquestions remember we started with thoseuh by the way we will turn it over wehave a customer experiences after thisbut I'm going to summarize theEnterprise R this aspect here what wasit it was my data is my differentiator Iwant to use my data to customize mymodels and I want to have datagovernance and privacy in place rightthat was the first one what was thesecond one the second one was that Iwant to deploy generative AI everywhereI want every one of my employees to beable to use generative AI but I need todo this with secur compliance supportacross the world what was the third onethe third one was I want to scale up tomeet this moment you're going to havetons of customers tons of users tons ofuse cases to be able to build this ontop of our infrastructure that isreliable and sustainable and thenfourth I need not want I need to beeffective safe compliant responsiblethis is where responsible AI comes intoplay so this is what we call yourEnterprise Readiness my my last pointbefore I turn it over to my good friendDoug is that you are adopting a platformnot a model this is really reallyimportant I want you to understand thisright it doesn't matter what modelyou're using it could be the Palm firstparty model it could be llama 2 from athird party it could be an open sourcemodel what you want to do is haveEnterprise grade Enterprise readyinfrastructure across the board you wantto have data governance and privacysecurity and compliance uhinfrastructure reliability andsustainability and responsible Ai Nomatter which model you're running andyou can do that now on Google Cloud youcan do it with llama you can do it withpalm you can do it with whatever soagain models will come and go theplatform is what stays and with that Iwant to turn it over to my very goodfriend Doug to actually talk to youabout a real world use case where acustomer puts responsible Ai andEnterprise Readiness into practiceDoug I don't think I'm on mate can youhear me yes we're good now we're goodnow so yes thanks everyone I'm DougEnglish uh one of the co-founders ofcultur amp and CTO and while we're heretoday in this session another10,750 questions will be answered on theculture ramp platform allowing ourcustomers to better understand theiremployees and how to intentionallycreate a betterculture I think it's fair I thinkeveryone here would agree thatgenerative AI is right at the very topof the hype curve right now uh with thepromise to totally transform the waycompaniesoperate and some of this is for goodreason AI enables us to do things thatsimply wouldn't make sense without it itis a massive step change inautomation but just because we candoesn't mean weshould today uh sorry culture amp uh weput people at the center of everythingthat we do so when we came to looking atAI we had to think very carefully aboutwhere and how we might introduce itparticularly when it came to things likeprivacy anonymity andbias today I'm going to take you throughum a decision-making framework thatwe've been using at col to help usdecide where and how to invest in AI umand then I'm going to show you a uh uman early look at a generative AI umapplication that we are working on atthe moment that will be released uhlater in the year on the vertexplatform but starting with the decision-making framework the three steps that wefocus on are building trust keepingcontrol and expandingvalue oh going the wrongway here we go so buildingtrust keeping keeping private dataprivate is the Bedrock of buildingtrust to um AI to introduce AIresponsibly um it is essential to havegood datagovernance do you know theclassification of your data are youmanaging the life cycle of yourdata are you interrogating your trainingdata for uh unintended biasare you complying with the with relevantregulations um particularly when itcomes to pii so for example if you'reusing pii to train models what processesdo you have in place to make sure thatyou can comply with regulatoryrequirements such as data deletionrequests as we've heard from Nema andmeline these Concepts have been built infrom the ground up with a Vertexplatform um and so it's been a greatpartnership to to be able to deal with alot of the challenges that we have interms of how we keep our data safe butonce we've focused on ensuring and thendemonstrating that our data is safe thenext question is will the customer um uhtrust the the outcome or the output ofthe generativeAi and this is made more challenging bythe fact that there is no one rightanswer for the output of generativeAI um of course there are many wronganswers so the thing that we've beenfocusing on is how do we make sure thatthe results are explainable how do wehelp the customers to understand um whatwas the reasoning what was behind theoutput and and how can they using thatas a way to build confidence in theoutput if we can do that well um it goesa long way towards building trust evenif they don't don't 100% agree with theoutput this is actually uh very similarto what we went through in the 80s whenum when computers uh first started doingum uh accounting calculations right theway across the industry it took time forum accountants to build trust um in thein the software and they did it bycomparing handwritten calculations withthe computer's results so if we can helpthe customers tounderstand what is to delve deeperbehind what is uh being presented um andconnect it to the things that are realunderneath the summary it goes a longway towards building trust but it alsoputs them in the driver's seat formakingdecisions we think of AI as anintelligent but subservient enabler notthe driver ofdecisions think of it as like a juniorwho's working for you um to and you'veasked them to summarize some informationyou need to be able to direct their workand if it comes to it you need to beable to correct theirwork AI can be really good at drawingout theinsights but you still need to shape thecontext and decide where to put theemphasis our customers want to be ableto play with the output so we let themwhat we want is to have a set of toolsthat allow them to identify the themesdraw out the insights test theirtheories andhypotheses but at the end of the dayedit anything they wantto at the end of theday at its core AI is lightning fast atcoming up with the well-consideredstandard answer but the real magichappens when humans interact and add thecreative flareand what is most important at the end ofthe day is that our customers take totalownership for theoutput and the actions that come off theback of it and to do this we also needto be able to demonstrate that we'readdingvalue adding generative AIcapabilities um as a gimmick to yourplatform is both pointless and veryexpensive but in the right applicationsit can add enormousvalue as an example um take one of ourtypical customers say uh a 10,000employee company running a survey evenif every participant of the survey isonly um is only providing a handful ofof comments on the survey our surveyadministrators are still faced with withtrying to make sense of literally tensof thousands ofcomments historically these would eitherbe skimmed and mostly ignored or oursurvey administrators would quiteliterally be spending days reading everycomment categorizing them trying to makesense of them this manual process isboth um error prone and prone tobias generative AI can do the heavylifting and help our customers to movemove forward with confidence much fasterthan they would be ableto if we didn't have that capability inthe platform so let me show you whatthis might looklike these are some screen designs of umof the the capability that we'rebuilding at the moment that we'll begoing to um production later in theyear and as we walk through building thescreens we're focusing on those threeaspects um um so the three aspects of ofum uh building trust keeping control andexpandingvalue so you can see here in the summarywe've we've used sentiment analysis tounderstand which comments are positiveand and negative and then we've we've uhsummarized those to draw out what arethe main themes that we're seeing acrosseach then at the bottom here we have abunch of insights that we've been ableto derive from the the body of of um ofcomments up in the top right there's a arefin button that's where the customercan play so in there they will be ableto get to features that allow them tofor example expand on one of the topicsor add the experience of a particularsegment of the company that they theyknow that the exec is particularlyworried about um if you hover over anyof those areas in yellow um if we gosorry next screen um you'll you'llactually be able to delve in and seewhat are some of the Exemplar commentsthat we used to drive that summary andso it's helping them connect the summarywith what's reallyhappening and thenfinally um we we're introducing otherlenses such as which comments are themost actionable so if we can Surface themost actionable comments early it meansthat particularly for ones that have goturgency they can deal with them straightaway before they've even read throughthe rest of the the set of commentsso thank you um Nema and meline for uhfor the opportunity for me to share someof the culture amp story I'm going to bearound for the for the the rest of theconference so if you want to continuethe conversation um out of this sessionI'm absolutely very keen to[Music]talk"
}