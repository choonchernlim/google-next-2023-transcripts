{
    "title": "Deep dive about reliable Google Cloud architectures with Egnyte and Cruise architects",
    "presentation_type": "Breakout",
    "categories": [
        "Architects, IT Professionals",
        "ARC209"
    ],
    "video_id": "eOxw0U67CFI",
    "time": "Aug 30 11:15 AM - 12:00 PM CDT",
    "transcript": "[Music]good morning everyone we ready to getstarted welcome to today's presentationwhere we're going to talk about how tobuild reliable applications on gcp withour customers Crews andignite so here's what we're going tocover today we will start with somethingcalled as deployment archetypes uh I'llgo into a little bit more detail on whatthat means uh think of it as groundingourselves in a little bit of theorybefore we get to the real world examplesstarting with Cruz followed by igniteand then at the end of the session we'lltake Q&A we have timed all of our talkswe will have plenty of time for Q&A sowe will take that at the end so if youhave questions please take a note ofthem I promise you we will get to themokay now before we dive in you'reprobably wondering who we are so itmakes sense to introduce ourselves andwe will start with you NES hi my name isnitish I'm on the container platformteam in the infrastructure Aug at Cruzum I've been with Cruz about four yearsand um yeah great to meet youall Roman hello I'm Roman Kleiner I'm aVB of engineer in at ignite and I'mresponsible for everything to do withignite's platform including how ittransergcp Le hey everybody my name is LeeGates I work at Google Google Cloudstudying reliability availability andperformance and happy to be here withyou today and excited for our talkwonderful folks my name is Tim Isaacs Ilead gcp platform reliability from aproduct management standpoint and I'msuper excited to be here and uh lead youthrough the next 10 or 15 minutes beforewe move to the other speakers wonderfullet's get started so um what are wegoing to cover today uh the keyobjective here is to discuss a fewdeployment architectures what we calldeployment archetypes it's just anotherway of seeing deploymentarchitectures and then um run throughthose with two case studies one fromCruz and nsh will walk us through thatand the other from egnite so what we'retrying to do here is start with a littlebit of theory and then match that theorywith some real world examples a quicksidebar what you see linked below is a alink to the to a very popular paper it'scalled Cloud uh archetypes deploymentarchetypes for cloud applications sorryit's um uh I would encourage you folksto to read it uh you can find it onlineit's a fairly straightforward search theauthors are googlers but there's nothingGoogle specific about the paper so it'sa very generic cloud-based paper and uhreally good information and there I'veread it a couple of times so Idefinitely encourage uh doing so uhyourselves okay so what are thesearchetypes that we are harping on uhvery simply put um we you should thinkof these archetypes as deploying anapplication in a Zone you'd call that azonal archetype or in a region aregional archetype across two or threeregions that's a multi- region archetypeand then if you're going across allregions across the world you would callthat a global application or a globalarchetype each has certain variants thatare more descriptive in name and we'renot going to have time to cover all ofthese we will pick a few and given thatthis talk is centered on reliability wewill examine them more from anavailability and reliabilitylens right and what you'll see is theseare effectively design patterns thatoptimize for a few things they optimizealong Dimensions like availableuh cost and complexity latency and atthe end of the day it's just a balanceof trade between these dimensions andreally what you're trying to do here isyou're trying to match your businessrequirements of your applications to oneof these one of thesearchetypes okay um you know generallyspeaking if it's a zonalarchetype you're deploying into a singlezone uh you may have a failover zone soyou can't expect very high availabon the other hand if you're deployingacross multiple regions you have yourapplication now in multiple regionsacross multiple zones so you cantolerate various kinds of failures andtherefore you can expect a much higheravailability right so that's theintuition behind uh these differentdesignpatterns so let's dive in the first oneis what we call a single zone withfailover Zone it's the moststraightforward one to also understandand if I get your attention to to thepicture on the right there uh youbasically have your application deployedin one zone the primary Zone it's alsovery simple application just you know offront end if you will in this examplewith a database you're keeping a readreplica of your database that's notactive in another Zone and when you havea failure you fail over to the secondZone if you've de deployed applicationsin the on premises world this will looksomewhat familiar where you have anapplic in data center one you haveanother data center not that far awayand then you use that data center forfail over when something goes wrongeither to your application or to thephysical data center itself so what thatalso means is when you are uh trying todo a on-prem to Cloud migration if youfollow this design pattern it's more ofa lift and shift you're not doing awhole lot of rearchitecture uh therefore cost andcomplexity also is on the low side butbut because you're only deployed in aZone you can't again expect a whole lotof of you can't have high availabilityexpectations 3 9 is roughly where youwill tapoutokay so with that simple example tostart let's move to the next one nowthis is single region now just thepicture alone will tell you that's alittle bit morecomplicated and what you're doing hereis you're deploying your applicationacross three different zones within thatregion you can therefore tolerate a Zonefailure or even a multizone failureright you can tolerate two zones failingbecause your application is deployedacross all three in this example you'reusing a little bit of a modernarchitecture you have a front end loadbalancer for your front ends you have abackend load balance end then your backends and a backend data store you havethree copies of your data one's activethe other two are replicas onstandby and um if a Zone fails youYou're simply redirecting trafficthrough your load balancers to the otherzones um and if your zones back up andrunning or your application in the zoneis back up and running then you're usingall three zones to serve yourapplication now if you're doing amigration from the on Prem world thenthere is some level of re architecturethat you'd have to do because this is alittle bit more of a scaleout uharchitecture and that also means from abest practices standpoint you have tostart thinking about things likeautoscaling your applications as loadincreases or scaling down or loadshedding as load decreases or if youhave some sort of a problem with aportion of yourapplication the nice thing though is umif you're using uh Google Cloud managedproducts you tend to have constructslike these that help you out so there'ssomething called as migs managedinstance groups people who have workedon Google Cloud are probably familiarwith this it takes care of a lot ofthings like autoscaling out or scalingin um when it comes to block storage wehave something called as Regionalpersistent disc which uh effectively uhcreates two copies of your storage uhsynchronously so they're kept up to datebetween two zones within the region soagain if a Zone fails you have a copy inanother Zone that would be up andrunning so um the single region you cantypically expect about 49 of of uhavailability okay so at this point let'sactually walk through a little bit of anexample and what we're trying to do hereis we're trying to derive a SLO right soat the end of the day you're going to beusing a set of Google products andresources uh in Google cloud and thenyou have to think about hey at theapplication Level how do I derive orthink about a SLO service levelobjective and in this example we try tokeep it somewhat simple we have threecomponents you have the load balancerthat's uh bringing in requests then youhave your compute side in this examplewe're using gke and then of course youhave your database uh in this case it'sSQL if you look at the product levelslas that you get from each of these theload balancer the SLA is 49 so under thecovers clearly we are doing a bunch ofthings to make sure it's 49 you'reabstracted from it so all you see is youknow a regional load balancer that has aum you know fairly HighSLA and then uh the gke Clusters hereare zonal clusters so you have an SLA ofabout two and a half two and a halfnines and then of course on the SQL sideif you're using manage SQL or Cloud SQLuh you get three and a half 9es nowthat's not good enough if you're tryingto construct an application let's justsay with four nines so what you do isyou start adding redundancy right so youdeploy GK you deploy your applicationacross multiple zones as we saw in thearchetype so you're now deploying gkeacross multiple zones you're doing thesame thing with SQL here we just usedtwo copies of SQL it could very well bethree and as you're adding D dunany ofcourse you're raising the availabilityright intuitively that makes sense andthe way you'd do that Math course it's abit theoretical but the way you do thatmath is 1 minus the error budget raisedto the number of um redundant copiesthat you have so in this example with GKit's 1 minus the error budget is005 raised to the power of three becauseyou have threecopies you do the same thing for SQL andthen you get some numbers now the factof the matter is those numbers are a bittheoretical the reality is you willfinally be bounded by something elsewithin the region could be somedependency or the fact that physicalinfrastructure can only give you so muchavailability within a single region andthat bound usually tends to be about 49so now what do you end up with you havethree components each giving you about49 if you architect your overallapplication in such a way that theyaren't fully dependent on each otherwhen it comes to failure modes then youcan expect that your application itselfcan also achieve about49s so that's a way to just think aboutyour application Level SLA when you'reusing Google products and Googleproducts typicallypublish an SLA and um You probably haveto add an redundancy in some cases toget to your target SLA okay so that wasan example with single region now let'sgo and get a little bit more advancedand now let's talk about a single regionwith a failoverregion now as you can see in thatpicture what are we doing here we havetaken the single region archetype andwe' have said hey you know what we needto also have something similar inanother region a pho region so yourapplication is again deployed acrossthree zones in the region um same setupas before but you have your data beingreplicated into a standby region soyou're probably doing async replicationif your region is far away and then umwhen there's a failure you're going tofail over into your standby region andyou're going to spin up your computeresources either just in time or youmight pre-provisionuh it all depends on what you're tryingto optimizefor this is certainly a more complexarchetype uh customers typically Reservethis for the mission criticalapplications rather than all of yourapplications uh as you can see the costof this is going to be a bit on thehigher side uh complexity is also goingto be a bit on the higher side and onething that you really should take careof from a best practices standpoint ismaking sure that you are well aware ofthe health of your application throughthe stack the reason for that is youdon't want to fail over unnecessarilybecause failing over to another regionis going to be a high cost activityright you are spinning up new resourcesyou're trying to make sure that yourapplication comes up in the right orderyou are moving your clients there you'realso operating on a copy of data that'sprobably 10 15 minutes behind right soyour rpos in the order of 10 15minutes so you want to make sure thatyou're really failing over when Iwhether your region goes down or yourapplication within the region goesdown right another thing that you shouldthink about is if your application isreally large taking up a lot ofresources is that you have capacity inthe region that you're filling over intoso some capacity planning in advance isa good idea one of the things that uhcustomers do is they pre-provisionedresources ahead of time or they dofrequent Dr tests to make sure that whenum something bad happens you have testedenough to know that you will fail overum and things will all work okay sothat's single region with a fellowregion sometimes you we call this a dualregion architecture right because you dohave tworegions the last one is more of a truedual region architecture where eachregion has an isolated stack so againyou're taking your application you'redeploying it in three zones within aregion but you're doing exactly that inanother region and these are both activecopies of your application so you'reserving clients from both regions youhave a load balancer uh some sort of ayou know DNS load balancer that'sappropriately uh partitioning yourtraffic into the two different regionsand so what happens is if a region failsyou still have your other region that'sserving traffic and uh you can decidehow you want to handle that situationyou can either redirect all your usersfrom the failed region to this survivingregion or you can say hey you know whatI'll operate in degraded mode and I'llonly serve about 50% of my users umappropriately or I'll serve all of myusers slowly right so it's up to you howyou want to sort of handle that againdepends on your businessgoals clearly this is a more expensiveand more complex design right you havemany copies ofyour application that's actively runningso you're actively you know spendingduring that time and it's certainly morecomplex because you have many movingparts and you have to make sure they'reall wellcoordinated so again this is a much likethe previous one this is something thatyou would reserve for your missioncritical applications versus just everyapplication that youhave Okay so let's do a quick recap umso we discussed the concept ofdeployment archetypes simply put is justdeployment architectures or deploymentpatterns um we discussed four of them umyou can Loosely classify them into asingle region versus a dual regiondesign and uh you go higher up inavailability but you're trading off costand complexity when you do so as you gofrom a single region to a dual regionand therefore you must make sure thatyou're appropriately matching thearchetype to your business goalsokay so this is the end of the thetheory bit to build a little bit of afoundation that we can now use with ourrur world examples and to talk throughthat we will start with Cruz and I'mgoing to hand over toNES can you hear me okayawesome okay so um we from Cruz uhhopefully all of you have heard about uswe a driverless car company based herein SF uh but before I talk about ourbusiness application uh of thesedeployment archetypes I'm going to justlook at a summary here right so this isbased off what Tim just talked aboutwhat deployment AR type are we choosingand why so immediately you'll see wehave like a pretty high requirement offive NS of reliability I'll talk aboutwhy a little bit later uh we're usingmultiple regions so it's a dual regionbut it could also be three regions ifyou wanted to instead of two and we useuh Regional GK clusters as our basis ineach of those regions so even within aregion we're using Regional Servicesinstead of zonalservices um for and then for ourapplications we sort of have like threelayers that our applications use this ispretty standard we have like a databaselayer for which we use multi-regioncloud spanner the great thing aboutCloud spanner is like multi-region outof the box we have a messaging layer Ihave a St about that talk about laterand then we have a custom load balancethat we' have built to uh distributetraffic across our differentregions okay so about Cruise um even ifyou've not heard about it still now likewe've been in news a lot recently um allof you are in SF which I think is far tosay is the driess capital of the worlddriess car capital of the world um weare a self-driving car company umheadquartered here we're building theworld's most advanced self-driving carsand these safely connect people to theplaces things and experiences they careabout um quick show of hands how many ofyou have actually been in a self-drivingcar not that many how many of you wantto be in a self-driving car sometimesoon many of you right so that that Gapis exactly what we're hard at work in uhat cruises right now to fulfill um weare rapidly expanding we recentlyannounced that we have gone to our 12thand 13th markets it's very fast I thinkwe're testing now in Seattle andWashington but we've been deployingwe're going to be deploying services toCharlotte and Raleigh in North Carolinaas well so you can see where we are asas a company right we have a productthat works it works in a few marketslike right now we have public servicesin SF Austin and Phoenix Phoenix butvery soon it's going to be across the USgeographically and it's going to behaving multiple Vehicles right hundredsthousands of vehicles and many manycustomers so how do we take somethingthat's built reliably in one place andsort of expand that across the countryand expand that to a huge set ofcustomers here um we have a uniqueproduct obviously uh the AVS themselveshave prettyy high availabilityrequirements um think of them as sort oflike iot devices right so they're iotdevices but they're also like constantlyon the move across these cities they'realso constantly on the Movegeographically spread right so you haveAVS in Miami as well as Austin as wellas LA and these are constantly talkingto our Cloud backends right like wheredo I go next to pick up a passenger umshould I go back to get charged into thegarages and our ride hill and deliveryproducts that we're building on top ofthis technology will only be reliable ifthe AVS themselves are extremelyreliable in terms of how theycommunicate with the cloudbackends okay next so uh a couple yearsago we were in R&D mode right and whenwe were in R&D mode we used a single Gspeed region so I'm showing you thebefore right so that you can see ourjourney here so when we were in R&D modewe had a single region a single Regionalgke cluster and we had sort of thesemonolithic Services deployed in each ofthose zones and all of them usedcloudsql DBS which is a regional productand GB Pub sub which is also a regionalproduct we had load balancers that werepretty straightforward just sendingtraffic across those zones within asingle cluster and the AV is stockedonly to a single region at this pointand um yeah this is sort of similar towhat Tim showed you before in a singleregion architecture we did not have likea failover or anything like that rightat this point we were only focused ongetting the technology itself to work solike reliability was like know the nextstep okay so what comes next so whatcomes next is um SL okay what comes nextis 59s right I toally talk about 59s so59 is like 26 seconds per month ofdowntime it's very very low but thinkabout the experience of a customer in adriess vehicle being stuck for 26 26seconds on the road in the middle of thenight right it's very uncomfortableexperience compared to like not beingable to access a website or anapplication for a minute or two right sowe want to make sure that the experienceour customers get is extremely reliableand we know that we can only give thatreliability with this level of Cloudreliability itself we are also in a nentindustry and this is very important it'sa highly regulated nent industry rightso we have to also prove to the to thegovernment our Regulators that this is aproduct that they can trust that ourcustomers can trust and that is going tohelp us spread this product across theUS so the F uh the fin NES here are notsomething we get easily right it'ssomething we have to archit toward wordsum some of the examples that Tim showedyou before like show a path to go fromlike 3 9 to 49 to 59 and that's sort oflike our journey here to towards thoseFinance ofreliability uh the other thing I wantyou to note here is the applicationshere are consistently deployed acrossthe different regions it means that wehave sort of minimized the amount ofrefactoring we have to do I talked aboutthe monolithic applications we had alittle before um by deployingconsistently across many regions it'seasy for our service developers to belike hey I have this one version of mymicros service I just want all the AVSeverywhere to use it right and thearchitecture that we've built sort ofallows them to do that um it makes iteasier for them to deploy their code tothese Cloudbackends okay I want to focus in on thelayers that we have as part ofarchitecture and we'll dive into acouple of these layers A little later ifyou look at each of these layers each ofthem have to have uh Finance reliabilityso the cool thing is with the SPdatabase layer that's multi-regional GSPservice that gives us Finance out of thebox so that's not a problem we had tosolve the next layer down is pubsub sothat's gcp pubsub which is a regionalservice so we had to architect Financeof reliability with that and then wehave the GK clusters which again areRegional and then we have the loadbalances which are Regional so you'llsee that at the bottom those are our AVSright and our AVS talk to a custom uhDNS load balancer which directs it uh todifferent regions to use and and that isalso like Finance of reliability rightso layer by layer if all those layershave Finance of reliability we getFinance of reliability overall I thinkhe showed you the math slide as well Timforthat okay so uh the two big things thatwe built here that we had to build inhouse are the custom DNS uh loadbalancer and the uh gcp pops subarchitecture I'll talk about the trafficlayer first you'll see here that we havetwo Regional clusters these are likeactive active you could call them andthe a has to be able to talk to them uhwithout like a failure like a Time takenfor fail over right so what happens hereis we have a custom DNS load balancerthat is constantly Health checking ourmost critical Services you can see thatlet's say service a and service B aretwo critical Services deployed todifferent clusters they have theircustom health checks with which thecustom DNS load balancer can check forand it'll only direct the AV to talk toa backend if it knows that's a healthybackend service in that region the samething is also applied for East Westtraffic so if you imagine that service agoes down in region Us West one serviceB can actually talk to service a inuswest 2 using the same load balancinglogic and when a health check fails it'sremoved obviously from the DNS uhresponse so no no AV after that is goingto be using that um a little more aboutthis custom DNS load balancer some ofour applications are very latencysensitive right obviously we need tohave like command and control of thesevehicles they need to respond veryquickly to them so the DNS layer itselfis configured with locality based loadbalancing sort of means that the AVSthemselves know which Market they'reoperating in and when they ask for aresponse who which Cloud end point I'mare supposed to talk to they get the oneclosest to them assuming that's alwayshealthy right it's only when the oneclosest to them is not healthy that itgets redirected somewhere else so it'snot like a random load balancing or likea no fully distributed load balancingit's definitely locality based for thoselatency sensitiveapplications uh so this this is I thinkthe most useful slide to you honestlyspeaking this is how we deployed aregional Pub sub um uh service and madeit like multi-regional and got likeFinance reliability out of it um so wehave an at least one messagingrequirement out of our messaging uhservice but because gcp pop sub is onlycan only be deployed in a single regionwe have to get Finance of reliability bydeploying them in each region and havingall your subscribers subscribe to all ofthem and all your Publishers writing toall of them them so this is obviouslymore expensive but it also means that ifan entire region goes down right all oursubscribers and all our Publishers canstill read from different regionsimmediately without like a lot loss ofummessages um yeah so this is how we gotfrom like a thing that does not havelike out of the box Finance ofreliability to something that somethingthat will give us Finance ofreliability okay I think I'm need tohand off to Roman now thank you somuchhello am I audible yeah awesome allright so I'm going to talk to a littlebit about ignite um it's a slightlydifferent product and architecture and Iwhat I'll try and discover more of thosearchetypes that Tim talked about in hisopeningoverview nowum um with a Gite we actually usedseveral archetypesI'll begin with one which kind of talksmore about our car product and in thatcase we have an active region with afail over region kind of scenario and ina moment I'll explain a little bit whythat is and what power is that overallwe are using more or less standard gcpTechnologies so we don't have too manycustom components within that uh butbefore I go much deeper um Let me let metalk a little bit what ignite doesbecause unfortunately I cannot make thesame assumption that the previousspeaker did so ignite uh has pretty muchtwo main pillars of functionality thatwe sell to our many customers and wehave 20,000 plus of these one is whatyou would call FAL system in the cloudor Advanced collaboration so you haveyour company they need to work on samecontent they work need to work on mutalprojects they want to do it in seamlessway wherever they are right um and itfrom the more basic use cases that youcan readily imagine to pretty Advancedones that are tailored for a particularindustry such as construction and thenwe have another pillar where people areadministrators in our case they wouldwant to reason about their data andunderstand that it's been processed inthe right way that there are noaccidental or intentional incidents sothis is like a full analysis whereas anadministrator can come in and say ohthis is something I need to worry aboutwhen it comes to data in my environmentso um when we look at all of that themain aspects that really would matterand I'll come to them in a moment isdurability because if there is one thingone thing that we cannot really affordis for anyone to lose their data theyentrust us with theirdata it has always to be the right oneit has to be the current one it cannotbe lostum again to put things in contrastavailability matters a lot because if asa customer you cannot access your datain most cases you cannot function as abusiness but that being said if we areever facing the very difficult choice ofkeep your data correct or keep itunavailable for a little bit durabilitywould Trump because durability will stayforever availability might come back ina few minutes right and I'm sure some ofyou have similar applications where youhave those kind of long-term versusshort-term concerns again I'm not sayingavailability doesn't matter and in amoment I'll go at length about how weare trying to reach if unit St too butwe always have as Architects think whatmatters the most right and what are thedifficult choices that we have toconstruct when we look at a system nowum one aspect I didn't put on the slidebut I'm sure everyone has it in theirback of their mind is cost because whatwe want to do is of course provide theright availability but also manage artiso we can provide competitive pricingremain profitable all the things thatall of us want to be at and that kind ofplays from a third angle into thearchitecture so I kind of want to keepall of this in the back of our mindsdurability availability cost when wereview all of that and of coursesecurity matters without saying I'm notgoing to talk a little a ton about thataspect but I do want to highlight thatwe're a little bit like GP in the factthat yeah we hold the data for ourcustomers but we can't access it that'snot our data that's their data right sothat also needs to be at the kind of atthe kernel of the thinking that theengineering has when it comes tomulti-tenant systems like that um nowwhat I want to do next is kind of take avertical slice through the most basicuse case I don't want to throw my entirearchitecture or entire architecture atyou but kind of exemplify that thinkingthrough a through one example and thisis the most straightforward one somebodygo comes in and wants to retrieve a fileyou know retrieve some content um and uhin thatcase we first would go through a globalload balancer and that Global Lobalancer would first of all tell whereyou are because we have customers aroundthe globe and we are running multiregions but you are from birth as acustomer from that point you became acustomer you are being assignedsomewhere it could be Us West Us EastEurope but you'resomewhere um and at the point yourrequest comes in we are already multi wedecide okay your request lands at sayZone B in in US West okay let's let'swork with that assumption for a momentuh and then we go through our APIgateways we go through our cash we gothrough all of the optimizations that umI put there and for Simplicity I evenomitted like half of them but the mainpoint is let's say the request Comm inand boom availability is Zone goes offin the middle of that or a particularservice in that availability Zone it canhappen right and you can uh you can saythat's like a three nights kind of eventso the way we constructed that is bydefault we stay within availability Zonebut if something happens we jump to theto the adjacent one and one can ask whydon't you do that by default why don'tyou just uh because they are close bylatency shouldn't be a big deal but forus costs now I go back to that principleI mentioned because we deal withpetabytes of data we deal with terabytesof data that probably got downloadedsince I got on this stage you know inignite's case so we really have tomanage our costs and we don't want to docross availability Zone traffic justbecause we can right we want to do itonly if we have to and that's part ofthis how the system was architected andof course if availability Zone goesentirely uh for a while at that point wego and we uh um uh all of the requestswill land on a given availability Zonegoing forward right so now let's ask thequestion what happens if an entireregion goes down right that's probablythe question that front of mind but umin that case we have going back to thearchetypes active in a fail over if youremember team's overview that was thethird archetype that he covered so wehave this fail over region where weconstantly go and we PR provision uh ourComputing there we constantly replicatethe data there it's always current butit's not servingrequests and I'll tell in a moment whybecause that sounds you have it whydon't you go the whole way right so I'llexplain in a moment why it's we wantdon't want to do that but first let'ssee if a region goes down we go and wetake a decision and we move to read thatreadon region right there and then nowuh why don't we want to have them liveall the time now I go back to that firstprinciple I talked about durability anddata recency because now many of youprobably know what cap theorem is andhow difficult it is to achieve it skillnow we want the data to be consistent solet's say I'm here editing some file andsomebody is there in the other part ofthe globe is Ed in the same file andthey have different regions serving thatone going out so you can imagine howmany cases now we have to deal with notto lose any of our two modifications tothat content it's almost impossible ifnot completely impossible I don'tremember the theory but let's say it'sif somebody manages to do that they cancommand a ton of respect and money sowhat we do basically we are saying okaywe want to simplify that active failover and if we fail over we do firstWhat's called the read only failover soyou can access your data but you cannotmodify it yet because we still if thatregion is not fully out and it's stilldoing some kind of semblance of life init we still might be in a tough spot butif that outage is prolonged we cannottell our customers say you know we canonly read your data you can modify itfor some time so that point okay let'supgrade the fill over to a primary atthat point it's a oneway street at thatpoint basically that becomes the primaryand and that one might become now thefailover and of course it would inolsome more so that's kind of a patternthat I don't think is that unique toignite if you kind of think about it innew architect your systems you worryabout cost you worry about umavailability it's definitely worthconsidering in many scenariosum so at thispoint um I'll just quickly want to giveone little counter example and thenwe'll pass to my colleagues for Q&A soback in the beginning I mentioned we'vegot two products or not products butlet's say pillars and I mentioned therewas one admin pH in where as anadministrator you can look at the stanceof your data um and there we actuallyhave a slightly different archetypebecause here the stakes are a little bitdifferent of course as an admin youcannot flight blind right if suddenly aregion went down it cannot just wecannot tell you okay for 2 days we willnot this thing will not be active butthat's different from saying nobody cancollaborate in your company right that'sa slightly different level of impact sohere we are running single region wedon't have a failover region but we caneasily create one on demand and the datais replicated so unlike with thatprevious example where we can like Snapour fingers and get a fail over withinan hour half an hour whatever here mighttake maybe half a day and again thatgoes back to the principle whereconstantly trying to balance and see anddo exactly the right amount ofavailability not more not less somethingthat gets us to the right cost[Applause]bracket"
}