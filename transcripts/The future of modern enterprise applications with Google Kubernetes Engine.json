{
    "title": "The future of modern enterprise applications with Google Kubernetes Engine",
    "presentation_type": "Breakout",
    "categories": [
        "Architects, IT Professionals",
        "ARC207"
    ],
    "video_id": "3ZvGPUecArM",
    "time": "Aug 29 02:15 PM - 03:00 PM CDT",
    "transcript": "foreign[Music]so I just wanted to thank everyone forjoining us todayum it's really awesome to be back againin person at least for me it's been alot of fun seeing everyone and uh beingin person for conferences again you knowTSA lines are back and jet lag is backand all that good stuff but today wehave a really fun session for you we'regoing to be talking about Googlekubernetes engine and why it should beyour Enterprise compute platform of thefutureum my name is Victor Salve I'm a productmanager I work onGoogle kubernetes engine or I'm going tobe calling it just gke going forward I'mjoined by some colleagues uh to my to myright here Sean DarringtonSean is the group product manageroutbound product manager for the storagespaceand we're really excited to be joinedtoday by jumpy Nakajima from Capcom whoflew all the way here from Japanso jump jump eight will be speakingtoday in Japanese and he's joined by atranslator Mika at the end all rightso containers and kubernetes right havereally been taking the world ofinfrastructure by stormum it's been providing uh on-demandscalability efficient resourceutilization for a range of applicationsfrom of course your modern apps which Ithink most of us associate containersand kubernetes withbut that's been expanding and it's beenextending to things like batch and ofcourse you've been hearing about AIMLof course gamesand even things like Legacy Enterpriseapplications are now being run incontainers uh in kubernetes Google opensource kubernetes back in 2014. and indoing sowe basically built the world's largestecosystem around containersand if you think of containers then as aspecification or a standard for runningcontainersum this means that your workloads arehighly portablebut in addition to the portabilityelement it's also created a uh anecosystem a huge community of OpenSource and and Commercial vendors thatare building and greatly expanding thevalue proposition of kubernetesso today Google remains really stronglycommitted to kubernetes we are by farthe largest contributor to open sourcekubernetesum and Beyond open source gkereally leads the pack as the mostautomated and scalable managedkubernetes platform on the planetwe support up to 15 000 nodes percluster and there are customers doingthings like virtual super supercomputers in their clusters they're ofcourse also doing large-scale llm modeltraining and so forthso why gke and it turns out thatdo-it-yourself kubernetes is oftenreally challenging right in the form ofa high degree of expertise requiredum it's also very labor intensive soyour day two operations the labor effortrequired there is very very highso what we're trying to do with gke isPreserve the spec the open source specas much as we canwhile providing additional managementcapabilities to alleviate that burdenand manage it for youright and so this is things like forexampleupgrade management right release newreleases of kubernetes come out so wehelp with upgrade management we helpwith things like automated backups whichSean's going to talk aboutautomated node scaling and all of thisgreatly reduces your day to operationstoil and gives you the control you needto be able to run your business the wayyou want to run itsecurity is another aspect of kubernetesthat we really lean into right so out ofthe boxwe bring uh a baseline foundationalkubernetes security postureand best practices alerting all of thatcomes out of the boxin fact we work at every layer of thestack from things like Hardware ofcourse to the virtualization tier tothings like OS we built a custom OS forrunning containers effectively andsafelyand of course kubernetes itself toprovide that comprehensive securitypostureI think when most people think ofkubernetes they think of scale right andof courseum kubernetes and gke scales to meet thedynamic needs of your business and atthe time for that workload so thatalleviates a lot of the work having todo with manually scaling up and manuallyscaling down instead you canautomatically have gke provision yourinfrastructure on demand and then watchit scale down when it's not neededand all of this comes with thereliability you'd expect from a companyas committed to Containers as as Googleis so I don't know if you all know thisbut almost everything at Google runs oncontainers so including search GmailYouTube and so forth all of thoseServices all run on containers and we'vebeen running containers for a very verylong timeand so it's not just the technology butit's also our Engineers our SRE teamsand so forth we're a completelycontainer first organization thatprovides us with a tremendous Advantageuh when it comes to actually operatingand running gke as a cloud servicenow in addition to the cluster levelcapabilities that I've just talked aboutyou probably heard that this week weannounced gke Enterprise Editionand this is really exciting becausesure we have a lot of services aroundthe cluster but what about if you have10 clusters 30 clusters 100 clustersa thousand clusters it starts to becomevery challenging to manage them at scaleso we've introduced additionalcapabilities like fleets and teams whichallow you to Define scopesand basically keep everythingsynchronized across regionsand also consistent rightthis is all packaged with security in awell integrated formatokay so what can you do with gku rightthere's of course modern applicationsand I think everybody kind of againthinks of that as the first thing heywe're going to run some microserviceswe're going to build something new let'suse kind of this sort of architectureand containers and so forth but there'sactually a whole lot more to it thanthatgke is being used for a number of thingsincluding stateful and Legacy folks arerunning databasesin gkeand Sean's going to be talking aboutthis quite a bit but that's reallyhelped by the notion of automatedbackups that will snapshot yourpersistence layerumsafe blue green deployments and anextensive selection of storage Rightstorage options and again Sean at thetoward the end of the presentation isgoing to get into this in a much moredetailand then of course you may have heardthat this year uh AIML is pretty bigrightum vertex AI is of course ourrecommended managed solution for AIMLbut it turns out gke is also an amazingplatform for AIML and that's becauseit Blends ideally the ease ofprovisioning of Hardware acceleratorslike gpus and tpusit Blends that with capabilities likecompact placement and highly efficientutilization of resources resourcesharing GPU sharing and so forthand this is often needed when you wantmore control right such as if you'retraining your own models and so forthand in fact I mentioned this earliermany of the largest llm models today arebeing trained on gkethe last one I'll mention is games andof course we're going to talk aboutgames in a lot more depth todayum from from for the gaming perspectiveuh especially live service gamesthey're also thriving on gke and inlarge part because of the elasticscalability meaning the unpredictabledemand of when people are playing thegamesum coupled with the fact that it'shighly cost efficientand we're able to reduce the managementoverhead associated with managing allthat infrastructureso let's dive into games a little bitmore I'm going the right direction hereso at Google Cloud we're actuallybuilding a platform for live gamesand this unifies performancewith Analyticsso we've identified three critical areasfor gamesand we're going to talk Beyond gke alittle bit just to paint you kind of abroader pictureand nakajima-san is going to be talkingabout a specific implementation thatCapcom did of this particular stackso starting with the game servers thisis the technology that brings togetherplayers from all over the world into acommon real-time experience we've opensourced the agones server which is agame server and it runs reallybrilliantly on gke and it scales verywell on GKnext up are databases Cloud spannertends to be that the the database ofchoice there for its massive scale andglobal global footprintand then of course there's analytics youwant to know how your players are are uhfeeling about the game and feedback andso forth so bigquery and vertex AIcombine really well there to allowcompanies to understand that thatbusiness Dynamic and what's happeningwith the players rightso do we have do we have any gamers inthe audience I know there's got to besome gamersyeah okay awesome I remember playing uhStreet Fighter in the arcade when I wasa kid spending most of my allowance onquarters into the arcade gameum so you've probably heard of StreetFighter as well it's a massively popularlive gameumand it runs on Google Cloud uh and andit's including uh and that includes ofcourse gke for the compute layer soplease join me in welcoming Mr jumpeiNakajima technology lead for capcom'sBlockbuster live game Street Fighter 6.[Applause]thank youand sothere you go okay okayum[Music]good afternoon my name is Nakashima andI am from Capcom Japan excuse myJapaneseumso Street Fighter 6 is a global Serviceoffering and it is built on amicroservices architecture deployed ongkethe services are interconnected throughgrpc and their traffic is controlled bythe andos service meshdatabase isso the database is cloud spanner whichallows for massive scaling whilemaintaining consistencyisthen after matching up playersthe actual games are played peer-to-peerbetween clients[Music]this is because fighting games havestrict latency requirements[Music]is this so this is the diagram showingthe network infrastructure configurationfor Street Fighter 6.clusters are built in four main regionsU.S Central South America Europe andAsiaum[Music]regardless of which region you areaccessing from HTTP requests are alwaysmade to the same clusterforeign[Music]what's important to note here is thatthe access lines to the various gcpServices only extend from the maincluster which is U.S Centralthat receives the HTTP requests foreignERS have grpc routes that lead to themain cluster which is U.S Centralum[Music]so that no main clusters ask the maincluster to process the data via GL PCand the actual access and processing ofthe data is only done by the mainclusterislet's take a closer look at themulti-cluster mesh configurationiswe have just explained the HTTP requestsare taken care of by the main clusterbuilt in U.S Central from any regionforeignnetwork is really aiding usforeignthis way the path of data access can beUnifiedumum sorry it's very small on this chartbut there's a little red lineum and this is lying is the only accesspath to the various resources uhbasically it means that the um only themain region would process the data andthat this line does not extend outsideof the main clusterforeignthis way user data is not scatteredacross the various regions and onlylatency and latest and remains constantno matter where it is accessedumokayso this means that the data access is onuh sorryum so this way the user data is notscattered across the various regions andlatency remains constant no matter whereis Success however you have websocketaccess flying to each Region's clusterand these uh the battle have serviceservers on the street fighter 6 and andbasically this is a visual Lobby serversforeignize the action of up to 100 players andneed to communicate with regions thatare physically close to each other dueto strict latency requirements foreignhowever the the visual Lobby servers arebasically onlyumperforming the action synchronizationcommunication and the data operation isrequested from the main cluster via glpcsthis is also to prevent the scatteringof the data and unify the data accessrouteso[Music]umthis access path which goes through glpcis constructed by multi-cluster mesh ofanthos service mesh which goes throughgcp's internal line it doesn't go out tothe internet which actually allows formuch faster communication than using theinternetthank you that is all for mypresentation that was the briefexplanation of the architecture thankyou very muchthank you nakajimasan for sharing yourexperience and congratulations to youand the team for Street Fighter 6. thatwas fantastic[Applause]so you know as you heard Victor sayearlier you know kubernetes and gke hasbeen around for a long time and manyEnterprises have been deployingstateless applications on gke and that'sperfectly fine to do however as morecompanies are deploying statefulapplications some of the moretraditional Enterprise applications arebeing migrated and deployed on gke andthat changes the way you have to thinkabout managing those Services becausethings like backup now become importantthere are other things around storagethat's also important but regardingbackup for gke this is something that welaunched last year at storage day andnext uh the virtual next last year andthat has been generally available forover a year nowwe're proud to be leading this and thisis now generally available as a fullymanaged service for you to deploy andprotect your clusters and this is adifferentiator for Google Cloud as youlook at the different reasons and thecapabilities of being able to nowprotect cluster configurations in a veryautomatic and consistent way it givesyou a very granular option to deploybackup for gke to protect the clusterconfiguration your namespaces of choiceapplication consistent backups and ordata that's used by gke so if you havepersistent data that needs backing upthis is a fully managed service that youcan take advantage of it's one of thethings that allows not only the recoveryof the data in the event of datacorruption or human error but one of thethings that a lot of our customers areusing this for more so than protectingthe data itself is actually the clusterconfigurations and that gives you asdevelopers in devops the opportunity forvery easy and consistent rollbacks forerrors that happenunfortunately very very frequently rightso as you're upgrading the Clusters ifthat happens you have a run into aproblem you can roll back that clusterconfiguration very seamlessly you alsohave the opportunity most gka clustersuse persistent disk or block storageothers use file systems and I'll talk tothat in just a moment but backup for gkealso gives you that opportunity to useand protect the data stored onpersistent disk it gives you thisflexibility to store and protect thecluster configuration and storage in aspecific and retention lock period sowhat this means is for a given backuppolicy you can Define what clusterconfiguration you want to protect thedata and you can set a specific periodof time that that backup is immutableand indelible so you can set it for daysweeks or years if need be and what thatmeans is that whether it be human erroror ransomware that compromises and triesto compromise your data that backup issecure you as an admin and even as asuper admin privilege cannot change thebackup policy you cannot delete thatbackup nor can you even delete theentire project that that backup isprotecting once that retention lockuntil that retention lock periodactually expiresso it's a great thing to protect thatbackup for that retention lock periodbut also from an Administrationstandpoint if you set it for a year andyou want to change that period to threemonths you now have nine more months towait until that one year expires so takethat into account as you're settingthose retention lock periods but this isalso one of the things that allows you alot of flexibility to protect thoseresources and data as I described at avery granular level and recover clustersin the same region either to the new orexisting cluster or as a migrationopportunity if you're moving from U.SCentral One To Us East four you can usethis backup and recovery process toactually recover and create new clustersin different regions very seamlesslywith the exact sameconfigurations that you use in theoriginal oneso very flexible to do but as Imentioned earlier this is one of thethings that's a little bit surprising inthat customers use backend for gke toprotect the cluster configuration as alarger percentage is actually protectingthe data itself so you can use it in avariety of ways cyber Haven will betalking in a session around backuprecovery how they're able to actuallyrecover their data 24 times faster withbackup for gke they have the confidencein their devops process and forregulatory purposes the backup Vault andthat retention lock period that I wasdescribing is one of the things thathelps them satisfy their compliancerequirements so you can hear more fromcyber Haven in that session as wellstorage is one of those things that alot of times has been an afterthoughtfor GK or just deploy persistent diskand you're done however you heard thismorning from Thomas and Sundar that 70of the unicorns today are using gkeright and are using Google cloud ingeneral and a lot of those trainingmodels actually require or prefer filesystem access for training they can't berefactored either from a cost or a Timestandpoint they can't be refactored touse object storage or maybe it's alatency requirement and if you don't usefile systems now you avoid having catdata cached locally in the pods andclusters but you also have idle GPU andTPU Cycles waiting while you'reextracting from object storage loadinginto the into the containers and thenbeginning the training so there are afew options you can look at one is in apassive storage the other is posix rightthese are full file system semanticsaccess multi-writer use cases you alsohave the option for fuse which has beenopen source for over 10 years that youcan use with object storage and thatgives you essentially the way a filesystem access to a bucket right and inall three of these scenarios whether itbe fuse posix or NFS it's all maximizingyour GPU and TPU Cycles because it's afile system it's immediately availablefor training and so what we announcedlast week and is generally available nowis cloud storage views this is a fullymanaged fuse offering that you can usefrom Google Cloud it's also free ofcharge but you can now Mount Yourbuckets like they were a file system itprovides that file system semantics butit's not full posix compliance so thereare some caveats like multi-writersupport and things like that but youhave the ability now to have yourmassive Scale Models petabytes Etcimmediately mounted to gke through theCSI driver use your pytorch andtensorflow workflows to do this and itprovides massive scalability and massiveperformance we have customers todayexceeding 30 terabytes per second ofthroughput with cloud storage and theirtrainingnot everybody's going to be at thatscale and that's perfectly fine but itis one of the things that now gives youmore opportunity to deploy a fullymanaged service in the packages that weactually provide we have a number ofimages that you can use or you can do ityourself as wellthe other thing that we announced lastweek was for file systems and in thiscase training models that need ultrahigh performance and multi-writersupport and that's where we introducedparallel store this is currently inpreview this is another new and newlyintroduced Google managed service it's aparallel file system so now it'sactually built on Intel deus's opensourcecloud-based deployment model it's a keyvalue store so it's very Cloud friendlyin terms of massive scale in terms ofthe number of nodes capacity Etc thatyou can do but it's one of the thingsthat actually maximizes the gpus andtpus as well because every pod andcluster has equal access to the data itsupports full posix and it's a parallelfile system but it's also ultra highperforming and provides ultra lowlatency so in this case you can see thatwe're 6.3 times faster than otherscratch luster deployments and weactually can exceed terabytes per secondof throughput with millions of iops and0.3 milliseconds latency okay verydifferent contrast to cloud storagedifferent purpose but it's anotheroption for a given training knowledgeyou have we have also integrated arational coding in the back end toprotect that data from if a node goesdown in in or data volume goes Offlinethat persistent volume is actuallyprotected via Erasure codingso these are two of the options thatwe've recently introduced cloud storagefuses GA parallel store is in previewand file store is a third option for NFSfor gke there are two different filestore options file store Enterpriseactually three I should say file storebasic file store Enterprise and filestore High scale they each havedifferent features and functions I'm notgoing to go into all the details in thissession here but these provide theoption to use different performancelevels capacity levels availability andpricing for gkefile store Enterprise we've recentlyenhanced the multi-share capability forthose that are using files forEnterprise multi-share you've been usedto this at 100 Gig persistent volume youcan now get down to 10 gig capacity perpersistent volume so again it's an NFSshare it's available to hundreds orthousands of pods in a given cluster ithas multi-writer support so every podknows exactly what file they're openingand closing and writing and you're notgoing to compromise your data from thatperspective so it's a great way to havea scalable way for not only the data tobe accessible across all pods but ifpods go down the other pods still haveaccess to the exact same data and yourapplications just continue to runI mentioned the differences in filesstore between basic Enterprise and highscale Enterprise has a 49 SLA associatedwith it which means that it actuallydeploys and the storage in three zoneswithin a region and synchronouslyreplicates every single right across allthree zones in a given region so nowyou're protected from a zono outage andif your architecture is such that youwant to do the compact placement thatVictor was talking about in differentzones within a region you can also matchthat availability with the storage offile store Enterprisebackup for gke I described how that canprotect data the persistent data thatyou want in persistent disk as well ashyperdisc but just the block storage andpersistent disk that will also supportfile store in the near futurein the meantime what we have coming nextquarter is the ability to just use filestore basic a file store backups toprotect either the entire instance ormultiple shares if you're using the 10gig persistent volumes you can have thatlevel of granularity two different waysto protect the file store data basedupon the file store to you that you'redeploying and that'll be available nextquartershortly after that we'll be supportingbackup for gke so you can use the backupvault in the retention lock in the samegranularity and policy based protectionin the meantime you have another way toprotect the data until backup for gkesupports file storeso we've been expanding our fileofferings not only for AI and ml butobviously for other HPC workloads andother General compute workloads but thisis a way you can kind of think aboutyour training model needs whether it betext or video and image and it's not aone-size-fits all right you can choosethe right storage for different modelsand pick and choose on the far left youhave the option for ultra low latencyvery high iops file sizes that are inthe kilobytes or tens of megabytes oreven you know 50 megabyte range that'sgreat for parallel store it's a greatsolution for a parallel file systemmaybe also file store where maybe youdon't need the terabyte terabytes persecond you don't need that massive scaleyou can choose something in the middleand on the far right when you look atcloud storage you can choose this nowwith fuse as a file system interface foryour training model needs but it givesyou that still very high throughputlower latency because it's regardless ofthe storage bucket you're using thestorage class it's still milliseconds ofresponse times or maybe tens or hundredsof milliseconds whether it be standardor all the way down to the archivestorage class with cloud storage you'restill talking milliseconds it's notminutes to hours to days as some otherSolutions have right so you now you havea Continuum of options for file systemaccess across parallel file systemsposix NFS and object storage to choosefrom across your portfolioI mentioned cyber Haven in um Arc 200 isa session there if you look at ARC 208these are some other sessions ofInterest Arc 208 is going to be talkingabout cloud storage and fuse in moredetail and codeway is going to beco-presenting their code way and forthose that aren't familiar have agenerative AI model for avatars they usegke cloud storage fuse to do this andthey've been able to ramp up to millionsof users seamlessly so you can hear moreabout codeway in that onethehyperdesk the persistent disk Imentioned with GK Arc 219 ruin Hess isgoing to be leading that with hyperdiscis our next Generation block storage andthen a little more detail on file storeas well as net volumes and Arc 220 andthen lastly Arc 217 in the lower leftthere for the high performance Computingthat will go into more details aboutparallel store and some of the specifictesting metrics that we have there sothere'll be many more many more detailsin those breakoutslastly I wanted to ask everybody justremind if you have a chance to fill outthe survey form it'd be great to getyour feedback for for that session so wecan always improve upon that and withthat I'd like to thank everybody forattendingforeign"
}