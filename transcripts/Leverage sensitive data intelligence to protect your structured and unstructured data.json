{
    "title": "Leverage sensitive data intelligence to protect your structured and unstructured data",
    "presentation_type": "Breakout",
    "categories": [
        "Security Professionals",
        "SEC103"
    ],
    "video_id": "f0RLO1QSp8c",
    "time": "Aug 29 06:00 PM - 06:45 PM CDT",
    "transcript": "foreign[Music]andwe're here to talk to you aboutprotecting your sensitive data rightso a few years ago Scott and I launchedhere cloud data loss preventionand we aim to bring you a core set oftools to help you to protect andclassify your sensitive data so that youcould reduce your data's risk throughits life cycletoday we're excited to share with youthat we're expanding beyond the lp tosensitive data protectionwhile important data loss prevention isreally just one use case that we see ourcustomers apply our tools towhile this new expansion will bring youmore tools and new features cloud dataloss prevention and the DLP API aren'tgoing anywhere we're not going to haveyou have to migrate or redo any code orredo any Integrations you'll find thatall in our new home herewe'll also continue powering workspaceDLP and DLP Chrome and Beyond coreEnterprise so those services willcontinue benefiting from all of ourinvestments and improved discoverabilityand improved detection models while wenow invest more in other areasone of the two key new components thatwe're investing in is what we call thediscovery service which we're going totalk a little bit about nextso Discovery is a service thatautomatically generates sensitive dataprofiles all of all of your data in anorganization it helps you determinewhere your sensitive data is so that youcan help protect it and make sure thatyou're doing all the things you want todothere's no jobs there's no code someusers would write inspect jobs andmanually try to build their ownDiscovery service so this takes care ofthat for you with automaticallyautomatic generation and orchestrationof these profiles it currently supportsbigquery and big lake and will beexpanding the cloud SQL before the endof the yearonce Discovery has been enabled in yourorganization there's a lot of differentways in which you can use the producedata sensitive profiles from the consolethe profile gives you a starting pointto just see general information aboutthe data sensitivity and data risk ofall of your data and tools toinvestigate who has been using thosethat how how the data is being used andhow what you're doing right now toprotect itforeignthere's also a new level of granularreporting data profiles go all the wayto the column level and so in thisexample I have a column that's actuallybeen classified as a credit card numberso the data the profile will tell youhey we think this is a credit cardnumber we think this is a socialsecurity number we think this is somesort of medical identifier we'll go allthe way into the column and tell you andtell you whether you've done anything toprotect it is it public does it haveproper policy tags on itwe'll also tell you things like is thisstructured or unstructured which mightindicate more risk of more datainformation hiding in thereof course we have hundreds of detectorsthat this works with and you can alsocustomize what data you think issensitive because sometimes your dataneeds and what you consider sensitivearen't the common ones like credit cardnumbersyou can also include all of the normalcustom detectors that you've known thatwe've had with DLP APInow the easiest way to turn this on isto just turn it on for your whole workone click turn it on and go but we knowthat most companies want to start slowand try sampling in a smaller group andso you can choose to select a folder ora project or projects and startprofiling only data within those smallareas before you go and turn it on forthe entire organizationyou can also choose when tables arereprofiled so you might choose that heyI trust where the data comes from this Ionly want to reprofile this if a schemachanges but I have another table wherethe data is coming in from a third partyI don't really trust I don't know howgood of a job they're validating thatthey're not sending me data theyshouldn't be and so those tables youcould choose to reprofileevery week every day whenever a datachanges at whatever Cadence you'd likeyou also have options to control when todo backfills so we obviously have a lotof data sitting in here already and youmight not have the budget the profileeverything all at once and so you canchoose to set backfill time stamps tosay only start profiling tables for thelast quarter or three months and thenslowly move that clock back as you havebudget to profile older datayou can also set things like minimum rowcount which helps you not profile datatoo fast so employee creates a new tablethey haven't really populated it withenough data signals for us to get a goodprofile of you can ask us to wait andwait until it has enough Data before weprofile itof course all of these controls can becustomized and configured for differentdata sets projects folders tables youcan set up regular expression patternsand set up the combination of rules andpatterns to just best suit your needsyou can even set up so like say youdisable all profiling on your testgenerated projects but maybe turn onmore frequent profiling for a data setthat is say a public folder or yourpayroll datawe have two modes of billing for thisthere's consumption billing andsubscriptions there's also a free toolto help you pick which one would bestsuit your company's size and needsonce you've enabled Discovery there's alot of different connections where wesurface data profiles to help you withyour operationswe have free out of the box reportingusing liquor Studio which gives a greatbird's eye view of your organization'ssensitive data and it's really usefulfor auditing and Reportingwe also can enrich your Cloud securityand secops by sending these profilesinto Chronicle and security CommandCenter so having this data alongsideyour threats and vulnerabilities letsyou prioritize your security work basedon the sensitivity of the impacted datadata Ops teams can also leverage thesesignals from right within dataplex so ifthey're doing a search or an auditacross your entire organization andthey're combining and searching withbusiness tags they can also combine insearch with the data profiles in thisdata sensitivitylastly since Discovery runs continuouslyyou can build custom alerting orevent-driven orchestration using CloudPub subthis could be useful for automatingpolicy changes or automating remediationor building customer alerting to alertyou say when a table goes from low riskto high risk and you had thought it hadno data data of concernScott's actually going to Now demo foryou that now that we've turned this onfor an organization how you can alsotake other actions with the dataprofilesthank yougreat thanks Jordanaokay here we're going to switch over tothe demoand umwe're going to walk through how you canLeverage The Discovery and the resultsto really take action to better protectyour dataand for this demo we're going tointroduce Angie who's a data complianceofficer for a large Financial Financialfirmand Angie has a problem they call reallyan ocean of dataand it's just full of unknowns and theway they look at it is there's aboutfive percent of the data that theyreally understand well and they knowit's sensitivethere's about five percent they knowisn't sensitive and then about 90 theyjust don't even know about sometimesthey don't even know it exists and a lotof times they just don't have control orkind of visibility into what's going onthereand this is what we want to try to helpAngie solve todayso the first question is really how canI get a viewacross of the data across myorganization even the data that I don'tknow about the data Maybe that's sittingin those projects that are in my org butno one's self-reporting it they're notshowing up in any dashboards at themoment how can I get that kind of widevisibilityso we're going to use the discovery toolthat Jordana mentioned and we're goingto go in and look at a live dashboardthis is on our test Organization forAngie and this is an example of thatbird's eye view we've been running itfor a little while we can see thataggregate view of all the data thatwe've profiled it's a very highlysensitive org now at the very bottomhere we can see a daily activity chartevery day the summary of the data thatwe found and the risk profile of thatdataand you can see here that there's beensome pretty big spikes even recently ofa lot of highly sensitive data that cameinto the organizationand again this just gives a little bitof thatum heartbeat of the organization someonegoes in and creates a project createsmaybe some tables in that project thiswill just pick them up profile them andshow up on the report herenow from this bird's eye viewyou might want to drill down and look atsomething like in this case what regionwhat geographic region is that data inso we can slice it and drill down by byCloud region or geographic region hereor drill down and look all the way downagain to a table or an individual columnso in this case we've drilled down to aparticular area where we have datacoming in from a partnerthat we use that data but it looks likewe found some very highly sensitive datathat was unexpectedso we're going to go here from thedashboard and we're going to go into thecloud console view of that tablenow what we see here is the tableprofileand down below we see the individualcolumn profile of every column in thattableand we can see herethat we have one column here that'spayment card information it's highlyunique credit card numbers so we seethat ranking there that it's highlyuniqueand what that means is that it's likelythat every single value in that row is aunique credit card number as opposed toa low unique score would be somethinglike the same card repeated over andover and over again so again this is allinformation to try to help us understandthe types of data and the size and shapeof that dataso the first thing we really want tolook at is who can access this data andwho has been accessing this dataso from here we can seethe detailed IM permissionsand we can see for our organization thatthe entire data engineering team hasaccess to this tableso that's a concern everyone in the dataengineering team can access this tablethey have an access Grant at the dataset level or at the table levelnext we're going to jump into Cloudloggingand what we're going to do here is we'regoing to lookas you see in this report we're going topull a report of all the accesses overthe last 30 days on this tableand as this loads inwe seesome accesses in the past weekand then we see some accesses up herewe're just going to look at this firstone here a couple weeks ago one of ourdata Engineers went in and queried thistable and from the access logswe can see who the actor was it wassomeone named Scott it wasn't me but itwas someone else at the company namedScottand we can get down and even seeall of the fields that they queriedso this is a listing of all the fieldsin that table that were queried so weknowjust from this log that about two weeksago Scott went in and viewed all thisdata and we know from the profile thatthere was highly sensitive data in thereso now we have both answers here but wehave too wide of an access a lot ofpeople can access this data and now wehave evidence that somebody went in andsaw the data that maybe shouldn't haveseen itso really we've Angie's discovered thiskind of anomaly a highly sensitive tablewith people that have accessed it inthis case we see again that Scott hasgone in and accessed those particularfieldsand it turns outumthat Scott has a reason for accessingthis tableand so really the next question is howcan they move to a more least privilegedmodel without creating unnecessaryfrictionnow in this case that data engineerneeds to run an aggregate database allright so aggregate dashboard where theylook at the payment types and theyaggregate the most popular payment typesso they take that data they throw itinto their bi tool and they run thatimagine a pie chart of different paymenttypes with the largest amount being thebiggest pie chartbut in doing that they're really goinginto that table and doing a select starand pulling all that data downso we want to allow Scott to still runthat querybut we don't want those sensitive fieldsto be part of that accessso let's go back to this data profileand to fix this we're going to usesomething called bigquery policy tagsso from herewe're going to go into bigquery andwe're going to just look at what thetable looks like at the momentso we see here this is in bigquerybigqueries view we see the schema we seethose sensitive information Fields hereand what we're going to do is we'regoing to apply a policy tag to theactual fields in that table now for thisdemo I've created a copyof this table just so we can kind of seethe side-by-side comparison so this isthat same table where we've gone in andapplied policy tags on the individualfieldsto see the little warning that we seenext to thosebut the payment type and the transactionamount is still available so I can runmy dashboard report if I was runningthat you know count or group by paymenttypebut let me go ahead and query the tablehereand let's say I do a select starjust like that log showed beforewe're going to run this query and younotice I got a result it came back noerrors were generated but there's awarning message that saidyour data's been masked and we see ifyou look at all the fieldsa lot of them are reporting null eventhough those fields are actually havedata in them and what we're doing hereis we're creating that balance betweengranting access to the state engineerthat needs to see those certain Fieldsbut restricting access to the highlysensitive Fields like contactinformation and payment card data so Ican still run my analysis as long as Idon't need to use those sensitive FieldsI don't have access tonow the reason that we set that up is wewanted that statement to work a selectstar still works if we jump into thedata security policy that we set upwhat we're going to see hereis that this policy we've categorizedour data into a couple differentcategorieswe'll zoom in here to these financialand pii categories we can see here thatwe put a policy on those called nullifyand that's why we're getting back justno results for all of those columnswhenever I tag something so in this caseI tag something credit card number itrolls up to that Financial policy whichnullifies it for those users you canalso put in a loud deny policy or othertypes of masking and allow deny policywould have rejected my query if Iincluded the fields I'm not supposed tosee again you can find the right balancefor what you needgreat so we've solved this kind of leastprivileged problem with that withminimal friction we didn't have to go inand make you know copies of the tableand have different access lists andeverything we can apply those policytags and get that fine-grained accesscontrol while still technically sharingthat whole data set with the with theentire data engineering team in thiscaseso next let's say we want to be able todetect and mask structured andunstructured data at query time now whatwe just showed was taking that profiletagging The Columns and applying thatmaster so applying that mask at querytime but what if we actually wanted touse our engine and inspect the data andmask it as part of our SQL so for thiswe're going to go inum and we're going to show what's calleda user-defined function in bigquerywhich will actually call our engine liveas part of the query and for this we'regonna we're gonna use this this demo setherezoom in a little bitso we have a very simple query that hasfour rows of datawe're going to run thisand you'll notice that in in our testdata set which is sitting right hererows one two and fourare the same valueand what we're doing is we are huntingfor email addressesand we are using our deterministicencryption to tokenize that data soyou'll notice in the results rows onetwo and four are getting the same valueRow three is a different valuenow just to kind of emphasize that pointand why that's important let's run thatsame query but let's wrap it with aaggregate query so what we're going todo is we're going to count the emailaddressesbut we're going to tokenize them firstand what you see here is as expected weget one email address now tokenized hasthree values count of three and theother one has a count of one and thereason we're showing this is when yourun tokenized data like this you canstill run joins you can still RunAggregates but the actual data is hiddenthrough our tokenization it's obfuscatedand so we can do that at query time andsee that masking right herenow the full power of our engine alsoallows you to do this on unstructureddata so if we run a very similar queryherein that First Column which saysencrypted what we're seeing is we'veactually hunted for the email addressinside and in this case also a phonenumber inside of the sentence inside ofthe cell and only encrypted that part soyou also have the ability to process iton unstructured data and this particularmethod is reversibleso we show that in the third column wecan actually take the encrypted valueput it back in and with permissionreverse it back to the raw data so it'sa very powerful back and forth engineyou can choose one-way methods ortwo-way methods but this kind of showsyou that end to endand what's important hereis let's say that you had a particulartablein this case let's say we had email andnotes in a table and we wanted to runthis on one of our tables and create acopy that we could then share out toothers so in this case what we're doingis we're running that masking of theemail address masking of the emailinside of the note fieldbut we can actually now materialize thisview or this result and then share thattable or save it if we needed to send itout outside of bigquery so again this isanother way you can actually manipulatethe data so that when you materialize itit's now stored at rest in an obfuscatedformand what's really cool about this[Music]umsystem here is it can also work on justabout any table that bigquery can accessso here's me running that same query buton an external table so this tableactually lives in Cloud SQLin a I think it's a postgres databasewe're running that same query but you'llnotice that the from I'm actually doingan external table query on the on thedestination but I'm doing that sameselect statement with our user definedfunctionand again we get those results out butthis is querying a cloud SQL databasenowso really anywhere that bigquery is UDSor user-defined functions can be run youcan now leverage this to manipulate yourdata and again maybe materialize itsomewhere elseand it's actually not limited tobigquery uh this isn't a screenshot ofus doing a very similar UDF calling oursame DLP system but running in SnowflakeSAS systemso from here as you can see we have avery similar encrypted DLP functionand in this case we've done differentmanipulations it's a very flexiblesystem to do partial maskingor full encryption as we see here withthe card number it's revealing everymasking everything with the last fourdigits and on the social security numberit's doing a full encryption and then weapplied it to some data inside of thenote field in this case again huntingfor certain data typesso we wanted to show that that's reallyhow we can help Angie in this case takeaction protect the dataand we showed some of this stuff goingBeyond discovery that sort of inlinemasking and now I'm going to pass itback to Jordana to go in more depthabout some of the stuff you can doBeyond discoveryohyeahthere we goso we've shared with you Discovery butas I mentioned since the data protectionis meant to cover more than just thediscovery servicethe cloud DLP API still lives on and westill have a lot of other services fromwithin the console we offer apis and anative Cloud console tool to inspectdata storage systems including Googlecloud storage bigquery and data storeand even custom storage systems usingour hybrid apis to investigate and findindividual findingsthis is really useful when you needreally precise details about whereexactly all your sensitive data is foroften use cases around de-identifying itwe also have tools to help you measureprivacy Risk by looking at statisticalanomalies and common re-identificationmetrics these re-identification metricshelp you inform you on the likelihoodthat someone could reverse engineer whodata belongs to or who it identifiesfrom the console and our apis we offer anumber of de-identification solutionsWhich Scott has just demoed a few ofthey come in both API forum and we havenative support for data sitting in cloudstoragewe have many Advanced masking techniquesacross structured and unstructured datawhich can be used virtually anywhere ashe showedimportantly your data analysts and yourresearchers can leverage thesetechniques to tokenize data whilekeeping referential Integrity so no moresaying well I need to have the emailaddresses for anything you don't needthe email addresses please tokenize itjust don't risk it and these tools aresuper easy to use and they won'tinterfere with their jobs and theirability to use the dataour platform and our apis are superuseful in protecting your AI and yourmachine learn your machine learningworkloads you can remove sensitive Databefore ever training on it or you canuse it when customers interact with youas the data comes in from the customersand the queries or as you send responsesback our apis are fast enough to servethat traffic in real timetomorrow morning there's going to be atalk at 11 on data governance andgenerative AI that I encourage you allto go to to think more about thisour de-identification platform is alsobuilt into the contact center AI so thislets you choose how and when totransform your customer sensitive Databefore it's used in insights andtraining it's fully customizable byusing a de-identification template sothat you can Define when and how andwhat it does so whether it does fullredaction or tokenization or masking orsome other techniqueso in summary sensitive data protectionenables you to understand your datamanage that data's riskwhile still being able to use that datafor all of your important workloadsto get started you can turn on dataprofiles for free for 20 tables and someof our consumption apis also have freetiers you can also check out dialogflowworkspace dllp or beyondcore which areall powered by sensitive data protectionthank youforeign"
}