{
    "title": "Build AI quickly, collaboratively, and with confidence with Colab using Vertex AI",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML124"
    ],
    "video_id": "-FXWM7pPmso",
    "time": "Aug 30 05:30 PM - 06:15 PM CDT",
    "transcript": "foreign[Music]good afternoon everyonethat's itcome on man we're up here we're up hereexposing our hearts and Minds to theworld let's try that again goodafternoon everyonethere we gowe are here to talk about building AIquickly collaboratively and withconfidence using collab on vertex AII think I'm supposed to introduce us nowokay so I am nenshad bartoliwala I workfor the Department of Motor Vehicles inthe state of Californiabut uh it's just a reference of thekeynote yesterday but uh I my day job isI actually run the product managementteam for the vertex ml platform and I amjoined by my esteemed colleague who isvery humble but he's one of the ogs ofthe vertex team he's been on this forwhat five years yeah five years sobefore when vertex was just a littlebabyKarthik was the daddyhi I'm I'm chandan I'm a nunchucks teamI'm a group product manager and I'm aI'm going to talk about collabEnterprise today so ask if you guys likethe product tell me uh if you don't likethe product also tell me but preferablynot too loudlybecause I'll hear itI will hear it okayokay so let's do a product introductionand overview that'll be me then I'llturn it over to Karthik and he'll walkyou through uh some of the details okayso what is collab Enterprise first ofall let's get a show of hands how manyof you actually use collab uh in yourday-to-day workfantastic so uh that's going to remainan amazing product available for uhconsumers but we now have an Enterpriseversion okay and so it has all thecapabilities of what you see in collabuh today but it also brings all theEnterprise level security capabilitiescompliance support repeatability Etcthat you need if you want to run this atscale in your business okayso history of collab it launched inNovember of 2017.uh what then happened is by November of2019 it got to 1 million users that isnot easy to do for any product butcollab just took off people got veryexcited by it uh Alpha fold launched oncollab in July of 2021and uh in June of 2023 we added somereally cool features I don't know howmany of you have used it yet but we'rekind of into this whole code assistancething uh hopefully you heard about duetyesterday as well as our Kodi models andso AI code assistance made its way intouh collab the consumer version of collaband uh then we introduced a really coolfeature in July called Auto charting youactually can take a data frame and askthe system to go and generate the righttype of chart and the system will kindof automatically do that for you uh justa small note but in the preview actuallyevery time you submitted that Karthikwould draw the diagram for you in thebackground now the software actuallydoes it and here we are in August of2023 and uh collab is now ready as anEnterprise product it's ready for all ofyou to start using today and we'rereally excited for you to start takingadvantage of some of its capabilitiesnow one of the great things aboutworking in Google cloud is that we haveaccess to some of the most amazingresearch uh from our Google Deep Mindand research teams and one of the coolthings that we get to do as productmanagers here uh in a dis in addition togiving demos about the Department ofMotor Vehicles is that we actually getto take research that comes out of ourresearch team and productize that and Ithink you've seen some pretty amazingexamples uhwe started this journey with somethingnamed after one of the founders uh kidselephant how many of you remember Hadoopremember when that was The Craze yeahyeah I still have the t-shirts my wifewon't let me wear them anymore they'retoo old but I still have them so westarted our journey in 2003 actuallytaking Hadoopwe took some of that technology and ofcourse commercialized it but we alsoalways have a parallel path for takingthings and bringing them uh into theopen source world and so I think thefirst set of libraries that reallystarted to democratize uh and bring uhto a broad Market neural networks wasactually tensorflow how many of you haveactually coded against tensorflow peoplegood awesome and so uh you know webrought tensorflow to the market we'vebrought kubernetes to the market andthese were all technologies that wereused inside of Google but then wedecided to make to you know available toa broader audience but we also tried toprovide these capabilities directly inthe cloud so you can see examples areautoml product for examplewell is one that came out of Googleresearch and then we productized uh Nasneural architecture search uh it is notthe rapper Nas he is not part of ourroadmap but neural architecture searchuh became a product in the Googleportfolio is still available today andthen you see more recent capabilities infact uh how many of you know thatTransformers the technology behind allthis channel AI stuff actually wasdeveloped at Google in 2017. yes thankyou for raising your hands diffusionmodels so if you've seen things likestable diffusion who invented thattechnology Google Google research andnow you know given where we are in 2023we have this amazing partnership withGoogle research and Google Cloud wherewe can take capabilities like thosemodels and like collab which wasactually built by Google research andbring it to all of you in an Enterprisecontext so we work really really closelytogether and it's funso one of the big things that all of youtold us is that uh you wanted to be ableto use these type of notebookenvironments across multiple Googleproducts and confession we haven'talways been great about that okay we'renot perfect but we do try to listen toyour feedback and get betterso with colab Enterprise how many of youheard the announcement yesterday aboutbigquery Studioremember hearing that yeahso the colab Enterprise and bigquerystudio is the exact same collabEnterprise in vertex so those of you whowant to do things like uh build your uhbuild your data sets and do featureengineering using bigquery data andusing big frames and some of thattechnology you could do that in colabnow you have your data set and you wantto start doing some uh you know plottingor statistics descriptive statistics ontop of that you could do that in colabyou decide you want to train a model andnow you want to do that in Vertex or youcan use bqml you could do that in colaband then deploy of course these modelsfrom collab so it's a single environmentthat spans the entire data to AI Journeywhich makes things a lot easier thanhaving to go through four or fivedifferent tools to get one job done forone uh one Persona or type of userokay is let's get let's get started isthat the cue for you to do your danceyeah that's that's the demo Let's uhlet's go ahead and switch over to thedemo machineand let's not let that play because wedon't want to do thatokay greatum so uh first of all ninja justmentioned collab Enterprise is availableboth through vertex and through bigqueryStudio I'm going to go ahead and bringit up in vertex right nowsoum what happens when it pops up is youcan see that there are two distinctpanels on the screen on the left handside is a no managed notebook storageand on the right hand side is where theeditor will pop up I'm going to go aheadand create a new notebook what this doesbehind the scenes is it creates amanaged ipy and B file it's industrystandard ip1d you can upload yourexisting notebooks to the servers andeverything should just kind of workumand it does it in the region U.S Centralone that I've specified now I uh I'mstopping on this phone and just kind oftalking about it a little bit because ifyou use collab today you'll notice thatit's a drive-based product one of thethings we did when we brought thisproduct to cloud is we introduce managenotebook storage that is compliant withall of gcp security capabilities andcompliances so you'll find that thenotebook storage does behave a littlebit differently but it's very much ontrack to be featureat Future parity between the twoofferings now the next thing I did is Iactually just executed this first codecell in the notebook and what happenedhere is that the notebook connected to aruntime a virtual machine that's runningin the same region and it's private tothis user me and it executed the codethat's therethis is actually using the defaultruntime which is an N2 standard two it'sa fully managed short-lived VM that weallocate as you start executing codejust so you don't have to do anyconfiguration to get started you justhit play you get the compute you need itruns wait the Karthik I use theseproducts every day I have to set upnetworking and vpcsc I have to yodel ata certain volume in order to get thisall set up did you just tell me that Icould open this and just get startedright awaywhat a wonderful prompt uh yes youabsolutely can and we also understandthat people have needs where they wantmaybe larger machines they wantdifferent machines they want access tothe full power of all the acceleratorsavailable on gcp they may need toconfigure networking or organizationalpolicies we have another mechanism inthe product that I'll show you in asecond for doing this but for right nowlet's just hang out with a friend thedefault runtimeand I'm going to go ahead and start thedemo talking about the thing thatabsolutely nobody else is talking aboutwhich is uh code generation andgenerative AI I'm sure you haven't heardmention of it yetum but the product actually comes withtwo code gen features um code completeand code gen code complete you can juststart typing in stuff and as it figuresout what you're typing in it should beable to do things like give you thatsuggestion kerasload model I don'tactually like that one so maybe I'll domodel equalssequence and hopefully it'll some pointfigure out that I'm trying to dosequences as you notice this codeGeneration stuff will get better as youtype in more code into the notebookit'll use the entirety of the contextthat you provide in the notebook togenerate code it'll likewise do the samething with the code generation featureso I'm going to go ahead and do that andI'm going to click createand I want to say hey can you give mesome Pi torch code for classifyingan imagean amnest data setand it helps if you can type and notmake too many errorsoh sorry I actually want to hit thegenerate button there it goes sowhat have we here we have Pi touch codethat loads the mnis data set fromtorchism and trainsa modelin addition to the code you get therecitation the set of sources that wereactually important in gendering thiscode now I'm a long time googler asnunchod mentioned so I'm not as big afan of Pi torches some people and I kindof prefer Keras so let me go over and dothatgreat it also gave me Keras code fortraining data based on the mnist dataset but Karthik is this just a stockexample no it actually isn't and this isactually really nerve-wracking to be uphere right now because this could havedone something else and given you aslightly different core sample this oneactually looks like it will run in abouta few seconds I'm actually going to hitplay and see if it does and uh well forthe sake of the demo I really hope itdoes but before I do thatlet me show you one other cool thing andI can just kind of saysummarize the above codein bullet pointsagain my spelling skills do need someworkbutit gives you a nice little summary ofthe code but you could then maybe go inand drop in as aumas a comment into this anyways I likethat I like that particular trick it'sit's pretty useful again if you put inbuild up your notebook and start addingmore stuff the code completion the codegeneration is going to get smarter it'sgoing to give you more useful and morerelevant results because the entirecontext that you provide in the notebookis being used to inform those thoserecommendationsnow comes the fun part for you maybelesser for me and I'm going to actuallyhit the play button and we're going tosee what happens hereso so far so good it's actuallydownloading and running this code andnow it's actually turning a modelI want to take a moment while this ishappening to talk about compute again soright now this is running on the N2standard form machine that is a defaultmachine for this notebookthis is a deep learning model it's notthe deepest learning model you couldcome up with but it is deep learning andit will probably benefit from having aGPUavailable to itnow we haveum one of the big and powerful featuresof collab Enterprise is the ability toaccess all of the gpus that areavailable on Google cloud and the wayyou can do that is through the runtimetemplates featureI'm going to actually stop that and goahead and flip over to the runtimetemplatessocreating uh accessing more powerfulcompute on collab Enterprise is atwo-step process first step is anadministrator creates a runtime templatesecond step is to use the instantiates aruntime based on that template I'm goingto step back and give you just a littlebit of context around why we decided toset this up this way on the one hand weknow that many users are going to want alot of a lot more powerful compute thanit's on the standard but at the sametime What folks who run data scienceteams run platform teams tell us is theywant some control over the types ofresources that uses spin up in theRegency spin up they want to be able toset certain configurations maybe theyneed to run them on certain vpcs andmaybe they need to disable external IPSthings like that this is where runtimetemplates comes in the idea is we wantto give you as an administrator theability to control the type of computethat you use has used while still givingyour users as much flexibility aspossible uh to be able to spin up whatthey need when they need itso the process for creating a templateis pretty simple you click new templateyou go ahead and run to this t-stepprocess for example let's say I want todo a deep learning runtime templateI've been executing everything in U.SCentral once I'll keep it in that regionyou could eventually add labels othertypes of metadata to thisyou can then pick the machine you can ifyou want to give your users access tosay a100 you have the full A2 Line Ifyou're looking for L4 if you have the G2line there in this case I'm going to goahead and pick something like an N1 highmem16 and that lets me attach an NvidiaTesla T4 or a V100the next step is I can specify somenetworking and security configurationshere as wellI've already created a template thatfulfills this basic format deep learningtemplates with GeForcenow once you as an administer have donethat you use this when they actuallywant to use itcan go ahead and go back to the notebookI'm going to go ahead and make that fullscreen and click on this connect to aruntime button up herenow you get two options here you get tocreate a new runtime and you can do itfrom a templateuh and what will happen is we'll spin upthe machine if you specified it for theuser to use that machine will be privateto that useroryou can connect to an existing runtimeI've actually already got a um a runtimemade from that particulartemplate spun up so I'm going to goahead and use that right nowand we're going to go ahead and connectto itwe're now connected to that and I'mgoing to rerun this codebut then I'm going to show you that I'mactually now running this on a machinethat has aT4 GPU attached to it I want to open upthe built-in terminaland you'll see that we havein we have all the Nvidia toolsinstalled on the runtime for your usersto work with I'm going to run Nvidia SMIthat's going to show you that I have aT4 running and that is now currentlybeing utilized at 17 percentby this model that's being trained hereandumthere it goes nowumwhile that's running I'm going to goahead and talk a little bit aboutcollaboration so I'm really happy withthis notebook I think it's greatum I want to of course share with myboss and then shot so that he can tellme how wonderful I am uh which is that'swhat you will normally do is just youknow sing my praises and anyways is thatthe right talkso you can go to the notebook browseryou can click on shareand we actually enable sharing via I ampermissions so this is the standardsharing mechanism across Google cloudand standard permissioning mechanismacross Google Cloud uh all you have todo is Click Share you can go ahead andsay Hey I want to share this withnenshardthere he is and I can give him Iactually want to give him code editoraccessandthere you go he now has code editoraccess to this notebook he can come inhe can run it he can do whatever hewantslikewise when somebody shares a notebookwith me I'll see it under this sharedwith me tab in the notebook editor againeverything is regionalized one of thecore foundations of how we've designedcollab Enterprise is to really respectregionalization that is something I knowthat's really important for a lot offolksum herenow in addition to sharing the other funfeature that we have is we actually alsohave built-in versioning so the systemevery few minutes will go ahead and savea snapshot of the file provided thereare some changes that have been thereand you can of course compare thecurrent version to the prior versionsnow because this is a notebook it'ssometimes not the most helpful thing ifto do this because you'll see theoutputs we thought of that and we allowyou to remove the output from the diffso you can see just the portions thatare your code you can also of courserestore and revert to a prior revisionof thissolet's go back and see how our modeltraining has actually hopefully wrappedup while we were working through thatand it did it did finish up and we endedup with the model that looks like it'sprobably pretty good it's uh accuracy is0.98 so you know this is this is awesomeI do want to just stop here and sayum you knowsix or seven years ago training in adata set for emness to this level ofaccuracy was a research challenge rightlet alone having the code to do thatwritten by AI that wasn't something thatwas happening in now six seven eightyears agoum so this is you know I know this is ademo that people have probably seenvariants of a number of products butit's still pretty spectacular how farwe've comenow that I've finished pontificating I'mgoing to go ahead and talk a little bitabout howcollab Enterprises integrated with bothbigquery and vertex so what I wanted todo here was I just wanted to run througha very simple example with a very commondata sets the penguin status to show youhow we could very easily pull data frombigquery use bqml to train a model havethat all integrated with vertex modelregistry so you can kind of doeverything from a fairly small set ofapis so here I'm just using the stock BQclient to go ahead and pull data fromthe public data set if you listen to thebigquery studio announcement you'llnotice also a new API coming out calledBig frames that lets you load this intoa bigquery native data framerepresentationnow if you print out the data frame youget that auto plot feature that nunchuckwas talking about there's actually twoparts to it the first is you can convertthe data frame to an interactive tableand then you can go ahead andfilter on any of the columns within itum or you can just go ahead and click onthis Nifty button and the system willuse some some smarts to try and figureout what the visualizations of this datathat are likely to be the most usefulfor you areand you can take all the codes that isgenerated and put it into you can takeall the plots that have been generatedyou get the code for them you can reusethem and work with them if you wantnow once that's done what I alwaysnotice about this particular example isthese 2D distributions for those who arefamiliar with the Penguins data set it'sthe goal is to build a classifier yougive it a bunch of measurements aroundindividual penguins and you're supposedto figure out hey what species ofpenguin does this particular recordbelong to and what this shows you isthat hey likely this Coleman length andcome in depth they're probably prettygood predictorsand if I were building a model fromscratch that would be useful informationinstead what I'm going to do is I'mactually going to run bqml in kind ofautoml mode and then she had mentionedautoml a little while agohere all I really have to do is I haveto tell bqml that I want to use thelogistic regression that predicts on thecolumn species and then register theresults of the vertex AI model registryright nowit's a couple of seconds to run so I'mjust going to go ahead and pop over tovertex AI model registry and show youwhat it looks like once it's actuallydoneso if I pop over to model registryI have my Penguins lr6 logisticregression six sixth attempt I shouldsay andjust before I jump too far actuallymodern registry is kind of the centralrepository for models and vertex andbqml all the multi-10 bqml all the modelC10 vertex can make their way here andfrom here you can do a bunch of stuff soin this particular caseI could go ahead and create anevaluation job I can deploy it it'sactually already got a live endpoint Icould create a batch prediction job Ican createum everything's version so I can seemultiple versions of thisI want to go ahead and click on thisview in bqml and I'm going to use thisopportunity to show you two things firstof all I want to show you that the modelis also available via bigquery studio soyou see it right here and you can seethe training metrics you can see theevaluation metricssecond thing that I wanted to point outisas nunchak said all the notebooks thatyou work with invertex are also reflected here inbigquery studio under the notebooksection and then the third thing Ireally want to show you here is that Italked about how these VMS use the endusers personal credentials for those whohave used notebook products on vertexbefore or in gcp you know that in thepast we use service accounts as theauthentication mechanism and what thatmeant is you couldn't keep track of theuser's activities from The Notebook intoour other services we now use send usescredentials so if the user callsbigquery from within the notebook theywill seeum that is traceable now they will it'llrun on their own credentials you'll seetheir identity and so onso with that said I'm going to flip itback over to nunchat for a slider twomaybe we can switch back to theumthing okay actually let me take the nextslide here next two slides it's veryhurtful I'm sorry you just handed it tome and now you're taking it back I'mgonna take it back that's hurtful okayI'm sorry about that I heard nunchucksfeelings that messed you up on my perfwe'll seeum anyways uh just as a quick review ofwhat we did we did a code completioncode generation autoplotfrom the other key features we talkedabout collaboration I am based notebooksharing automatic versioning then wetalked aboutum how we have zero configcompute option as well as a configurableflexible compute optionand then we haven't talked a lot aboutEnterprise horizontals but as we get theproduct through a life cycle and get itinto GA and Beyond we'll be supporting akind of full set of gcp securitycapabilitiesnow oh now I get it yes thank youokay so I just want to walk through thestack so that we understand where thesecapabilities fit into the overall uhvertex set of offeringsso the first part of course which is nota direct part of vertex is the GoogleCloud infrastructure okay and of coursewe depend on this very heavily we havestate-of-the-art capabilities with gpusyou saw Jensen Huang on on stageyesterday but we also announced the newversion of our tpusv5e I think if I got it correctly and wecontinue to invest to make sure that weprovide the absolute best rock solidHardware that you can use for AI andmachine learningthe second layer of course is the modelgarden and you would have seen thatyesterday as well and the idea for us isthat we're very proud of our first partybottles the one that we've builtourselves like palm and Cody and imaginebut the fact is that even at the scaleof Google we can't build everythingourselves right and so uh We've we'vemade our approach very open we provide aton of Open Source models you saw llamaand code llama yesterday but we alsohave stable diffusion and many manyothers that we provide inside of themodel Garden environment and the idea isyou should have the choice if you wantto use an open source model that allowsyou to do what you want to do you shouldyou should be able to use it there's noreason you have to use Google's modelsthen the AI platform is whattraditionally we've called this vertexactually now vertex AI encompasses thiswhole thing uh it's a it's a brandingshift but it's important to knowso the AI platform represents all thecapabilities aroundbeing able to build and evaluate modelsso that includes notebooks that includesour training service that includes ourmodel evaluation services and the likeit includes all the services aroundbeing able to what ml Engineers use toput models into production so this isthings likepipelines and our prediction service andthe feature store and and thiscollection of capabilities and then ofcourse many of the pre-built apis thatwe can use in order to be able to uhsolve specific use cases without havingto do a lot of configuration and one ofthe things that that we're very proud ofis that we have built all of thegenerative AI support in vertex directlyinto the platform we haven't outsourcedit to somebody elseso you all the skills that you've builton vertex already whether it's using ournotebooks or using our training serviceor using our inference serviceeverything that you did for predictiveAI the generative AI stuff uses theexact same platform it's all thesecurity the compliance the way we usegpus and tpus is exactly the same andthat is not the same approach that someof the other folks in the market havetaken okaythen we have two package package systemsthat we provide one is search this isEnterprise search so being able tosearch on your data and being able toground the results how many of you haveheard this term hallucinationright yeah that's not just for GratefulDead concerts anymore it also happenswith these large models thank youuh it's you know it's uh these modelsactually will make things up and sobeing able to ground your data uh andand show empirically that the resultyou're looking at on the screen isactually uh derived from data that youactually have in your Corpus is reallyreally important and that's where searchcomes in and then of course conversationuh everybody's is in chat bot land Ithink you know everywhere you go you'reseeing people come up with new versionsand new iterations but these can be verycomplex it's not just about informationseeking you can actually do entiretransactions inside of a chat interfaceand so all of these build on top of eachother so actually the AI platform Powersmany of the large language modelcapabilities in search Powers many ofthe large language model capabilitiesinside of conversationthen there are solutions some of you mayuse in your businesses today these arethings like Doc AI which continues toget new innovation or contact center AIcapabilities Etc but the key point I youknow I want to emphasize to everyone isthat you know vertex has become thisvery very rich platform it's not justthe just the core infrastructuralcapabilities but many of these higherlevel services and uh colab integratesreally well with all of them so if youchoose to use collab because you want todo in fact in the model Garden when youclick on fine tuning an open sourcemodel it'll open up a collab notebook wewant all of these services to integrateand work well together so that you canget to productivity quickly it's not funhaving to stitch together a bunch ofservices you know we we know that and sowe've we're trying to make it a loteasier and make the entire vertex stackwhich now includes search andconversation these other areas workreally nicely and and help all of youget to productivity quickerI think it's back to you oh thank you umso uh this slide is for those who arealready using vertex workbench and thequestion we often get is how do we thinkabout the differences between workbenchand Jupiter labso you know workbench is built onJupiter lab in the C standard veryfamiliar to a lot of your users a lot ofdata scientists and analysts live inJupiter lab today the product is veryflexible very customizable and againit's open in the sense that it's builton the open source version of Jupiterlab so you can do a lot of customizationyou can bring in extensions things likethatit's a good choice for data scientistswho are already using Jupiter lab maybeon their laptop and you'd like totransition them onto the cloudit's also good if you're working withvery complex projects where you havethings spanning multiple files maybe youhave shell scripts and Python scriptsand other things in there it's reallynice in that scenario and it's got areally nice set of native git supportbuilt right into itcollab Enterprise on the other hand iskind of designed to be more of a zeroconfig serverless experience it's veryfocused on collaboration it's excellentfor users who don't want to manage orworry about compute at all they justwant to hit go and start typing and runtheir code it's great for projects thatcan be encapsulated in a single notebookand it's good for users who don't wantto worry about git where that built-inversioning is going to help them keeptrack of their work and avoid data losswithout having to do and do a bunch ofgit commandsso that's how we think about both ofthese products and and how they live inthe market and the types of uses theymight be uh applicable towardssogoing with the theme of vertex is nowkind of one large platform where we'retrying to take you all the way throughthe ml journey I want to use the nextdemo in the next few minutes to talkabout how you could fine-tune afoundation model using our SDK fromwithin collab Enterpriseuh how many people out of curiosity arethinking about fun fine-tuningFoundation models gen AI models okay sogood amount if I think about it multipletimes a day absolutely that's greatthat's greatum so uh in that sense this is this isprobably how a lot of ml is going to bedone in the future you're probably notgoing to start with nothing you're goingto start with one of these Foundationmodels you're going to take yourcompany's data your data or dataspecific to the problem you're trying tosolve fine tune and that's going to behow you get really performant thing sothis is a really important use case andwe want to make sure that we make it assimple as possible so if we could flipback to the demo computerI'll go ahead and show youhow simple we do make itokay so I'm going to go ahead and popinto model Garden again in the the themeof showing you how we're trying to makesure everything comes together anddoesn't feel as like a bunch ofIndividual Services but one cohesiveplatformyou can pick any of the existingFoundation models or any of thefine-tunable models that we have fromvarious sources and if you click on themyou will often get a link that says opennotebook and what this does is it willopen a notebook in Co-op Enterprise thatgives you instructions how to work withthat particular model and then you couldexecute that particular notebooknow I've actually made a slightlysimplified version that shows you how totune text lesson as I have labeled it sohopefully demo threeI think what I really want to justemphasize is like howsimple this issofirst thing I'm going to do is I want todo some setup I'm going to you know putin my project ID regions Define theservice account that can be used andthen from within the SDK I just say heyI need to pull the list of textgeneration models right and then I'mgoing to pull from the pretend set and Igive it the name of the pre-trainedmodel that I want to work with in thiscase text bisonand then you know you can immediatelytest and see if it works right you cando model.predict give it a prompt andit'll give you backa response therenowto tune the model it's literally thisblock of code right heremodel.tune model you give it yourtraining data you specify someparameters and then you specify whereyou want the job to runand then you click on play now whathappens when this happens this actuallycreates a Vertex pipeline job and I'mgoing to go ahead and click over so youcan see that pipeline job in action fora secondso for those who aren't familiar withvertex pipelines this is a machineLearning orchestration System it's builton top of cube flow pipelines and whatyou're seeing here is a pipeline thatactually goes through and does all thethings necessary to tune a model using afairly efficient algorithmfor doing thatumand then once it's done tuning the modelit actually goes ahead and it deploysthat model to an endpoint so you canstart testing itthis pipeline takes a little while toexecute about 30 to 40 minutes or so soI'm going to actually go ahead and showyou when that's done by clicking on thisview alternate tuning jobs buttonI do have to pick the rightregion and you can see I've been I'vebeen doing this a lot I've beenpracticing my demo quite oftenumso I'm going to pick one that I'vealready got set up here and I'm going toactually click on the test button hereand what you can see is that thatimmediately takes me toumto The Prompt Library here but you cango ahead and ask it you know you canprovide prompts and test it so I can sayhey tell me the best thingsabout vertex AIand umit should give me back hopefully a nicenice set of things about vertex Ai NoSimplicity power flexibility securitythese are all things we want to talkaboutand literally that's that's all that youhad to do to tune this model that thatmodel does live in the model registrythat we talked about earlierum you can see it here you can see it'sbeen deployed you can look at theendpoints you can kind of do whateveryou want to do from this from this pointherenow uhsorry support the U.S Central one toshow you thatthis model was trained in in theNetherlands but uh deployed in Iowa soit's it's quite a global modelas you can seeso with that saidum let's say I want to now evaluate amodel and the question now becomes howdo I do that I'm going to go ahead andflip back to collab Enterprise for asecond and I want to show you the codesample that actually does thatand it's equivalently straightforwardthere isn't a lot more that you have todo here it's simply you get the tunemodel that you just tuned and you haveto provide the identifier to it and thenyou actually provide your ground truthdatapicking a particular task you need to domodel.evaluateand again this spins up a Vertexpipeline that you can go take a look atand then in the model registryall of these results areregistered and you can kind of see howthey compare to each other if you'redoing multiple runs on multiple versionsfor example this particular model I'vebeen training and tuning in a couple ofdifferent ways and umevaluating with a few different sets soI can go ahead and see oops I don't wantto do that I can go ahead and see thedifferent metrics from the differentruns I've done and how they compare upagainst each otherand so again the point we're trying tomake here I think is that we've tried tobring this all together into onecohesive platform we have an SDK thatmakes it very easy for you to executethis Foundation model tuning evalprocess so if we can flip back to theslidessolet's just go ahead andokay so the just a recap here is youknow you pull that we pulled thatFoundation model we've initiated atuning job in an vertex pipelines itgenerated some adapter layers uh andthen the model was registered with modelregistryuh it thenserve that model in a pretty efficientwayapplying the new adapter layers uh andthen you could call that model and testit and see what happened so that is theentirety of the workflow it took maybeyou know less than 20 lines of code toexecute and do so very verystraightforward everything's built ontop of vertex pipelines technology thatmany issue already used and are familiarwithand umso overall I think we're making a lot ofgood progress of making some of thesekey workflows very very simple for youum I'm just going to close out here Ihope to have a little bit more time forquestions but it looks like we won'thave that by saying uh collab Enterpriseis in public preview today it'savailable via the vertex UI if you golook at it if you want to access it by abigquery studio it is behind an allowlist please contact your accountrepresentatives and they'll help you geton that and the code generation featureis also behind and allow this so if youwant to access that let us know andwe'll get you on there as well so thankyou everyone for your time on the umafternoon of the second day and I hopethose of you have happy hours to get toI'm not standing a new way or anythingelse so thank you and have a good day[Applause][Music]"
}