{
    "title": "What's new for data and AI",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA209"
    ],
    "video_id": "bj-MkdrSeU8",
    "time": "Aug 30 01:45 PM - 02:30 PM CDT",
    "transcript": "foreign[Music]for data and AImy name is firat and I'm here with mycolleagues Vincent and also materse whowill be taking over from me as we talkthrough the session so we have a packsession actually so what we'll do iswe'll first coverwhy everyone is really looking to do youknow data and AI Investments how theycan get value out of that and we'll thengo and look into some of the Innovationthat supports the need as well everyoneis talking around uh you know AI thesedays right it is not a secret if you godown the you know exhibition Hall everysingle vendor has something related toAI but how can you get the value out ofthis how can you really see your AIprojects going into production and getthe value is really the key for that andwe'll be touching base to some of thechallenges that we have been observingand we'll be touching base how thingscan come togetherreally to solve these challenges as wellwith the rapid acceleration and you knowwhere we're titled generative AI thisyear d10 AI platform teams are reallypresented with new challenges and thereare a lot of challenges firstly aroundin ability to enable the organization atscale usually you find there are fewteams who can traditionally do mlprojects also itthein an increasingly complex environmentas well which tools do you use there area lot of applications and Tool basesthere also at the same time which onesare going to make the most impact inyour organization is a key you can seethis as a multi-objective optimizationproblem in a way right where do weinvest and where do you get the most outof it and it is really challenging tokeep up with the pace of innovation evenif we look at the foundational modelsand stuff you'll you'll be hearing thatthere are a lot of them be coming outall the time they use models with youknow fever parameters or you know moreparameters and such as well rightand the you knowsorry I'm going wrong directionand I've been warned about this theclicker you press down it is notintuitive and this presentsopportunities for us as well right soif we can bring all users together if wemake all users as part of the data andAI ecosystem and if we manage theserisks that and challenges that we seetrade governance that goes not from thedata side but also to the AI side aswell we'll be you know dealing with someof the complexities that we see and ifwe provide the users and the teams withthe most Innovative and the latestapplications and the tool stack they'llbe able to succeed and this reallybrings us the you know how you can getthe most out of uh from your data and AIprojects it'steam sports it shouldn't be that youhave a data engineering team and youhave a you knowdata science team and they don't worktogether we really need to bring themtogether and they should really worktogether but all of this can only happenif you have the tool sets that supportsthat right the tools that you haveshould be able to allow collaborationbut it should also enable the governanceof it as well and you should reallyinvest into the solutions that keep youreally ahead of everyone else there's anopportunity costI spoke recently today one of theleading Banks and their CDO told me thatthey invested into just over 100 mlprojects and only five of them gone intoproductionthis there's a huge opportunity Costaright because they they weren't surewhether they had the right governance inplace for example to be able to see andapply and answer also The Regulatorsrequirements as welland we are also seeing this from theanalyst community and everyone is reallyaligned with the same as well so thefirst is you really need to set thefoundation for your data and AIecosystem and let's talk to that alittle bitdata warehouse have been around for along time they have been around forreally four to five decades they havereally helped us to answer what was inthe past they've been really reallysuccessful but they have been really youknowexpensive as well and they they willreally focused on one specific taskthen within the you know past decade ora little bit more than past decade westarted having the data Lakes right sothe data Lakes came to address some ofthe challenges that the data warehousesthemselves had and they were reallylooking to answer some of the questionsnot just what was happening in the pastbut also what is happening now as wellstill you know most of them are notlooking into what is going to happennext and that's where the lake housescomes and that's where an environmentthat you have that you can getmulti-modal data and also you can havedifferent personas all operating in thesame ecosystemthe good news is that our data Cloudreally data and air Cloud really fitsinto thiswe have the building blocks that allowsyou to have that AI lake house withinGoogle Cloudit starts with the complete threat ofthe Native Solutions these are mostlymanaged Solutions and it gives you theEnterprise capabilities but in this pollwe'll be focusing on just the data andAI portion of that right so the core forthe data is within our ecosystem isbigquery and within bigquery aroundbigquery we have the you know the dataproc and dataplex which deals with theHadoop side and open source as well asthe metadata management as well and onthe other side we have the vertex AIwhich gives you all the capabilityaccess to all the capabilities from theAI side of things which my colleague youknow Vincent is going to take youthrough some of the announcements aroundthatandand that is very similar to what youwould have you still need to bring thedata in you need to process that datayou need to understand that data and youneed to put the rail guards around thatwithin your organization to be able toreally answer some of the challengesthat we mentioned at the beginningwhile this thing that it should also beable to accessible as I mentioned tomost of the data personas that you haveas well and going beyond the datapersonas with some of the newcapabilities that was announcedyesterday with duetai is what we arealso saying too and let's talk a littlebit around that but if we take a stepbackin here youEnzo data AI platformtraditionally many organizations aredivided into a data organization and anAI organization right so you have thekey data engineering tasks which youbring the data in you cleanse the datayou transform the data then on the otherhand then you start doing some dataanalysis around that you do explorationwrangling and pre-processingand that date site goes and fits intothe ml tasks that you might have youwould be developing your models youwould be doing first your futureengineering selecting what are the keyfeatures that would have the most impacton the problem that you are solving andthe model that you are dealing with youtrain your model and you experimentaround that and this is an iterativeprocess and then once you are happy youdeploy right and then you serve the usecases that you have again this is aniterative process you learn continuouslyand you go and alter thatif this acts as a separate entities interms of the tool set and in terms ofhow the team set up it becomes verychallenging and let's talk around howsome of the tools that allows you tobridge that Gap together as well okayso one of the things that you can usethe AIML is if you are a developer forexample you can go and call an APIyou don't need to you know train anymodel and you can get access to thingsfor example it can be a vision API youcan go and call a vision API from vertexright it will be able to give you whatare the entities within thatunstructured data on the other end ofthe spectrum you can go and build yourmodel you can go and train the model anduse specific capabilities that weprovide to the vertex sidemost of the users will come into themiddle though more around the automl andwhat we call a bigquery which I'm goingto talk in a minute around it as wellwhereby you automate some of the tasksyou are automating the training part forexample and you are in you know doingmodels of the inference and this comesback with all the capabilities aroundthe llms as well these days it gives youit eliminates the need to build andmanage data pipelines you know let's saywe are using bigquery here and thengenerative AI models it also streamlinesthe governance and helps you to reducethe risk of data loss by avoiding thedata moments it reduces the need for youknow writing and you know managingcustom codes as well don't get me wrongI'm not saying that you shouldn't bedoing that I'm saying that most of theyou know teams your analysts and suchrather you knowmore numbers within the organizationright will be able to be part of thatuml engineer is still developing thatand making that available through thisenvironment and you're testing goes andscales much further than you could dojust with the data scientists and uh youknow the ml Engineers okay and it reallyenables you to break the barriers itallows you to do this in a secure wayand there's so many you know use casesaround us right so you can as I said youcan call directly unstructured daytimeprocess you know unstructured datathrough that whether it is coming astext or image or as a vision and thatthere's so many you know applicationswhat it does is thoughit gives you the capability to do theprompt engineeringfrom the SQL language right you areaccessing record mlthrough a data warehouse traditionallyor a data Lake traditionally and itgives you the ability to promptengineering and gives that creativityto the analysts who are nottraditionally you know focused on doingthe ml tasks rightand one of the customers in fact we wepublished a Blog this morning as wellaround this uh one of the things thatthey are doing is they take the data thecustomer interactions that comes throughthe ingest us into the lake throughbigquery and they use llms directly fromSQL they look into the sentiment andthey you know generate an email back tothe customer right this is a realEnterprise use casethat's how you bring data and AItogetherokayand there's there's more capabilities aswell that you know will be available tothe users for example by using the AIyou'll be you are also Bridging the Gapbetween the personas which I'll touchbase in a minute in in a bit more detailif you are a data engineerand if you want to uh look into a modelfor classifying some of the data thatyou are receiving you might not know youmight not you know have experience ondoing that before by using somethinglike directly from the interface itallows you to generate that code andyou'll be able to do that yourself itdoes a chord completion it helps you toyou know find out errors but it isfocused on the Enterprise use cases whatthat really gives us is it gives us theability to many users coming togetherand becoming part of the data and AIecosystemwhen we look at it who can actually useAI today right very few can researchml algorithms and new ml applicationsrightprobably you know tens of thousandsa step up is the engineersstill not in you know huge numbers butprobably we have a few million mlEngineers out there who will be able tobuild the modelsright the next is we have tens ofmillions of developers who can come andcall apis you can bring them and makethem as part of your data and AIecosystemand also we have analysts right analystsunderstands the business better thanmost of the engineers like myself rightthey have the context of the businessif you give them the ability to haveaccess to very sophisticated you know mlmodels they'll be able to give the mostvalue to you as wellthe idea is bringing all of the personasand making them part of the data and AIecosystemand we can you know really expand thatand we can look into you know how thisdemocratization of the you know personasgoes beyond as wellit comes from the toolsif the users are using similar toolsrightif they're accessing the same data setswhich is also governed based on theroles and everything that they havethey'll be able to achieve what I havementioned beforeand we also announced the bigquerystudiowhich is based on a collab Enterprisewhich Vincent is going to get a littlebit more detailbut but it is a single unified workspacethat allow SQL and notebook interfacefor all data users in one placeyou can use SQL pythonspark JavaScript or even naturallanguage you can go and describe becauseit has Duets AI built in as wellit gives you the ability to use you knowopen source Frameworks like you knowpandas and stuff to you know prepare andtrain the models that you havethis really leads into more improvedcollaborationbut at the same time with the dataengineering capabilities that comes withthe data quality and you know datalineage and such through the bigqueryside and dataplex side as well you canhave this scouring a supply all of thatthe key is though to focus on maximizingthe productivityand it goes beyondthat you know everyone is talking aroundvector embeddings and such how you canmake access to all the the vectorindexes through traditional uh you knowdata sources that you are using well thegood things is that you can see thevectors as the long-term memory for llmsand now with the capabilities that weare bringing up you'll be able to usedirectly to a SQL Vector capabilitiesjust like geospatial and such as wellbut you know beforehand nowhere to uhyou know Vincent let's take a you know adifferent view on what I have beentalking around the top bit is usuallywhat data analysts and data Engineersare focused onright but what we are saying these daysmore and more is that being asked toalso do what the bottom bit thetraditional data scientists and mlEngineers have been doingyou know the green boxes here representsthe ML and the blue boxes represents thedata analyticsand we are seeing and we'll be seeingmore and more impact and we'll be seeingmore of this happening as well and withthat I would like to hand over to uhVincent who will take you through moreon the uh bottom part of this thank you[Applause]great thanks Rodum so as everything fraud was talkingabout we can have far more impact byworking together bringing skills andcontext across the organization into thedata and AI workflows so what's thethread that really connects everythingso with collab Enterpriseuh that's where we're making the threadacross the data in the iCloud so collabthe public version from Google researchis already used by over 7 million usersbut we have been receiving feedbackwhere users to really use it inEnterprise production use cases theyneed the right security controls thatare consistent across theirimplementations on Google Cloud sothat's why we're bringing collabEnterprise into the Google Cloudenvironment with all the securitycontrols customers and it expectit Powers The Notebook experience withinbigquery studio which you just saw it'salso the core experience within vertexAI so it's the same notebook behind thescenes and we're actually bringing thisinterface to more surfaces on the dataand AI Cloud such as dataproc anddataflowthose will come in the futurethis all really drives collaboration andproductivity for data analysts dataEngineers data scientists machinelearning engineers and it's great forI.T because it's all the securitycontrols they would expectbeyond that I also wanted to talk aboutIntegrations between vertex Ai anddataplex so this brings org-wideorganization-wide search and discoveryof models and data sets to democratizeaccess and drive collaboration across anorganizationthis also comes at a low cost since youonly pay for usage of the data catalogAPI and any business date any businessmetadata added via the catalogI also wanted to touch on someadvancements we have with our pipelinesservice and accompanying resourcesso similar to what we did with modelGarden where we've exposed over 100different models from Google open sourceand third-party we're bringing pipelinevertex AI pipeline templates in thegallery so your users can go findresources that Google has alreadydeveloped pipelines for based on bestpractice best practices we've seeninternally and externallythis also democratizes access tostandardized templates so that you knowyour teams are working consistentlywe also added the ability for datascientists and machine learningEngineers to schedule pipeline runs sothat you're always and continuouslytraining your most important modelsso the next topic we want to talk aboutis how to extend your data and AIEnterprise writing strategy forgenerative AIso after a lot of thought we ended upwith this point of view on how ml Opsevolves with Gen AI and we've builtcapabilities that seamlessly plug intovertex ai's platform and bring this allto lifeevery blue box is something new that youwould have to think about and that we'vealso thought aboutand that's what we're exploring todayand all the capabilities we're releasingtoday so first if we start withDiscovery this is really where yourusers discover models so you we have tokind of ask ourselves and you would askourselves questions aroundwhat models do my users have access tohow can I find those who has access towhat how do I know how they were curatedand who curated themwhen it comes to customization throughtuning you need to know how your data isbeing used in that processhow your your tune kind of adaptersmight be used when it comes todistillationyour your organization can get more outof a foundation model by using less ofit which will increase the performancereduce cost and reduce latencyand when it comes to prompts you need toknow how those are being used by all theservices you're using and for retrievaland taking actionhow do you know that your or how do youimplementJenny I to interact with other Jennyeyes including taking action such asbooking a plane ticket based on a chatconversationand when it comes to evaluating andmonitoring these new powerful models youhave to take additional steps to makesure everything is going correctlyand for curated in data high qualityexamples for specific tasks and for yourdomain are even more important to getmore power out of these capabilitiesso I'll talk about a lot of the newannouncements that we have in thecontext of these four pillars around ourapproach for Enterprise readinessit's all around data governance andprivacy security and compliance supportreliability and sustainability safetyand responsibilityI'll walk through each of these pillarsand bring in the highlights thereso first on data governance and privacyso we're helping you extend yourgovernance and privacy to thecustomization of generative AIsowe've heard this consistently throughoutGoogle Cloud next but customer data isprocessed and stored securely along theway and it's not used to improve ourmodels unless you explicitly ask us tothis includes your your input promptsresponses and adapter layersI wanted to highlight tuning so we giveall of our customers the the sameFoundation models but we also know thatyou have a lot of proprietary data thatyou can use to differentiate yourselvesso we've released the capability fortuning where you can use a little bit ofyour data to tune our foundation modelswhich creates an adapter layer that sitson top that you have complete controlover that adapter layer is not used orgiven to any other customers it's justsomething for you and you can delete itat any time it just adds an additionallayer of customization on our standardfoundation modelsthe next things that we wanted to coverwere prompts so just continuing toreassure you about how Google thinksabout prompts we these we secure theseat every step and they're only used togenerate output for generative Ai and wedo we don't use them to train our modelsand on extensions this is the capabilitythat you can use to connect to otherreal-time data sources and to to driveaction such as booking that plane ticketbased on a chat conversationon security and compliance support we'rehelping you manage new artifacts andparametersI wanted to highlight our new version offeature store which was built from theground up on top of bigquery and thatmakes it so that you can inherit all theaccess and governance controls youalready have for bigquery which is greatfor it it alleviates data movement whichalso lowers costsand we now have leading low-levellatency for features so that's twomillisecondsthat's great for real-time use casesespecially in services like retailbeyond that for tuning management sotuning is extremely important now so byusing a Vertex AI pipeline service youcan orchestrate the tuning jobs managethose jobs and all the outputs getstored into model registry which is howyour organization can discover andcollaborateadditionally we also implemented a lotof new security controls and we know youneed this to use these things inproduction so VPC security controls CMACwhich is customer managed encryptionKeys access transparency and dataresidencyon reliability and sustainability we'rehelping you evaluate performance andmanage infrastructure I wanted tohighlight the new evaluation servicewhich has two new capabilities the firstcapability is automatic metrics which ishow you can evaluate the performance ofa foundation model against your groundtruth data and the second is automaticside by side which is how you cancompare the or compare evaluations oftwo different models against each otherbeyond that we have Ray rayon vertexwhich is a managed version of Ray and itextends the open source version of Reybut it implements or integrates verynicely into vertex AI so trainingprediction mlops and security controlsfor accelerators and Assurance we haveseveral new tpus and gpus that aresupported across vertex Ai and then theability to create long-running jobs andtraining which will help you assure thatcapacity and have lower startup timeson safety and responsibility we'rehelping you Monitor and moderate thegenerated outputI wanted to highlight safety scoreswhich provide scores based on differentcategories that may be that might beharmful and as as customers you can usethese to maybe tag content before itgoes to your users or block itcompletelybeyond that so we have recitation checkswhich provide sources from responsesfrom our foundation models are verysimilar to those in the training set soyou can use those and display thosehowever you'd likeand then for grounding to help mitigatemitigate against loose Nations weenabled you to ground our llm andFoundation model responses in factualdata that you already have yourselvesso with that we also wanted to touch onwhy it's so important to makeinvestments to keep you ahead of thepackwithout needing large teams of machinelearning researchers just focused on R Dfinding a good partner is criticalso I want to just briefly high that thisone more time everything in blue issomething that you or we would need tothink about and we have large very largeteams of data scientists ml researcherswho are always constantly thinking abouthow to do this for ourselves withinGoogle for all the different productssuch as Google search and YouTube and wetake all of our learnings and we makethat productized through vertex AI soyou'll always be at the Leading Edgewith usand this is just uh beyond the amount ofpeople we have I just wanted to kind ofhighlight and touch on some of ourhistory here that kind of proves thistrack record I know you can't read thedetails and that's not as important butit really just shows the timeline andthis all started with Hadoop where in2003 and 2004 we published papers onGoogle file system and that wasinspiration for Hadoopthen in 2017 it was Transformers wherewe published the seminal paper attentionis all you need and that reallygenerated a lot of the interest forgenerative AI that you see today and wecontinue to double down on innovating anAIso just to recap here's a lot of the newcapabilities that we talked about todaywe encourage you to check out some ofthe highlighted sessions later todaygive people a second to take picturesandso this before I hand it off to Mateoswho's our customer who's going to sharemore about their their platform we wantto leave you with this new AI Readinessassessment which includes generative AIyou can scan this QR code complete thesurvey and you'll get a sense of whereyou're at in your maturity level andyou'll receive prescriptiverecommendations on things that you cando across people process and tools onhow to go to the next levelso with that I'd like to welcome matteosfrom Grupo boticario who's going toshare more about how they use data andAI to meet their customers where theyare thanks[Applause]good hi everyoneso helloI'm Matthew Garibaldi from grouplet me go to the next slide so I comehere to show a business case using mostof the tools that these guys justpresent to you to say that that's trueit works rightand I'm a data and AI director in groupaudio let me first introduce the groupuh who isa Cosmetic Company basically we sellperformance makeups skincare products weare the biggest Cosmetic Company inBrazil we are mood brand as you can seehere in the bottom of the slide in mostof ourbrains that we sell we are Omni channelit's a very complex ecosystem there wework with B2B and b2c and we are in thetrend process we developed most of theproduct that we sell since the RND untilthey start right and talking about groupof which carry numberswe have a tree industry in Brazil eightlogistic warehouses seven offices plusmore than 45 000 employees directedindirectly last year we say we sold 4.9billions dollars and we are working witharound the far point eighty thousandstars and regarding this far part 8 000Stories the business case that I wouldlike to present to you today becauseit's a very complex as I mentioned andwe have a very nice and big challengeddata problem hereuh so starting from the questions uhonce we have all this this informationall this number of store what looked tobe the perfect are Optimizer to retailfootprint using an eye we have questionslike uh what should be the customerbehaviors front of our stores whatshould beum what happened with our competitorsshould we open a big a store in a bigcity or a small City we have a lot ofquestions and despite of that we alsohave a to answer is how we optimize OurStars that we are open today right andregarding that we divided the solutionof this problem in six steps that wepresent to you guys now and and all ofit then we are using Google Cloud theFutures here and the first one in thefuture we analyzed more than 2.7 000Futures regarding this problem includingsome business knowledge to understandwhat we should doFutures using big aquaries and they alsoare very large future starsolution in the second step we gothrough the prediction model we create aforecast model to predict uh what's thepotential sales of each region in Brazilthat we should have and with thedisputation we create a hit matter inBrazil where we should invest or not ourefforts right right but it's not onlyabout that we could we should understandabout in the third step our competitorshello effects cannibalization from othercompanies andelasticity of the demand and with allthesestep two and three together we go to thestep four in which we create a model tothe optimization model to find what isthe best place in solution to reallocateor create new stores here in the steptwo that's the predictive model we usethe light GBM in vertex zingai deployedin vertices Ai and then the firstOptimizer we use a gravity model alsodeployed in vertex AIin the five step we started the thefinal person to understand okay what wedid it works or not uh so we decided toopen three stars in which we pilot ifit's working or not the results of ourpredictor modeland in this validation side we alsodouble checks on Golden rules and at theend we could compare in this in the laststep the result of these new starsopened by our model versus the uh theother stars that were had had in placewe got like eight six percent of acurrency and this is what was very goodand give a green light to go aheadumwhat what are the benefits that we reachso first I will summarizing three bigbenefits the first oneis regarding scalability we couldcalculate it for the whole Brazil as Imentioned it's more than four thousanduh Stars a currency because we couldlook inside these mountains andefficiency we are efficiency torecalculating and everything againquickly and taking fast decisions rightuh and about the the results soas the green light of the pilot we gothrough2023 open more than 100 Stars uh basedin our model uh this is the best resultof opening star in the last 10 years ofthe company and we are very safe aboutwhat we are going we also find more than500um potential locations to open arereallocate to start from no place toanother and the most important ourreturn of Investments the Roy aregreater than 108so comparing with the other stars thatwe didn't have before this project rightuh talking about the gcp architecture asI mentioned in the beginning we use mostof the tools that the recent and faradjust mentioned here since the ingestionand the storage of the data and the thedeliverable of the value with machinelearning and analytics I believe thatone of the most advice that I should Iwould like to leave you here is to givea good results of a databases cases Ishould invest in three components likefirst a good data engineer team to makereliable and single Source data thefirst part the second in the datascience team and invest in the datascience thing not at the end of theproject not even in the middle it shouldbe the beginningas fire Dimension and the third one isthe system you needed a system in the 20process to put all these people togetherto work and make the the delivererfaster and quickly for the company totake good business decisions rightso this is the example so far efficientI finished I believe that you're gonnafinish thethe presentation"
}