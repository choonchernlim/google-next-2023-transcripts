{
    "title": "Exploring Google Cloud's data and AI foundation",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA301"
    ],
    "video_id": "uy5Ker43jxc",
    "time": "Aug 31 11:00 AM - 11:45 AM CDT",
    "transcript": "foreign[Music]so we're going to be talking about thefuture of data and AI on Google Cloudmy name is Samick VD I'm the area Techlead for data analytics at Google cloudand like many of you I've also beendoing a lot of work with AI recently andso we're going to talk about how thosedifferent pieces intersectand there'll be a few different piecesto this talk we'll look at some of thethings that we've just announced and howthose build a foundation for ourplatformas well as what the future might looklike and that's going to be a littlemore philosophical there will beaudience participation there will be aquiz so pay attentionand so just to get started let's look atthe presenthopefully you've been to some of mycolleague sessions this weekso maybe there's a little bit of reviewbut just talking about some of thethings that we've announced that aregoing to help to build this foundationfor data Naithe first thing is bigquery studio andI'm hugely proud of the team for alltheir work to put this togetherit is a notebook Centric experience forworking with all of your data and AI inone place whether you're using python orSQLand taking those things and putting themin a place where you're not having tochoose do I want a data workspace or anAI workspace it's all one unifiedexperienceand we we recognize that thosedisciplines are only going to get closerover time and so we really view this asa core piece of that offeringnow speaking of pythonwe're also really excited to announcebigquery data frames now bigquery hasalways been very SQL Centric naturallyit's a data warehousebut we also want to make sure thatthere's an excellent python experienceand so with bigquery data frames you cannow use your favorite open sourcelibraries in Python to write code thatthen executes directly in bigqueryand use that seamlessly with SQL mix andmatch however you wantso that's all surface leveland then if we look a little bit deeperone of the things that I'm reallyexcited about going toward the futureis the support for Vector embeddings inbigqueryand I really like to think aboutembeddings as sort of a third essentialdata type where you have structured dataunstructured data and embeddings whereyou could think about an image where youstart with raw image data unstructuredmetadata about that image structuredmaybe it's automatically extracted maybeit's manually annotated and then youhave embeddings that are generated forthat image maybe one maybe manyand what's exciting about these is itreally allows you to interact with largelanguage models and all sorts ofinteresting ways where they can sort ofidentify similarities that humans mightnot see and so this allows you to dothings like search across them you canuse this to identify data for a few shotlearning if you're building a promptaround that and I really think this issort of the beginning and thatembeddings are really going to be sortof the foundational capability ofbuilding this data knife ni platformanother thing we're very excited toannounce is this next Generation featurestore and so this takes vertex AIfeature store and bigquery and bringsthe best of them togetherso that you don't have to move your databetween them to take one data set youcan apply governance rules to it use allthe things you're used to using inbigquery for running analytics againstit and seamlessly use that for onlinesurveying and although latency fashionas welland really this Confluence of data andAI is sort of exemplified by featurestore having it all in one place usingthe same toolsand then over on the businessintelligence side I'm really reallyexcited to see all the work that theteam has put into announcing duet AI forlookerand this allows you to do everythingfrom generate chartsusing natural language to doing thoselittle tweaks to charts saying you knowthis line is too big it's too smallto then actually generating slide decksand sharing those interacting with yourdata using natural language and I hopethat folks caught the presentation frommy colleagues Kate and Andrew if youhaven't I really encourage you to watchthe recording it was a really excitingvideo about what the future of thiswould look like where it's not onlycollaborating with an AI but it'scollaborating with other people and sothe future of AI and bi looks reallyreally excitingso these are the things that we have sofar and really tying all these togetheris this idea of Da and AI labs and thisis something that you can sign up fortoday we'll have a QR code at the endand really this acknowledges the factthat it's an incredibly fast-movingspace and not everything is going to beproduction quality immediately andpeople are excited to go on this journeywith us and so by signing up for thisyou can have early access to theexperiments that we're running some ofwhich will work out some of which won'tand really you know discover what we cando together with AIso that's todaynow let's let's look at the future andso in trying to predict what the futureof this space might look likeI think it's useful to sort of thinkabout three possibilitiessoroughly we're going to call these thethe asymptote Universe thedomain-specific master universe and thesingularityand I'm gonna explain what those are andthere will be a quiz so pay attentionso the first one the the asymptoteuniverse is is really you know modelsget better but they don't get bettervery quickly and sort of big jump thatwe just saw in capability fromreinforcement learning from Humanfeedback we don't see similar jumps tothat we see things you know stay at thesort of sub 99 quality level andyou know there's a lot of engineering toreally turn these into usefulapplications you have to assume thathumans are going to be in the looppretty much in you know in perpetuityuntil we have some continuous jumpingcapability and so there's just like alot of engineering to backstop thosedifferentissues with with model quality and Ithink that there's actually really goodpreference for this in other disciplinesso like look at self-driving cars wherethat has really just it's been a slogright like you're trying to crank outanother percent another fraction of apercent to get them better and like it'suseful but it's also it's hard and itdoesn't mean that like all of a suddenit's magic and it worksthat's Universe oneUniverse 2 is domain specific Masteryand so this is where actually models doget really good not at everything but atspecific tasks and so imagine that fornatural language to SQL for examplereally like you get to the point whereit's it's you know indistinguishablefrom 100 quality and so you can actuallythen assume that you don't need a humanin the loop for those sub tasksand this is actually the thing thatwe're going to focus on the most todaybecause I think it creates reallyinteresting questions for how do weredesign our systemsif we end up in this sort of scenariobecause you can then have these discreteboxes that say you essentially have anAPI contract of I'm asking the model togo from natural language to SQL and itjust does it I don't need to check thatwith a human I can treat it like a bitof code that you know does thatdeterministicallythe last possible Universe Singularitynot going to talk too much about thisbasically AI takes all our jobs and youknow you sort of you're back to thismagic box of like it can do anything andsonot a whole lot useful to speculatethereso what we're going to focus on Universe2. I'd love to to get a quick pull ofthe audience in the next five years doyou think that we're going to be inUniverse one raise your handuniverse 2.and universe 3.all right I think I think the twos haveit that was that was great participationthank you I one of my colleagues wassaying you're going to get 10 hands atmost so 9am crowd you are killing itthank you very muchyes it was a leading question Fairso in talking about what this looks likefor for Universe 2 I think it's reallyhelpful to to look at what does our whatis our mental model for interacting withlarge language models and in futureadvancements look like and so where westarted I think for a lot of people issort of this magic box of like it can doanything andI don't know about you I've been in manymany conversations where that is thestarting point if someone says like ah Igot the language model to do this thinglike let's ship it it's amazing and soyou sort of have to like walk that backand say like ohmaybe it's very cool I appreciate yourenthusiasm and so it you know thatenthusiasm is great but I think wherethe challenge isit prevents us from thinking criticallyabout yeah models are really good atsome things and then they're not good atother things and so you know how do weactually create a taxonomy around thatthinking to then say if we're designinga system if we're you know have a blockdiagram of boxes and arrows where does amodel make sense and where doesn't itand if you know it's just like one boxthat is a machine learning model andlike magic happens that's not superuseful or rigorous so you know moving tosomething that is more defined and oneway to do that is to think about lensesand so this is really you know lensesroles thinking about things that modelsare good at and so then how can you sortof fit these in different slots whereyou've got you know maybe a standardsystem in one place that's talking to amodel in another context and then youknow chaining these different thingstogetherand so beginning with the translatorwe've seen the models are really good atthis like they're good at looking atpatterns and then you know translatingnot only between sort of languagelanguages whether that's human languagesor machine languages to humans and viceversa but you can also look at how thesecan translate from intent to action andthings like thatthey're also really good at summarizingand so there are a number of cases whereyou want to take a lot of informationand collapse it into something smallerthere's some fun interactions withembeddingers around this as welland then they seem to be an interthere's interesting use cases aroundpersonalizationwhere you can think about again sort oftaking intent action so like let's saythat I sort of have a sidecar model thatI'm using for my bi tasks and it'slooking and saying like wow Sam you lookat Revenue graphs a lot and so it usesthat to infer like this is something youcare about and it starts to build anidea of what are the attributes that I'mlooking for when I you know want acustom built reportso you can use this this one this is oneapproach to sort of look at you knowwhat our model's good at what are theynot another one is sort of applyingsystem one system two thinkingso this is you know getting intopsychology a little bit are folksanybody familiar with system one systemtwo thinking yes great from DanielKahnemanand so system one thinking is this thissort of fast abstract as an abstract artlike making fuzzy connections of likeyou know what you know somebody asks youa question what is your instinctiveanswer to that question and and it seemslike this really matches how modelsbehave in a lot of ways like they theysort of infer a bunch of patternswhether those patterns are you knowrobustly grounded or not and they sayyeah here's my answerwhereas system two thinking is is reallymuch more analytical and structured andtends to look a lot like programminglanguagesand we don't see models being as good atthis you know you sort of see like ifyou give a model a math problem forexampleit tries to sort of pattern match it andsay like you know I know there's numbersthere's some operators this is aplausible way to give you an answer butit's not applying rules to say you knowshould I add these things together howdo I track my work you know it doesn'tunderstand the significance of a decimalpoint and so it sort of puts it in theresomewhere because it has seen thereneeds to be a decimal point but itdoesn't understand the sort of semanticimport of thatand so then you actually combine thesein a plug-in architecture and you knowthis is the this is the way that we'reseeing you know how to bring those twotogether in a way that's productivewhere the model sort of handles thesystem one thinking and then you handthis off to sort of a system two plug-inlike an analytical engine like justrunning a little python function in linethe is handling that for youso these are a few different ways tothink about what these modelcapabilities could look like in the sortof domain specific Master universe andso let's assume wild success that likewe get to 100 that a lot of thesedifferent subtasksyou know what would that look like whatstill matters because you know now youcan suddenly assume that you have thesethese subsystems that you like you don'thave to program them anymore and howdoes that change your overall systemarchitecturewell you still need engines to actuallyrun stuff and you know being a dataanalytics person I'm you know heavilybiased but you know I think this is thisis actually a really important thing toto think about in terms of like criticalpath where usually if you're writing aquery for example you're spending a lotof time composing the query and takingyour human intent and translating thatto SQL or Python and then maybedebugging it and then the actual time torun that on the engine is sometimes areally small fraction of that whereas ifwe think about a possible future where Ican take natural language and turn thatinto an executable query very quicklyall of a sudden like the time bound isactually coming from the engine and soyou get to this point where if you wantto sort of have this languagemodel-centric future you have to thinkabout you know what does it look like tohave engines much more on the criticalpath of you know if you're iteratingthrough different approaches and then Ithink like a key piece of this is makingsure that the architectures you'reworking with are serverless so they cansort of scale up and be responsive andso the bumper sticker I've not yetcreated but I'm going to is llm's heartserverless and feel free to steal thatbut I think that this is a reallyinteresting sort ofcollaboration between language modelsand serverless herethe second piece is verificationso you've tried to get a model to dosomething how do you know that it didthe thing that you asked it to doand the the sort of simple answer isn'treally satisfying where you say well Iasked it through a thing and it gave mesome SQL and then I looked at the sequeland it looked correct and that's greatif you are a SQL expert and if everybodythat also needs to verify the thing isalso a SQL expertand empirically I have a bunch ofcolleagues that have said you know heyit generated some SQL and it lookedreally good and then it actually took mehalf an hour to realize it was wrong andsubtly wrongand so you know if if we're in thissituation where we're depending onmodels to to do this translation for ushow can we actually create languages orconstructs that are optimized forverifiability because a lot ofprogramming languages we expect humansto take a lot of time writing them butif we're in a future where like humansare going to take no time writingsomething they're going to spend alltheir time verifying and checking whatdoes that change semantically like whatdo we want to prioritize for how thatlooks and so I think there's someinteresting open questions aroundlanguage research that could you know behereand there's access control and so youknow I I'm not planning to Grant a modelaccess to every you know every bit ofdata in my company without anyguardrails I'm imagining you're probablynot going to do that eitherand sohow do we think about is there a middleground now that is better than thestatus quo because if a model only hasaccess to sort of what it's humanwould also have then you you get intothese these same sort of slow iterationLoops ofI need access to that table now I haveto go ask for access to that table and Ihave to wait an hour at best to getapproval and you sort of iterate andlike again you're sort of slowing themodel back down to human speed andslower than human speed in fact and sohow can you think about can we changeAccess Control models can we build inmaybe some some privacy Centricconstructs so that you're you'reactually allowing the model more accessinitially but maybe you're controllingthe outputs in a more careful way oryou're sort of doing something like thatdata training and data still matter aswelland so I I think that like a key pieceof this isdata quality is probably going to matteras much if not more going forward Ithink we've started to see the theplateau that you get with generalpurpose models and how you know they'repretty good when you try to apply themto a specific domain but like we'reactually having high quality fine-tuningdata is really importantand so how do you how do we continue tocurate good data sets how can we makesure we can share them how do we tracklineage all of this this still reallymatters and then what I think isexciting that actually turns this into afeedback loop is you you can use modelsto enhance data then too and so whetheryou're creating synthetic data sets andmaybe rewriting them to create betterbetter training data there's they'resort of rather than just data poweringAI you also have ai powering better dataand so I think that's a really excitingpart of this futurethen there's communication and so I Ithere was a meme that was going aroundmaybe folks have seen something similarof you know I want Bob to attend ameeting and so my intent is Bob attend ameeting I go to the model the modelwrites like a multi-paragraph email thatinvites Bob to the meeting Bob uses hismodel to extract like Sam wants to go tothe meetingwe don't really need to round tripthrough two models to to convey thatintent and so like howhow does the interaction with withlanguage models change how wecommunicate intent and information toeach otherbecause if we're you know if we're usinga model to generate a slide deck andthen somebody is using their ownlanguage model to condense that slidedeck and re-summerize itit seems like we're wasting our time isthere is there actually like a kernel ofinformation that we can extract that youknow is the core of what we want tocommunicate and then maybe there aresort of different ways to customize thatfor different audiencesand then finally they're they're ethicsandthis this really matters becauseparticularly in the data space I thinkthere are correlations that can exist indata that you know may or may not begrounded in reality and going back tohow models really like to find patternswhether those patterns should orshouldn't exist and so I think we haveto think really critically about whatdata are we providing to models are wethinking about selectively re-weightingit if the you know training set that wehad was biased in a certain way how dowe re-weight that and you know my my ownpersonal experience with this was thethe bio that many of you read for cloudnextI fed in some bullets you know Sam doesthese things he does these things and uhyou know it's actually a really reallygood bio that came out from the the chatbot that I was usingexcept for two things so it gave me twodogs and I was you know it was very cutemaybe that's that's in my future it alsogave me a wifeand my husband wasn't really veryexcited about thatand so if we're thinking about likeusing models for data imputation and Ithink we have to be really careful ofsaying you know hey there's this blankfield in the samro you know what shouldwe put there and if we're not careful Ithink you you create a lot of sort ofdangerous correlations and so we have tobe really careful heresoif these are you know these are thethings that we still matter in the sortof domain-specific Master Universe howdo we how do we try and navigate thatand so talking about how Google'sapproaching this how I would imaginemany of your companies are approachingthis is sort of plotting this coursethat really prioritizes modularityand so we think about how do we makesure we have the best infrastructure tobuild all this stuff on how do we havegreat applications for people to usethis in a first party way and then alsohow do we partner because I think thatyou know there's there's so muchInnovation happening here it's you knowpretty unrealistic to think that that'sall going to happen at one place so howdo you plan to slot in different pieceswhere relevant and so one of the thingswe've been prioritizing right now andthis goes back to those slides at thebeginning is really you know how do wemake the best infrastructure for alanguage model-centric future and it'syou know things like vector storage andembeddings and things like that becausewe think that like these are going to beat the heart of so so many workloads andthey are fundamentally hard problemslike they're not going away and so if wecan solve these at scale and make surethat they're sort of off-the-shelfsolutions for for using them like that'sgoing to be great for everyoneand you know we don't want to stop therewe want to make sure that we're usingmodels to really provide an amazingfirst party experience as well and soyou think about the work that'shappening in the I duet for example andand you know looking at like how youknow how do we take the ways thedevelopers and analysts and differentfolks are interacting with our platformand take the best of machine learning toto make that betterand then finally how do we partner andhow do we make sure there's this modularecosystem whether that's peopleproviding udfs or providing high qualitydata for people to Federate andfine-tune on so that you can you canreally like pick your use case and takethe different pieces that you want andand think about like going back to yoursystem diagram where does the model makesense where doesn't ititerate like this is a super fast movingyou know we have to sort of think aboutlike where are we now where my newBeauty be in three monthsand so looking at like where are we onin the Improvement curve and and likespecifically like are we at diminishingreturns and I think this is you knowwhenever there's a ton of exuberanceabout a new field like there's also adanger of putting a lot of effort intoefforts that have diminishing returnsand so if you think about prompt tuningfor example like it's really reallyexciting to like get a prompt that worksand then you know you spent five hoursdoing that and then get nowhere for thenext five hours or realize that like ifyou just move a comma in a weird waylike that actually gets you someimprovement and so you know how do yousort of do a breadth first search ofapproaches so you're not going down thisone specific path that might you knowreally just like hit this qualityasymptote and you end up wasting a lotof time and then the model changes andit's all you know obsoleteand I think we also have to be realisticof you know with some of these use casesif we look at a bunch of differentapproaches and something like nothing isgetting us there like maybe we actuallyare in this asymptote universe and wehave to think about you know are therenon-machine learning related approachesthat we really need to employ becauselike we're just we're just not going toget there by focusing solely on themodel and we need to build a systemaround it to make up for thoseshortcomingsso those are some thoughts in the futureand what we'd really like is for anybodywho's interested to sign up for thisdaai Labs you know we're going to beiterating quickly we're going to bereleasing a lot of stuff you know youknow and I'm really excited to explorethe space with youif you want to do that QR code is thereI'll leave that up for a little whilesee lots of phones out so yeah this thisis going to be early access to some ofthe innovations that we have we're goingto release this across a number ofproducts and we're really excited to goon this journey with youall right thank you very much you'vedone a wonderful audienceforeign"
}