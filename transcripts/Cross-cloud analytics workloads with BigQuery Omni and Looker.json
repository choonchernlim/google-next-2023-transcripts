{
    "title": "Cross-cloud analytics workloads with BigQuery Omni and Looker",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA300"
    ],
    "video_id": "0E18ZCHQAfc",
    "time": "Aug 30 01:45 PM - 02:30 PM CDT",
    "transcript": "foreign[Music]welcome to Google Cloud next 2023 areyou enjoying the conference so farawesome great welcome to the session I'mVidya shanmagamI'm product lead in bigquery and I haveit near valued customer Albin who'scoming all the way from France here he'sthe director of engineering at teeds saywelcome to Alvin thank you for joiningusgreat audience thank youso before we jump in I just want toquickly share what we'll cover today soyou can see how this relates to whatyou're thinking aboutwe'll first talk about some of the greatTechnologies we have here in GoogleCloud uh that power cross Cloudanalytics and workloads includingbigquery Omni and looker we also have acool demo to Showcase some of these newfeatures we have as well as cross-cloudjoins and governance with dataplexintegratedand saving the best of the last we hearfrom our customer teams on their journeyto bigquery and bigquery Omni fromredshiftso let's jump inlet's start with data right this is adata analytics session so let's startwith some numbers here over the lastdecade we've seen a massive explosion indata both in data types data volumeif you look at numbers in two yearswe're going to be hitting 120 181zettabytes I had to Google what azettabyte is and it's one followed by 21zeros it's such a large number it's uh 1trillion gigabytes so very very massivewhereas all of this data coming fromfrom all of your applications from apiswhether it's transactional systemswhether it's streaming or whether it'sany form of batch processing systems andwith this volume and explosion of dataand different types of data it's sittingin different data silos and storagesystems whether it's warehouses whetherit's data Lakes object stores relationaldatabases and more and more customersare also having this data spread acrossmultiple Cloud platforms majority of ourcustomers and Enterprises we talk tothey have data sitting in multipleclouds did you all know that 9 out of 10organizations they fail in theirmulti-cloud strategy nine out of tenorganizations this was very veryshocking to me as you know as a PMworking on this area and that's whywe're all here to talk about multi-cloudanalytics and learn some best practicesso let's dig deeper into theseTechnologiesso how does looker how does bigqueryomni all of these things come togetherwe talked about customers wanting tomanage their data silos they want to domore with their data sources here andmore and more customers want to combinethem understand the end-to-end data forData Insights for their analytics needswith bigquery Omni you're able toconsolidate your data into a single paneof glass for your query for youranalysis for your data transformationfor all your needs with looker on top ofthis Consolidated data then you have arobust consistent semantic layer you canvisualize you can explore your data andwith this you power all your dataexperiences all your different workloadsso what is bigquery sorry clicker on thewrong direction what is bigquery Omnimany of you might have heard or triedbigquery Omni but I'll give a little bitof what what the nuts and bolts of thissolution arebigquery Omni is a fully managedserverless bigquery offering that'srunning on AWS and azure what itessentially is compute that is runninglocal to your storage so it's accessingyour AWS S3 buckets or your Azure blobstore directly without actually movingwithout actually replicating any form ofdata with this you have a single pane ofglass to query your data at ease you'realso able to do a lot of cross-cloudjoins cross-cloud materialize viewswhich I'll talk about soon with all ofthis data sitting in different placesyou also want security you wantgovernance and bigquery Omnia loves youto do a consistent and unifiedgovernance across all of your data setshereso let's see with an example how thesingle pane of glass works right in thisexample I have a fictitious gamingcompany who has several titles andplayer data sitting across AWS S3 Azureblob store bigquery managed storage aswell as GCS these are all disparate datasources they're all physically locatedin different locations but what Omnialoves you to do is see it all in thesingle bigquery interface it all acts asif these are native bigquery tables weare not replicating data we are notcopying any data we're just providingyou access to that data by bigquerycompute running in these locations whichmeans for data analysis for anythingwith a single SQL statement you're ableto access all of this this is as we'vetalked with several customers superpowerful because instead of you havingto go into each of these platforms andquery your data move your data throughdata pipelines we're giving a singlepane of glass single axis and what moreyou can also set row level column levelaccess current roll and fine-grainaccess on these data sets herenow next I know it's very cool to go andlook at all your data at a single paneof glass and maybe run ad-hoc queriesbut that's not enough right you want tocombine this data you want to do a lotmore with that data and cross Cloudanalytics is where that comes in so wehave several capabilities in ourportfolio for organizations to do crossCloud analytics and I'll be talkingabout some of them here today sostarting out with cross-cloudTransformations so you might want toquery the data you might want to locallytransform them and bring bring only dataset that you need for bigquery forfurther analysis so we have a capabilitycalled cross Cloud transform that allowsyou in a single SQL statement query yourAWS data or Azure data pre-process themfilter them and then create a table inbigquery directly in one statement sowhether it's a new table that you wantto create or you want to append to anexisting table we support both of thoseoperationsnow we are very very excitedI need to figure out how to turn theclicker in the right direction sorryabout thatum so we're very excited to announce avery very net new capability calledcross Cloud joinscross-cloud joins is a single statementdirect cross Cloud join join between twoclouds so in a single SQL query you'reable to now join a table that you havein AWS or Azure and the gcp tableno other cloud data warehouse vendoroffers this capability this is somethingwe're doing by running sub queries onyour behalf in the AWS data set bringingonly the relevant data you have here andjoining ithow many of you are excited about thiscapabilityawesome thank you we have this inprivate preview for you to try it outokay talked about cross-cloud transformsI talked about cross-cloud joins great Ican ad hoc query some things but what ifmy data is changing what if I wantperiodic dashboarding periodic reportingI want to power up local dashboards thatI want to use for my business analysisor executive reporting how do I do thisright I'm running ETL pipelines I'mbringing my data periodically what do Ido and so we have a net new capabilityhere called cross Cloud materializedviews that allows you to do just thiswhat cross Cloud materialized usesallows you to set up a localmaterialized view in AWS you can specifyyour refresh intervals based on howoften your data is changing and then youcan create a remote materialized view orcross-cloud materialize view in gcp onceyou have that materialized view nowavailable in bigquery and gcp it'saccessible to the entire gcp ecosystemyou can run analytics you can use itwith dashboarding bqml AIML any form ofoperations are now available here sothis capability is recently launchedavailable in private view as well foryou to try outnow we talked a little bit about singlepane of glass we talked aboutcross-cloud analytics what aboutgovernance several of your organizationsyou think deeply about security managingyour data data thinking about accesscontrols so we have a very very tightintegration with data catalog anddataplex and that's what I'm going totalk to you here todaywith integration with data catalogyou're able to like seamlessly searchyour data discover enrich it withmetadata with business glossary you'realso able to do fine-grained governancewith row level access and column levelaccess and we have in the futuregovernance rules coming which will allowyou to do this at scalelastly we also support lineage sowhether your data is in gcp sitting inAWS or Azure once it's a big lake tableyou can run lineage on it you can trackand understand your data assets so thegovernance is not isolated thegovernance is cohesive it's unified it'sconsistent no matter no matter whereyour data iswouldn't it be cool if all of thesecapabilities I'm talking about isavailable in a region close to you sobigquery on these Regional rollout we'rerapidly expanding into several newregions and very happy to say we haveGlobal coverage with our recentlylaunched APAC regions and Europe regionsthis summer just a few weeks ago welaunched the EU Dublin region in Irelandwe also launched the U.S west region inOregon we have several more regionslaunching later this year so we haveGlobal coverage and we're continuing toexpandI just won't spend too much time on theslide but what I want to share is thatwe've heard your feedback we've heardour customers talking about howcross-card analytics needs to be morepowerful more performant and so this isa set of capabilities our team's beenhard at work in launching in the lastseveral months we talked about thejoints the materialized views we alsonow Federate from AWS glue catalog ifthat is your source of truth and youwant to keep that in sync that'ssomething we support here we have queryacceleration and performanceacceleration now we support we havesupport for analytics Hub in Omniregions I didn't put this on the slidebut we also support Iceberg and Deltaformat on Omni here so with that we haveseveral new capabilities for you all totry it outnow how does this all come together wetalked about all of this Technologiesbut I want to bring this bring this alltogether before we jump into it sureright our goal in gcp is to provide acohesive cross-cloud analytics platformwhich means there are multiple buildingblocks starting out with bigquery Omniatalked about how it consolidates yourdata across clouds in a single pane ofglass with big lake table integration wehave fine-grained governance providingrow level column level access for all ofyour cross-cloud analytics for freshconsistent data we have materializedviews we have cross-cloud joins now thatyour data is all Consolidated in BQ andgcp then the power is yours right withlooker with ML models with vertex CI youcan do anything with your data so nowyou're taking the organizational datathat's all siled which is you know notspread across different places to nowcome together to power your analyticsand insights for your organizationI'll pause there with that I'm going tojump in we will have time for Q a laterin the session so if you have anyquestions please think about it we'lljump in there um so with thatI do want to show some demo and some ofthe cool features we've talked about aswell as talk about our unifiedgovernance herelet's seegreat I did pre-record this demo becausewe did want to cover several differentfeatures and we want to bring thattogether in this short session here uhso what we will be seeing here is adiscovery experience so as a dataanalyst for a fictitious organization Iknow that a symbol here I know that Ihave orders data sitting in AWS and Iwant to be able to go and discover thatdata what I'm looking to do here is I'mgoing to then go intosure if this is playing just give me asecond oh it is playing okayum so yes I'm going into the discoverybeing here and I'm going to look fororder items data here and what you cansee is on the right side this data andthe stable is coming from AWS like Italked about it's in a different Cloudhere I'm going to quickly look at theschema for this and this makes sense forme I'm going to pause here for a minuteto just talk about the joins capabilitythat we hadso I talked a lot about cross-cloudjoins and I want to show how real it ishere right so as an analyst I know Ihave orders data that's sitting in AWSthis is my point of sale data I have allmy e-commerce data in a bigquery tablein gcp and for me to be able to likelook at my holistic organization look atmy holistic order data I need someFields sitting in AWS I need some otherfields sitting in gcp and before this Iwould have to actually run ETL pipelinesmove my data bring that to gcp for me todo that now what we are showing here isin a single SQL statement you're able topull the fields that you need from yourAWS table pull the fields you need fromyour gcp table and through a left joinactually create a Consolidated data setso this is the power of the Cross Cloudjoins that you all applauded me here forso let's jump in and see how to createthis thing it's going to run here in aminutelet's seeso now it's processing and once thetable is created you can see that I haveFields sitting from AWS and Fields thatare here in gcp all in one Consolidatedtable then that's available in gcp forme to use as I mentioned it can use itwith any of the dashboarding tools ofyour choice you can use it with bqmlyour ml models you'll you can take it tovertex AI for your training now I'velooked at the schema looks good to meall the fields that I wanted from mydifferent sources are herewhat if I want to do more governanceaspects with it I want to profile I wantto do data quality and all of thosefeatures are something that I'm going toshow here right so I want to understandthat my data that I got from twodifferent sources as an analyst I don'tknow what's in that Source it'sstatistically distributed it's not tooskewed so I did a quick data profilescan this does take a little bit time torun but we fast forwarded here to thedemo so you can see that uh it's thequality is fine for me what I'm going tothen do is I'm going to set up dataquality rules I want to make sure thatas new fields and new rows are coming inthey match a set of criteria here sohere are some data quality rules thathave been automatically generated basedon the profile we run so you saw thatwith recommendation space so I didn'tspecify it and there are some fields fornull check there are some fields to sayhey should meet the set of criteria herefor one of these fields so these areautomatic rules that have been set onthe combined data just based onrecommendations without much effort fromyour end it automatically pulls said ifyou're happy you can create this dataquality rule make sure that any datathat's coming in matches this we have ascorecard which talks about how many ofthese rules have passed how many ofthese rules have failed and will giveyou automatic alerts as well if you setthat up uh so that's a bunch of thingsrelated to like profiling quality checksnow I want to do fine-grained governanceright uh so if you jump to that part ofthe demo hereI want to set row level access to aspecific group to just say these are thefields that I really want this user tobe have access to no other field so I'msetting a row level access here sayingthat one of this fields of the terminalstatus is what should it return I runthis and on the Consolidated table Iwould be running this as an admin itwill set that rule level access policynow let's go query this table and seewhat it's going to return for uswhen I go query this table you can see Ialready see a flag that only a subset ofrows are returning and then the fieldsthat are here are matching the rulelevels that I've set it's only giving meaccess to that and all the other fieldsare hidden from me so this is powerfulrow level and column leveljumping further into lineage so theConsolidated table we know has data fromgcp and data from AWS so what you cansee here is telling me the source andthe flow for the data so in this casethis table is from gcp going further tothe order tables this is the one that wegot from AWS here and if you see here onthe right side it's S3 bucket that thesource of the data it's a parquet fileso I not only can profiles can setgovernance but I also can understand thelineage of my data and continue to trackit lastly what we're going to show isnow I want to share this data with myorganization so I want to enrich it withsome metadata I can set a bunch ofdifferent fields whether it'sdescription whether it's labels whetherit's expiration time so once I set allof these fields now I have my data setand ready to go and can be shared sothis is kind of the end of the demo butwhat I want to umquickly talk about we saw a bunch ofdifferent things hereum what I want to share here is that westarted out with just knowing that thereis a data set in AWS we searched for itwe discovered it we knew this is thedata set we won and then through crossCloud join we took data from there andfrom gcp created a Consolidated table weran data profiling and we had automaticdata quality saw the dashboard therethen we did uh row level and columnlevel security here we saw row levelwith fine-grained governance we also sawthe lineage capabilities and thenmetadata enrichment so all within thisfive minute demo you saw how withbigquery with Omni together we were ableto do cross-cloud analytics you're ableto govern uh your data very holisticallyso with that I want to transition backto um Alvin here to come talk aboutteach Journeythank youthank you Vidyaall of these announcements are reallyexcitingand they are particularly on point foruskids is no exception to the industryTrends and to illustrate that I took theliberty to steal your very first slidewe have a large volume of data it isincreasingly distributed it serves moreand more use cases and it's spreadacross all major three Cloud providersmercero and I've been working at seedsin Montpelier south of France for thepast seven yearsin seven years teeds has evolved a lotand so has its ability to deal with datain seven years the two biggest additionsto our data stack were the introductionof bigquery and Lucatoday I give you an overview of thisdata Journey what is teeds and why do weneed so much datathe tools and Technology we put in placeincluding bigquery and Lucathe challenges we have with cost Cloudprovidersand finally our single pane of glassstreamso what is thisteens provides an end-to-end onlineadvertising platformwith kids brands are able to reach up to1.9 billion usersand with kids Publishers can monetizetheir content with advertising thatrespects their usersnow providing advertising to 1.9 billionusers generates a lot of data and itrequires a lot of data tooso data teeds itself two major use casesthe first one is operationalto keep showing relevant ads to theright users we need to collect data totrain machine learning models and to usethese models predict user Behaviormost of these infrastructure is an AWSto train those models we use a mix of S3EMR and Sparkthe second major use case is Analyticswe provide data and insights to ourusersto our clients through data exports anddata visualizationsand to our internal usersthrough a self-service bi platformanalytics is the use case that made uschoose Google Cloud seven years agoso let me show you a high level recap ofhow our data stack has evolved over theyearsso we started with AWS onlywith a spark based machine learningframeworkthen seven years ago we introducedbigqueryour primary goalwas to provide a powerful reportingcapabilities to our clientsnow to provide data to our customers ina timely manner it requiresTransformations such as dataaggregationsto do that we introduced DBT awell-known open source tool that allowseveryone at kids to describe thesetransformations in a standard waythese Transformations are then executedinside bigquerynext we needed to provide datavisualizations in web applicationsunfortunately bigquery was not the righttool for that at the time so it showsredshift that allowed us to have a lowerlatency and tosupport a higher concurrencythen a major addition to our businessintelligence capabilities was theintroduction of Lucait helps every teacher employee to takedata driven decisionsand lastly tech savvy users still havethe options to run direct queriesagainst the raw data using Athenabigquery SQL or even spark notebooksI'll now take a bit of time to presenttwo of these tools which are bigqueryand localthere would be much to say aboutbigquery but in the interest of timeI'll only illustrate with this grapheach line represents the adoption of ourone of our data technology attacks sparkbigquery and redshiftso don't mind the exact figures they aremade up but my point is bigquery iswinning the adoption race at teensnow why do you think is the number onereason for thatis it more powerful is it cheaper it'snot but it's definitely simplerit's simpler to learn it's simpler touse and it's simpler to maintainas a company and as we grow as a companyit is becoming more and more importantto provide simple tools that can beadopted by most people and theSimplicity of bigquery has really helpedus doing thatis our most recent addition to our datastackwe recently had to change our biplatform so we compared many tools andwe ended up choosing Lucas here are thethree main reasons whyfirst is the looker modalization layerit abstracts the complexity of ourunderlying data it is defined as codeand versioned in git and it allows acentralized governancethe second reason is that it dedicatesthe processing to the data warehouseso it may seem a basic feature butactuallymost of well-known bi platforms areactually requiring requiring you toto import all of your data into the intotheir systemand finallyLookers self-service explorationcapabilitiesit lets people interact with your modelsdirectly and be able to take data-drivendecisions in a self-service wayunfortunately dealing with multipleCloud providers comes with itschallenges here are some of thechallenges we havethe cost of ownerships are free toolsbigquery redshift and Athenawe also have many different ways toquery the data we have looker we havebigquery SQL we have Athena SQL redshiftSQL or even spark notebooksand finally we need to maintain jobs tomove and transform the data betweencloudsso we can summarize all of thesechallenges into a single one it isbecoming more and more complex to dealwith datathat's why we are now investing intoreducing this complexity our goal is torationalize our data stackthe first candidates to thisrationalization is redshift so let megive you a bit of context on why whichshows redshift on top of bigqueryour goal was to embed data intointeractive client-facing webapplicationswe expected low response time and a highvolume of data of queriesunfortunately in 2018 bigquery was notthe right tool for that redshift had alower latency for small queries and wasable towas able to take more concurrent queriesthanks to several small redshiftclustersI'm glad to say that bigquery has gottenbetter sincethanks to several enhancements in theresource allocation systems and somefeatures such as the bi engineit is more realistic to use bigquery forthis use case nowso that's what we donot only it reduces the complexity ourdevelopers have to deal with but it alsohe moves the need to move data betweencloudsso that's where we are todaynow what's nextwe still have too many ways to explorethe data and we still have too muchclosed Cloud complexityso let me share my vision for the yearsto come I'm calling this the single paneof glass dreamthe single pane of glass is a singlesimple way to access all the data wherethere is it stored on S3 or bigqueryso in this dream we are using Iceberg asa table format for our S3 data Lakeiceberg is an open source table formatthat brings many interestingcapabilities such as acid transactionsand performance improvementsthis format is supported both by sparkand bigqueryin this dream it is possible tocross-cloud to join cross cloud data forsmall queries or to easily transfer databetween clouds and of course all of thisdata would be accessible in localso that's it for me thank you so muchVidya for inviting me on stage and nowI'm counting on you and your team todeliver on this cross-clad vision andmake this dream a realitythank you so much Alvinthank you all for beingthank you for being such a greataudience[Music]foreign"
}