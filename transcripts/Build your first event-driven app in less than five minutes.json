{
    "title": "Build your first event-driven app in less than five minutes",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV202"
    ],
    "video_id": "gn9oxKvEz-Y",
    "time": "Aug 29 03:30 PM - 04:15 PM CDT",
    "transcript": "foreign[Music]thank you for joining after a heavylunch I do understand why you havejoined the session after lunch can Itake a guessI wish you don't do that we'll try okayI think you wanted to pick somethingsimple and an easy session after lunchand hentia picked us and I totally agreewith you that is what we're going togive today if we are gonna make it weare going to Showcase to you how simpleit is to build a decoupled even drivenarchitecture within Google cloud and howeasy and simple to scale and buildperformance we'll have few co-hosts withme and you'll see how but we'll go withthat okay to wake you guys up a littlebit few riddles from my side brought toyou by dirt AIwhat has lot of holes but can hold watergood job okayokay let's start with the easy one rightthe answer is sponge okay what has a lotof keys but cannot open a doorokay you guys these are all the firstthings that you're there told me so putit in here make it easy next one whatare a lot of events that you cannotattendhuh not at your day I thinktell mewhatumokayeven darkokay that was my made-up thing hopefullyit was okay so yes it's it can be popsup or even dark with a lot of events butyou cannot attend let's get started I amKavita gowda I am the PM lead for theorchestration products here at Googlecloud and I kind of lead the even darkworkflows tasks and schedulertoday you'll be joined with two dataArchitects from ANZ Bank are gonna joinme and you'll see how and you canconnect to me at LinkedIn using that QRcode and this is for to stay connectedif you have any questions later on Etcand anytime you can you're welcome toget connectedawesome let's first jump into anz's banksuccess story we are very thankful toour customer ANC who has graciouslyagreed to bring their story to youANC has used Google Cloud products tocatapult their online banking servicesto 10x they relied on even drivenarchitecture and Google Cloud productslike even dark pop sub and serverlessplatforms to build their online platformwith high scale and performance withoutMuch Ado let's welcome our two speakersback there there you go[Laughter][Applause]has been leveraging the Google Cloudplatform to build its event drivenarchitecture we are headquartered herein Melbourne Australia we are one of thefour largest banks in the ANZ region andproud to be one of the 25 largest banksin the world in terms of marketcapitalizationso we have been joined by two dataArchitects they're from Australia andthey couldn't be here with us so theyhave sent these slides in the recordingand any questions to them you can askfor me and if I cannot answer I'lldefinitely get the answers for youonline or through your emails soundsgood let's get startedexactly is NZ plus simply speaking NZplus is our new digital retail bankingplatform designed to help improve thefinancial well-being of our customersnow to deliver this proposition anzx isbuilding this digital retail bankingplatform heavily leveraging Google cloudand it is on gcp that the event drivenarchitecture in anzx plays a criticalrole in arming our customers as well assystems with accurate and timeinformation and insights now let me handit over to sat so he can launch straightinto discussing How We Do Eda at Anzathanks trade and hello everyone I'mexcited to talk about our option ofevent driven architecture in as edx solet's start by looking at some of thekey objectives we have in mindwe have been heavily involved indesigning and implementing event drivenarchitecture within our Enterprise tomeet our strategic goals as well as tomake ANZ plus a successful offering forour customerswith even different architecture we'reable to deliver real-time use caseswhich is a fundamental requirement forany digital Bank as you can imagineaccess to timely data and insights isParamount for not only our customers butour staff as wellas such we are looking at opportunitiesto shave off even a slightest bit oflatency where possiblefor example page utilize Pub sub andevent Arc to deliver events in real timeto the consumers instead of themperiodically polling usas you can imagine banking is inherentlya complex domain with many subsystemsand even more integrated set ofIntegrationsin order to move fast and deliver valuequickly and fail gracefully it ispertinent to design Loosely coupled andhighly cohesive systemwhich is exactly what Eda helps as wellasas we are powered by Google Cloudplatformwe take every opportunity to adopt andadapt exponential Technologies andpatterns to build up robust andfuture-proof system architectureto that end Kappa architecture help usstreamline our data processing pipelinesand avoid inefficient two-speedprocessing of our data that isdigitalized same stream processingpipelines to realize our operational aswell as analytical demandsnow let's have a look at our azx Edaimplementationso this slide presents a bird's eye viewof our event driven architectureimplementationour messaging platform is underpinned byGoogle's native servicesthat is pops up and even talkas you can observe in this diagramin the center we have pops up and eventArc they play a central role to enablemessaging between various producers andconsumersfurther to this we employ the use ofcloud event specificationit's great for us due to the fact thatit is also a first class citizen inGoogle's on Eventing ecosystemon top of the picture there is an arrayof Business Servicesactively interacting with a messagingplatformthese could be our business servicesdeployed on cloud run or Cloud functionor even our back and stream processingpipelines in data flow for exampleadditionally our Eventing platform alsosupplies real-time information to ourdigital banking mobile app which is whatYou observe on the rightapart from these two we have a range ofproducers and consumers in shape of ourcore banking systems deployed onpremises as well as SAS vendorsfinally in keeping up with the theme ofadopting the latest and greatest inexponential Technologieswe are actively implementing the datamesh framework within the EnterpriseEda is a key contributing partner to ourdata my strategy by allowing us to builddata products using events and hostingthem on bigquery for feature consumptionnow SRI will discuss some of the keycomponents in The Matrix of our Evaimplementationover to usuallythank you sat all right let's look atsome of the key features of our Edaimplementation as we mentioned earlier amastering platform comprisespredominantly of event Arc and Pub serveand especially Pub sub is something wethat we consume and anger a lot as youcan observe that we have over 2000topics deployed in our environments uhthat funnel over 50 million messages perday Pub sub is really great for us asit's massively scalable and can easilyhandle our current volumetrics but alsosupport our future growth amountsanother great aspect of Pub sub is thatit supports both pool as well as a pushmodel now in the latter or the pushmodel for example we are using bigquerypush subscriptions to directly relatedata into bigquery event Arc is anotherservice that we are now activelystarting to consume to build ourEventing pipelines one of the mainbenefits that event art provides is theabstracted infrastructure layer that iswe don't need to manage the underlyinginfra at all it's all managed for us thegreat Advantage is its ability toasynchronously deliver events toserverless components such as Cloud runnow we have a lot of services deployedin Cloud run which in many cases requireaccess to events and event Arcseamlessly delivers these events toCloud runone of the key elements of our Edaimplementation is our use of cloud Ms ifyou don't know what cloud events areCloud events is an open sourcespecification for consistentlydescribing event data and our use ofcloud events has also allowed us now tobuild a lot of common libraries thathave become part and parcel ofaugmenting pipelines for those who areinterested in learning more about Cloudevents feel free to Google for it orvisit claudulents.io and you'll comeacross heaps of beneficial literature onitall right now let's look at an actualimplementation of a campaign that wewent live with recently the feature wascalled refer a friend or for short graphand the key aspect about about itsimplementation was it was that itheavily utilized event driven flows nowas you can see in the middle wireframesrefer a friend is a feature of the NZPlus app that enables existing customersto invite their friends to join the bankthe friends then need to complete aseries of checklist or a checklist ofsteps or items such as they need to jointhe bank they need to create a savingsgoal and make at least three cardpurchases when these conditions are metboth the referrer and the friend or therecipient receive a monetary reward fromthe bankall right in the next slide uh we have adiagram that you're seeing and it's asignificantly cut down and a simplifiedversion of the actual implementationarchitecture of refer a friend let's tryand look at the architecture now at avery high level the various actionsperformed by both the parties that is areferral and the recipient results inevents being emitted up for example whenthe recipient joins the bank ourorigination system is going to emit anorigination completed event similarlywhen they create a savings goal theaccounting system emits a goal createdevent so on and so forth all theseevents then flow through into our Googlepowered messaging platform to eventuallyget delivered to our reward stackerservice on cloud run for furtherprocessing and reward fulfillment nowthat you all are familiar with the keyconcepts of graph let's together buildour very own event driven application inunder five minutes stimulating therefuse casenow that you all are familiar withdirect Concepts let's build our very owneven driven application in under fiveminutes simulating the rep use casewhich she has just explained in theprevious slidehere's how the demo works we have a paidpublisher service theMcLeod run and its job is toperformwhich we will set up to gather showthe shop these events then are deliveredto a dummy reward service via event docthis report service will manage itsstate in spanner database so keep trackof all the incoming events and assessesif all the required events have arrivedso that it can discuss that awardthe way it will work is that I willinvite Sheree to join the bank via ANZPlus mobile appwhen the invitation is accepted by trainthen the fake publisher will generate anevent called invitation accepted whichwill flow through to the remote servicevia the pipeline which we will set upsubsequently she will download themobile app and perform the requiredactionssuch as complete onboarding set up asaving School Reform 3 transactions withthe completion of the steps additionalrelevant synthetic events will begenerated and delivered to the rewardService as you can see on the screenokay uh when the reward service observedthat all the events have arrivedit will Mark the completion of reward bygenerating an event called reportcompleted to the same messaging platformin addition we will also set up asubscription to the bigquery databasetable to store all the eventsand this is somewhat recent release fromthe Google whereby you can just set asubscription and point it to a topicenter the bigquery database table allthe events on the topic then will bestored into the bigquery tablethis comes in very handy uh in the demobecause we can quickly verify if aparticular event has landed or not andin fact is it is very good tool to makeany reporting analytics based on theevents your systems are publishingwithout further Ado let's get to thedemookay so what you see on my screen is aGoogle Cloud console and here's the listof cloud run Services which we havebuilt and deployed already so that wecan focus on the midi bits that isbuilding and deploying our Eventingpipeline in under five minutesso these are the services which you sawon the previous slides as well so thisis fake event publisher that is CN eventpaper and fake remote tracking servicewhich is CM report trackerso as part of preventing pipeline wewill create a pub sub topic and an eventArc trigger which will subscribe to thetopic we will createand this Fair given publisher willpublish event on the uh this new topicwe will create and event after we willsubscribe to this topic and deliver allthe events to the CN reward trackingserviceokay so uh for simplicity's sake we arecreating a single topic for this demohowever in practice we have got topicsaligned to the bounded context followingdomain Independence and principlesprovision thisis for thiswe will run a series of gcloud commandsthat I have stored in a shell scripthowever in practice we use terraformmodulesso let's have a quick look at our scriptokay so as you can notice uh there are aset of environment variables declared ontop of this shell script this is somebasic hygiene practice so these are thevariable we will be using in the gcloudcommands on this shell scriptso the first G Cloud command is thegcloud sub topic create it will createthe topic cloudmax dot demo which wewere talking about earlier and then thenext one is gcloud event top triggerwhich will create an event order triggerfor us and it will deliver the events tothis Pub sub topic which we are justcreating uh if you notice what I'mhighlighting and we also configuring itto deliver all the events to the cloudand service which is CL robot trackerservice which you saw on the previouspagein addition we're also creating abigquery push subscription which issomewhat recent released from Googlewhereby you can configure a topic towrite all the events to a big querytableso this will come quite handy in thisdemo we can confirm that if a particularevent has arrived or notin practice this bigquery table is avery powerful when you want to buildyour reporting analytics based on theevents that your systems are publishingokay so without further Ado let's runthis JavaScriptfingers crossed hopefully it willprovision our infrastructure very soonand once that's done we will go toGoogle Cloud console and confirm if therequired infrastructure is created ornot okay cool looks like it has alreadycreated the topic now it's creatingtriggerlet's go to our Cloud consoleand see if that topic is creatednoiseand now let's see if the event oftrigger is createdbut we're still waitingoh cool okay so this event talk triggeris created and it iscalled to subscribe to This Cloud nextor demo and it's going to deliver theevents to our report tracking serviceawesomeokay the shell script is completed aswell so that means the bigquerysubscription is created as wellso now our Eventing power plan is readyto deliver the events end eventso let's publish some events shall weso for that purpose we have created thismini website to generate the syntheticevents it will interact with the fakeevent Publishers to publish the eventsso this is the website so here you'llnotice there are four buttons first oneis accept and invite open account creategoal and make three card purchases solet's assume I have already invited mybest friend Shri to join the bank andnowand right by clicking on this button soonce you click on this button in thebackground it will generatean eventso let's quickly see what's happening inthe cloud runokay so let's have a look at uhinvitation accepted this is the mostrecent one please ignore the previouslog as I was actually uh testing thisbeforeand now let's have a look at it it haslanded in the bigquery subscription aswell yes invitation accepted is landedthat's great okay so the next step let'sgo back to our website oh you can seethat it is Tech so this step iscompleted so let's go to the next stepopening an accountwhile it is doing that let's see howquickly it arrives in the bigqueryawesome okay account opened event hasarrived as wellthe account is open second event hasarrived as wellso now let's create a goalokay similarly we will confirm that inthe victory yes goal createdandright nice so the gold created event hasarrived as wellso the last bit make three cardpurchases by clicking this button we aredoing our last stepright three uh transaction created eventhas already arrived and we also noticedthere's a report completed because ourreward tracking service realized thatall the events have arrived so it haspublished the reward completed event asexpected wow congratulations it's alldoneso thanks Ray and now we will be bothreceiving a reward greatawesome hopefully this was reallyhelpful for you guys and we are reallygrateful to ANC to have showcase theEnterprise scenario I think one of thoseslides that had the performance inlatency I think it'll help you guys inrealizing how much scale and performanceyou can get out of Google Cloud Eventingproducts without much I do let's go onto our next slide that uh we're gonna doanother demo here so this demo is toorchestrate your service fast and easyyou did see that ANZ use cloud run andthen try to orchestrate few events andwaited for an action to take some kindof a reward we want to showcasesomething similar but how you would doall of this in a serverless mannerwithout writing a code right no code ora low code scenario with Cloud workflowshow many of you guys have used cloudworkflowsokay few hands so Cloud workflow is aserverless product which orchestratesand automates your business processeswithin the Google Cloud ecosystem it'sused in data pipeline creation yourbusiness processing we also have seenthat the platform admin using it tomanage their Google Cloud using gcloudcommands and in the future we're alsogoing to release Cube cuddle APIcommands in it so that you canorchestrate your gke cluster and managethem also within without writing anycode and it's all yaml based at thispointhow are we going to realize this in thisdemo is we are going to create ane-commerce website we are a company weare building e-commerce website andwhenever a user makes a purchase on thee-commerce website we are going to addthat order into cloud storage and thiscan be anything right it can be yourfirestore or another DP event hark as aCDC even subscription to firestore orall of that events can be subscribed andthen used to trigger workflowsand once the storage has been made theevent Arc is going to pull the event andTrigger the cloud workflows and in Cloudworkflows you're going to do some logichere we have kind of tried to create uhsome fake logic here to Showcase thisdemo usually you write into yourbigquery or the table for data analyticsyou would store it into any kind ofstorage maybe in this case we are usingthe storage system so that's easier andthen we are also showcasing here arewards API private endpoint if ifthere's more than three transaction weare going to call the rewards API whichis going to give us some kind of acoupon and then we are going to emailsome simple workflow here for you guysto Showcase its capabilities within fewminutes here so the rewards API is aprivate endpoint I don't know if peopleuse cloud workflows this was one of themost asked feature to be able to call aprivate endpoint and that is what we'rereleasing in Cloud next and you'll seemany many more good things and the nextannouncements in infused lights okaylet's get started with the demo herewhat we're going to do with the demoinitially is we are going to take youguys through how we build the ammo inthe cloud workflow and once we buildwe'll deploy all those resources andthen we're gonna take you guys throughan e-commerce websiteso let's get started here and this isthe cloud workflow consoleand here what we're doing is we arereading an event and getting all theevent information and storing it intothe variables inside so we are basicallyassigning as you can see here assignproduct name number customer name theseare some of the information we got fromthe event once we have it we want tostore somewhere right and to store ifit's a first time customer you don'thave the storage created for thatcustomer so you kind of do try andaccess exception blocks and a knownexception in a known exception we aregoing to create that profile if it doesnot exist so it calls a create profilecustomer profile and this is a subworkflow you can create sub workflowswithin workflows and you can call otherworkflows you can do all of those Magicsall we are doing is creating some buckethere and creating a customer table andthis is the slow that happened only ifthe first time and after that what we'regoing to do is save the information intothe bucket and again as I said this canbe any or any of your data storagesystem and once you do that we are goingto go ahead and save information intobigquery this is againum most of the customers we have seen dothis so we're just adding this for demopurposes so here's a logic where you cannow list all the purchases made by thecustomer and then make a condition thecondition here is if I see more thanthree items or equal to three items weare gonna to get rewards going to theflow of get rewards else will end thisworkflow and in the get rewards as Isaid this is a private endpoint it canbe anything it can be on your VM or itcan be a gke private endpoint we haveenabled that and I think it's Europeanwith ppcsc this enables you to createthat parameter and then call serviceswithin your perimeter and then that justgives you a coupon out and bring thecoupon in and then send an email send anemail there's also a sub workflow hereall it does is call send grid API andthe send grid APIum you just send an email to thecustomer and do an HTTP post and all ofthis rewards is reward steps goes onlywhen you have made three purchases ifnot it just goes to an end so it's thatsimple so everything is an enamel youdon't you did a lot of things what you'dhave done with your microservices andyour other things within one simple yamland it's gonna get more powerful as wellso workflow also has this visualizationcapability which is at the native stageat this point where it kind of helps youto realize what your workflow does rightwhat's the next step Etc workflow canalso do call backs workflows can wait itcan pull so it helps in your manualapproval and it integrates with eventsit can wait for an event once the eventis brought in then it can start up againor it can it'll call back and it'll waitfor the event to occur and in that casemaybe a human Pro approval or somethingelse and it can triggers from there hereyou can see the graphics will help youto figure out what cause what in ourcase in a try block it directly goes toa save but it's to the bucket and thenbig query Etc so this visualization isgoing to change in coming months so stayconnected whether it's going to be muchmore easier to author your yaml we arealso integrating with the duet AI so allyou have to say is whatever I said sofar in the demo slide just type it in itshould be able to produce this for younow let's go ahead and create theseresources in the gcloud command and thenI just want to pull together how easy itis to just call a gcloud command andcreate all the serverless resources andthey are serverless it manages theexecution it also manages scale andperformance for you and we are herecreating the bucket First Once thebucket is done we are going to createthe workflows so for a workflow you needto provide a service account if you wantto call all the other services correctso to call all the other services theservice account should have permissionso we have gone ahead and created all ofthat before in hand and make sure yourservice account uh whatever Servicesyou're calling it has permissions to itso let's provide the service accountthat we have provided here to our gcloudCommand all you have to do is workflowsdeploy and then put the source as thedemo yaml the ammo can be stored in yourCI CD and then you can automate all ofthis once done you can see your yaml solet's go ahead and now do even darktrigger so even target has a directintegration with workflows so all youare saying is event arc when there'sthis event something happens in thisBucket please call the workflow with theinformation and that's where it is sofilter based on your bucket and then putyour storage and it should be able tocreate it so it has a direct integrationand you'll see in the console that youcan see the trigger right in theworkflow consoleokie dokie next is the data set and thebigquery data set we are creating hereand that should be done so so that waywe can add create a table and add allthe logs into the bigqueryin the console let's come in and typethe workflows name to see if theworkflow exists and you have variousdifferent filters you can use and I'mjust going to use the name here for thenext demo and you can should be able tosee the workflowsoum as I said this we are not able toannounce completely what we'll bebringing in respect to the entirevisualization as it's going to unfold inseveral different months so we're goingto put some announcements so stay tunedand just the bucket is created is whatwe are showcasing hereand then we'll go and look at the eventriggers so even triggers is reallyhelpful it's a very simple mechanismright triggering is one is to one whereI'm listening to this gcp Services ithas about 136 Services evens for all the136 services and it has directintegration with many of the data storesof Google Cloud which is going to comein handy um so in this case we are justsaying hey this is the trigger for cloudstoragenow let's go and make our first purchaseso let's buy and let's see our workflowin action so we clear all of this insuch a quick uh steps and you can makeyour Enterprise think come torealization within few minutes so we arenow seeing all the steps that theworkflow took for this execution itshows there's an exception there becausewhat we did we did have a if there's nocustomer bucket let's go create itthere's a try fail and then it has it aexception catch to create the profileand we also logged into it you can doall the logs and you know all thestandard things and here you can seeyour even payload that came into yourworkflows as well let's quickly switchto our bucket and see if we can see thedemo customer sorry we give a lamecustomer name so the bucket has to becreated in the customer name and thename here the demo customer now it hasthat file this is all done by workflowit's just basically we're going throughthe workflow and the bigquery shouldalso be able to do it so now all of thisonce all of it's done we'll make twomore purchases to see uh the rewardthings so ideally with your Eda evendriven architecture you can use many ofthe serverless products that Googleprovides and it has said one is to anintegration with all of these productsthat helps you create an Eda with createyour Kappa pattern easily end to endwithout having to spend much time andGoogle will take care of your scale andperformance so now I've made twopurchases you can see all of it here andI think we are just going through andshowcasing you that the workflows wentand created this file as what we saidand now that all of these have been doneyou should be now we have that conditionthat is if you have made three purchasesyou're gonna get some coupon and thatshould have triggered the get rewardsand would have sent an email let's seeif we got an email in a second hereso all of this should have triggered anemail workflow andthat's it you got a coupon and a 50 offfor your thing so that's just a simpleuh workflow demo that we just wanted toprovide and to Showcase you how simpleit is to put together with a low codescenarioum and at this point workflow supportsabout 10K parallel executions and we aregoing to have we have a greatannouncement about it uh in just asecond so let's go quickly to some ofthe launches that we are makingso uh here's if you want to take asnapshot you can take we're going totalk about each one of these in a secondand go talk about it so these are someof the uh announcements that we havewhich are going to land and next monthor next two months and post next twomonths uh please follow our workflows uhfollow our roadmaps for both even darkworkflow and task and scheduler a lot ofit coming your wayeven dark is also going to support aninternal HTTP endpoint that is thisagain is a vpcsc for your security notonly it can talk to run Cloud runfunctions and gke and workflows now itcan call any endpoint that you provideboth internal and externaland she's it has many different TCPsources 137 and then it has about 3 000events through the logs and 26 directintegration including our firestore anddata flow both of them are in publicpreview we are going to go ga with themshortly in the next quarterso next is the workflow which I talkedabout private invocation public previewand then this is something that workflowis going to improve a lot on today whatI showed you is workflow executed andthen you can go and see in the executionsteps what are the steps that it hasright that is still not released that'sstill in preview that is what you'regoing to see next month and we're goingto improve a lot more on it because it'snot sufficient what we have today foryou guys so we're going to work a lot inbringing the parallel execution you canstep through the loop and see whathappened what are the variables that gotpassed all of this Advanced executionhistory and debugging are all comingand definitely the CMA K support foryour security for both workflows andeven darkso switching to task task released easytask easy I don't know how many usecloud tasks and scheduler hereoh wow not many it's just one or twothere awesome uh these are one of ourvery famous products used by almost allthe large Enterprises of Google cloudand we pass something called easy tasknow that it's easy to manage your queueyou provide all the information thedestination in the queue so your HTTPrequest into it is going to be simpleso these are some of the roadmaps thatare gonna land um as I said for eventArc the sources are all going GA in thenext quarter and this quarter forworkflow execution historyum it's going to improve a lot in comingquarter and we'll keep releasing it andmaking blocks and announcements on itum and we are also so this is anotherannouncement workflow can have 5Kparallel executions that means you canhave your 5K workflows running inparallel in a region now that can beexpanded to 100K or even we are tryingto make it Limitless so we have thishuge requirement from our customerswanting to run workflows and we haveseen many running parallely hundreds ofworkflows in a minute so it's used forbatch it's used for data pipelining it'sused for Eventing so many differentcasesso these are some of them and I thinkI've reached my time and this is aEventing inside a group sign up that weare um if you guys want to stayconnected with us there's a lot of newexciting things happening at Eventingum with Google Cloud products I cannotannounce them as we are not deliveringthem in this next quarter but this superexciting thingsum that I cannot fully talk about but ifyou get to be an Insider group we aregoing to connect with you you will be inthe front seat driving some of thosefeatures and also using them and gettingtogether with us on private previews Etcinterested please sign up here and we'realso taking some design partners thatmeans jointly we're going to designtogetherum so enter the informationcool all the feedback here as you guysalready know and thank you once againfor attending the session and being withme and hope it was simple and easy okaynow the claps thanks"
}