{
    "title": "Filestore and NetApp Volumes: The future for modern and virtualized workloads",
    "presentation_type": "Breakout",
    "categories": [
        "Architects, IT Professionals",
        "ARC220"
    ],
    "video_id": "crwR1mudoVU",
    "time": "Aug 29 04:45 PM - 05:30 PM CDT",
    "transcript": "foreign[Music]everyone Welcome to our session todaywe're going to talk about file store andNetApp volumesand I'm going to learn how a clickerworksyou can't use a clicker that's me I'mVijay I run product for file Solutionsat Google I'm going to be joined bykohavit who's my engineering counterpartso she actually builds everything andthen Sean and we have a special guestfrom Salesforce we have lavanya here aswellall right there we go so a common themethrough this session and a lot of thesessions is how do customers how do gcpcustomers ensure that they have theright infrastructure to to power theirbusiness and so today we're talkingabout file storage but I'd invite all ofyou tomorrow there's a spotlight sessionI think it's uh 202 is the sessionnumber at 11 45 and the speakers therewill talk about this theme at a muchhigher level and look at how do weoptimize at a system level acrosscompute storage and networkingconsidering hardware and software tofigure out how we meet all the uniqueworkloadsrequirements and if we do that right wecan optimize for AIML we can optimizefor modern workloads and traditionalEnterprise workloadsso storage challenges you know thequestion comes up why is storage trickyand fundamentally the reason is it's notone size fits-all lots of applicationsdo very well with object but there's alot that fundamentally need fileprotocols and application workloadswithin the workload they're not uniformythey're something like AIML as you guysknow the needs will vary dramaticallyand if you're modernizing or you'remigrating you start looking at iops youlook at performance you look atavailability you look at latency and youend up hey I might need a combination ofdifferent Services across block file andobjectso with that in mind what we're going totalk about today first is a brand newproduct Google Cloud NetApp volumes thenwe'll start talking about Ai and we'lltalk about Google storage fuse and a newproduct parallel store and then we'lltalk about modern workloads likeSalesforce we'll talk about Enterpriseworkloads like VMware and sap and howfile store rounds out the portfolioso as of Thursday last week we launchedGoogle Cloud NetApp volumes and this iswell if you're familiar with the NetAppoffering that exists today in the GoogleCloud Marketplace you'll know that was avery tight collaboration between bothcompanies this offering is a true Googleproduct so there's no longer spendingtime with both companies you just gostraight to Google and and you get atrue Google product so customers nowsingle point at contact for salesbilling procurement support and you justchoose NetApp volumes just like youwould any other Google service so it'sfully managed and it's tightlyintegrated and unified with the GoogleCloud you use the same apis or theconsole to access it the same managementto apis and all the same horizontals andservices that you'd find in any otherstorage product like file store or cloudstorageRich data management of course built inas you'd expect you can take thesnapshots you can copy and clone for tevand Dev purposes and replication isgoing to support you when there's eitheryou know zonal or Regional outages aswell backups are coming later this yearbut pretty soonuh and then one of the big asks thatwe've gotten from customers is now herealong with NFS protocol NetApp volumesprovides a SMB Windows protocol as wellalong with the Dual protocol the systemis going to scale all the way from twoterabytes to half a petabyte and thensecurity is baked in by Design includingcustomer provided encryption keysso let's dig into the functionality alittle bit there's there are multipleservice levels that you can choose andconsume premium and extreme our GA todaypremium comes in at 64 megabits perterabyte and the extreme offeringactually doubles that both have storagepools up to half of petabyte and ifyou've used the NetApp offering in themarketplace this is one of a number ofnew Concepts this idea of pools so poolscan be provisioned very large and thenthey can be carved up and provisionedinto volumes that go as small as 100gigs so that gives you a lot offlexibility on how you deploy yourapplications and your data pools areassigned to service level you can movebetween them dynamically the SLA threeand a half nines for premium and extremeand the protocols as we mentioned NFSSMB and dual protocol as well standarddirt is coming soon very soon andthat'll come in at 16 megabits persecond and it'll go to all regions afterthe initial rollout to the first 14regionsdata protection like we talked aboutsnapshots copies cross replication andbackups now can be applied to the volumenot just the pool for additionalflexibilityso let's dig into storage for Windowsright so now we have as Google Cloud afully managed SMB storage offering tosupport Windows workloads and it has allthe Deep Integrations that you haveexpected and seen from NetApp overDecades of experience so multi-channelfor smb3 to really optimize theperformance of your windows VMS andintegration with managed ad the fileserving piece in the cloud obviously isone big piece it's going to check offuser shares sap vdi all those scenariosyou know but there's also theopportunity now to serve for remotelocations so that works in the casewhere your users are on Prem when yourdata is in the cloud or if you wantlocal caching and local performance youcan use Edge caching which used to becalled Global file cache and in thisscenario your data is in the cloud onNetApp volumes and you can cache itacross multiple locations in a VM onVMware where and you can configure thesize and all the active directory stuffyou'd expect kind of gets inherited andjust works seamlessly for yousnapshot also is integrated right intowindows so your windows users can rightclick select the previous version grabwhat they need without having to file aticket and again just integrate itoutside the boxall right next slideall right and then on the Linux sideright so as we said this is a fullymanaged service for NFS including dualprotocols or NFS and SMB with Kerberosand AD and Rich data protection it'sDynamic on-demand scaling and strongsecurity with client managed keys sowith that we will switch to Ai and I'llI'll hand it to Seangreat thanks Vijayum you know one of the things that canyou hear me okay is that there right nowit's turned up okay so one of the thingsthat we've been investing in you heardSundar and Thomas talk about this thismorning there's a lot of things with AIthat matter right however a lot of thetraining models actually leverage andwant to utilize file systems for theirstorage and the training and they can'tbe refactored or you don't have time torefactor that to take advantage of cloudstorage which really supports the largemassive scale multi-petabyte massivethroughput requirements but cloudstorage is not the answer for alltraining models and so there's acondition where you're looking at filesystem access to maximize those GPU andTPU resources instead of waiting for anextraction on the cloud storage loadedinto the machines and then run it inyour cluster right so you want tominimize that you'll hear Livonia talk alittle about that as well but one of thethings that we've been doing is reallythinking about this from a portfolioperspective it is where is NFS storagemake sense where does posix make senseand where does object storage and fusein this case make sense fuse is an OpenSource service that's been availablewon't people use that today with cloudstorage to make their buckets mountablelike a file system it's not full filesystem but it's a think of it kind of anin-between and all three of thosescenarios these are ways you canmaximize the GPU and TPU resourcesbecause the data is immediatelyavailable for training now last Thursdayin addition to announcing and launchingGoogle Cloud NetApp volumes we announcedat cloud storage views this is alsogenerally available it's also free thatyou can now begin to usecloud storage fuse with your buckets nowyou can mount those buckets like filesystems they behave and act just likeyou'd expect they're not full filesystem semantics so there are somenuances between using fuse compared toNFS or posix but it's a way that we havecustomers today using object storageyou'll hear code way talk about that inanother session we'll reference at theend they're using cloud storage fuse fortheir Avatar generation app and theyhave massive scale as you can imaginethey have millions of users using thisand it's now a supported offering fromGoogle which does make a difference asopposed to just rolling your ownwe have multiple ways if you canactually use pre-built images to getstarted with cloud storage views andobviously we support Pi torch andtensorflow for many of the applicationsthat need that so this is the one of theother new file services and I'm usingfile Loosely here with fuse that weintroduced in addition to parallel storeso last week was a busy week for us inthe file Solutions area parallel storeis also in preview and new this is basedupon the open source Intel Deus projectthis is a parallel file system thatdelivers ultra high performance andultra low latency for gke workloads aswell as other HPC workloads but in thiscase we're focusing on AI this issomething that's actually much higherperforming than other luster scratchofferings from other competitors it'salso something that delivers that ultralow latency of 0.3 milliseconds as yousee on the slide that's dramaticallydifferent than object storage or cloudstorage latency of tens of millisecondsor hundreds of milliseconds right andthis is something that we've also builtin Erasure coating on the back end toprotect that scratch storage space sothe difference here with a parallel filesystem is you can scale out the numberof nodes based upon your needs andperformance all nodes have equal accessto the storage and you can get terabytesper second so throughput with ultra lowlatency and that's a very different wayto think about delivering storage fortraining models so as you think aboutthese three different offerings the newnew things are cloud storage views andparallel store but also file store isused by many companies you'll hearLivonia talk about that as well for theNFS storage this is something if youthink about the different models betweentext and audio and video you don't haveto use one storage for all different allof your training models you can mix andmatch the combination that suits yourworkload of the profiles whether it befile size of kilobytes to megabytes isvery well suited for parallel store allthe way to the other end if you'rehundreds of megabytes or gigabytes sizein files that's where object storagedoes really well throughput is anotherarea I mentioned parallel store duringterabytes per second file stores like 25gigabytes per second but cloud storagewe have customers exceeding 30 terabytesper second of throughput for theirworkloads so it really will Scale basedupon your trading needs and the lastthing I'll mention on this slide is theIOP side of things rightparallel stores millions of iops cloudstorage not so much millions of iopsmuch very it's a different workloadright so you have to think about theseacross the portfolio of yourrequirements which gets into the gkeworkloads for file store this is one ofthe things that's not new file Sourcesupported gke for years but what we'veintroduced is we've enhanced file storeEnterprise to support multi-shares forthose that are using it today you'vebeen able to do 100 Gig now you can alsodo 10 gig persistent volumes so it'sanother way to think about persistentstorage in a different way formulti-writer applications and whether itbe thousands of PODS or tens ofthousands of PODS they all have equalaccess to the same NFS of storagesimilar to parallel store right so amulti-writer use case is one of thethings that NFS and posix does well andfuse doesn't this also is one of thethings that supports higher availabilityfor your pod configurations in that ifyou have a pod or cluster go down theyall have access to the same storage theyautomatically fail over so you can havethat persistent storage acrossinterruptions as wellfile store you'll hear a one more slidehere there are different options betweenbasic high scale and Enterprise filestore Enterprise delivers a 49 SLA whichmeans that it's actually synchronouslyreplicating the data across all threezones in a given region so if you'redesigning your cluster config withcompact placement you can look atdifferent zones for availability and nowyou're protected against a zono outagefor NFS storageand lastly file store backups is nowsupporting right the next quarter willsupport gke so there's two differentways you can protect your gkeenvironments backup for gke which willprotect the cluster configurationapplications and or data in anyconfigure any options thereof I'm notgoing to go into the details of backupfor gke but that will also protect thedata store and persistent disk filestore backups will just protect the filestore data and that's an interimsolution integration with backup for gkeis on our roadmap but you can at leastnow very soon be able to protect entireinstances or if you're using files forEnterprise backup multiple shareswe've been mostly talking about thenewness in terms of parallel store andCloud volumes file store we've also madesome uh additional enhancements to thepackaging and pricing for file store Imentioned the 10 gig persistent volumesupport now for file store Enterprise ifyou look at the top we're also renamingfile store High scale to be files forzonal to correlate to the availabilityof the storage service files forEnterprise we're renaming to file storeRegional to again correlate to theavailability of four nines that we'redelivering through the SLA you can seethe difference is just looking at thefile store columns between pricingpackaging I should mention one I thinkthe pricing at the bottom is a newpricing That's the older list price sothere's differences in pricingavailability and capacities andperformance so you can match theappropriate file store tier to yourapplication workloads and in some casesuse multiple combinationsthen at volumes you see on the second tothe far right different capacity largerstorage pools different protocols thatwe that we support with Cloud volumesnow nfs41 SMB there are also otherroadmap items for file store includingbackup and nfs41 and you can see on thefar right parallel store so I wanted toget everybody just a quick perspectivethat this is a file solution portfoliobased upon what storage is optimized foryour workload whether it be a modernworkload or an Enterprise workload or anAI workload these are the solutions thatare really going to support thosevarious needsand with that I'd like to introduce uhand bring up lavanya to share how sheand Salesforce have been using few keand file storeso this button righthello everyone thanks for joining ustodayum I'm going to show you like how we areat live raising file stores atSalesforce so we are like small devopsteam managing uh Salesforce uh devopsoperations for the AI research teamad Salesforce our AI research team arebuilding like so many constantlybuilding like large language modelswhich are like computer vision naturallanguage processing models and then AIfor Sciences AI for economics what notand also the latest generative AI modelsfor all the for training all thesemodels we have been using file storesfor more than four years nowand we areso uh the main advantages I mean the usecase that we are using is like fortraining the models we need to storelike massive amounts of data like whichis petabytes of data sometimes and we doprovision multiple instances of filestores for storing that dataand based on the use case we do selectthe type of the file store that isoptimal for that use caseso the advantages that we are gettinghere is like they are simple to createand simple to manage and most of thefile stores are scalable we can eitherincrease the size or decrease the sizeas per our use case and also like weconfigured I mean we followed fewtechniques to optimize the throughputlike we have provisioned the file storesand instant file store instances in sameregion as the compute instances so thatwe can get maximum throughput and alsolike you can configure gvinx such aslike network interfaces to get bestperformanceso coming to the file storecategories so the one we are mostlyusing is the high scale like which isalso named as zonal now so this is theadvantage with this one is like we canscale up to 100 terabytes and when it isnot in use like you can decrease thesize as welland uh the further workloads like wherewe need more than 10 terabytes of datasize then we go for high scale and alsolike when we provision Project Specificfile stores like which are shared bymultiple team members so in that casethese are proven to be like very highperformanceohhello okay so uh maybe maybe I will notwait for the question for the audienceso let me try to to give you a quickquestion so it seems where you have aiworkloads so the costs seem like it itrequires you know like you requireendless number of resources ofinfrastructure which includes networkingstorage compute can you let me know howdoes firestore high skill helps you toreduce the total cost of the projectbecause at the end of the day you wantedthe work will be done but you don't wantto to to pay so much money of courseyeah yeah actually the high scale or thecostlier version of the file stores butstill it helps to reduce like it helpsto get low latency which helps to reducethe time for job completion and also uhlike we can reduce the overall cost forcompute resourcesthank youand coming to the basic SSD so we usethis category for workloads which arelike close to 10 TB and then where wecan increment the file store size likeup to 2.5 terabytes at oncethe main difference between SSD basicSSD and zonal is that you can evenreduce the size in high scale whereasyou can you don't have that option inbasic SSD because of the underlyingHardware but throughput wise they bothare almost sameand maybe I will have a small commenthere so we have just expanded files orzonal capacity to cover one to tenterabytes range so in that case uh sofile store Enterprise or high scalecould also be an option so this is afast solution so definitely you can seeit as a menu of solutions for your needsI of course I think that would be anawesome solution for our workloads rightnowand coming to the basic HTT we domaintain like user specific file storagelike in the in those cases like we usebasic HDD where like the performance isnot a bottleneck and uhby creating like hundreds of terabytesof data still the file store is thecheapest cheapest resource that we arepaying for I would sayyeah and and just to say the cheapestand you know just to think about it youhave so many uh type of workloads andapplications and eventually you knowlike a simple NFS protocol a simple NFSsolution supports all of them so it'skind of like uh um amazing how all theseworkloads are needs uh basicfundamentals of file activities exactlyand coming to the accessing like uh mostof our workloads are gke based and theyneed to access like the file stores onthe go so video you create like PVpersistent volumes and persistent volumeclaims in user name spaces so that theycan attach their volumes to n number ofpodsso the read read and write manyAdvantage comes with these file storesespecially the network file stores whichis so convenient for accessing the filestores from multiple instancesand coming to the backup of coursebackups have to be there to for thedisaster recovery so there are multipleoptions for backing up the file storesso one way is like creating thesnapshots and backups at like periodicuh time period and then the other optionis utilizing the storage transferservice which is available in gcp todayyou can schedule your jobs andautomatically transfer the data fromNFS volumes to the Google storagebucketswhich is like cost effective way forbacking up the datasothese are the resources you can check itout and let me know if you have anyquestionsthank youokay thank you lavanyaumI I will say just before going to theEnterprise workloads which are kind oflike obvious but so important fororganization I will say that as anengineering leader for me uh to lead thefile solution team and get feedback fromcustomer is one of the most importantvalues to assimilate in the organizationsometimes you know as Engineers we'reexcited of developing like new coolTechnologies but we need to understandhow customers are using these productsand how their benefit and to understandthat sometimes hey maybe it's the costthat actually impacts the customer ifthey want if it will benefit them it'sactually amazed me as in as a youngengineering leader but yes today Idefinitely understand the differenceso let's talk a bit about Enterpriseworkload so while there are many typesof Enterprise workloads most of themshare similar characteristic theworkloads are critical to the Dailyoperation of the business and itssuccess and what is common that theyhave no tolerance to this for disruptionor compromise on data protection or datacorrectness they consistently and simplyneed to work that's all right so in theupcoming uh slide I will give you somekind of two examples of how a fasterRegional offerings supportingmost of the Enterprise workload and howeventually these workloads are criticalfor the customers who are migrating tothe cloudso the first one is gcbe Google CloudVMware engine so this engine helpscustomer to migrate to the cloud withminimal disruption without the need toconverting their virtual environment tothe cloud-specific environment so theysimply need to copy okay the environmentand by that they reduce the time and thecomplication of the migration processand this method is well being used byour customersso if I'm talking about file store butby the way also NetApp so first of allfaster tiers are GCV certified and itmeans that when we are using fastercustomer can customize our data storeexactly to their needs and there areseveral use cases on this slide so theycan either the main two of them is theycan either start from very smallcapacity or expanding their storagewithout adding any additional of GCVcompute nodes and the Second Use casethat in case of Disaster Recovery thecustomer can save cost by runningminimal GCV resources and full storageand only expand the GCB resources whenrecovery is required andadvantages are obviouseffectiveness so as for faster it'ssupported for all GCV regions some ofthem are not GCS and all the featureslike external backup are available inthe GCB use casesso I mentioned NetApp so NetApp CBS isalso supported GCB North Americanregions and upcoming in Q4 Networkvolume is going to be GCB supported inQ4so let's give example for criticalapplication and their use in theimportant and the importance of theirreliability and high availabilityso uh the first one is the shared fileuse cases in the cloud so there are manyapplication and workloads that arecritical to organization whether we aretalking on production systems okay webservers that are used for the customerCommerce or shared resources that needsto spin up more gke nodes to adversebusiness needs on demand and there aremore and more okay any Interruption ofthis use case can cause severe impact onthe org and we have for that the answeror file to store architecture that canbe one of the solution to ensurebusiness availability and data integrityas Sean already mentioned file storeEnterprises Regional availability thatsupports full lines SLA currentlysupport from 1 to 10 terabyte and soonit will support uh to uh for 100terabyteso every time the application actuallymakes a right so the data is beingsynchronously replicated in threedifferent zones soumevery time we have a Zone outage wellnot every time I hope it's rarely so theapplication doesn't know about that andit seamless to the the user and also allmaintenance operations are notdisruptive that this is even furtherreducing the risk to the organizationum so let's slide so sap is a greatexample for critical businessapplication that use both for cloudnative customers as well as migratingcustomers to the cloud I guess I don'thave to explain how uh the critical uhand important availability of this setapplication to the businessuhin this architectural dock you canactually see a three major competentcomponent that I would like to highlightthat eventually uh um ensuring theperformance and the high availabilityfor our customers the first one is atthe DB layer we have the Hana DBworkload so we have improved theefficiency with introducing hyperdiscextreme new service which is designedfor extreme workload that needs highiops for DB workloads the availabilityof is insured in this case for with theHana DB replicationwe have application layer the fasterEnterprise for regional availability ofshared files which we already mentionedin the Ford mirror slide which isreplicated in three zones actually hereyou see like two uh um like purplesquares which represent two zones butactually we support three and lastlyusing the backup and the r for off-sitereplication in Castle Regional failureso Google Cloud backup ndr can backupthe DB and the app while file store canbackup the assured files and recoverthem in different region in case of adisasterso these like the GCV and the sap uhwere like example for criticalapplication that customers uh uh uses afile store to support the organizationumwell that was the last slide and thenext I would like to encourage you tojoin the next session uh if if yourinterest about storage uh so you aremore than welcomeforeign"
}