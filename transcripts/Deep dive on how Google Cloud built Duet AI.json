{
    "title": "Deep dive on how Google Cloud built Duet AI",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV213"
    ],
    "video_id": "UfAsk1rcI0k",
    "time": "Aug 30 11:15 AM - 12:00 PM CDT",
    "transcript": "foreign[Music]welcome to the session on a deep dive onhow Google Cloud built do AImy name is Rakesh duper I'm part of theproduct management team at Google cloudand I'm joined with two distinguishedcolleagueswe'll be coming up on the stage in aminute Cyrus he's a senior Tech writerin the Dual AI team and Dima he's asenior product manager in the doodaiteam focused on chat experiencesso for this particular sessionwe're assuming that you have some basicunderstanding of what do AI is so you'vebeen at this event for the last day orso I'm sure you've heard something aboutDavid AIor Google has been talking about thissince IO so there's some familiaritywith what duetai is and what are the usecases it coversthis is a 200 level session so we willbe diving deeper into how we built do AIwhat were our experiences what welearned and that is what we want toshare with you so as you embark onbuilding your applications that are llmbased or using general AI you know youcan learn from the things that we wentthrough and hopefully use them as youbuild your applications towards the endwe'll have a brief discussion on theroadmapand talk about what are we thinkingabout in this space for the futureso without further delay let's getstartedso first of all just a quick recap onwhat dual AI is so duper AI is theintegrated AI assistance across all ofthe gcp products so it's integrated AIassistance for developers it'sintegrated AI assistance for operatorsfor security users for data users andeverybody interacting with Google Cloudthrough the variety of differentinterfaces whether you're workingthrough an IDE whether you're workingthrough Cloud console or you'reinteracting with gcp in other ways youwill be exposed and you will be usingduet AInowwhether you are a beginner or an experteverybody will benefit from Dr AIso like I said earlier this particularFocus will be on the specific use casearound chat experiences not the codingnot the other experiences but the chatexperiences and so we will look at whatwe did around building the overall chatexperiencenow anytime we're training a model forthatwe need a lot of data and for do AI weused Google Cloud documentation GoogleCloud best practices a lot of blogs andother content that we publish to trainthe overall modelsso like I mentioned a second ago280i is exposed through many surfacesbut for this particular one we're goingto focus on the chat interface most ofthe time you will see the chat interfaceshow up on the side panel and you caninteract with it asking questionsbut as I will talk through the sessionyou will see in some cases it is alsoembedded within the console itselfwithin the UI itself so it's not just aside panel it's integrated morethoroughly through the productinterfacesso let's imagine a new user who'sstarting to use gcpthey want to learn about gcp productsthey want to they may have some commonquestions about the different productsthat we offerso that user could start by asking aquestion about the services gcp offersin this particular casewhat is migration Centerand do it AI will provide a responseand the response can sometimes be longand if you are somebody who just wants abrief response to see what is theservice really about Give me a two-linesummary you can have a follow-upconversation and say just summarize thisin two lines and you will get anappropriate responsenow as you start becoming more familiarwith the services Google offers lots ofservices you may want to go in and saywhat is the most approach what is theservice that is most appropriate foryour use caseand you can ask that kind of a questionso in this particular case for exampleif you want to use a data service youcan ask what is the difference betweenspannerand lidb and which one is moreappropriate for your specific use caseforeignnow as you become more familiar withGoogle and all the cloud services youwant to start asking how to questionsyou've decided what service you want touse you want to be able to say how do Ido some specific task and so you canstart asking those kinds of questions aswell as shown on the slide here in thisparticular case the user is asking howdo I connect my data sources to look ourstudioin responseyou know do a day I will provide you asummary of how you can actually go dothatas well as provide some information withlinks to go look for additionalinformationnow you're even more familiar with theseservicesyou want to start running some commandsagainst these Services now who hereremembers all the commands in gcloud allthe arguments and parameters in all thedifferent yaml file syntax that we havefor configuring these things probablynobody if you do you can talk to usOffline that would be awesomebut so you can go ahead and start askingabout questions start asking questionsabout gcloud commands and in thisparticular example for example hereand if a user says give me the gcloudcommand on how do I list idle VMSand so you get asorry I'm moving the other directionso you get a response back from do it AIindicating what that gcloud command isand if you notice towards the middle ofthis command there are actually twotemplate parameters right the project IDand the locationas we sit here right now do it AIprovides you generic commands whichmeans it does not understand who you arewhat projects you are in what resourcesyou are usingand that aspect of personalization issomething that we're actively working onso when I come to the roadmap section Iwill talk a little more about that sowhen personalization is added in herethese commands will be much moreconstructive in the sense that they willfill out this information automaticallyfor younow your experience with Google Cloudbecomes richer and you start looking atother things so let's say you run into aproblem and you want to troubleshootsomething you're in Cloud logging you'relooking at logs Explorer and you see allthese different logs that are availablesomebody else wrote those logs youdidn't write those logs and they are insome Json format and json's you know agood structured format but not theeasiest thing to understand becauseeverything is just like broken out inmany different parts so you can select aspecific log eventand say explain this log event to me andso you will get an English languagenarrative and a summary of what this logevent is about you can follow it up bysaying why do these kinds of Errorshappen and you will get a responseindicating why this kind of Errorshappen you can have another follow-upquestion say what actions can I take tofix those things and so you will get aresponse accordinglysimilarly if you're looking at codeand let's say you inherited somebodyelse's codeI've yet to run into a developer whosaid that person wrote awesome code andI'm inheriting it most of the time thefirst thing to say is like oh that wasreally bad codeso if you do want to understand whatsome piece of code is actually doing youcan take that piece of code and ask duetAI to summarize it for you and you willget an appropriate response as wellso hopefully this gives you just ageneral quick idea about the differentkinds of interactions you can havethrough the chat experiencenowthis is not an exhaustive list of allthe use cases that you can have there'smany many more things you can do but inthe interest of time we decided not tocover everything but now we want toPivot and show you the behind the sceneslook like how did we go about buildingthis what were some of the challengeswhat did we learn and for that I wouldlike to invite Dima to the stage demo[Applause]thank you Rakesh hello everyoneso when it comes to applying llmsadopting them for the Enterprise useon the spectrum ofthinking about it or maybe playing withit experimenting and having somethingrunning in production I was wondering ifI could ask you for a quick show ofhands those of you who are thinkingabout itEnterprise contextawesome thank you what about folks whomight be already experimentingspotted down cool thank you runningsomething in production with customersawesome thank you so much it's amazingto say so many practitioners here in theaudience we are humbled to stand infront of you today to share some of ourthoughts on adopting llms for theEnterprise use and would very muchappreciate the opportunity to connectwith you all and learn outside of thissession as wellso if you considering a few things um asfar as the context so first of all wehave this very powerful new technologyat our hands which has a really widerange of potential applicationsum loms they're trained in massive datasets can learn really complexrelationships between data and generatetext which is both informative andfluenthowever just like any technology they docome with limitationsfor one they are probabilistic in naturewhich means that sometimes they cangenerate incorrect or misleading outputfor the users so when we're building forthe Enterprise accuracy could be one ofthose aspects that we that are reallycritical for our application especiallyif there is even a smallest chance thatour customers might be relying on theoutputs of our application to makebusiness critical decisionsso it's important for us as Builders tomake sure that we put right mitigationsin place and also apply responsible AIdevelopment principles to our day-to-dayworkin addition to the new technology we'realso looking at a new interactionpattern which also comes with benefitsand limitations on one hand it's amazingfor both our users since it's verysimple and also is becoming relativelyrecognizable across all platformsand it's also great for us as buildersas it comes with that promise ofproviding us with the universalinterface where we are no longer boundby having to express the capabilities ofour system using traditional knobs anddials buttons Etcon the other hand it could be reallydeceptively simple and require a lot ofheavy lifting behind the scenes to makesure that we make it workfor example on the back end we need tobe thinking about how do we funnel thoseopen-ended inputs to write actions or onthe user experience side how do weeducate our users on how it works andalso how it doesn't work to make sure wecan help them use it safely and get themost out of itso we will talk about a fewconsiderations that might come in handyas you go about adopting large languagemodels for Enterprise use in your ownapplicationsincluding how we approach some of thosechallenges using the red AI as anexampleso before we dig in excuse me I wouldlike to introduce you to this softwarestock simplified view of the softwarestack that's powering the AIforeignpublication which has front-end layerwhich deals with user inputs and outputsmiddleware layer where we are doing someprocessing on the inputs as well asresponses on the way back and the backend which houses the foundational modeland supporting our infrastructure so thefront-end layer will take care of thingslike accepting user questionalong with any prior relevantconversation contextthis is our prompt or a basic unit ofcurrency that we'll be manipulating herehas prompt goes through the stack itgets interpreted and processed by eachlayer all the way up until it gets backto the user as a responseso middleware layer this is where wefigure out a few other things forexample intent of the user questionapplies and filters add the Preamblegrounding facts as a part of the processcommonly referred to as promptengineeringand we will discuss details on thatlater with examplesthen the backend takes care ofretrieving the most relevant model inand generating the response there are afew other things that are happening herefor example capacity rationing pullingcitations other metadata for those ofyou who might be using a managedsolution such as vertex AI a lot of thatheavy lifting will be handled out of theboxnow on the way back upum this is our other opportunity todouble check the response for Qualitybefore we parse it and presented theresponse to the user in a way that'seasy to understand and use and that'sthat also is an opportunity for us tohighlight any known limitations of theunderlying technologysoin a day-to-day work of working in anyproductwe as Builders face many decisionsacross product design implementationdetails across the entire stackas we think about those it's importantfor us to calibrate those decisionsacross against those responsible AIprinciplesthey are important for both consumer andEnterprise application contextsbut as we unpack those in the context ofEnterprise the implications might bedifferent for example again safety andaccuracy could be especially importantfor Enterprise applicationsso we strive to apply those principlesin our day-to-day work on dot Ai andwe'll also would like to highlight andshare a couple of practical exampleswith you of how we do that across thestackforeignso for the rest of the presentation weare going to assume that you alreadyhave a product or maybe a customerproblem in mind that you would like totry tackling with the help of largelanguage modelsand we will talk about topics that wethink you just like us might run into asyou adopt llms for the Enterprise usefrom selecting configuring and tuningthe foundational modelto experimenting with prompts and promptengineeringto building user experience and to allthe way up as you as you put thoselayers together testing to make surethat it all works we'll talk to youabout 14 Concepts across these fourcategories highlighting techniques thatyou might want to consider when youbuild an end-to-end applicationso from here I would like to hand it offto Cyrus to talk about the model errorplease welcome Tyler[Applause]thank you divafor us as Builders a really powerfulbreakthrough with language models isthat they're much easier to tailor toyour use case than say traditionalmachine learning modelswith language models you can take amodel off the shelf and customize it abit so that it works for what you'rebuilding you don't need to think as muchabout things like data labeling andcustom model trainingthis makes it way easier to startto start prototyping but it puts morepressure on selecting the rightfoundational model in the first placeif you want to get started you can checkout the model Garden on vertex and ifyou're not sure how to approach modelselection you can approach it how we didwe started by thinking about the purposeof the model or the context in whichyou'll use the modelfor example the model Garden hasdifferent models for our chat use casesversus models for generating codenext you'll want to consider trade-offsin latencyand model size a larger model mightproduce better results but it will takelonger to generate responsesif you're building a chat application itmight be okay to have a bit more latencyyou might be all right with waiting abit longer to hand results off to theuser but if you're building a codecompletion service you might want toreturn your you might want to returnyour code suggestions as soon aspossibleforeignafter you've selected your foundationalmodel you can tune it or customize itfor your use casethere are three main approaches here theeasiest approach is what's called promptdesign with prompt design you'reactually not retraining the model at allyou're just providing context tokens asa part of the prompt for example likedemon will talk about shortly you mightprovide the model with a preamble thatgets prepended to every turn everyconversation turn in a chatbotbut prop design alone might not beenough small changes to the Preamble canhave a big effect on the quality of theresponsesin these cases you can considerfine-tuningwith fine-tuning you're actuallyretraining the model with full finetuning you're modifying all of themodels parameters so that the responsesare more like examples that you providebut there's a there's a challenge herelarge language models are large they'rereally largethis means that with full fine tuningcan often take quite a long time and itcan take a lot of compute resourcesa faster alternative is what's calledparameter efficient fine-tuning hereyou're only modifying a small subset ofthe model's parametersand of course prompt design andfine-tuning aren't mutually exclusivevertex supports bothand a great way to jump in is to useprompt design first and see how far youcan getthen you can leverage prompt designalongside fine-tuning to help you bridgegapsokay you've selected your model you'vetuned it the final step is to take themodel and configure it to produce morecreative or consistent responsesto customize responses along these linesyou can look to the temperature valuesthe decoding strategy the top p and thetop K valuesI like to think about this level ofcustomization this configuration asoccurring along two dimensionswhen temperature and top K are turned upresponses might be more creative butthey'll be less consistent you might getmore detailed vocab but you're lesslikely to get the same response when youenter the same prompt in multiple timeson the other hand when temperature andtop K are turned down your responseswill be more succinct they'll be lesscreative but they'll be more consistentlike a lot of work with language modelsfinding the right configuration cansometimes seem more like an art than ascienceon working on duet we spend quite a lotof time getting the configuration rightyou can do the same in gen AI Studiowhere you can toggle these dials thesesliders and see how responses changewith different temperature values anddifferent decoding strategiesokay I'm going to hit it back after Dimato talk about the middle layer and thestack the prompt engineering layer[Applause]so now that you have your foundationalmodel selected and configured let's talkabout a few things you could do in themiddleware layer to further customizeyour application to your particulardomain and use casehigh quality of responses we'll talkabout both a few things you can do onthe front side on its way down as wellas on the way back up as far as responsepost processing is concernedyeahso first let's talk about preamblewhich is a set of instructions that wepass to the model on every conversationturnthis helps our foundational modelaccommodate itself to our particular usecase so for example for that AI we wouldinclude some instructionsto respond as an expert in Google Cloudand this also helps us stay make surethat our assistant stays on brand andresponds in the tone of voice specificor unique to our organizationa few thoughts on how to use staticPreamble effectively first of all don'tthink of it as a magic solution butrather as a guideline on what you wouldlike your assistant to be able to do itcan be really tempting to includeeverything as a part of the Preamble forexample you might want to limit yourassistance so that it doesn't respond toquestions that are unrelated to yourdomain but you still need to think aboutguardrails which which is somethingwe'll talk about in a minutenumber two we also found that beingspecific as specific as you can in yourPreamble hopes a lot like for example inthe case of a DOT AI if we were to get adatabase related question we might wantto include more specific instructionsrather than saying be an expert ineverything Google Cloud we can say be anexpert in database Administration and gocloud and that helpsand finally simple Preamble can go areally long wayfrom our experience we recommend youstarting simple not over analyzing thisjust include the most importantinformation you would like your model tohavestart simple iterate learn from thereand refineif you do go down the road of optimizingyour preamblethere are a few things to considerit all can be model and configurationdependent but we found that even subtlethings like tone of voice punctuationorder of force in the sentence couldhave impact for example at one timeduring one of our early iterations ondot AI we found that the tone of voicefor example using please feel free todiscuss certain topics worked materiallybetter than being more firm in sayingonly discuss these topicsof course there are multiplecontributing factors including perhapsthe training data that you use to tuneyour model for example in our case someof our documentation tends to takesoftware tone so as a result the modelmay be able to understand instructiongiven in a similar language betteragain this is just another state ofexample to highlight the importance ofexperimenting and with differentvariations to find out what works bestfor your particular use caseso now we talked about how we could usepreamble to provide guidelines on whatwe would like for our system to be ableto dowe also want to think about what wewould like our assistant not to be ableto do and express those as guardrailsstarting with the basic ones whichessentially are filters that we apply tothe user query before we send it down tothe model for response generation oreven before we do any prompt engineeringso this is our first line of defensein protecting the user as well ashelping ensure safe and responsible useof the large language modelswe can implement this layer usingregular Expressions as well as machinelearning safety filters for that AI weuse hybrid approach where for example wewould leverage regular Expressions tofilter out Jokes which today are out ofscope of what we would like for data tobe able to do we may change this laterand then Jackson personality just toshare an example a few thoughts onhow to apply or think about basicguardrails again in addition toprotecting the user this also helps usas Builders to constrain the problemspace that we're looking at and make itmore tractablethose are also very easy to implementand extend regular expressions forexample also can help us especially ifwe're dealing with open-ended inputsthey can help us with break lossscenarios where sometimes we cannotanticipate ahead of time all kinds ofquestions that we might want to blogso it's a really great first step butit's also very hard to do everything inregular expressions and we might want tothink about specialized filters to makesure we can catch more sophisticatedpatterns in the user querersso this is where the specialized orintent based guardrails come inso those are also filters that we applyto the user's query based on the user'sintentfor example for the red AI we wouldclassify user's intent in one of manycategories for example if the user isasking about VM cost savings we classifythat as recommendations related questionwhich is something that we definitelywould love for the AI to be able to helpwith so we'll let it throughsometimes we get questions that arecompletely unrelated to cloud like forexample recipe or restaurantrecommendationsthose questions will we Block in casewithout AI because this is gained out ofscope of what we would like our productto be able to do todayand in other cases we also utilizeguardrails to flag some of the nulllimitations like for example for billingquestions do that AI right now is notable like Rakesh mentioned to accessuser level data so we recommend totriple check the response to make sureit's valid if it's a billing relatedquestion and provide user withalternative means of accomplishing thatso if your thoughts on applyingspecialized guardrailsnumber one there are multiple techniquesthat exist for intent classificationwith on that large language models workreally wellcontent classification and provide areally easy way for you to get startedwhere you don't need to train the modelthen again this helps us furtherconstrain the problem space to to makeit more specific to our applicationacross the entire stack the choices thatwe make here can make our job easier forexample when I think about Preamble forthe red AI we don't need to be concernedabout designing it for use cases thatare outside of scopeand also finally this helps us provide amore delightful user experience in caseswhen we don't havea good match for the for a given intentwe can fall back with a disclaimerthat's specific to to that contextand for those of you using vertex AI itcomes with generative fallbacks thatmakes it make it easier to get startedand Implement something like that foryourselves as wellso now that we have the intent and ourprompt past the guardrails we can dosome further processing on it sogrounding could be a really relevantconcept you consider in this contextthe process of grounding provides largelanguage model with relevant facts toimprove the accuracy and quality ofresponsesthose facts could be retrieved fromdatabase search engine storage bucket orany other source we include them as apart of the prompt along withinstructions to ask the model toremember or keep those in mind when itrespondsfor example for the AI for a questionlikehow do how does bigtable handleconflicting write requests one of therelevant tags would include couldinclude details on the algorithm usedfor that particular product for Contentresolutionthere are multiple ways to approachgrounding or more broadly retrievalaugmented generationyou might you may also in this contextthink about embeddings plugin basedretrieval this area in general is anongoing research and development areawith lots of discussion out there in thecommunitywe found that using Enterprise searchplus the large language model togenerate search query could be veryeffective way of getting startedand this is here again with vertex AIwhich comes with Enterprise search youcan consider implementing a similarapproachand another observation I want to shareis that grounding is not or sometimesit's it's not effective it could beeffective for some questions but not forothers for example in case with the AIwhich is designed to help with gcpproducts like Rick and shared in thosecontexts grounding is very effective insome other cases we work with AI workswith code autocomplete where groundingcould be less effective so again this isanother context where you can considerusing intent to decide whether to or andhow exactly to implement grounding foryour own applicationand now we're on to the final line ofdefense before we in in terms ofensuring safe and high quality responseson the way back we can filter out anyundesirable responses and Implementadditional quality checksso we can leverage this steppost-processing to apply guardrails justto double check the response againstthings like whether it might beoffensive or not factual or off topicjust like we do to the prompt guardrailsshould be applied here as wellit also allows us to add use casespecific disclaimers if we need to as Imentioned dot AI for example can suggestto double check things in certain casesand finally this is the step where wecould Implement some additional qualitychecks specific to our use caseand as needed rewrite or even regeneratethe entire responsefor example for the AI we would doublecheck if there are any links hyperlinksthat are included with within theresponse we will double check to makesure they are valid if they're not wewould attempt to restore them and ifwe're not able to restore then we wouldflag this to the user transparentlyof course we could regenerate uh butthat would come with additionaltrade-offs so the best approach reallydepends on your specific application andyour desired trade-offs between accuracyquality and latencyso we talked about a few things we coulddoin the middleware layerto constrain the problem spaceto our domain and use case and improveensure high quality of responsesI'd like to also briefly discuss threeuser experience design principles thatwe could apply to help maximize thepotential of our llm poweredapplicationsnumber one is setting expectations whichwe believe it's very important to beclear and upfront about capabilities andlimitations of our systemconsidering how especially consideringhow new this all isa few illustrative examples of how we dothis indoid AI for example we would addGeneral disclaimers to remind our usersabout limitations for example when theyopen a new chat or look at code snippetgenerated for them we would suggest todouble check that codewe also Implement fallbacks forquestions like out of scope for ourproductand in general failing openly as aprinciple highlighting this brokenhyperlink scenario for example issomething that we use for the Nai wethink that setting those clearexpectations helps us maximize thepotential of llm power applications andalso build trust with usersyeahsecond principle is around helping ourusers craft good problems especially incases when we allow for open-endedinputs like we do for the AI chatwe want to make sure we help our usersbe as effective as they cana couple of ways we do this on the DIside we include a a set of curatedexamples example questions for examplewhen user starts a new chat to help themget the conversation started as well asembedded in the context that explainbutton that Rakesh also highlighted inthe beginning which provides an exampleas well as a way for the user to dig inexamine the details and see one way ofcrafting an effective problem forthemselves which can they can then applyin other contexts as well and of coursedocumentation which is another simpleyet very effective vehicle for us tohelp educate the user and encourage themto experiment and figure out strategiesthat work best for themselves when itcomes towriting good problemsso we want to look for opportunitieslike that to empower our users and helpmaximize the potential of our llmpowered applicationsfinally number threewe would like to think about AI poweredapplications as helpful assistancewe wanted to design them to make surethey work alongside the userand that's an important safetyconsideration as well especially in theEnterprise context given today'slimitations of the underlying technologyso a few examples of how do Ican how we are trying to make sure thatwe help our daughter users stay in thedriver's seatwe include citations to sources thatwere used to generate information sothat our users can see where it camefrom and verify things for themselveswe also include links to relevantcontent content relevant to a givenqueryto provide a user with ability toexplore get different perspectives andvalidate thingsand another one is around reviewingcommands before they are runso notice this really subtle differencebetween copy a commanded was generatedversus run itwe think that subtle ux design choiceslike that really matter and help usencourage and enable safe use and alsoincorporate some of those responsibledevelopment principles as a part of thisparticular layer of the stacknow back to Cyrus to talk about testingthank you Dimatesting language models is difficultit's really difficultthese are non-deterministic machineswith open-ended inputs but working onduet we've developed and learned severaltechniques about evaluating and testinglanguage models in a more systematic andmeaningful way we want to share some ofthese techniques here with you todaythe first lessonthat we want to share is the importanceof structured prompt datalanguage models are a new technology andthe new data source that comes with itis prompt data your evaluations yourtests are only as good as your promptsprompt data at a minimum consists of theexpected user query The Prompt and theground truth response what the responseideally would look like if it wasgenerated exactly as you wantedwe found and we think you'll find aswell that managing prompt data in astructured way with well-defined schemasis absolutely criticalthis way you can get all of the benefitsof rigorous data engineering fromversioning to filteringfor examplewe don't want to only understand qualitybroadly we want to understand qualityfor specific products we want tounderstand quality for specificprogramming languages and we can only dothis because we use structured metadatabecause we have well-defined schemas forour promptsyou can of course do this as well in genAI Studiookay now that you have your prompt datain gen AI Studio I hopehow do you pick the right metric to makesure that you're working towards andbuilding a really great user experienceon duet we found that you often need arange of metrics not just one in orderto measure quality and the way thatmatters to yougeneral purpose metrics like perplexitycan give you a general sense of modelquality but they can't tell you verymuch about performance on specific tasksor correctnessto understand quality from theseperspectives we built out our own custommetrics suite and we used techniqueslike expert ratings and comparisonsbetween a ground truth response and agenerated response with techniques likeblue scoresin order to Compare Quality acrossmodels we leverage standardizedbenchmarks like mostly basic pythonproblems a data set of programmingchallenges designed to test the qualityof a model's generated python codeI'm going to tell a quick story hereone of the first things that we try tomeasure correctness is comparing theground truth response to the generatedresponse using blue scoresblue scores are a common metric fornatural language processing tasksthey're easy to calculate and they'reoften a metric that you might considerto get started withwell we found that blue scores aloneweren't enough to measure equality tomeasure correctness in the way thatmattered to usin Google Cloud there are often morethan one where I'd answer to the samequestionblue scores weren't able to capture thisdistinction for instance if the modelgenerated a response that showed how tocomplete a task in gcloud but the groundtruth response complete the task in thepython client Library blue scores didn'tcapture this the response was correctbut the blue scores were lowthis was one of the first findings thatwe had that led us down the path ofbuilding out our own custom metric Suiteso that we could evaluate blue scores incontext and better understand theoutcomes that matter to usokayonce you've chosen your metricshow do you use them to run effectiveevaluationsthe key here is to run evaluationscontinuouslyall the time every day for every changethat you makeeasy enough rightin practice you'll be making changesthroughout the three tiers of this stackso you want to think about theseevaluations as controlled experimentsevery change that you make whether it'sa change to the Preamble in the promptengineering layer whether it's a changeto the temperature value whether it's achange to the tuning method they shouldall be evaluated systematicallya common approach to perform theseevaluations with large language modelsis to rely on humans human evaluationswe found that human evaluations weren'tup to par for us for a couple reasonsthe first is that human evaluationsdidn't operate at the pace that weneeded in order to run continuouscontrolled experimentsthe second is that we found humanevaluations weren't often that great atmeasuring correctness instead humanevaluations would measure whether or notsomething looked correct of course whatmatters to us is whether or not theanswer actually is correctso an effective approach that wedeveloped was a automated testingframeworkwith automated testing framework wecould calculate quality metricsprogrammatically then we would calibratethose metrics against expert ratingsthis approach is very effective butrememberwe're building a product that is goingto have a great user experience for realpeople for humansin the end Direct customer feedback andhuman evaluations should always lead thewayall right I'm going to bring Dima andRakesh back up to the stageall right so we have talked about quitea few quite a few 14 accounted topics tofor you to consider when you go aboutprototyping your own llm poweredapplications just to reiterate threemeta points that cut across number oneEnterprise applications there they tendto be unique and Target to specializeTarget specialized use caseson the one hand this can help us asBuilders to make the problem moretractable by applying constraints acrossthe stack but they also come with uniquerequirements that we need to keep inmindfor example we talked about accuracythere's many morenumber two large language models ofsurrounding development as a domain soas Builders we need to stay agile andflexible keep up with new trends and atthe same time balance fastexperimentation with those with doingdevelopment responsiblythe good news is that the gettingstarted is easier than ever vertex AIprovides a library of foundationalmodels and all the tools that you needto get startedpotential applications of llms go WayBeyond chat that we highlighted todayand we hope that the general principleswe discussed will come in handy as youbuild your own applicationssuper excited to see what you do nextso oopsso um hopefully this gave you a goodoverview of what are the things involvedin developing llm-based applicationsand we put a lot of effort into AI butwhat are we thinking about as we moveforward so you heard about some of thechallenges uh with duete with any kindof llm based application it's newtechnology it's probabilistic to gainthe trust of your user you know theyexpect perfect responses but with theprobabilistic model it's hard to give aperfect response right the things thatwe're going to focus on in the nearfuture is make Enterprise Readiness forDo-it AI a much more holistic experiencewhich means reduce hallucinations wewant to improve the quality of theresponses we want to improve theaccuracy of the responses and one thingthat is probably the most critical isunderstand the intent of the user rightI mean the user can ask any kind of aquestion right we're not constrainingthem what do they actually mean and howdo we provide the best response to theintent of the question even if they havespelling mistakes or poor grammar buthow do we provide a good response tothat is the first thing second thinglike I mentioned at the beginning isfocusing on personalization you know howdo we make it understand your projectyour resources you know other billingdata that Dima was talking about so thatthe responses that we provide are muchmore rich contextually and the lastthing is the steward AI experience willnot just be a side chat experience butwe much more integrated like the loggingexample I gave you so whatever you arein the cloud console or in the IDE andif you're looking for a specific pieceof data and you want advice orsuggestions or help about that you'll beable to invoke do it AI right from theresoum for those of you who may not haveattended other duet AI sessions or ifyou're interested in more here's just aquick list an introduction to duet AI Ithink that session already happenedyesterday but its recording will beavailable so as you go back to yourcompanies you want to share that youknow that's one of them there's adeveloper Focus developer productivityFocus session that's tomorrow morningthere's a spotlight session thisafternoon at 4 45 which kind of brings alot of these things together and if youwant to learn about prompt engineeringthere is a session tomorrow as wellabove all if you want to kick the tiresand try this on yourself and see whatthe experience looks like go to theinnovators Hive and you know there aredemos there which are showing you thelive product you know try it out therewell thank you all very much for comingwe really appreciate your uh you knowbeing here and listening to us and enjoythe rest of the event but if you get anopportunity do give us some feedbackthrough the application thank you verymuch"
}