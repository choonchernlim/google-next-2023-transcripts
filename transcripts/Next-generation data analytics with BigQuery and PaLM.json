{
    "title": "Next-generation data analytics with BigQuery and PaLM",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA211"
    ],
    "video_id": "yPq7Gie3yOw",
    "time": "Aug 31 12:15 PM - 01:00 PM CDT",
    "transcript": "foreign[Music]welcome to the Next Generation dataanalytics with bigquery and palmI'm Chris Crosby I'm a group productmanager here at uh bigquery and I'mfocused on Advanced analytics Advancedanalytics is a set of capabilities thatwe have within bigquery that go beyondjust SQL this is things like addingspark stored proceduresum going after adjacent market like loganalytics and search but then alsothings like Ai and mL of course joinwith me as soon as you want to give aquick intro hey everybody I'm Shane MetzI'm the CTO at Faraday and uh yeah we'rea consumer predictions uh company butyou'll hear about more about us lateryeah thanks so a quick rundown of whatwe're going to talk about today isum we're going to give an introductionto Google's data and AI cloud and I'mgoing to give a demonstration of ourinterface for that now which is bigqueryStudio we're then going to hit on someof the foundational models that we'veactually integrated with bigquery I'mgoing to show a very lightweight ragdemo with bigquery data and then finallyuh him back off the Faraday he'll talkabout how they've put some of thesecapabilities into their customeranalytics platformso ml is pretty pervasive throughout allof the Google cloud data tools there'sobviously vertex which is this wholeSuite of machine learning tools but thenbigquery has integration for doingmachine learning at scale ouroperational data warehouse databaseslike alloy and spanner they can use theinference endpoints that you wouldcreate in vertex and you can have lookerthat gives us predictions back to thebusinessbut what we had found by working withcustomers is the journey for creatingthese Ai and ml applications you'regoing to go across a lot of theseproducts that each have their owninterfaces that you might end upswitching programming languagessometimes you're even trying to movedata in and out of these differentsystems and that's why we announced thisweek bigquery Studio our goal withbigquery Studio is we want to give youthat guided path through the data and AIJourney uh if we want to make it easy totap into all the different variouslanguages and as we started to build outbigquery studio and its interface onething that we realize very quickly is itwasn't just a UI problem either weneeded a more natural programminginterface for bigquery other than justcopying the SQL statement into a pythonnotebook and so as part of bigqueryStudiowe've also created a new uh pythonpackage bigquery data framesthis python package it pushes to Ai andml processing that's done typically it'sdone locally in your notebook that'sgoing to go back into bigquery and thenthat's going to let you work with theseCloud scale data sets that you reallyneed to build generative AI applicationsnow the Big Frame package that's goingto come pre-installed in bigquery studioEnterprise co-lab our notebook Partnershex and deep note but you can also justgo and pip install this right now andtry it outthis big frame package it does have twodifferent apis one isbigframes.pandis uh it it's not exactlypandas but it should be very familiarfor those of you that uh are coming froma pandas background and it is for dataexploration so the things you're goingto be able to do in here is things likeinput output of data if you need tobring in data from different uh Sourcesystems and put that into bigquery itmakes it easy to do that there'summanipulation including things likeindexes and sortingit gets you access back into the pythonecosystem so it lets you tap intodifferent visualizations you might befamiliar with like matplotlib andSeaborn and finally it lets you writeyour own custom Python and then deploythat back into bigquery and run yourpython code on bigquery data at scalethe second API bigquery.mlthis is essentially bqml exposed as apython interface so all the bqmlfunction that's built into bigquery isalso here but very soon there will alsobe a handoff to the vertex 2.0 API so ifyou did have a custom model you'll beable to hand that directly to vertex 2.0and it'll understand how to work withthat uh Big bigquery Data through thatbig frameso now that we have python exposed inbigquery I thought it'd be fun to getstarted with bigquery studio and findsome useful python packages maybe youmight want to go try out hereso what you're looking at here is justour landing page for bigquery Studiowhich is probably going to look familiarto a lot of you and what I'm doing hereis I'm searching for a table that mighthave some python functions and I'll goahead and preview this dataand what comes back here is a bunch ofinformation about the python packagesthat are available in Pi Pi looks kindof interesting so I'm going to go checkout the landing Edge it does look likefolks are using this and I can go andlook at the exact SQL statement thatgenerated that table and I'll Trace thatback to the initial tables where thiscame from and I can see very uh easilythat this through the lineage does thisreally this came from a bigquery publicdata set this is just data that we havein bigquery that we expose to you tomake it uh easy to get started with alot of common data sets and so I now cango look in our Marketplace check outwhat that data isand I see that it's got this uh uh allthe details about this how where it camefrom and now I kind of know where thatdata came from I trust that table so I'mgoing to go ahead and start to look atsome of the descriptive statistics thatare associated with this and veryquickly I can feed things like you knowthere's about 4 800 is the averagedownload of python data most of the datain here is going with python3 so itlooks pretty interesting so what I'dlike to do now is explore that furtherwith the python notebook and so I'mgoing to come inand we'll turn it uh we'll spin up a newlight dot notebookby default I'm going to have twodifferent ways to get started with thatdata the first example is traditionalpandas if you think your data can fit inmemory the second one shows you how toget started with big frames thebackground connections these are allvertex runtimes the same ones thatyou'll use with Enterprise co-lab and ifyou're using big frames for the mostpart you can stick with the smallestinstant instant size because all theprocessing is again getting pushed backinto bigquery not the notebookso just a very quick you know gettingstarted with pandas here here where Iread in the data into a big frame againit is happening on the bigquery side youcan actually see the uh at any point thejob that's actually getting generated asa SQL statement behind the scenes forthis so there's a quick example in thisinstance here when I'm creating the dataand it stays in bigquery I can even giveit unique indexes so if I know that Ihave a primary key in my table I can letthe I can let G read the read gbq knowwhat that is and we'll use that we'llkeep all the data in place and you cansee okay here's the data uh just runninga simple head that came back informationabout the python functionsand here I can this is just anotherpiece of typical painters manipulationI'm doing a filter I'm looking for theBig Frame packages that are out on Pi Piand you can see that there's actuallyI'm trying to figure out the number ofdownloads what are the popular downloadsand there's a lot of roads for bigframes because every time I went andchanged a description or a version itcreated a new rowso I'm just going to do a simple Groupby via a pandas operation and now I haveessentially an index of names with thenumber of data logs next to itand againumwell I'm just now turning that into adata frame and what I want to do thoughis I'd actually prefer that this data besorted by the number of rows instead ofby the name and so I can reset the indexthis is something you don't typicallyget in a data warehouse where you haveto go you don't have guaranteed orderingbut we can create this within the dataframe within the Big Frame and so I cansee them it used to be the name that'sthe index name but now I want toactually store these sorted index by thenumber of downloads you can we also dosupport multi-indexing if you need to gothrough multiple layers like you wouldin typical pandas that's available butwhat I can do have now is a sorted indexfor all of the Python packages uh to buynumber of downloads and then let me justtake a quick look at you know what aremaybe not the most popular packagesthose are pretty familiar to all pythonusers but like what are the next setbetween like 20 and 50 that might beinteresting for us to go take a look atand so that's what comes backnow of course this is all just aprecursor this is how you typicallywould get started with your machinelearning just exploring the dataunderstanding what's therethere is a lot of text here alsoassociated with this data and so I'llshow just a quick summarybut then we're going to come back tothis later and do some more interestingthings with the actual text descriptionso just a a little teaser hereumnow you may have noticed something thatwas happening on the left hand side asthis whole demo is happening is therewas versions of the notebook that weregetting stored as we were doing allthese manipulationsso I'm gonna actually go and look andcompare the notebook that I was playingwith versus the original notebook that Istarted with and you can see where allthe changes occurred and so I'm going togo ahead and just go ahead and revertback to the original notebook that I hadand restore that versionand so now back you know right where I'mstarting from I had that whole versionhistory as we wentand now that I have this notebook and Ihave some cool packages maybe I want togo share that with one of my teammatesso I'm going to go aheadhere this notebook with Joe Malone ournotebook product manageryeah Joe uhand so we share that with Joe we'll justgo ahead and make him an admin so he cango and clean up all of my code and fixthat for meand now it's shared with him and I cango save that notebook and uh move on andso that's generally bigquery uh studioin a nutshell and how you could use thatto get started with some of uh your dataanalysisnow I want to get into some of theInnovations we've actually done with thevertex AI foundational models inbigquery so we've extended the bigquerySQL capabilities with llms there's now aremote SQL function that you can use torun a SQL query and that's going to usethe vertex text bison model on yourbigquery data today text bison is backedby Google's Palm 2 large language modelbut over time you can expect that thoseunderlying models are going to continueto evolve so you're always going to haveaccess to Google's latest Innovations inthe AI spacewhat did I when I said you knowintegrating with SQL what does thatactually mean this is a good example ofwhat it means what you're going to do isyou're going to come in and create aremote model that references a cloud AIlarge language model V1 again that'sPalm today and then I can now run a SQLfunction that can generate text I giveit the model name and then I give it aprompt along with any data that I mighthave that uses it this example here I'mgenerating some new data where I have abunch of cities in a column and I'msaying hey give me the country for thesecities and it'll generate new data thatmight be useful for Downstream analysisI can't go forwardokayI think this isyeah so here's the next demo veryquickly to show off how we're actuallyusing this and this is a real example ofsomething that we did on the big framesteam in this example I'm going to usethe big frames.ml API so we use pandasbefore now we're going to use the mlpackage and you can see what comes backthese are mostly a subset of the bqmlmodels by the time we hit Generalavailability all the bqml models shouldbe there and I'm just going to set thisup and what I want to actually do hereis I want to use the Palm 2 model to goand help us bug batch big frames to helpus find some examples that we didn'tquite get right the first time and wewant to go fix that and so what I'mdoing now is I'm reading in a CSV filethat contains all of the apis forum for a pandas data frameand I can go do a quick check and lookforthe API and when I read that in csvn itactually does move it into bigquery andit keeps all of the you know the rows asyou would expect all the ordering and sowhat you're seeing now is just all ofthe different API calls that areassociated with the pandas data framenow what I want to do is I want to setup my prompt and what I'm going to askthe llm to give me is I'm going to tellit to generate pandas sample code fordata frame and then I'm going to listeach of those apis that were in that CSVfileso at that point I'm going to run thisprediction this is feed up this is spedup a little bit for the videothere you goand when that comes back I'll show aquick example of what comes back whichis essentially a set of example code foruh in pandasfor each of the API callsforeigngets cut off but those are you know fullexamples but they're all in Panda such athing and we need to uh test big framesso python is typically pretty good atprocessing so very quick just textprocessing function I have right hereI'm going to tag it as a remote functionwhen I do that what happens under thehood is that's going to get deployed toCloud functions and then it's going tocreate a remote function in bigquerythat hooks into itand so all that's Auto deployed so youcan actually run that python code atscale I can see the names of either oneof those functions that were created Ican give it a name so if I wanted tohand that off to somebody else or knowwhat that name is or keep that in a dataset I I could do that but in here wejust created a default data set adefault name but you can go see I searchfor it and it does exist as a SQLfunction as well in bigquery so I cancome in and you can see what thisfunction does it's pretty simple butwhat it does is from bigquery SQL I canjust put in import pandasource PD and itreturns import big frames SPD that's aSQL statement that's running pythonunder the covers that you could use asany other SQL statementso back into our notebookI now I'm just going to apply this is ayou know standard data frame techniqueof applying that function to ouroriginal llm code and now I have a bunchof big frames generated code from thellm that we actually did go and runagainst big frames to go find a bunch ofbugs to we could go troubleshootso what are some use cases you mighthave for ML generate text uh we areworking with a beauty supply productscompany and they're creatingum personalized emails so they have datain their database of columns that arelike demographic information like thisis a woman from uh canvas who's age 60and then it's personalizing the messagethat they want to send to themit's really good for a lot of common NLPtasks that can get problematic so thosethings like classification inventoryextraction sentiment analysis llmsreally can help simplify a lot of thatand then rewriting and rephrasing soputting umwe were working with this one callcenter and they have a lot oftranscribed data that comes from theircalls it often doesn't the computeroften doesn't get it right it's kind ofsloppy and so they're actually using thellm to clean up a lot of that data tomake it easier to read Downstream by theanalystsoum now that we've talked a little abouthow to just call the llms from SQL anduse that with big frames I do want togive a quick example of how to take theuhuh the bigquery data warehouse data anduse that to actually put some guardrails around that llmand I'm going to do that with a vectorsearch using and now generate textembedding and ml distance so before Ihop in here just to show you before Ihop into the demo just to show you whatwe're going to get so you have an ideaof what we're doing is the step firststep is we're going to train this Manticembeddings which is we're going to takethat python data and we're going totransform it into numerical vectors andthen we're going to go find within theuh the vector space similar clusters ofinformationsolet's pop into the demoso the first thing I'm going to do hereis we're just going to create one ofthose remote models this is essentiallythe same thing that you saw in bigframes but this is going to be just theSQL version of itand I'm going to create a prompt it's atable of props that's just one promptwhich is what's a good python packagefor working with embeddings in bigqueryand then I'm going to go ahead and callout to the Palm model and I'm going toget back the answer to that questionusing that model and my prompt some goodpackages for working with embeddingsand you'll see what I get back here andI can set something things like thetemperaturewhat I get back is BQ embeddings it's agood choice for working with embeddingsand bigquery it provides simpleintuitive API blah blah blah that soundsawesome I definitely want to check outBQ embeddings I'm going to go use BQembeddings right now so let me go takeBQ embeddings and do a search for thatin that list of python packages that wehave from pipeiand it turns out there's no data becausethere is no package called VQ embeddedjust completely made up it's just ahallucination by the llm it's nonsensewhat do I do so what we're going to dohere now is I'm going to take the actualdata about the python packages and I'mgoing to create vectors out of for eachof those based on the palm embeddingmodel here now we do support other typesof smaller models if you need those likeuh Bert and some of the other ones buthere I am using the llm oneand now just so you can see what itlooks like after I run that function inbigquery is I have on the left hand sidethis is an array of numerics along withsome other information including theoriginal content that uh I I want tolist from the tableso with that I'm not going to create astored procedure so just a script that'sruns in bigquery and what it's going todo is it's going to augment that promptas it come in as it comes in the inputis we're now going to be the The Promptthat I send it and the first thing I'mgoing to do is I'm just going to takethe query that comes in and I'm going toturn that into a vector itself and whatthat's going to allow me to do is I cannow search within the vector spaceagainst the that python data against thequery that I give it and see what arethe common things that are clusteredaround it are you going to use mldistance ml distance is a Brute Forcetechnique so you're going to get theslowest result but probably the mostaccurate result most of the functionswithin bqml doof does now supportembeddings based on that what comes outof the content generation but we'regoing to use these ml distance here andI'm going to limit to the top fivepackages that come back and then what Ido here is I'm going to just Loop to thetop packages and I'm going to extend myprompt to understand what these packagesare and that way I have some guard railsfor the L1 to say Hey you know provideme the answer but within the the scopeof the data that actually exists andmakes sense you have some data to feedin and so now I'm gonna then the laststep is I just rerun that exact samefile model I did before but with myaugmented prompt so I will now kick offthat stored procedure in a separate callhereso back into SQL games just a SQLstatement but you can see the steps asit runs I'm going to rerun that exactsame uh prompt which is what's a goodpython package foruh working with embeddings in bigqueryand now we kicked it off and you can seethe you know we're now going to actuallydoumdo that distance function to findsimilar real data firstand that's what this is a show that'swhat that is right there and then youcan see the prompt the new prompt thatgets generated and so this is now thenew prompt that gets generated which isfrom the below list of python packagesprovide the answer to the question thenit's the input that I had and then alist of real data uh from the warehouseand so with that new prompt I have a newanswer to the question about what's agood python package for working withembeddington VQand that answer isthe best package we're working with uhbigquery is Big frames and that's legitbig frames actually does have a bunch ofembeddings it's the right package youshould go use if you want to try to dothisso what are some use cases for Vectorsearchum that you just saw it's oftentimesgood for long-term memory so it's kindof expensive and processing heavy tocreate a bunch of these uh vectors soyou want to keep them just stored inbigquery that way if you have otheralgorithms that you want to do again youdon't have to regenerate the embeddingsuh semantic search it's a very very bigbuilding block for semantic searchespecially you can pair it up withthings like k-means model which we alsosupport and have some blog post aroundum as well as just things likerecommendations find me similar thingsthat's uh step one of what everythingyou saw just now because exist today youcan go use it coming very soon and weare looking for you know previewcustomers for this uh by the end of thisyear we are going to also support Vectorindexes directly within bigquery meaningthat you'll actually have aum a way to quickly that you can justpoint a uh using SQL you can just Definea vector index on a table to point tothe embeddings and we will keep thoseupdated in an index behind the scenesthat's going to provideum approximate nearest neighbors searchtwo other real quick things just the endon of ways we've integrated llms intobigquery one is document analysis a realquick highlight on this oneum if you put your data through documentAi and you have a bot a lot ofstructured data on the bigquery side wecan actually generate a table of all ofthe information completely structured asa table on unstructured data with thisfunctionality and then finally ourbigquery migration service which is a uhit's basically a compiler with a bunchof heuristics for converting differentlanguages like teradata SQL intobigquery SQL we've now augmented thatwith additional AI recommendations so ifyou don't like what's coming out of thecompiler or there's something missingyou can just generate an AIrecommendation then accept the rejectthatso with that I'm now going to hand offto Saturday to talk more about howthey've actually used some of this stuffawesome hey everybody so I'm Sheamus I'muh I'm the CTO and the co-founder ofFaraday and I've heard us described asheadless AI or machine learning forCommerce and we're built on bigquery thethe number of things that you know Chrisjust showed is just scratching thesurface of all of the functions that arerevealed directly inum in the data warehouse and sowhen a new function comes out inbigquery ml we're often able to turnthat into a new product on our platformso let me see if I canhere we go yeah we power the predictionsbehind a lot of call centers tablet appsuh vertical crms basically if you have adatabase of us consumers then we canbuild lead scores churn scores uh allsorts of all sorts of different thingsand what sets us apart is that we'reusingumthird-party offline data responsiblysourced to enhance that so instead ofjust looking a customer in terms of thenumber of times they've come to yourwebsite or some Anonymous devicedetails Faraday actually knows every usadult and can work from features like doyou like to Garden do you like catswhat's your household income all thatstuff and something's not mentioned herebut there were were happy to announcethis quarter is uh the ability in ourmodels to mitigate bias along any one ofour demographic features and so you knowlet's say you're in you know banking orfine banking or insurance and you haverequirements aroundensuring that you're not doing proxydiscrimination well you can actuallyactively invert bias inside a machinelearning models so we're trying tofollow Google's responsible AI practicesand and build that all and make it kindof table Stakes for any buddy trying todo consumer predictionsso we also do LTV and all of thesethings correspond toumessentially functions made available tous in bigquery now it's funny when Chrissaid you know create a remote model forthe llm you know create a remotefunction the thing about bigquery andbigquery ml for us is that it's notremote right it's all happening insideof our data warehouse and so we're notdoing any ETL and we'veumwe've used all the different model typesup here on the screen everything from XGboost to k-means to build Real Worldproducts and a story I like to tell isbefore bigquery ml our data science teamwould develop a new product a new a newapproach and then they'd pass it off tothe platform team and the platform teamwould turn it into HTTP calls and retrylogic and all that stuff but ever sincewe moved on to bigquery ml our datascientists are building the modelsthemselves by invoking SQL from pythonsosometimes it's a lot to process when welook at you know bigquery Studio whichis an amazing Innovation but you kind ofask yourself well could I really build areal world application on top of astudio product no and that's not thepoint you know it's more forexperimentation when it really comesdown to building uha machine learning product in this dayand ageyou're probably going to be using pythonto do the orchestration to to kind ofset up the stage but the ability to justinvoke SQL and take all the knowledgethat your employees have about SQL whichhas been around since the 70s uh insteadof having to relearn window functionsand pandas and all that stuff and againBig Frame is a great product my datascientists have been asking for lazydata frames for for big query for a longtime SQL is really a great way to dothis stuff so explain predict that's agood example of the SQL function builtinto bigquery that lets us createexplainable AI so that when we do aprediction of propensity to purchaseacross 50 million customers we're ableto explain on every single row why thatperson got that score well it's becausethey like cats or it's because uh youknow they live in this area or somethinglike that so it's it's very featurecomplete that's another thing I'd liketo say about bigquery and vertex ingeneral is that the variety of modeltypes isum is very strong and so you know Ithink one of the most popular use casesis time series but you've also gotclassification regression clustering andall of it works at scale and so whenwhen Faraday was transitioning from ourprevious provider to bigquery ml one ofthe things we're able to do is basicallytake tables that were 250 million rowsand 250 columns and run predict againstit with a brand of forest with 256 treesin it and it just you know it took 10minutes and the key thing was that italways worked you know we didn't have toto build a lot of orchestration aroundthatso one interesting use case forgenerative in particular is sentimentanalysis and that's because when aclient comes to us they have structureddata in the form of transactions clickstream view stream but they might alsohave call center logs or you know othernotes that their employees have taken orsomehow collected and soif we can extract this then we can useit in our predictive models right we canessentially create featuresuh from unstructured data and so here'sa real example of a call center logand then what we did was we tried tofirst use the cloud NLP function so Ihope there are product managers in theroomand what we found is that it just didn'tget it like when we tried to ask it wellhow does this person feel aboutfinancial productsthe NLP API just didn't quite get itright it wasn't making connections uhholisticallybut thenyou know we asked the llm we did thecreate remote connection uh to a textbison model and then we ran thisumbut we ran this promptand we started immediately getting cleanuh you know a clean analysis of it nowone interesting thing about this isumsometimes the llm would respond withhere's your answer and then a markdownblock full with Json and then sometimesit would respond back with just plainJson and so among other things you canumyou can tweak the parameters to mlgenerate text and turn the temperaturedown to zero to get a really seriousanswer instead of a really creativeanswer so that's a good a good tip therealsoum I if I understand correctly if you'retrying toif you want an explanation to bereturned in a certain form that would bea good use case for fine tuning andfine-tuning in in uh in bigquery ml'sllms is related to fine-tuning andvertex Ai and it basically resolves downto make a a file where every line isadjacent with an input and an output andthen the llm kind of learns how you wantit to respond to certain things andthere's other projects like Jason formerthat we've been talking to the productteam about maybe implementing but anywaythis is this is really cool because ifI'm building a model for retention orlead scoring or anything like that forthis financial clientI can get a sense of how people feelwhen they when they've called in so thisis something thatum is really cool and nice to have rightnext to the dataanother use case is content generationand I was very happy to see this I wasat a chat yesterday with the chief dataofficer of uh and I'm going to manglethis pronunciation of Carrefour which isthe biggest retailer in France andpossibly in Europe andumhe had a chart of projects that could bedone with generative and he had oneaccess was impact and the other axis wasfeasibility and sothe most impactful and the leastfeasible at least according to hisinitial analysis was something like aContent Factory that would allow you togenerate personalized marketing and sowhat they did wasturn briefs into very targeted marketingcampaigns so what we're going to talkabout a faraday though is since we haveaccess to individual consumers that abusiness hasand we also have a national data set ofdemographic data demographic propertyFinancial life event all that stuffwe can actually personalize the messageson a per person basisumso you know today and this goes back tothe whole advantage of bigquery ml beingthat all this stuff is built directlyinto the database instead of having tobe accessed through the network you knowthe previous approach was you know let'sspin up a a very robust HTTP call tosome external llm which by the way youknow you also have to be concerned aboutensuring that whatever prompts that yousend in are going to get saved on theirllm which is another advantage of thevertex AI Foundation models is you ownthat particular model and anything thatuh that it sees is is going to stay ininside of your VPC so the previousapproach was again the network but withllms and bigquery we can create a promptfrom every single row of data and sohere what I'm doing is I'm saying I'mjoining my marketing campaign which hasone Roper person with my demographicdata which has one row per person in thewhole United States and I just picked acouple different attributes to tell themodel about and so what I loved aboutthis was that I took a real customer ofours that sells intelligent humidifiersand I said well how would you rewritethis for an older person and itimmediately came back and I don't knowmaybe they should fix this in theirmarketing in general but it's it youknow it's it simplified it down to ahumidifier that turns itself on and offnowcontent generation is fraught and so oneof the reasons we picked productdescriptions instead of an entiremarketing email to start was that we canimagine rolling this out whereumyou know maybe it's under the fold it'sthe kind of thing that once you've hitthe initial marketing message that waswritten by a humanmaybe we follow up with some gen AIgenerated uh customized content but uhsome of theum I was actually talking yesterday withthe CTO of the world's largest marketingagencyum who some of you may have seen akeynote and he was saying well take arag approach you know uh or maybe whatThomas was talking about you know within grounding and just ensure thatum you're able toensure that the llm is making responsesfrom a real Source about your particularproduct another another time I triedthis and this was actually before Iturned the temperature to zero I askedit to to come up with some marketingtext for another product and it inventeda tech not like a humidifier technologythat didn't even exist it's called likeclear air or something like that so youdo have to be a little bit careful withthaton this use case I will also say aninterestingum an interesting possibility to thinkabout is usingthe results of predictive AI likedecision trees to inform your promptsright so like if I'm gonna do this forall of my customers I don't just want toalways have the marketing message begenerated according to age and genderright depending on product affinitiesthere might be different things thataffectwho that Brand's clients are and soagain using bigquery ml classifiermodels I can build a model predictingwho's likely to be a customer in theUnited States and then I can look atthose feature importances and say wellmaybe I'll take the top five you knowmaybe one of the top five is like aninterest in science and then I can addinto my prompt you knowrewrite this message for somebody whohas an interest in science so it's stillearly days uh but it's it's a veryinteresting and and and chiefly it'ssomething that you can experiment withwithout moving this data anywherewithout you know asking your datascientists to write any python to take aCSV and hit an open API or you know somekind of an APIso that was our two use cases and if itif it comes down to one thing it's theintegration I I think that the lack ofthe fact that you don't have to ETLstuff the fact that Google research isessentially taking care of parallelizingeverything it reallyum I think is a an interesting approachthat you should consider when you'rebuilding a machine learning applicationis instead of going towardsyou know python pandas spark it's it'sinteresting to to build it just directlyin SQL uh because you know it's kind ofthe lingua Franca[Music]"
}