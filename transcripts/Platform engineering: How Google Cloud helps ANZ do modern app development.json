{
    "title": "Platform engineering: How Google Cloud helps ANZ do modern app development",
    "presentation_type": "Breakout",
    "categories": [
        "DevOps, IT Ops, Platform Engineers, SREs",
        "OPS301"
    ],
    "video_id": "QDghS96Kd9g",
    "time": "Aug 29 02:15 PM - 03:00 PM CDT",
    "transcript": "foreign[Music]my name is Nick eberts I am a productmanager at Google working on fleets andI'm I'm here with Michael frano Michaelyou want to introduce yourself yeah higuys uh my name is Michael fanaro I'mone of the platform Engineers for ANZwhich is an Australian Bankyeah that's awesome we also have Tim amajor contributor to this talk he'ssitting right here he's going to answerall the questions at the endall right so what we're going to go overtoday we're going to talk about platformengineering what is platform engineeringand how it's different from devops maybeI don't know and then also uh ANZ isgonna we're gonna talk about theirJourney towards building an independentplatform we're going to talk about teamstenancy and how we can help solve thatwith TKE fleets and then we're going todive into the evolution of AMC'splatform like how they're progressingwith the Google order over the nextcouple of yearsum do a little bit of a deep dive intofungible clusters another demo and havesome q a if we have time sound goodthat no no doesn't sound good all rightlet's go all right soplatform engineering Michael you'veheard this term before Shirley but wheredo they come from like why are wetalking about this now yeah so platformengineering has been around for a fewyears now I think it's going in a lotmore popularity a lot of people out heretoday probably have heard the termdevops is dead and all these types ofthings and I don't think platformengineering is really there to replacedevops at all they actually worked welltogether but what platform really is atits Crux is it's thinking changing theway you think and you build the platformitself thinking about as aas a tool not just a tool but an actualumyeahso one of the things is that werecognize right is that when we're onthis path to devops it was oh hey youknow ship the org this way I'm going toco-locate these Engineers with thesewith the with the software teams andthat's the way it's going to work andthat works for a lot of people too butwhat we're seeing is that especiallywith kubernetes there's thisproliferation of clusters you've got alot of infrastructure to manage andthere's a good benefit to centralizingit right especially on theinfrastructure bin packing side but alsoon the human being toils side you canyou could build this abstraction andthen deliver that to the dev Engineersinstead of having to kind of ship devopsacross your org of hundreds of businessunits so the thing is platformengineering iskind of like a repurpose of the devopsphilosophy so devops is greatbut it's a philosophy it's a practiceand platform engineering is just one wayto sort of implement that with kind ofcentral controlsum so I love this model uh shout out tomy co-worker Eddie viaba he came up withthis and I stole it so thank you Eddieif you're watching umso this this kind of model helps youbreak down the problem right on the topyou have these domains that you have toship and and sort of think aboutbuilding right that's the point of theplatform you're going to talk aboutum how you're going to ship code howyou're going to build code how you'regoing to deal with tenancies securityobservability and then on the bottom youhave like Cloud providers and a pile oftooling on top of it the interestingthing here is that the commoninteraction between these two layers isgetcontainer images or oci images and theGoogle or Google kubernetes resourcemodel rightand so that the power of having thosecommon abstractions really helps youhave flexibility and choice over what itis and you're going to build and howyou're going to build itum so hopefully this model helps you outwhen you're reasoning about uh platformsbut let's go to the next slide I alsowant to call out that when you build aplatform you have to figure out who yourusers areum maybe in day one is your prototypicalum Dev user I don't know what that meansanymore but maybe that's your first userrightum the beauty of kubernetes is that asyou progress and build that interfaceand build that abstraction for the devuser you can then say Oh wait hang on Ithink llms are really cool right now somaybe we should build an abstraction foran AIML data scientist human personum and you could build it on top of thesame infrastructure so two key things isone you can serve multiple multiplepersonas from the same platform bybuilding interfaces that make sense forthemand then on top of thatdon't try to do all of them at oncedon't build a platform for 10 differentpersonas at once you will not have agood time likely fail pick one get aquick win learn some things and thenstart to add the users as you go alongyeah so before we really get into whatwe've done in ANZ and like how we'vebeen able to deliver our platformwe'll start with like what is what is itthat ANZ has tried to do over the lastfew years so anzx was a division in thebank that had this vision of reimagininghow banking would be doneand so what this led to was whateventually became a new digital platformor a new digital offering to itscustomers known as Amazon Plussothis is uh this is the new bank thatwe've been delivering over the last fewyears and these are just some of thefeatures that the new digital bank hasbeen able to cater for now historicallya lot of these sort of customer Journeysor experiences were very fragmented wedefinitely had mobile apps and we hadweb apps but a lot of these experiencesstill meant that customers would have togo to a branch or go see someonephysically and that wasn't what wewanted to achieve with this new digitalplatform that we're buildingso why was it worth us investing theplatform team to create ourselves an IDPinside of anzxit comes down to thisevery one of those customer experiencesor Journeys translates to tens hundredsor even potentially thousands ofdifferent micro services so if we wantto be able to scale and provide the bestcustomer experiences and Journeysrapidlyat a velocity right that continues togrow and meet that demand then we needto be able to have a way to ensure thatEngineers are focusing on the rightthings and not having to deal with lowlevel complexitiesand the reality isthat this ecosystem that we're buildingcontinues to grow and this is somethingthat engineers in all organizations facethis uh this ability that where theyhave to create a platform to be able toensure that your engineers can movewithout that frictionso how did we do it well first of allI think it's important to look aboutwhere we actually came from so wedefinitely didn't get it right the firsttime and so about two years ago westarted building our platform and wethought we knew what our Engineersneeded and so we had regulatoryrequirements and we had securityrequirements and that led to our firstinstance of production which eventuallyled to us going live with our ANZ plusoffering in about 22 and two so sincethen it's been fantastic we've had arock solid uh production cluster wehaven't really had any massive outagesor anything like that howeverthinking of the platform offering as aproduct to our internal Engineers thefeedback was always consistent from theengineers and that was that it wasextremely hard to actually get theirsoftware all the way through toproduction especially in a financialorganization it has so manyum Gates and things that the processesthat they have to go throughso we wanted to try and address thisfriction and really simplify theirprocessso what that led to was us partnering upwith Google engineers and that'sactually last year that's where I metNick and I met some other greatengineers in Google and we tried toreimagine our platform and treat it likea product rather than just a collectionof tools that we throw at engineers andtry and get them to figure out thosecomplexities and how to use themand so we're actually still building ita lot of the things that I'm going to beable to demo a little bit later arethings that we're building and are inFlight right now so this isn't like aperfect thing we're continuing to evolveand the key part is we're always lookingat changing our engineering culture sothat we get early adopters into this newplatformand that way we get these feedback loopsvery early to make sure we are solvingthe right problems as a platform teambecause we don't want to waste effort ifno one's going to adopt it in the end ofthe day and I think that's a really goodgauge if you're tackling the rightproblemsso what did we do well at a high levelwe've tried to build the platform as anecosystem of our own internal apis sothese are contracts that we have betweenus and our engineersand so what we're able to do with theseapis is we're able to use these tocreate really good Automation and we cancreate clear interfaces using API V3schemas and these interfaces are nowdeclarative things that we can store inSource control and Engineers are able toself-service choosing from an array ofuh patterns that we've alreadypre-approved and have prepared for themout of the box and it takes away a lotof that complexity now the other part ofwhat we've been able to do in thisjourney now that we've got this alldeclaratively defined is we're leadingheavily into get Ops so in ourparticular case we're using flux CD tobe able to sync all these manifests intoour management clusters Withinour custom built operators andcontrollers will then be able toinstantiate those thingsnow interesting note um for those whohaven't heard of KCC that's an opensource Google tool it's calledkubernetes config connectorand what this allows us to do also isalso build our infrastructure and lifecycle manager with our kubernetesapplications so this has been a hugething typically we're always we're usingterraform and the lifecycle managementwas completely fragmentedum and I'll touch on a few of thosepoints a bit later but using things likeKCC where it's a declarativerepresentation of your infrastructureflows perfectly with the skid-offs andcreating multiple clusters and fleets ofinfrastructure which we'll touch on soonand obviously the end goal here is thatwe want to be able to have our Engineersself-serviceable completely autonomousso that us as platform we're not in thisprocessand we get this unified ability whereeverything that we're doing followspatterns so rather than having 1200different Engineers doing their ownthing everywhere and it's the same thingwe can unify that experience and get thesame outcome for those engineersso what does that look like well nowthat everything's an API and what Nickjust talked about with this platform isthere's sort of different ways that youcan interact with the platform so one ofthe things that we did very early on isa lot of Engineers are familiar with Gitthey're familiar with CLI is they lovejust jumping in their terminal and doingthings so this CLI is a wrapper so whatwe can see is happening here iseffectively a engineer can request whatwe call a workspace and this is a higherlevel construct which effectively meansthey're going to get a gcp projectthey're going to get tenancy they'regoing to get IEM they're going to getworkload identity Federation for keylessauthentication so that GitHub workflowsthey're going to get all these thingsout of the box and all they give us is alittle bit of information and this willspit out all the the declarativeresources in order to create all thatand bootstrap them so historicallyonboarding teams would take somewherebetween three to six months for them tobe onboarded and be able to eventuallyget their code to production which isjust crazyit's a long time it's a very long timeso with this approach we've able tospeed this up so requesting a workspaceonboarding new teams has been reduceddown to about 15 minutes so a massiveincrease or decrease I should say inthat time that we can deliver them yeahand in this bottom line what they'redoing here is they're actually definingthat they have an intent of using aparticular Cloud runtime they want touse kubernetes and they want to usecloud runand what this does is this thenbootstraps them into a kubernetescluster in the right environmentsthey're defined and again gives them thepatterns that they neednow it's not just a CLI um ultimately wedid build a UI to drive this a lot ofEngineers maybe they like click up sothey like to just be able to see thatvisual representation and that's fine sothey still have a UI to be able tointerface with this as well and then forthose superhero yaml stitches they canalso just directly go and create themanifests they don't have to use the CLIat all this is just an easy way tobootstrap the template itselfbut Nick we've got this this far liketell us like what's Google doing to makea lot of this easier for us as wellmoving forward yeah thank you soMichael's talked a bit about fleetsright fleets are organized organizationsof clusters you can you can create gkeclusters clusters and other places andadd them to fleets and manage themtogetherum but on top of that we started tobuild Concepts to help you with tenancyright so one of the problems you haveright now with kubernetes or with GK ingeneral um if you go in the consoleactually if I show hands who's using gketodayBrad pretty much everything yeah so sowhen you go on the console and you lookat a cluster you either have raid accessto the whole cluster right access to thewhole time the the the the our backboundaries around the cluster right andif you start building a multi-tenantmodel in which you're slicing thatcluster up across multiple teams youwant to be able to give a UI that'srestricting those teams only to thenamespaces that they belong to in rightso we built this concept of a scope ateam scope that allows you to createumaggregations of namespaces acrossmultiple clusters bind role-based accesscontrols between those those namespacesthat get created in the Clusters andyour groups and users in Google Cloudidentityum and also keep up with uh adding theClusters that you want to bind to thosefleets or to those Scopes rather so thatwhenever you bind a cluster to a scopeit automatically creates that namespacein the cluster so enough talking aboutit right uh we're here for live demos umthis is now the time that you stop usingthe internet andand so this is familiar right you're allusing ke it may be a little bit lessfamiliar because you could see theEnterprise SKU up here um this we we uhreleased this into preview todayum I want to drill in to the team's flowright so I've got teams hereand you can see I've got two tenantscreated right I've got the alpha tenantand the Bravo tenant now I'm going to gointo the alpha tenantoops and you're gonna see that I've gotthe T I have team one group that's boundto it so this means that there's goingto be a role base access control thatgets installed in all of the namespacesand all the Clusters that's bound tothis team scope I've got some somemonitoring um this is going to improveas the product improves over the next uhsix months to GA and you can see whichclusters I've bound this scope to I havetwo of themUSC's newest West and you can see thenamespacesum so you can see that I have demo andnew demos so I have two namespaceswithin the scope that are distributedacross all those clusters now if I wasgood at demos new demo wouldn't be hereright now because I'm supposed to showyou creating it in lieu of that I'mgoing to create another demo uhnamespace so to create a new namespaceI'll add namespaces uh we'll call it newdemo twoum and update the team scopeand there's umterraform for all of this stuff thateventually there will be KCC for allthis stuff so you could do this withinfrastructure as code it's just easierfor me to show you the portal and nowI've got a new demoum namespace and if I look at theinspect the Clusters you'll see thatthis namespace is popping up in thoseclustersumbut that's not enough right is it nameslike do we stop in namespaces does ourjob end there no we want to actually putsome applications in those namespaces sofor now what that means is you're gonnayou're gonna go out of our flow and goprobably into some git flow somewhereand we've gotum a PR all queued upum so I'm gonna merge this pull requestand when I merge this pull request it'sgoing to installum an application in that namespacecreate a HTTP route with for amulti-cluster Gateway which allows me tothen access that application through aload balancer that's going acrossmultiple clusters in Google Clouduh so let the suspense buildum as that's addinglet me show you the route I think it'sinteresting sothis HTTP route for new demojust also with mentioning that umeverything that we're demoing here islike we've open source this repo sowe'll send out a link or we'll link uplater and yeah if you want to have alook at what we've actually done andprobably around and see some of thethings then feel free all right so umit's just a where am I at this app justgets some metadata about the Pod andknow that it's living on and tells youwhere it lives so when you hit it ifyou're if you're getting routed to theregion that's closest to you it's gonnait should report back say hey I'm in anode on us West here's my IPumand I've appended a value so oneinteresting thing here is I'm usingmulti-cluster Gateway I've got a sharedGateway for this team already stood up Iadd a new namespace I don't have to addanother load balancer or Gateway what Ineed to do is just add another routewithin that tenant or that namespace soit makes it easy right I'm just adding aroute it's going to adjust the the rulesthat are on that load balancer andwithin a couple of minutes I should beable to hit that endpointum so I'm using a path prefix which isweird because it's kind of a suffix butwhateverumand this is the old appit's the that was already there you cansee that it's hitting where are youI'm here pod namespace is in demo that'snot the namespace we've created so if Iadd that suffix that's new demoit is not yet uhoh there we gosorryand I'm gonna try this two more timesand we'll come back to it later if itdoesn't route correctlymoving on if that workedit would have went to a pod that's in umit would have went to a pod that's inthe new namespace that I just createdcalled new demo we'll come back to thatthough if we have time and I will itwill work it just get Ops takes timeright you declare your stateand then you waityou declare your stateand then what do you dowait yeah ultimately it is eventualconsistency so what happens after theapply that's going to go through like awhole lot of people's orchestrationbetween controllers and operators okayit's a lot of moving parts to make allthe multi-cluster Ingress actually workso yeah and so that that concludes thedemo I will prove it to you that itworks by by the time we leave here Ipromise so ummoving on let's so we talked about yourplatform Journey right like the start ofitbut you I assume you didn't get itperfect from the get-go you talked aboutiterating so tell me some of theproblems that you came up with in thesolutions that you had yeah so early onin our platform journey and even justrecently as we're sort of buildingum the platform that we have there was anumber of different things that we werefacing as platform operators now thesearen't all concerns that necessarily theengineering teams had but they werecertainly like they're a bit of a mixedmixed case and this is an infinitivelist right there's there's a whole heapof other things that we've been tryingto solve as we've been progressing theplatform and trying to evolve thatproductso just touching on these really quicklybecause I know probably a lot ofEngineers at some point have hit one ormany or all of these issues at somepoint in time the first one that we'vefound really difficult uh prior to whatwe're trying to do with fleets andmanaging the life cycle of clusters hasalways been Disaster Recovery now a lotof people including ourselves wedefinitely have tools that allow us torestore but if you brick a clustercompletely your worst like your bestcase scenario from that point isprobably going to be like just torecreate the clusterunless you're ready to devote hours andhours to debugging that clusterand I'll touch a little bit more on thatin the future but in our casewhen you recreate a cluster that's goingto change a lot of dynamic or uniquevalues that are between each cluster soeven if you do an NCD Dom or you'reusing like an open source tool that doesBackups it's not a trivial task just towhat to copy everything across and hopethat that apply just gives you thisbeautiful thing that's recreated thatcluster it doesn't simply workso that's one of the things that we weretrying to solve with thisthe other thing that that then leads tothat I've seen is configuration driftlike you see this all the timeEngineers are playing and like I'mguilty of this as well I'm pretty sureI've left a few tests namespace Fostersand what this is this is actually apretty bad practice because what we haveis if we have 1200 Engineers across theecosystem all playing and manuallycreating things and backboarding there'sno single source of Truth to recreateany of that and it leads to this likedrift where a lot of changes aren'tbeing backboarded into our source codewhich isn't good either and this issomething that like Obviously good Opsdefinitely helps portray this forwardsome of the other things that then thatthen Cascades onto is unreproducibledeploymentsI'm pretty sure everyone's probably hadthat moment where a deployment workedyesterday nothing's changed but tomorrowit doesn't work and you're now trying tofigure out what has changed is it thepipeline maybe someone's changed some ofthe networking for that thing and it'sextremely frustrating not being able todiagnose what had changed in yourdeployment even though nothing seemed tohave changed in your pipeline conflictnow that leads to inconsistentenvironments I probably won't Touch TooMuch on that it's prettyself-explanatory butthe next thing is like these danglingresources because people are notnecessarily following best practices ornecessarily look following utop'sprinciples you find that in thesetraditional push-based models peoplevery rarely clean up after themselves sowhat you get left with is a lot ofkubernetes resources that are justdangling their left and these are justorphaned resources now there's somereally good open source tools to solvethis but when using things like git Opsand using Argo or flux or config syncthis just becomes completely eradicatedit's just not a concern anymoreand then obviously the last two are kindof like just funny favorites we've allhad this where you go to production youhit this manual approval gate now you'vebeen writing code or you're deployingsome sort of change and now it goes offto a manager of some sort and he has toapprove the pipeline the reality is thatperson probably doesn't actually knowanything about the context of thatchange and yet he has to be the one toapprove itso I find that really funny whereas ingithubs inside of different everything'sbeen driven now from your source codeand actually what you're doing is you'reempowering your engineers these are thepeople that you trust to manage and dotheir own life cycle management anddeployments which is a bit of amentality and a cultural shiftand obviouslyum some of the things that you get withjust traditional push-based models inthis case this is pretty specific togood Ops but you you end up alwayshaving some disparity between yournon-prod or your not production and yourproduction pipelines now there's alwaysgoing to be something either it'sconfiguration or it's networking or it'sfirewall rules proxy like it could be anumber of things and so it decreasesyour confidence when going to productionand that's not something we wantEngineers to face we don't want them tohave low confidence in you or in theirown Pipelinesso what does it look like after we we'reusing git Ops we're using KCC and we'reusing sort of this x ecosystem this isan interface or abstraction that we'vebuilt while a day Zero experience lookssomething like this an engineer coulduse the UI to create their workspacethey could also just use the CLI withGit and in these cases they give thathigh level intent of what they want touse based on the patterns that we'vepredefined and we'll automatically onceit hits this repository and syncing toour cluster our operators andcontrollers are now instantiating thosethings and we're creating their entireworkspace of things as I mentionedbeforeday twolooks something like thisEngineers now they interface with theirrepository we're not just throwing atthem tools unnecessarily and saying hereyou've got five different uis to debugand troubleshoot your toolthey deploy to their repository we havea good Ops workflow and at all of thesepoints through the flow we have feedbackloops and in those feedback loops wegive them deep links to the relevanttools that they can look at totroubleshoot and debug their applicationbecause we are rendering theirkubernetes resources for them because wedon't want them to have to deal withthat low level complexity we knowexactly what's the environment thecluster the application the namespaceand all these things we can give thempredefined search queries in GoogleCloud monitoring for example we can givethem other deep links to other Insighttools and so rather than trailingthrough a CD pipeline wondering why ismy application not deployedwell now it's very intuitive they canactually be directed to where to findtheir application is failing and whyit's failingum and so this is a much betterexperience for our engineersand behind all of thisum obviously uh I'll get to that nextactually that's fine so there's a lot ofbenefits to this rightum it kind of feels like a sales pitchme saying all this butultimately I can tell you that we'veseen a lot of benefits and in a highlyregulated industry like a bankyou know we have a duty to be secure andresilient and to buildour applications with stability so bydoing this we've increased all thosethings exponentially and on the otherside of the personas as Nick was talkingabout earlier the engineering experienceis increasing has become much better andwe're getting a lot of positive feedbackand Engineers are enjoying the abilityto have that autonomy and that trustum so enough about this we're going totalk about fungible clusters and fleetsof clusters so I'm going to let Nickintroduce what fungible clusters areit's probably a term you haven't reallyheard ofyeah yeah yeah so funny word fungibleright um I don't know why we chose thatbut it's the word that we're using theidea here is that the Clusters reallydon't have uh personalities think of itas like the you know 10 years ago VMSbecameum you didn't want pets right you weregetting cattle poor cattle anyway uh thesame thing is applied to clusters rightyou don't really want to have specialclusters clusters that are long-livednecessarily you want to have shapes ofclusters so what do you do you define ashape of a cluster now on with gke thatmeans you define your Fleet config andyou define how you want to use thenetworking things I talked about earlierand how you want to set up your configsyncs or your flux or go see thesethings such that when I add a cluster tothe fleet all I do is pass in a labelright that label's bound to somethingthat understands how to apply all theright configuration to that cluster andthen you just wait like my failing demoearlier which works by the way I'm goingto show you at the end anyway so theidea idea of a fungible is that you'repre-baking doing all the work on DayZero adding a cluster with intent andthat cluster is coming up to Stateum you can go to the next oneand so like at day one cluster comes onboardum I'm using multi-cluster Gateway ormulti-cluster Ingress so my applicationsget IPS everything's routed I've got uhantho service mesh or managed istioessentially that's stretching networkingacross multiple clusters so I havefailover between clusters and crossclusters service discoveryum and what like what's nextyou the business comes to you andthey're like listenthere's been auh an increase in latency that we reallycan't bear for our end users rightum and the sres have figured out oh hangon this is likewe've actually see that this is comingfrom a section of customers that are notreally close to the the Clusters thatyou have right now uh in fact they'reall on the East Coast or something whereI liveum I am my own userokayand um soyou add this cluster to this new regionwith the correct label right the onlything different is that it's it'sgetting put in a different region itcomes up to State it starts servingendpoints up that get added to the loadbalancer automatically and withinand amount of minutes small in dependingon how many applications you have tostand up it's getting hit with trafficand you've all of a suddenum increased not only High availabilitybut reduce latency in the process andit's not too costly because the if youhave cluster Auto scaling and horizontalAuto sailing setup the load is going torebalance itself based on the requeststhat are coming in so you're not reallypaying a lot more to get that valueright so that's the idea of fungibleclusters so andbetter than hearing me talk about it uhMichael's going to show you a demo inwhich he walks through this yeah I'verecorded but yeah this is pre-recordednow the reason I pre-recorded this isbecauseyou don't want to sit there and justwait for a cluster to come onlineum that could be a bit boring but I'llshow you everything leading up to it andlike cut a section out with the magic ofyou know editing and then you can seewhat happens at the endall right so this is going to be a demoin using git Ops for KCC and creatinginfrastructure in a way that scales sothat you don't have to add thatcomplexity onto your usersso what you can see here is I'm actuallyshowing that scenario that Nick justwent through we've got a managementcluster that's close to zero oneand we have this other Regional clusterthis is the one that's actually hostingour applications the management clusterhere is purely just for your platformoperators your customers never have tosee thatand so I'm just hitting at a testapplication this is the one that we'vealready deployed that's the where myapplication you can see it's in Us Eastone so obviously we want to spin uptraffic that's closer for us Australiansso we want something in maybe Us Westoneso what we can see over here is this isthe configuration that I've storeddeclarative in my repository now there'sa bit of a hack script here this is justto create the management cluster sodon't be alarmed by this there's a bitof a chicken and egg like Inceptionthing where you need a cluster to createmore clusters so this handles creatingthat initial cluster and that's justyour management clusterthe kubernetes folder up here there'sthree folders there's clusters nowthat's simply a folder that flux uses tolifecycle managers itself and toregister the Clusters then there'snamespaces now this is like this is allcustomized so if you're familiar withcustomize you'll understand this alittle bit but this is just where we'recreating namespaces for platformcomponents and where we're deploying theplatform tooling we don't really wanttenants to necessarily have to see thisthis is all the stuff behind the scenesand then when we onboard tenants weactually have a tenants our tenants aredeclaratively defined in this bottomfolderand what that does is that that allhappens as part of their bootstrap whenwe onboard a team andthe last they want to use kubernetes astheir Cloud runtime so we create them aflux tenancy which then allows like TMAnot to deploy you to team B's thingsthey have that like isolation because weare using multi-tenant costs like theseare multi-tenant clustersum so we've tried to simulate that hereas welland so you can see like they've definedtheir application here in the apparepothis is the typical flux resourcethey're using Helm it could becustomized could be home could beanything else in this case it's a Helmchart so they've defined their homechartand this is what they want to deploynow the interesting thing to note herewhile we're creating this clusterI'm just going to probablyyes I'm actually just going to show youthe applications show you how it'sdeployed so we all know that there isreplicas but while we're looking at thisthe interesting thing to note here isthe application team never have toDefine all of the cost is in productionthey just defined that they want theirapplication in production so when we'retalking about fleets of clusters thatcomplexity of 1 or 500 they should nothave to be contextually aware of thatcomplexity at all so that thisapplication can scale Across The Fleetsand they only have to know about theirapplication in one cluster they don'thave to think about how many are behindthe scenesso in this case um where I'm up to soI'm just showing you the uhmulti-cluster Ingress and themulti-cluster service resourcesnow these are all kubernetes resourcesso we can Define them and store them inour repository and have them also in Opswhich is awesomeand over here you can see that themulti-cluster Ingress object isrecognizing that I have a service thatis in this cluster it's creating the NEXfor me automatically and setting that upto a global load balancer so this islike handling that split of traffic thatNick was talking about earlier that wewant to already havebut we want to have this automaticallyhappen when we add clusters we don'twant to manually be configuring all thisand this is sort of the beauty ofmulti-cluster Ingress or multi-clusterGateway if you want to use API Gatewayor Gateway API so that's fantastic sowhen we want to add a second cluster nowI've just stitched this together andI've copied it myselfrealistically you'd probably have somesort of template or some sort of engineor thing that spits this out internallywe have our own tooling that would dothat but for the sake of the demo Ihaven't actually ported all that overhere so you can imagine this is allpre-generated stuff when you want to adda cluster it's all just cookie cutterstuff it's just it's a cluster without apersonality it's just another zero twocluster doesn't have a special name wejust know that this is another identicalcluster of production except it's goingto be activating in a new region for usso this is what we're going to deploynow in this caseum when we deploy a new cluster I don'treally want to have all these manualsteps of like bootstrapping flux andthen deploying all these tools and allthese thingsso what else is showing there with thatum that alert is that flux is able toautomatically trigger a workflow thatuses workload again Federation whichgives us keyless authentication back toour gcp projects so they can dynamicallybootstrap not only flux but everythingthat flux then Cascades and knows aboutso it automatically gives all of ourplatform tooling into this cluster andthen subsequently after that'ssuccessful it'll automatically deployall of our tenants and their componentsand I haven't had to add any otherconfiguration I've literally just saidgive me another cluster and that allhappens which is which is goodum so in this case I'm just showingthose sort of bindings to make workloadidentity Federation work with GitHub sothat's something really cool that weused we do use GitHub workflows thereare scenarios and use cases for that sonot everything can just be magicallydone by git Ops you've got to pick andchoose what you need to use when youneed to use itbut in this case this is the thingthat's actually giving us that work alot of data for iteration and this is aKCC resource so you can do it viaterraform or you can have it done viagithubs and do it with config connectorso where I'm up to right now is I'm justgoing to merge that pull requestum at least I know mine will workbecause it's recorded whereas nextdidn't work sorry Nickit works now yeah wellso similar to nextum it does take timeum so you can speed this up with youknow creating much more fine-grained orreduced the intervals I wish you'rereconciling you can do things like put aweb hook receiver in here so it speedsup GitHub will actually push the eventand trigger a flux event to sync so youcan do things to speed this process upfor the sake of the demo we didn't gothat extraum so you can see over hereI am looking over here and I've actuallyseen that the new clusterwhile we're waiting for so we've gotcluster zero that's here we're waitingfor flux to update to sync and applythat config and then what we should seeis a new cluster we should see clusterzero two come here and all I'm doing issort of just showing you what it lookslike if you were looking at it throughthe terminalum you don't have to do this you canjust like walk away and come back withyour coffee and things will be donebut in this case we can see the clusterzero two came up it did take about eightminutes so there's a bit of a you knowmagic editing thereby now we have a cluster zero twonow what happens after the cluster'sready well like I said we still need toput everything onto the cluster it'sjust a Bare Bones cluster at this pointso through that alert that we configuredearlier it's now automaticallytriggering a workflowand this workflow will then doeverything that I need to dynamicallyfor me and it's automatically detectingthat metadata of that cluster so thethings like the cluster name anythingunique or dynamic it's able to figurethose out based on the alert we providedand it's using that payload to then dowhat it needs hereand so now we're just going to changeour code context so we can locally seeit in the terminaland what we should be able to see is seeall those components now coming upand still we haven't actually doneanythingnow why is this important because ifyou're handling fleets of clusters tensto hundreds of clusters and you'retrying to scale your Fleet of clustersyou can't be managing this in thetraditional sense where you have to gotrigger 500 different pipelines thatmight be in different teams anddifferent repos it's just not going towork and that's why one of theadvantages here for us of using git Opswith our API driven platformhas been so advantageous hereso what we're seeing here iseverything's starting to come up towhere my application is starting to syncnow it didn't come up immediately I wasa bit impatient we are showing thisusing autopilot so this isum sort of like the hybrid between gkestandard and maybe Cloud run sort ofthat sort of serverless experience so itdoes take a few seconds for the computeto spin up to our needsbut in this case if I as you see I didit again the namespace now exists andthings are slowly coming up for usand what I'm checking here is that themulti-cluster Ingress is runningum and we're pretty much going to seethis all automatically create new negsto the load balancer that was alreadycreated and then we'll be able to hitthe application and hopefully we'll beable to hit it on the terminal and whatwe're actually going to try is hit thatapplication now live so I think we'regonna okay I'm gonna skip to you Nicksurewe're using this nowcome onis yours workingyeah so there's some extra stuff you canjustyou can ignore that but this is justgood stuff to say if you want to lookthrough the UI there's all thisinformation the gcp will provide youwhen you want to look and manage yourfleetsso you can feel free to go through thaton your own accordumjust something good to sayall right ah there we goum so can we can we go to my laptop onemore timepleasesorry we're there okay so this is theend point that he was hitting earlierthat was going to us East and now youcan see it's going to Westumrepeatedly I just got to say man Ididn't do anything for this demo Ireally appreciate that you did that andI'm gonna slow clap until everyonedefenseyeah all right[Applause]quickly because no I will never hear theend of thislook see it's workingit's going to the new demo heyall right hold on Nick they're all doneyeah okay we can go backall right so yeah yes I look there'sother benefits to writing um fungibleclusters I won't go through all thislist but when you think of your cost asas more immutable resources and when youstart to life cycle them in that way Iwould sayum in our case we've tried to treat ourworst case as our best case scenario sowhat I mean by that is if you're goingto Brick the cluster and you have torecreate it that's what we're going toactually do as many times as possibleand get really confident and really goodat recreating clusters and so in ourcase that's what we're striving to doand what that does is that exposes allof the Toil and friction in that processso when it actually does occur yourengineers know what needs to be done andbefore that's even occurred you'vealready safeguarded yourself and fixed alot of the tech debt that you might havefacedum lots of other reasons why you mightthink about using clusters in this wayand using fleets of clustersfeel free to check this out in your owntimeum I'll hand it over to Nick to give ussome final wrap up yeah so we are atwe're at the end um it's just some quickclosing thoughts one please if you'regoing to build a platform treat it likea product okayit's not a one-time thing you don't justbuild it and walk away it's it's got alifeum alsocheck out fungible clusters it's goingto be a little pain up front maybe alittle more than a little paint up frontbut your life will be easier for it inthe futureumFleet tendency is GA today so the fleetteam stuffum are back and name spaces all GA todayuh Engineers are in the frontand thenum yeah do you want to talk about itreach out reach out to me or any of myteam we're happy to tell you about itand get you like a road map sessionwhere we really get the rubber hittingthe roadforeign"
}