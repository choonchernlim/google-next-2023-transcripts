{
    "title": "How Orda\u014ds Bio takes advantage of generative AI on Google Kubernetes Engine",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV201"
    ],
    "video_id": "JzxlB7U9Y14",
    "time": "Aug 29 04:45 PM - 05:30 PM CDT",
    "transcript": "foreign[Music][Music]welcome how is everyone doingit's so nice to meet in person this yearisn't itso let's get startedwe are living in an exciting timesEnterprises around the world areleveraging artificial intelligence totransform their businessesGoogle has always been at the Forefrontof AI Revolutionin this talk we'll share with you howcompanies such as audios are takingadvantage of Google kubernetes engine toaccelerate their AI Journeymy name is Malin Patel I'm the directorof product management in Googlecommunities engine and I'm joined todayby two of my co-presenters Mr TonySeward who is the director ofengineering in a Google Commoditiesengine and also David Longo who is theCEO of audiosat Google customer feedback drives aroadmap for products and services solet's start with the problem thatcustomers have told us many customershave complained that building generatingAI platform is hard really hard theyhave to address so many complexrequirements starting from portabilitycustomizability scalability reliabilityperformance security cost efficiency andmany moreour Google kubernetes engine team hashelped many customers successfullyovercome those challenges so today weare going to share with you some of thelessons learned and the best practicesso many customers are training andserving models across multiple cloudsand also on-premnaturally they want freedom to writeonce and run everywherethey would prefer open source solutionto avoid vendor lock-inour Google kubernetes engines open apisfully support portability so you canwrite your code once and run everywhereplatform Builders have to support manydifferent machine learning tools andFrameworks to address the diverse needof multiple teamsnaturally they prefer flexibility tocustomize their software stackGoogle community's engine offers thefull flexibility to customize your toolchain as well as framework of yourchoiceit gives full control or underlyinginfrastructure and the software stackmany organizations today are strugglingto obtain gpus and gpus often they arewilling to trade time and locationflexibility for obtainability once theyobtain their gpus and gpus often theyfind it really hard to do Fair sharingquota management also cost attributionand many other things across the teamsso Google kubernetes engine offers thenative support for open source toolingsuch as Q which gives you the freedom totrade your time and location flexibilityfor obtainabilitywith Q each team can get their fairshare of resources and even better theycan trade the unused resources of otherteams for the teams who need it the mostwith Q most important jobs get thehighest priority and the lower priorityjobs can be preempted when the resourcesare scarceso many of our customers are trainingmassive models of hundreds of billionsof parameters naturally they want highperformance and scalable super computersto train these massive modelsGoogle kubernetes engine offers industryleading scalability so you can scale asingle gke cluster to up to 15 000 nodesto build your own supercomputer to trainmassive modelstraining and serving massive models issuper expensive naturally our customerswant lower cost and higher efficiencyGoogle kubernetes engines offers manyAdvanced features such as Auto scalingso you can dynamically scale yourcluster based on your demand and theload it also offers GPU sharing andTighter bin packing so you get highutilization of your resources it alsooffers fast node startup time to loweryour over provisioning tax all this andmany other features allow you to loweryour infrastructure cost not only thatGoogle kubernetes engine help you tolower your day to operations cost ofmanaging and maintaining your trainingand serving cluster to get better totalcost of ownershipin order to build a generative AIplatform you have to accomplish manydifferent tasks for example you have togather data clean the data extract thefeatures build your models provisionyour cluster for trainingalso do theprompt fine tuning once the model isfully trained you have to put it inproduction for live traffic and alsomonitor the performanceyou need very powerful platform andreach set of tooling to fully automatethis process and make it simple easyrepeatable reproducible and auditableso Google kubernetes engine team isbringing out many different Innovationsto accelerate your journey fromprototyping to production so I'm superexcited to share with you some of ourlatest and greatest innovationso I'm very thrilled to announce thatGoogle's tensor processing units are nowgenerally available on gke so now youcan get the benefit of thestate-of-the-art performance offered bythis tensor processing unit and Industryleading scalability offered by theGoogle kubernetes enginecustomers like character AI lightrixwords and biases and grammarly arealready using tpus with gke to get bestprice performanceI'm also pleased to announce theirlatest generation of TPU named dpu v5eare now available on GKoffers up to twice performance perdollar compared to Prior generation oftpus which is a remarkable Improvementdouble the performance for the samepriceTPU V5 also offers flexible VM shapes tosuit your diverse needsusing a multi-slice technology you canscale V5 egka clusters to tens ofthousands of chips so in order to serveyour most demanding workloadI'm also pleased to announce that our A3VMS which are powered by Nvidia h100gpus are now generally available on GKA3 VMS offer an order of magnitudehigher Network bandwidth between the VMScompared to the prior generation of VMwhat it means is that now you can feedmore data to your data hungry gpus tokeep them busyA3 VMS come with eight h100 gpus in asingle node this node providesmind-blowing compute capacity of 26 EXAflops in a single node so now you cantrain your models fasterusing Google kubernetes engines industryleading scalability you can create a gkecluster with tens of thousands of h100GPU helping you create your own supercomputerRG to VM family is powered by Nvidia asfour gpus which are purpose built forinference workloads so our G2 familyoffers up to four time more performancethan a prior generation of T4 gpus soyou can serve your model fasterG2 also offers significant cost savingscompared to the 8 and G family of gpusI'm very thrilled to announce thatGoogle Cloud Storage fuse is nowgenerally available on gkefuel stands for file system in userspace using GCS views machine learningpractitioners can fetch data from Googlecloud storage using standard filesemantics without having tocompare comply with the Google'sproprietary apisso now a data scientist can Port theirmodel from other platforms and run it ongke without making any code changes tointegrate with Google's proprietary SDKso GCS fuels not only supportsportability but it also speeds upapplication startup time so you can savetime and moneyGCS use also comes with built-insecurity such as it authenticates usingtheworkload identity and it does notrequire privileged containers offeringyou a better security processorin summary Google kubernetes engineempowers you to focus on your coreMission which is to build models trainedmodels and server models without havingto worry about underlying infrastructureand the compatibility issues so now I'mpleased to welcome the CEO of audiosDavid Longo to tell us how GK is helpingordinos accelerated AI Journey okaythank you so muchgood afternoonit's lovely to be here and speaking toyou at Google next thank you all forjoiningumI'm David Longo I'm the CEO and founderof ordeos or deos is bringing the orderof digital bits to the chaos of physicalatoms what I mean by that is that we'redoing protein design on computers we'redesigning drugs from scratch usingcomputerssospecifically we are increasing the speedof mini protein generation to 30 timesthe speed of previouslythe previous processes and we're able todo that because of Google because ofGoogle kubernetes and how we'veorchestrated our design engine in thecloudso the way proteinsthe Whey proteins were discoveredpreviouslywas using Library screens so you imaginemillions of physical models being runthrough assays or through tests untilone of them may possibly set off a testthis process takes weeks or months andtypically results in what I wouldconsider to be a compromisemolecules are poor they're not doingwhat they're expecting they have offTarget effects and side effects andpatientsand so what we are doing is the oppositeof thatwe are starting to design proteins fromscratch in silico what I mean by that isthat the drug Hunter can input thetarget of Interest the the protein andtarget of Interest the disease Target ofinterest and specifications for how theywant that protein to behavethat is embedded into a representationthat the system can understand thesystem then generates proteins de novonovel from scratchthose proteins are evaluated in silicothrough various other in Silicon modelsthat allow it to know how well it'sdoingand from that reward the generators canbecome better at outputting betterproteins if that makes senseeventually these these molecules aretested in an in vitro labbut I've already mentioned generatorstrainers evaluators a number ofdifferent software systems appsenvironments that need to be corralledtogether to work together in harmonyso let's talk about how we're going todo that so this is a protein designengine that's going to be highlyscalable we want it toum we want it to be easy to use we wantit to scale to the needs of ourorganization to work with our severaldrug programs all at oncewe have a user interface that it'seasier to use by biologists their apisthe connect the user interface to theback end there are many AI models inproduction that are being trained inproduction that are being tested inproduction that are being used inproductionit needs to be event driven becausefrankly I don't want to run gpus all dayif my biologist is only going to use itfor two hours a day so we needed to onlyscale up when we need and scale downwhen we needthere should be a single programthat leads this thing so we consider anexperiment to be a single run but thatexperiment may call off hundreds ofmodels hundreds of calculationsand obviously as I said we need to scaleto zero to minimize costsin terms of uh what Mullen said aboutaccessto these models are power hungry so theyneed access to GPU while some other onesmight only need CPU or some combinationthereinand training of course requiresmulti-node orchestration so we needthose gpus to be able to communicatetogether on time in the right fashionkubernetes solves this problem bycreating an orchestration platform thatallows us to orchestrate our hundreds orthousands of different containers andmodels to work together and communicatetogether easilyall of these systems are natively loadbalanced meaning that they can scale upto demandthey can scale up and down importantlyso when they're not in use they canscale back in to save coststhese systems are self-healing meaningthat if there is an issue if one of thepods fails because some calculation wasjust too hard it can build back up andtry again it's self-healinghowever kubernetes out of the box atleast to my knowledge is is not eventdriven or at least it's very difficultto have events Cascade into scale-ups soI'll tell you about how we solve thatandwe're ideally with kubernetes we'redecoupling the infrastructure from thescale so our programmers don'tnecessarily need to know exactly whatmetal they're on they just need to knowthey need more power and kubernetes willobligewe've already talked about the supportof CPU and this thing about multi-nodeGPU training so there's been kubef flowthere's been some other Alternatives butwe found them difficult to use in oursettings so we had to find anothersolution that again I'll tell you aboutthis is a view of our protein designengine on gke so what we have here ifyou imagine this giant box is a clusterone cluster now mind you I'll tell youabout how we use multiple environmentswe have clusters in different places butthis is one cluster on that cluster wehave everything from the user interfaceto the protein engine to the apiscontrolling those we have proteinstructure models that predict proteinstructure we have protein structuremodels that predict sequence fromstructureand all of this all these evaluators indifferent separated namespaces that wecould tag the cost and tag the the umthe activity accordinglyand then we also have things like Mullenmentioned the need to clean data so wehave things like airflow running in onthe same cluster using the sameresources and sharing the same resourcesto maximize that spend and then withtraining we can use torch X which I'lltell you about to orchestrate thosemulti-node training usesbut now this is all one cluster so if Ido it once if I set up these systems foran evaluator I can use that same systemfor a generator I can use them to trainor I can use them to set up data itallows us to have our organization focusour learning and our resources into onesystem that can benefit us in manydifferent waysso I mentioned these two missingrequirements and I'll tell you a littlebit more so first not event drivenso what do I mean by event some eventdriven means if I start a run itCascades to another run which Cascadesto another run this this famousSpaceballs quote do something dosomething do something and that's whatwe're talking aboutwith Native kubernetes scaling you haveto Scale based onum onusage utilization so when the CPU is tooover utilized it'll scale up orsomething along those linesuh what we need is something that scalesbased on the number of requests sobatches of information if you imagine sowhen we have one structure that needs tobe calculated perhaps that's one podwhen we have a thousand structures thatneeds to be calculated perhaps that's100 podswe did this with an open source toolcalled Keta Keta is kubernetes eventDriven Auto scalingand this is a wonderful solution thatallows us to monitor events in typicalevent cues like redis or any kind of Pubsub systemit feeds that data into the kubernetesAPI to drive scaling and it allowscontainers to scale to and from zerowhich allows us to control costthis is open source MIT licensed you caninstall it into any cluster whether it'snew or existing it's trivial to installand it can extend into whatever sort ofeventHue you might havehow Kettle works is that you define ascaled object this is a custom resourcein kubernetes that gives the parametersfor which to scale the specificcontainer so it might be the queue thatit needs to listen to it might be ascaling metric so if the list is length10 only scale it to two something alongthose linesum and it tells the system how to scaleup or down and also tells it to scale tozero so for us we went from having atypical Helm chart or a typicalum kubernetes chart to having oneadditionalum specification so rather than justhaving a pod we now have a scaled joband that scale job controls how this podMay scale up or scale down and maintainsa zero footing so that we're notspending money at all timesmoving on I mentioned that kubernetescannot natively schedule multi-node GPUsystems again there there are solutionsfor this and Google certainly has theirown Solutions we found an Sr to go adifferent route and so we went with anopen source solution called torch Xthis has been long requested of the pitorch Community as ofum a few months ago now I believe torchX was released by pi torch this is asystem for distributed training and uhsimple multi-node multi-system elastictraining using torch so again this isnative to torchand it allows an easy CLI interface youcan schedule both on your local systemor on kubernetes with just the change ofsome parametersum this allows us to elastically trainas well so I mentioned that self-healingproperty of kubernetes the value of oftorch X is that you can use thatself-healing to actually pick uptraining where you left off so I'm suremany of us have experienced where you'rerunning a you know 64 node trainingsituation and one of the nodes just hasa hiccup and now you're training is shotwell that's the value of elastictraining self-healing and torch X isthat it'll self-heal that broken nodeand continue alongthat was torch x one one other thingI'll say there is that it uses abatching system on the back end thereare many Alternatives but we use volcanowhich is again is recommended bytorchacks and is very trivial to toexpand or to deploy onto something likekuberneteswe also leverage kubernetes to managemultiple environments so in a in acompany like ours I suppose I haven'tmentioned this but we we design proteinswith computers right that means we needbiologists that means we need computerscientists that means we need molecularnatives that speak both languages sowhen you have that together there tendsto be some friction where the biologistreally wants to design their protein andthe developer really wants to try theirnew feature I know I'm one of the onesthat wants to try my new feature so wehave multiple environments to allow forus to test out new technologies newfeatures while our biology team cancontinue to deliver on our Partnershipsand our pipelines this also allows us toseparate resources to make sure that thecorrect compute is in the correct areaand that cost is defined accordinglyin these multiple environments we useGitHub and Cloud build to deployseamlessly between them we have thistied to git flow so our PRS get launchedto Dev and our tags get launched to prodit's very simpleum the power of kubernetes is that weonly have to code these things once weonly have to code the infrastructureonce and we can repeat that throughoutwhatever environment we want and also asmentioned it's it's standard acrossclouds so for us although we don'tactually license our software if therewere a case where we did license oursoftware we could launch into any anycustomers cloud trivially withkubernetesto talk about a specificas we're at a Google convention Al PHAfold is a big Topic in the protein worldum for those of you that might not uh bebiologists proteins the this Center ofLife uh is a a string of amino acids sothese small molecules that um combineinto a string of of residues that turninto the protein that folds so there'suh primary structure which is thatstring if you look at how they fold intomicrostructures like helices and sheetsthat's secondary structureand easy to figure out for a long timebut tertiary structure has been thislarge unsolved mystery and that's theactual 3D fold of a protein so when aprotein is produced what does it looklike in three dimensions we know now andwhere we we believe for a long time thatstructure determines function so thestructure of proteins is wildlyimportantthe only way we could do this previouslywas with expensive Technologies likex-ray or NMR or Crystal or um cryo-embut because of the advances of alphafolds we can actually do this on acomputer nowas I mentioned protein folding isimportant for a variety of reasons notthe least of which I mentioned the thefunction is determined by structurethat's true both of the drugs that we'reproducing but also the target we need toknow exactly where on the protein we'regoing to bind how that's going to createDownstream effects based on itsstructureumwe are we can use structure to evaluateantibodyum antibody control antibody uh qualitywe can use structure to evaluate riskslike off-target immunogenicity anyanything along these linesand then it's also obviously incrediblyimportant for lead identificationum for both biologics as well as smallmolecules The small molecules require abinding pocket to bindAlpha fold broke new ground two yearsagoby topping the critical assessment ofprotein structure prediction this is acompetition that was run each year andAlpha fold two increased the accuracy ofmodels from 60 percent to over 82percent to give you an idea NMR andx-ray crystallography are around 80accurate so now our in silico models areactually as accurate as in vitro proofI've already mentioned applications ofprotein folding but the way we're goingto use this with um in silico models isfor both protein engineering and de novoprotein design so if I make an iterativeimprovement to a protein I can ask Alphafold how did that change the structureand because of that every time I make amanipulation I'm going to call out toAlpha folds to run a structure over andover again now I mentioned x-raycrystallography you're talking aboutmonths to get a single structure ormaybe weeks if you're lucky with Alphafold it takes us about 10 minutesI think that's an improvementin the denova design case we can alsoleverage Alpha fold to move around thespace so we're not doing iterativeresidue residue improvements we'reactually moving around in larger chunkslike motifs or domainswith Google kubernetes enginethis is a trivial system to outline Ididn't mention that Alpha fold usessomething called multiple sequencealignment this is a way of test ing thesequence that you're looking to get astructure of against every other knownsequence to look for its evolutionaryhistorythat part of the pipeline is acombinatorial problem so it can happenon CPU very easilyso first we use a batch system or abatch queue to take all of these jobsthose jobs take the input sequence andpass them into the first featurizationpipeline that featurization pipeline asI mentioned starts with a combinatorialprocess so it's going to be run on CPUto generate the msas that we need forlater or deep inferenceonce those features are generated thosefeatures are generated back on a queuethe or are placed back on a queue thejob Picks Them Up and places them nowonto GPU for the Deep learning aspectthat does the MSA and sequence embeddingto tertiary structure predictionfrom there those uh that GPU inferenceis again placed back onto the queue forour own internal confidence metrics tobe calculated with their own deeplearning techniquethen finally those results are passedback into both cloud storage and to theuser interface via an API withkubernetes this is again trivial we haveour event queue we have our scalingability we have our Resource Managementall within kubernetes and it makes Alphafold scalable to sort of mind-blowingproduction scale to the point wherewe're doing thousands or millions ofprotein structures in a day wherepreviously it would take weeks to do onewe are very thankful to be here and veryhappy to be working with Google Cloudnot the least of which for Google'sconstant Innovation but also their theircollaboration and their willingness tofocus on the best interests of theclientone of my favorite quotes is of courseWalt Disney's it's kind of fun to do theimpossible and thank you forum hearing me out as ordeos creates TheImpossible with Google Cloudthank you[Applause]"
}