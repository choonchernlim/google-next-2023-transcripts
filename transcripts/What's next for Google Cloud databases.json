{
    "title": "What's next for Google Cloud databases",
    "presentation_type": "Spotlight",
    "categories": [
        "Database Professionals",
        "SPTL204"
    ],
    "video_id": "BzQbzb2QYIE",
    "time": "Aug 29 06:00 PM - 06:45 PM CDT",
    "transcript": "foreign[Music][Applause]are you ready for some databasesyepthe Need for Speed so we will have areally exciting day today on databasesso I am Andy Goodman's general managerand VP of engineering for Google Clouddatabases and I'm super excited today toshare with you what's new and what'snext for our databases joining me onstage will be rithika Gunner seniorproduct management in the database teamSundar narasiman SVP of saber labs andproduct strategy and a fantastic groupof demo presenters there's nothing likedemos so we have plenty of them intoday's sessionso it's no surprise to anyone in thisaudience that generative AI has reallycaptured our imagination and it hasopened up new possibilities in allfacets of our daily lives from text andimage generation like you saw in today'skeynote with Thomas to immersivecollaboration tools and even toaugmented search experiencesgen AI is the key to unlocking value inthe Enterpriseand it really has the power to transformcustomer experiences and employeeproductivity and we're going to talkabout both of those todaywe believe we're entering apost-training eralarge language models also refer to asllms are already democratizing access toAI for Developersno longer do developers need to beexperts in deep Tradingbut sorry in deep learning but ratherknow how to best take advantage of llmsaccording to the Bureau of LaborStatistics there's 10 times moredevelopers than data scientists soimagine if we can put AI into developershands we'll have at least an order ofmagnitude more Innovation from Ai and soas a result we believe that applicationdevelopers will be driving the bulk ofthe innovation in applying generative AIwithin the Enterprisenow these developers are going to belooking for the best ways to leverageand integrate gen AI into both new andexisting applicationsand they're also best positioned to takeadvantage of the power of llms withapplication data to deliver the best andmost interesting innovation in theEnterprisewe think about this shift as the shiftto generative engineering or as I liketo call it in short gen enginejust as developers integrated Opspractices into software development andwe call it devops and and the devopsmovement started we already see gen Engas the Revolution being led bydevelopers who have Proficiency inapplying gen AIand with the rise of gen Edge the realvalue for Enterprise comes whendevelopers are combining generative AIwith their proprietary data to provideaccurate domain-specific experiencesand so because of that and becauseoperational database sit at the heart ofall application data they really play acritical role in how developers willultimately build these new AI assistedexperiencesnow Google Cloud we offerindustry-leading databases for any sizeorganization this includes a broad setof innovative databases both relationaland non-relational such as alloy DBCloud SQL Cloud spanner firestorebigtable and moreand we see leading organizations such asEquifax Deutsche Bank Renaultsaber Yahoo and others modernizing theirapplication stacks and building newapplications with Google Cloud databasesnow let's hear from one such customercharacter AI about how they're usingalloy dbn spanner to power theirgenerative AISthank youcharacter AI is a generative AI platformthat allows users to both createcharacters with personalities that feelsaliveand engage with these characters in away that is almost indistinguishablefrom human interactionmillions of users use character formillions of different use cases gamingand entertainment book recommendationsrecipes and life coachingthe database is the center of anyapplicationsince the migration to lodb we actuallyserve five times the query volume athalf the query latency and confidentlyprovide a reliable service to our userswith very high uptimespanner is Best in Class distributedsystem that is known throughout theindustry to be Rock Solid and allows usto ingest terabytes of data every daywithout any worry that we're going tobring aside downgoal is to scale one of the fastestgrowing consumer products on the marketand that means getting to a billionusersand with Google Cloud I know we can getthat[Music]I just love what character AI you'redoing and thanks so much for yourpartnership Jamesnow in order to help organizations likecharacter AI innovate fasterwe're focusing on key three on three keyareas first of all providing operationaldatabases with built-in gen AIsecond breaking down the silos betweentransactional and analytical systemsand lastly helping you modernize yourdatabase Estates by migrating off Legacyproprietary databasesnow let me start with Gen AItoday gen AI applications face a varietyof challenges that llms alone do notsolve first they need to provideaccurate and up-to-date informationsecond you want to deliver contextualuser experiences and last we need toenable developers to innovate quicklyand make it easy for them to build andoperate their applicationsnow databases with Vector support arewhat we see is the bridge between llmsand Enterprise gen AISnow here's why first databases generallycan provide the most up-to-date data foraugmenting llm promptsand this helps this helps us ground llmsfor accuracy and relevanceand combine it by combining data fromyour production databases with the Parovllms your gen AI apps will provideaccurate answers based on real-time datasecond much of this data especiallyconversational data is unstructuredand Vector embeddings can encode thesemantic meaning of this unstructureddata like product descriptions help desktickets and conversation historythis allows your applications to bringrelevant unstructured data from yourdatabase to the llm based experienceenabling immersive semantic search andcomplex history-based conversationsand lastly the best part is you can doit within your database right thedatabase that you trust and love and andthey're already supported by robustecosystem with the business criticalreliability data protection andperformance you expectand developers already so familiar withthem they don't have to learn or set upnew systemsnow postgres has emerged as theindustry-leading relational databasebecause of its Rich functionalityecosystem and thriving community andaccording to stack Overflow it is themost popular database in use today byprofessional developers with over halfof them choosing postgresand we're seeing a lot of innovation inthe postgres community around Vectorsearchsuch as extensions like PG vector sothese are really really exciting timesto be part of the postgres community andthe combination of vector search and SQLreally enables these very expressivepowerful design patterns while remainingsimple and familiarnow we already support the best postgrescompatible database with loadband ADB runs anywhere it runs in thecloud it runs on premises it runs at theedgebut we wanted to do moreand so we asked our customers what theyneeded as part of their gen AIapplication development Journeyand here's what we heardfirst it's got to be easy and integratedsecond it needs to run everywhereand then lastly it needs to perform wellbecause our customers are building veryinteractive experiencesso we went off and we innovatedand as you heard in Thomas's keynotetoday we announced alloy dbaiatodb AI provides PG Vector compatiblesearch that is up to 10 times fasterthan standard postgres so you can reallyget those interactive experiences usingadodb AI it also allows you to generateVector embeddings directly from withinyour database and fully integrates withvertex Ai and the open source gen AIecosystemand as an integral part of value DBalloy dbai runs everywhere so not justin Google pretty much anywhere you wantit to run now let's double click on someof these key features within lodb AIfirst our PG Vector compatible searchwas tightly integrated into the alloy DBquery processing engine which gives usup to 10 times better performance as Imentionedin addition we've added Vectorquantization support so we can actuallysupport vectors that are four timeslarger than standard postgressecond alloy DB automates embeddingsgeneration to easily transform thatunstructured operational data intoVector embeddings simplifying your genAI app development that includesautomatically generating embeddingsusing remote models in vertex AIand we've even brought in somelightweight models into alloy dbai sofor some lightweight use cases you canactually generate those embeddingswithin the database itself and thatsimplifies the stack significantlyimproves latencies and dramaticallyreduces costand lastlyalodb AI fully integrates a Vertex Aiand open source tools such as Lang chainto best support Developersso in summary allo DB now provideseverything you need really the keycapabilities you need to build and runEnterprise gen AI apps and we're goingto continue to innovate on rwb AI asquickly as we can based on your feedbackit is available in preview today throughthe downloadable ADB Omni that runseverywhere and soon will be launched onthe Adobe managed servicenow let's take a look at iwbai in actionwith sandy guythanks Andy let's explore how easy it isto build a gen AI enabled experienceusing this functionality and just toshow you guys how open this platform isand how easy it is to take advantage ofwherever you are I'm actually going todemo this on AWS with alloy DB Omniwe're building an app for simpleSuperstore a home improvement store withlocations across the countrytoday we have a simple application builton our database but we'd like to build amore interactive experience wherecustomers are bring us the problemsthey're looking to solvejust like they do in person when theyinteract with our friendly helpfulAssociatesso we decided to incorporate an llm topower a chat applicationlet's consider a simple use case acustomer enters the Redwood City storeand asks the question what kind of fruittree would grow well in my backyardthis is the response of an llm withoutany additional contextthat's great except we don't have anyapple or fig trees in stockso let's make this better by groundingthe llm in our own operational datalet's take a look at our alloy DBinstance in my SQL notebooknow we've already migrated our data intoalloy DB Omni so my product catalog andinventory data is already herewith a single line of SQLI can add a column that willautomatically generate Vector embeddingsfrom my product descriptionsthis simple postgres functioncalls a remote model in vertex AI textembeddings geckoto transform my data into embeddingsI could also use a local model that runson the database itself with no need forspecialized Hardwarenow in the interest of time I've alreadycomputed embeddings on thirty thousandrows for each product in my productcatalog and created an indexso how do we use these embeddings tomake our llm more actionablefirst I construct our prompt ingenerative AI Studioas you can see here my prompt providesguidance for the llm on the user and howto answer the questionas part of the prompt I want to feed thellm a list of candidate products to drawfromin a perfect world I'd feed the llm allof my in-stock products but that exceedsour llm token limits instead let's tryto feed the llm 10 highly relevantcandidate productsso jumping back to my notebookI have my products tableand as you can see I have my new productembeddings column thereand I have my inventory tablegreatso to construct my query I need to jointhese two tables filter for in-stockitems in the Redwood City store and thensort based on similarity to the user'squery string using PG Vector let's runthis querythat was pretty fast as Andy mentionedalloy DB runs Vector queries 10x fasterthan standard postgresokay so now I found 10 Canada productsit looks pretty goodokay so now let's feed all of this tothe llm including the user's input andthe candidate productsI'm going to convert these to Jsonand then go back to my generative AIStudio prompt and paste them in hereremember the user's question was whatkind of fruit tree would grow well in mybackyardamazing I have resultslet's seea Meyer lemon treethat's in stock I love that because it'snot only a great recommendation for thisuser but they can walk out of the storewith it todaybecause I asked the llm to return theproduct ID as part of its response I canvalidate the response and provide theuser with more information like photosand location in the storethis is what the end user experiencelooks like to the customerand if I follow up with something likewhat do I need to do for it to grow wellhere we can follow the same processgenerate a list of candid products basedon the question and previous llminteractionsfeed that to the llm and have it use theproducts to generate a recommendationas you can see the key to making thisfeel richpersonalized actionable and Enterprisegrade It's a combination of your datawith llmsan allo dbai makes that super easy noextra mail stack no moving data aroundno convoluted application architecturejust a few lines of SQLthanks and now I'm passing this back toAndy thank you[Applause]so two things I love about that DemoFirst it just shows you how easy it isto kind of bring Vector search into yourSQL and of course the second one it ranon AWS there was a live demo on AWS andit really shows you that you canactually use alloy DB Omni everywherenow Switching gears as you heard in theopening keynote duet AI in Google Cloudisn't always on collaborator that usesgenerative AI to help Cloud users of alltypes do accomplish what they need toaccomplish better and faster for exampledevelopers are often challenged inwriting and optimizing complex databasequeries so we decided to help themtoday we're excited to announce thepreview of duetei in Cloud spannerwith duet Ai and Cloud spanner you cangenerate code to structure modify orquery your data using natural languagewith the red Ai and Cloud spanner itwill automatically generate SQL that canbe reviewed or Modified by developers sothey can spend more time innovating andless time writing and optimizing theirSQL codenow let's look at the power of duet AionCloud spanner with cat Colemanlet's say I'm working at a fictitiousgaming company symbol gameslately we've been having a problem withplayer churn and I've been asked to divein and help identify a list of playersthat we think are at risk of leaving ourgamehere's how I can use duet AI to quicklyand seamlessly complete this usingnatural language promptsto start I navigate to the new spannerstudio in the cloud console where I canstructure modify and query my game'sdataI want to see the number of activeplayers in the last 30 days to see howwe're trending in natural language isduet AI how to query this dataduet AI automatically suggests SQL codethat I can then explore and modifyI see the numbers are a little lowerthan usualI can use a machine learning model topredict which players are at risk ofchurn right nowgreat duet AI Returns the number ofat-risk players we have right now toprevent these players from churning I'mgoing to give them some playerappreciation tokens with a little morehelp from duet AIand voilausing duet AI in Cloud spanner I wasable to Breeze through a sophisticatedtask using natural language prompts allinside of the new spanner Studioso this is super powerful as you can seeyou may have also heard we announcedsomething very similar on bigquery todayas you're going to have this kind ofexperience also in bigquery and restassured I know the next question isgoing to be like when does it come toCloud SQL when does it come to halodb wedefinitely have an intentionto also bring these kind of capabilitiesto our other database servicesnow as you saw in Thomas's keynote todayduet AI will also simplify the last mileof complex database migrations fromOracle to postgres and we will coverthat later on in this session so we cantell you how duet AI is actually goingto help accelerate that now I'm going tohand it over to rithika to talk abouthow we're unifying transactional andanalytical systems[Applause]foreign[Applause]doing some great database announcementsand we're going to keep the drum beatgoing so data has always been a criticalingredient for the successfulapplication of AI and that's why oursecond Focus area is around unifying ourdata in AI Cloud by breaking down thebarriers between transactional andanalytical systems to deliver thefreshest and most contextually relevantdata to apps and to decision making soone example of this is data stream forbigquery which provides a simple andeasy real-time data replication fromtransactional databases like alloy DBpostgres MySQL and Oracle directly intobigquery today data stream for bigqueryserves thousands of customers andprocesses over half a trillion eventsevery single month now we've alsodelivered query Federation capabilitieswith Cloud spanner Cloud SQL andbigtable May taking data available rightfrom the bigquery console allowing youto analyze your transactional data inreal timebut we wanted to build on thesecapabilities and provide a trulyInnovative way to democratizeoperational data for analytical purposesand that's why today we're announcingthe general availability of cloudspanner data boostthis is a breakthrough technologydelivering high performance workloadisolated on-demand processing ofoperational data to support analyticsreporting and more data boost takesadvantage of Google's disaggregatedcompute and storage architecture andprovides on-demand isolated computeresources to process analytical queriesdirectly on the storage layer withvirtually no impact to the existingtransactional workload with data boostusers can analyze their Cloud spannerdata via bigquery VIA spark on dataprocthey can export it using dataflow orthey can use it in their own customapplicationsand because these resources are fullymanaged by Google with a pay-per-usemodel it provides a cost-effectivesecure and scalable architecture withoutany additional management overheadCloud spanner data boost is Federationdone rightnow let's take a look at data boosts inaction I'd like to welcome my colleagueGabe Weiss to the stage to give us alive demo to show us the power of databoost welcome Gabehi everyone I've been given theimpossible task of demonstrating awesomedatabase performance live on stagewhich you're totally not seeing me doright now is kicking offtheoretically kicking off a couple ofqueries both because I need you to seeme doing it live so I can prove to youthat there is no tricks no magic nothingat my sleeves and because I need to beable to show you the impact or in thiscase no impact because data boost isawesome that these operations are goingto have on our database the spannerinstance we're using is emulating adatabase for a massively multiplayeronline role-playing game this particularinstance is tracking all of our playeractivity around their inventory andin-game currency it's currently sittingat just over three terabytes of data andthe table that we'll be interacting withhas over 4 billion rowsin our game the monetization folksmonitor the player activity in near realtime so they can adjust offers on thefly during Live Events and do deeperanalytics for future events these folkswant to constantly analyze live playeractivity that lives in spanner combinedwith the historical data and analyticsliving in bigquery all this has tohappen without impacting ourtransactional workload because whathappens if our inventory system lags ingameour players are going to figure out howto exploit it they'll duplicate theiritems ruin our in-game economy now I'vegot a big problemso before I dive into about horrible Imean interesting things that ouranalysts are trying to do to our data Iwant you to take note of the databasename so I can prove to you that all thisis happening against the same spannerdatabase game DB we have two externalconnections from bigquery they're bothagainst game DB the only difference isthat one is not using data boost and oneis using data boost okay next I want toshow you our CPU utilization graph we'vetaken the game servers offline so that Ican really show you what's happening andright about now you might be saying toyourself hey Gabe wait a second Itotally see CPU spikes on that graph Ithought you said data boost was supposedto prevent that from happening andyou're right it doeslet's take a look at the time stamp hereso 402if you're keeping track of time I wasn'teven on stage yet so let me show youthis is the window where uh I ran thequery before I came on stage look at thecreation time401 lines up with our CPU Spike so thisis the query that ruined our economy thequery analyzes the players that havebeen dealing in the highest value itemsacross the last 75 days so we know whoto Target with our in-game ads now hereis the window that I ran at thebeginning of our our demo it's the sameSQL query but I want you to take noteour connection string this one ran withdata boost enabled and if you rememberat the beginning I kicked off a coupleof queries because one query just wasn'tdangerous enough for meso this is a notebook that runs a sparkjob that calculates the rollingretention of our entire player base inother words give me a list of all theplayers that have traded at least oneitem in a specified week or any weekthey're after it's a very intensecalculation that ends up scanning mostof our 4 billion rows and if you note inthe notebook here we have again samedatabase data boost enabled trueall right is everyone ready to see somemagicback to our CPU graph I'm going to goahead and refresh it on the last hourall right here we have our PR nightmareinducing CPU Spike caused by the no databoost connection and here is thetimestamp at the beginning of this demoI'd like you to note there is no Spikeso data boost has successfully isolatedour analysts queries and avoided ruiningour in-game economy everything you sawhere today is detailed in a blog post sothat you can recreate this in yourenvironment please don't take my wordfor it we've got more Demos in theShowcase area of the Expo floor and atthe innovators Hive come on by and chatthanks back to eurydicaforeignwasn't that a fantastic demo showing youthe power of data boost well this is whycustomers such as Cirque a Brazilianfinancial institution are quicklyadopting data boost to benefit fromreal-time analytics on spanner data nowto further break down the silos betweentransactional and analytical data we'realso making it easier to ingest datafrom bigquery back to operationaldatabases like bigtable with just a fewclicks applications often need data fromtheir data warehouse for use cases suchas personalization or recommendationshowever typically getting such data intooperational databases means filing verylaborious ETL jobs or filing helptickets from your data Engineers but wethink there's a better way to where adeveloper can get the data directly intotheir data warehouse into directly fromtheir data warehouse into theiroperational databases use usingself-service native ETL capabilitiestoday we're excited to announce reverseETL support from bigquery into bigtablewith the new bigquery export to bigtablefeature applications can serve andanalytical insights to their userswithout having to touch any ETL toolsthis feature is available for sign upand previewnow these are some of the ways we'rebringing truly differentiatedcapabilities to unify our data and AIworkloads across the entire data lifecycle but don't take my word for it Onecustomer who's built a data and AIFoundation across Google's data and AIcloud is saber saber is a softwaretechnology company that powers theGlobal Travel industry processing morethan 12 billion shopping requests across1 billion Travelers every year let'swelcome to the stage SVP president ofsaber labs and product strategy Sundarnarasiman to talk about how they'repartnering with Google to transformtheir business Sunder welcomehello everyonehow are you doingit's kind of afternoon isn't itmy name is sunder narsim and I also leadEnterprise architecture and platformengineering at saberand today from a customer Viewpoint Ithought I'd share with you our journeyto Google Cloud tell you a little bitabout what saber doeshow we've approached the process ofmigration and then spend a little bittime talking about databases inparticular and leave you with a fewthoughts about what I think the futuremight look like I've been really excitedto hear rithika Andy and others showcasesome of the really coolI'd say Innovations in the in this spaceand over the next few minutes we'llcover a few of thoseso what is saber and probably not manyof you know uswe are acompany that we aspire to be a globalPremier Technology platform in traveland if you we operate in two sort ofbusiness unitsAirline Solutions as part of travelSolutions we really runwhat are called passenger servicesystems that provide retailingdistribution and fulfillment for some ofthe world's largest Airlines you mayrecognize American Airlines JetBlueAlaska and even other countries otherairlines across the globe let that andgo Etcwe also run a travel Marketplace we takethose Airlines and we connect thecontent that they provide to sellersacross the globe and we do the same sortof thing for hotel years and that'sreally what the hospitality Solutionsbusiness unit is and in the marketplacethat we sell we have 400 Airlines maybea million plus hotelsandabout 50 000 odd agencies some of themare onlinePriceline you may have heard of e-travelgroup but also that's not only LeisureTravelers but business Travelers you mayhave heard of Amex gbt cwt so in shortwe really sit at the middle of traveltransactions there were B2B companypredominantly been business for severaldecadesand when we thought about what it wouldtake to take this company which had youknow a plethora of Technologies runningfrom mainframes mid-ranges we reallystarted with thinking through not justmigrating to the cloud and learning tooperate in fact the people enable theminside of it really we have one of thelargest trained workforces in GoogleCloud but we really said that wasn'tenough we needed to transform thecompany the way we operate the way wethink about developing solutions for ourcustomers for end users for travelersandsaber for all of our existence has beenone about Innovation and we said notonly do we need to migrate put ourPlatforms in the cloud but they need tofacilitate the innovations thatTravelers need and we all want to expectfrom a platform company such as saberand databases are at the core of all ofthisand if we cart back into you know manyof you are Enterprise companies that ifyou ask looking and if you've been inthe business for a couple of decadessaber was you had pretty much one ofeverythingin operational databases we hadmainframes we had largeOracle everywhere and we also haddocument databases couch base andobject-oriented databases vertica on theanalytical side again we hadpretty much teradata vertica we had ranour own Hadoop clustersand when we thought about where wewanted to go it wasn't just aboutmigrating every one of those intoGoogle Cloud but as ritika said what wasactually happening in the databaseindustry is this unification that shetalked about the unification oftransactional data with what you mightcall analytical data because if you lookat the trends of storage compute thesewe realize we're going to converge andin order to create that Innovative newapplications that our customers wantedit was about imbuing embedding travel AIin all of our applications We examinedall of our suite and we identified over60 such use cases where travel AI thoselittle what I call raisins in the loafof bread that would really enhance ourproduct offering to our customers andnot only are we going to embed this AIapplication in this call it integrateddataecosystem but we also needed to connectend-to-end applications that all of ouruse cases up over the top that you seein effect taking advantage of the new AIcapabilities that would enable them tomake even more money make enhance userexperiences possible for all of us asTravelersand if you looked at what's differentabout saber compared to maybe you knowother database users or companies mostof our databases are Enterprise classhave lots of pii PCI if you're allprobably typed your passport ininternational travelPCI Data obviously we pay with creditcards and gdpr privacy is very importantand so the security and compliancerequirements of these databases areimmenseand the consistency requirements havebeen in place since the 60s and 70s whensome of these databases were put inplace in fact the early days of saberadvertisements literally had pictures ofpeople with people sitting on the sameseat like multiple people on the sameseat because until saber came alongeven seat assignments were not done in aconsistent wayand if you look at availabilityin we say how many nines right five foursix in fact we have SLA penalties if wedrop or have outages not only do we getwritten in the paper we make all of youtraveling public suffer we want to gethomeand or to an important business meetingso these kind of requirements are reallywhat you know we live by we breathe andwe think about and in terms of how weended up you know using these plethoraof database products that you heard Andyand others talk aboutthe key point I would like to leave withyou is really think about the contextualuse caseswhen you have strong transactionalconsistency requirementswithout compromising on scalability orperformance spanner is a great choiceand in fact the PNR those six characterlocators that youkind of see in your itineraryconfirmations right those are calledpassenger Name Records and that complexis perhaps one of the most demanding interms of performance and when we liftedit and made it run on spanner it wasn'teasy rightit was in effect required while wesatisfied the acid requirements weconnected it using Pub sub to othermultiple Regional spanner replicas thatwere optimized for read performance soI'd encourage you to think about thatkind of uh what might call use caseswhere spanner really shineson the bottom you know there are the usecases not all of you know if you want tobe cost effective there are other usecases we sell products and I've listed acouple of them there where we provideMarket intelligence or Global demanddata to our customers and for those uhkind of use casesthe other databases that you know suchas alloy DB or Cloud SQL are perfectmatchesand last but not the least at the verytopwe as I mentioned we had a lot of Oracledatabases and in order to realize ourshutdown of our on-prem data centers ina timely fashion we literally move themto essentially the bare metal Solutionon Oracle and we still continue to runsome of them but in the process ofmigrating as Andy you know kind ofpreviewed our databases andconsolidating them in an integrated formthat we actually hope to go forward within the futureand if you were to say like okay whereare you there you know saber in ourmigration Journey we're about a third ofour 10-year Journeyand we would say about 90 percent of ourworkloads are in the public cloud andit's been a great partnership with Andyand his team they literally sit team byyou know with our Engineers work veryclosely with their Engineers to get usto where we areand in terms of the future what reallyexcites us is really all the things youheard about today in terms of generativeAi and AI in general that vertex AIproduct on which our travel AI productsare built is going to be I think a keyfor us as a business going forward andin fact one of the engineers we had ahackathon just three weeks ago he saidif you're not using llms every day as aprogrammer you're falling behind and notonly is it important to get theproductivity improvements but in termsof Automation in terms of reducing coststhat in call center applications or helpdesk applications all of those are goingto be very important with thisgenerative Ai and llm Technologyand the second part is also importantthis unification that you know ritikatalked about in terms of transactionaland analytical databases I'd go one stepfurther and say operational data in factin the keynote you saw a demonstrationof an alerttriggering a processing step togetherall the way through analytical to evenoperational data and those kinds of usecases are real value to not only our B2Bcustomers they make the lives of endTravelers be much more you knowenjoyable because at the end of the daytravel is really about you knowconnecting to the people in places youlove and that's the mission that we allsee as you know Primary in our businessin in saber and last but not the leastyou know we often talk about data assilos within our own companyand I think it's important that as theseconvergences happen companies find newways of collaborating across each otherwe didn't talk too much about productslike analytics Hub which enable ourpartners coalitions those Airlines andhotels to come together and provide newproducts new ways of exploring new waysof really buying and you knowexperiencing travel that isn't possibletodayso with that you know I'd leave you youknow tomorrow there's actually a anothersession with Joe defonzo our CIO who'sgoing to talk about more migrations ifyou're interested in it I encourage youto go to that session I wouldn't butthat I hand it back to rithikaSunder thank you that was such a greattransformational story I it's been apleasure working with Sundar and histeam and the entire saber team on theirdata and AI transformation so let's moveto our third theme for Innovation whichis centered on assisting you indeveloping modern and data-drivenapplications with an emphasis on beingopen now open means enabling you tobuild your Solutions wherever you needwhether that be on-premises whether thatbe across various public clouds or atthe edge it also means making manageddatabase services available with OpenStandards and open apis while supportingyour mission critical workloadsand lastly it means fostering an openpartner ecosystem of solutions designedto help you move faster now we've heardfrom many of you asking us to help youmodernize your database workloads asquickly and as easily as possible and weanswered that call with alloy DB youheard Andy and Sundar talk about thebenefits of alloy DB including the newlyadded gen AI Innovations with alloy DBAI we're thrilled to announce that todayalloy DB Omni the downloadable editionof alloyed EB is moving from technologypreview into public preview alwdb Omniis designed to run everywhere on GoogleCloud on AWS Azure on premises and evenon your laptopsince its initial launch we've addedmany new features to loydb Omni we'veadded many of the Gen AI capabilitiesincluding allo dbai that Andy discussedearlier we've also Incorporatedadditional performance benefits and wehad added support for postgres 15.we've also added extra utilities tosimplify the management of alloy DB Omniwe're also announcing support for ledbOmni is another choice in our databaseservice for Google Cloud distributedhosted which is our air gapped privateCloud environment for regulatedcustomers alliedbi Omni meets you whereyou are and can take you where you needto go in your database modernizationJourneyand we've made it easier than ever tomigrate from these Legacy from Legacydatabases today we're also excited toannounce the general availability ofOracle to postgres migration to supportour database in our database migrationservice we're making it fast and easy tohelp Enterprises migrate their schematheir data their PL SQL code from Oracleto postgres and it doesn't stop therewe're also excited to bring the power ofduet AI to Oracle to postgres migrationsand including alloy DB which is nowavailable for sign up in previewwith duet Ai and DMS we'll offer AIassisted code conversion to automate theconversion of database code such asstored procedures functions triggerspackages custom PL SQL code all of thisto postgres so let's take a moment tosee it in actionnow we're going to start by seeing themagic you're going to start you saw themagic of duet AI this morning in thekeynote I pre-recorded a demo here andlet's see in more detail how easy it isto migrate your Oracle databases toalloy DB I'll start here by opening upthe console this is your One-Stop shopto create and manage all of my databasemigrationsfirst I'll open up the conversionworkspace I pre-created I've alreadyselected the Oracle schema I'd like toconvert on the left you can see that DMSdoesn't just convert the schema objectslike tables and Views but also thestored procedures and functions I'llclick convert and DMS starts convertingthe schema after the initial conversionit looks like there's still some issuesin the past these would have to bemanually updated which would be bothtime consuming and error prone but nowwith the power of duet AI I can automatethese and address these last mileconversions let's see it in action hereyou can now see the Oracle tree thatincludes all the objects I selected inthe previous step I can now view thealloy DB postgres tree also which showsme how DMS converted the source for eachobject there's a side-by-side comparisonthat you see here that shows thecorresponding Oracle and postgresdialect you can see here these are theitems that didn't convert see the errorsand warnings normally I'd have to fixthese manually thanks to the power ofduet AI I only have to show the systemhow to address a few let's try it out inthis conversion we have a specificproblem because assist state is anoracle-specific function which dependingon the context doesn't have a postgresequivalent therefore the translationrequires a manual intervention as soonas I manually fix the issue duet AI overhere kicks in check it out duet AI haslearned enough to propose a fix for theremaining objects in this screen I cannavigate through the various suggestionsand review the proposed conversions Ican accept reject or modify thesuggestions we're going to accept allthe suggestions herenow with no outstanding issues I'm nowready to move the converted schema toalloy DB now with the biggest and mostcomplex steps out of the way I canquickly and easily migrate my jobs andI'm well underwaynow wasn't that amazingit's no wonder that customerslook it's no wonder that customers likeChicago Mercantile Exchange group arelooking to alloy DB for their mostdemanding workloads and they're alreadyin the process of migrating severalOracle databases now being open alsomeans being committed to delivering thebest open source compatible managedservices so that you can spend more timeinnovating and less time on managing theplumbing of your databases we'rededicated to making Google Cloud be thebest place to run your MySQL and yourredis workloads Cloud SQL which is ourfully managed relational databaseservice for MySQL postgres and SQLServer workloads is used by more than 95percent of the top 100 Google Cloudcustomers last month we announced majornew availability performance and dataprotection enhancements in Cloud SQLwith the introduction of Enterprise PlusEdition for MySQL and postgres workloadswe worked closely with customers and theresult speak for themselves Cloud SQLEnterprise Plus deliver for MySQLdelivers up to three times higher readthroughput and up to two timesImprovement in write latency compared tothe Enterprise Edition it also deliversthree times higher performance thanAmazon's comparable MySQL servicenow in addition to boosting our MySQLperformance with Enterprise Plus we'vealso worked on supercharging our memorystore for redis offering with a brandnew capability today we're announcingthe preview of our new fully managedoffering memory store for redis clustermemory store for redis cluster is aneasy to use open source compatible rediscluster service that runs on redis 7 andprovides sub millisecond latency withget this 60 times more throughput thanthe existing offeringcustomers such as Palo Alto networkstested memory store for redis clusterand found it to be easy to use highlyperformant and easily scalable this isjust another example of how we're makingopen source compatible database Serviceshighly performant while simplifying themanagement experienceand finally open just doesn't doesn'tjust apply to our technology it's alsoabout developing an open ecosystem ofPartners today over 1 000 Partners powertheir applications using Google's dataand AI cloud and to reinforce ourcommitment to Partners we're excited tolaunch our new Google cloud ready forcloud SQL program this is a program thatrecognizes partner solutions that havemet the integration requirements withCloud SQL and it joins our alreadyexisting Google cloud ready for Alloy DBpartner programour Google Cloud databases are committedto helping you build modern data-drivenEnterprise applications with an emphasison being open and now to close I'd liketo welcome back Andythank you ritikaas you can see from all we've spokenabout today the future of data and AIhas Endless Possibilities Google Clouddatabases offer an intelligent unifiedand open platform to support your gen AIjourney and we hope you found today'ssession insightful and inspiring hereare three things you can do to learnmore about these Innovations first wehave lots of Deep dive sessions in thedatabase professionals tracksecondshowcase on the show floorand just talk to us Google Cloud expertswe'll be happy to answer your questionsnow here's a quick overview of what'snew at next and a list of other valuablelearning experiencesthank you so much for joining us todayenjoy the rest of next"
}