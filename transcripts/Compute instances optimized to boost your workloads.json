{
    "title": "Compute instances optimized to boost your workloads",
    "presentation_type": "Breakout",
    "categories": [
        "Architects, IT Professionals",
        "ARC216"
    ],
    "video_id": "sFsF7_0jSIg",
    "time": "Aug 29 02:15 PM - 03:00 PM CDT",
    "transcript": "foreign[Music]so if you came here to attend erc216you're in the right roomif you came here to attend somethingelse you're still in the right room stayhere feel free to comment come up infront if you wantummy name is called Steve Doss most folkscall me KD simply just go by that I'llbe joined by solil Surreyand over the next 45 minuteswe will go through a number of differentannouncements and and topics inparticular so let's go to talk aboutInnovations and announcements in makingour infrastructure portfolio uh richerfor your useChris is going to talk about operationsautomation security and compliance andthen we'll hear from a customerokay throughoutthis event and throughout ourinteraction with you you'll hear us talkabout how we optimize for workloads foryour workloads and we firmly believethat the best infrastructures that whichis finely tuned and optimized for yourworkload they may be AIML workloadsmodern workloadsother workloads that you haveand through this we focus on corepriorities of making this infrastructurereliable or making the Constructorsecure cost efficient simple andsustainablebut the reasonwe embarked on the Journey of cloudand the reason Google in particularshines is because of the bottom piecewhich is this unique platformInnovationsthat make our infrastructure shine thoseare around custom silicon that we buildit's around Cloud systems that are builtfor scaleand around AI driven automation thatmakes the lives of our customers you allbetterthank youbut today in particular we're going totalk about four ways in which we helpyourun high performance workloadsrun them cost effectivelyleverage tools and automation tooptimize their operationsand finally Safeguard the cloud throughsecurity and complianceOkay sostart with and you'll hear this in thefirst section with salil there's thistension betweenuncompromising performanceand costrunning high performance computeworkloads are super importantbut they're not always important for allworkloads there are workloads which needto optimize for call for efficiency forcosts and we will talk about how ourportfolio allows you to balance thetrade-offs more effectivelythe second piece is around running thecloud optimizing operations and we talkabout a number of different tools thathelp you do that Chris will cover theseabout flexmix future reservationsan equivalent code componentand then finally we have avery unique and differentiated approachto to security to complianceChris is also going to cover a number ofdifferent Innovations in that spacearound confidential Computing assuredworkloads and our unique approach tocomplianceso lots to cover so without the furtherAdo I will welcome salil up on the stagesalilthere you go take it awayokay live thank you for coming to ourtalk today uh thanks Katieso as Katie mentioned uh we're going tosort of cover our compute portfolio andgo deeper into the choices that are sortof available to you as our customersso customers such as yourself like havehad a few conversations since todaymorning and like are looking to buildmodern new applications using the bestthat the cloud has to offerbut at the same time you don't want tosort of forget traditional Enterpriseworkloads which for many of you form thevast majority of your ID landscape rightso at Google Cloud our mission is topurpose build infrastructureto account for needs of all of yourworkloads and our compute portfolioreflects thatso our general purpose offerings aredesigned to span a wide cross-section ofworkloads like I would I would Hazardlike up to 90 of the workloads that youhave in your data center could be sortof classified as general purposeand there is but we have a bunch ofdifferent offerings in there and each ofthese offerings are designed to sort ofgive you some amount of optimizationsbalancing for costmaximum flexibility as well as extremeconsistent performanceour specialized VM offerings on theother hand are purpose built to designto sort of give you maximum performancefor a given resource type and a resourcetype here being compute so if you reallyneed like a high clock speed like CPUor memory so you need like memory ratioslike really high memory for sap Hanakind of workloadsor gpus for your aim applicationsand todaylet me share with you some announcementsthat we're making and updates that we'remaking to our portfoliofirst the sea family is sort of gettinga makeover right so C Used to Be computeoptimized with the launch of C3 and itsshift to general purpose we aresignaling its broad applicability to abroad cross-section of workloads muchmore than what it beforethis family is optimized for greatperformance and minimal disruptions toyour workloads and this is think of itas a great family for workloads that donot write any performance variants whilerunningwe do all this while also deliveringindustry leading storage and networkperformance and we'll talk about that inthe subsequent slidesyou might be wondering what is C familygood for which workloads map on to seefamilyand like I said it's for a generalpurpose offering so it's a broad swathof your workloads typically customersrun end user facing applications theseare applications which are Revenuecritical for your business these areapplications which are low latency andthey show up in the form of databasescaches streaming workloads Networkappliancesand suchcvms are also the first set of DMS thatare based on the newest elements ofGoogle Cloud titanium architecture asyou heard from Thomas today hopefullysome of you made it to the keynote uhtitanium is our custompurpose-built dedicated Hardware stackthat offloads the CPU and providesperformance reliability scale andsecurity improvements for your Cloudworkloads this is great because thisfrees up the CPU to focus on customerworkloads and maximizing the performancefor customer workloadsthe new titanium architecture also comesdesigned to transparently handleinfrastructure updates so while weupdate our infrastructure in thebackground there is absolutely zerodisruption to your workloads which isamazingGoogle's new custom built infrastructureProcessing Unit or ipu which is part ofour titanium architecture allows us tooffload the networking from you know thehost onto a dedicated network cardoptionso which is which is which allows us tosort of achieve like staggering resultslet's take a look at what our customerExpo Gio was able to achieveX which I O designs an extremely highperformance layer 3 switch designedspecifically for broadcast media andfinancial streaming services customersthey were able to sort of achieve fourand a half times Improvement andperformance and they were they got up to183 gigabits per second and 30 millionpackets per second out of a single VMinstance and we believe that we can goeven higher and we've seen numbers tothat effectlast but not the leasttitanium also enhances the security foryour workloads because we are able to doline rate encryption and much much moreuh enhancing the security profile ofyour Cloud workloads running on ourplatformtitanium has been underway for many manyyears many of the products that youalready use benefit from the titaniumarchitecture but the newest elements oftitanium are sort of coming we'rebringing them to you in the guise ofcvms and hyperdisc but this is going tobe the foundation of all future GoogleCloud offerings so this is going to bethe under architecture that underpinsall of itwith that let's dive into C3 Google wasfirst to Market to bring general purposeVMS based on Intel's fourth generationSapphire Rapids uh processorbuild on the latest compute storage andnetworking Innovationsc3vms offer up to a 35 Better Priceperformance than previous generation VMSwhile the customers also get 50 fasteraccess to ddr5 memory as well as AMXaccelerator which is used for CPU mlinference and is 12x faster than the AVX512 instruction setbut that's not allC3 also like I said is based on thetitanium architecture and we are able tonot only improve the packets per secondperformance we are also able toumachieve 200 gigabits per secondthroughput for a single VM instance thisis 2X or previous generation and forthose of you who are not going up tothat high in terms of network bandwidthconsumption we are also doubling the 2xstandard VM bandwidth so without optinginto tier one networking the standardbandwidth lean scales linearly dependingon the size of the instance all the wayup to 100 gigabits per second which istwice as much then you can get anywhereelse in public cloudand last but not the least it gets evenbetter with hyperdisc because weannounced hyperdisc last year it's ournext Generation block storagearchitecture it allows you to trulydecouple storage and compute andtherefore allows you to maximize TCOsavings for your customers and yourworkloadswithit we are able to deliver up to 15xhigher iops and 8x higher throughputwhich is in preview right now thattranslates to roughly 500k Ops per C3instance which is again the highestavailable to you in public Cloud so thisis great but we're not stopping with C3I'm super excited to sort of announceour c3d offering which is sort of rightnow in preview based on amd's fourthgeneration Genoa processorsc3d combines C families Enterprise gradereliability and tooling with thesignificant boost provided by amd's forGeneration Genoa processors these aremassive machines these are up to 360vcpus 2.8 terabytes of memory on a wholehost so these which makes them great forsort of processing large data sets andwe have seen our customers are realizinganywhere north of like 45 percent gainsprice performance relative to ourprevious generation AMD VMS and we haveseen great results on a wide variety ofbenchmarks such as data processingin-memory databases relational databasescode compiling workflowsarm that brings me to arm and arm is soas I talk to customers our customers aretelling us that arm is a great part oftheirinfrastructure is strategy and they'readopting arm increasingly and as we dothatthey're conveying their excitement to usso today we are super excited topre-announce our upcoming c3a BMS basedon ampere processorand we expect c3a to deliver 40 BetterPrice performance relative to comparablex86 instances in the marketc3a will be available in more regionswith more features with Advancednetworking and will be enabled with upto hundreds of isv applications rightout of the gate this should really allowyou to sort of you know enable andenable your workloads on arm and we haveseen some good success with thatDailymotion is seen great results and Ithink it makes for a very cost effectivesolutionwith these announcements we have acomplete C portfolio across Intel AMDand arm and we allow an enabled choiceso you can choose what is best for youand your workloadswhen we think about Switching gears whenwe think aboutmaking and you know the things that weneed to do to make Google Cloud platforma great place for researchers scientistssuch as yourself to run your HPCworkloads we typically think about threethings first is fast and affordableinfrastructure so that you get those TCOsavings and you have the lowest time tocomplete your jobsecond is easy and compatible ourplatform should be easy to use for anindividual researcher as well as in HPCGuru right and it should be compatibleso that it allows us to sort of pluginto all the partner offerings that wehave out there third is partnerpreferred we work very hard to enable abroad partner ecosystem and that allowsfor us to expose that choice back to youas a customerwe are optimizing our infra capabilitiesacross compute storage and networking asan example we recently announced andthis is in preview our H3 VMS hdbms arepurpose built for HPC workloads andoffer up to 3x Improvement in Burn nodeperformance and up to 2x lower cost thana previous generation VMS which isstaggering the benefits this benefitslike a wide variety of Industries sofrom molecular Dynamics to like weatherforecasting to computational financeoutside of each three we are also makingother improvements to make sure that youcan run HPC workloads in a seamlessFashion on our platform an example thatI would like to sort of call out ispanel store so palette store is amanaged file system service which wentinto preview today and it's built on theIntel deos OSS stack it's an ex itprovides extreme iops like millions ofiops it provides extreme throughput soyou can think about like 100 gigabitsper second measured at the maximumcapacity and extremely low latency andit is 6.3 times faster read throughputperformance compared to any othercompetitive uh like service offeringavailable in public Cloud todayso let's go a little bit deeper into H3H3 offers industry leading performance Italked about per node performance goingup by 3x and costs coming down but wealso do all this while maintaining highefficiency for example on a popularweather forecasting Benchmark we wereable to demonstrate that we can go up to4000 cores over 4000 cores keeping 90efficiency which is almost like doubledin the previous generationswe are extremely pleased to sort ofpartner with a wide variety ofecosystems so rescale alter answers toldCAE parallel Works to actually bring allof this Innovation into you so that youcan choose the best integration pointsfor your HPC workloadswith that let me turn it over to Krishto take you through infrastructureoperationsthanks uh so you heard about the breadthof the portfolio that we have withrespect to VM families and uh one thatis actually built with a lot of yourworkloads in mind it's not aone-size-fits-all even though thegeneral purpose for workloads fit intoour general purpose families for themost part what we'll actually coverthrough in the next few minutes isreally how do we manage that growingportfolio of VMS and the new familiesthat are coming in in an efficientsecure uh and automated way so we'llcover through a number of differenttopics as we go along that cover all theway from reliability to security andeverything in between so let's startwith uh reliabilityso a good VM portfolio really needs todeal with all of the different thingsthat it needs to optimize for theworkload but at the same time it reallyneeds to be Rock Solid and reliable soone of the things that we by doing atGoogle cloud is investing pretty heavilyinto node level reliability so when youthink about that you're really talkingabout firmer level reliability you'rethinking about hypervisor levelreliability and sort of overall Machinelevel reliabilityin total so one of the things that we'redoing is reliability at scale we're veryvery happy to announce that we haveupped the bar on overall reliability forgeneral purpose machines from what usedto be 99.5 percentage to 99.9 so it's athree nines for all gel purpose uhmachines going forward and on top ofthat for memory optimized machines we'resort of pushing the bar even higher to99.95 percent reliability so it's 395reliability going forward so startingtoday those two are going to be the newbenchmarks on reliability that we haveindustry-wide and one of the otherthings that we're doing here isproviding you the information to be ableto go ahead and then monitor the overallreliability and health off theenvironment So within the console todayyou now have built-in dashboards thatallow you to observe the overall healthof your environment in a very very easyway and of course there are apisavailable for doing that as well and ontop of that we also add recommendationsand alerts if there are issues that weactually find with respect to theoverall reliability of the environmentso in total we want to make sure thatthe base reliability level you havereally large numbers that you canactually depend on and provide you theinstrumentation that allows you to goahead and then tackle any issues thathappen even past that in a proactive waytalking about proactiveany large Fleet of anything for thatmatter whether it's compute machines ina data center or large fleets of carsthey will need maintenance and we wantto make sure that the active maintenanceor life cycle management does not reallyimpact your workloads so Google has beenheavily investing historically and evenmore so now on a set of technologiesthat allow you to do live migration offyour workloads so customers such as Etsyand aerospike use that pretty heavily inensuring that their workloads themselvesdo not get disrupted as a result of themaintenance actions that Google takeslive migration allows you to go aheadand then move a workload from onemachine to another without disruptionwith memory transfer to the data hasactually shows up and the computationessentially happens without any pause ontop of live migration we also have liveupdate which allows the actions that wetake for the software stack at the nodelevel to be done without any disruptionto your workload so live migration takescare of you know sort of anything thatmitigates the movement of machines fromone to another while live updateessentially does the In-Place updatingoff your node software withoutdisruptions between these two we expectthat a vast majority of what we do froma maintenance standpoint will actuallybe taken care of without any disruptiondeal workload but on top of that we'realso providing mechanisms through whichyou would actually get much moreproactive notifications for thosesituations let's say you've got a largesap Hana database or you're running awhole bunch of GPU oriented workloadsfor your AIML jobs we want to make surethat the overall notification period islong enough in such a way that you'd beable to go ahead and take actions basedon the fact that there is a futuremaintenance event that's coming in andthat's not the last thing we also arelooking to introduce user triggeredmaintenance which is really maintenancehappening on your terms on yourschedules so the collection of thesecapabilities then allow you to go aheadand then tackle Fleet Maintenance in aleast disruptive way for your jobsmoving from there we also want to talk alittle bit about flexibility ofprovisioning within your environmentso mix we're actually pre-announcingthat here at nextimagine a manage instance Group which isa way in which you would actually have aset of homogeneous VMS at very largescales hundreds if not thousands thatcould actually be deployed as one entitywith this new capability we'reintroducing two dimensions offlexibility for these large managedinstance groups one dimension offlexibility is by VM family so you couldmix and matchdifferent VM families into a singlemanage instance group in such a way thatyou could go ahead and optimize one partof that manage instance group for onetype of workload from a priceperformance standpoint and another partis a different price Performance Pointbut all being managed as one group orone entitythe second dimension that we'reintroducing is really the consumptionmodel today when you deploy a managedinstance group it's either all on-demandworkloads or all spot workloads andneither shell to mixwith this new capability that's comingin we're actually allowing you to goahead and then provide a mix ofconsumption models between on-demand andspot which then allows you to optimizeboth on the availability and costfactors for your particular workloads sothis is going to come into previewshortly you want to make sure that youknew this first heremoving from there and talk aboutcapacityCloud capacity is elasticwhen you need more capacity you growinto it when you have less needs youknow you just kind of give it insomebody else has got that need theycould actually use that and that's kindof how Cloud capacity works and we allknow that howeverthere are situations where you have acritical business need and you need tomake sure that that cloud capacity isabsolutely assuredto be there for you when you need it foran example let's say you know your photoroom and you've got a very large approllout that's coming up and you knowthat's going to happen in about amonth's time and you need to make surethat you're not just depending on thenormal elasticity of the cloud but youwant to have a highly assured capacityavailable to you at that time that'sexactly what they do future reservationsis the capability through which we'dactually provide you that high level ofassurance For an upcoming workload burstthat you might have in the future inyour environment this can be applied toa variety of use cases clearly a futureburst in workloads is a good one anytimethat you have rare uh Supply constrainedresources that you want to have yourhands on in some future time that's anexcellent place but you could actuallygo ahead and use that too you're movinginto a new Data Center and you want tomake sure that that migration is goingto be successful for you and you knowexactly when that move is going tohappen use future reservations and thatallows you to go ahead and thenapportion that capacity for you at noextra charge so this is a capabilitythat we're public purviewing today thatthen allows you to go ahead and then gostraight into the console and thencreate a future reservation for any newworkload that's coming in that you needburst capacity for sort of additionalcapacity for fully assured for you allof the capacity planning and theAssurance is taken care of in the backend and you're able to go ahead and thenenjoy using this capacity at the timethat you need for your most criticalworkloadsmoving from there we want to talk alittle bit about Job management how manyof you were at the keynote and thenheard the word Ai and have a word countquite a few right so a lot of the AIjobs essentially end up being largebatch jobsso I've got a model training work that'sgoing on or I have some inference jobthat's going on that's a lot of ittybitty workloads that are all combinedtogether to form one giant workloadwhat Google batch allows you to do is toessentially act as a funnel as a managedservice that allows you that collectionof workloads to be brought in into oneentity the Google back service and thenexecute it from there we have a numberof different Partnerships that we'vebuilt over time and continuing to buildand invest into where whether it's lifesciences whether it's finops whetherit's core AIML workloads or any othersor HPC type of workloads as you knowsalil is talking about with the H3 VMSyou'd be able to go ahead and then bringall of those together into a singleentry point that is fully managed foryou from a job subjunction standpointfrom a job Control job notification andjob assembly perspective so Google batchis available in production for you totackle all of those challenges as you goforwardvery excited to talk about a particularparticular that is really really sweetfor Developershow many times did you have to actuallygo in and then do something in a consoleand just wished that you could simplyautomate the 15 clicks or 20 clicks thatyou did to go ahead and then take thatone actionwe're debuting equivalent code componentthat's available in production on thecloud console today that allows you toSimply do exactly that you're able to goahead and then take a series of UIactions and have those UI actionsparametrically convert into code thatyou could use right awayand that code would be available in avariety of form factors you could usethat as rest API you could use that asterraform you could use that as ourgcloud CLI all of those are availablefor any of those actions that you wouldtake on the console for a series ofthingsdevelopers dream because now I couldtake that one set of actions that I doon the UI and simply go ahead and thenparametrically automate that to n numberof times that I want to do embed that inmy scripts embed that into my automationFrameworks and go from theremoving from there I want to talk alittle bit about security and complianceso today Kevin mandia and Thomas Koreanin the keynote kind of highlighted anumber of different things that arehappening from an overall securitystandpoint at Google but here in thenext few minutes we'll talk a little bitabout some of the things that we'redoing from a compute standpointthe first thing is really aboutintegrity of your environmentconfidential Computing is not new butwhat we're continuing to do with it iswe partner very heavily with two of ourmajor Partners AMD for their secureencrypted virtualization or Sevtechnology that allows you toessentially have signature drivenhardware-controlledsignatures that you could actuallytackle at the firmer level and up aboveat the host software level that allowsyou to go ahead and then have a clearview of what that software is any changethat actually gets done for thatsoftware and be able to secure thatenvironment at the lowest level possiblewe're also expanding that in the C3platform that cilia talked about earlierwith Intel's trusted domain extensiontechnology again very similar from ahardware perspective that allows you togo ahead and then get that utmostIntegrity for that node going forward soconfidential computingcompliance is a hugefactor for many many of our workloadsnot necessarily for U.S government orsome other governmental needs but evenfor our industry needs whether it'sHIPAA whether it's PCI whether it's nebsor any other industry level complianceone of the approaches that Google hastaken in this is not necessarilysequester or ask you to sequester yourcompliance needed workloads into somecorner like a gov cloudwe've taken a different approach inproviding you the controls that you needon our regular data centers in such away that you're not really operatingwith a smaller set of services on somesequester gov Cloud but you're operatingwith the broadest set of services on ourgeneral purpose public cloud datacenters with the right controls that youcould actually go ahead and apply tothemwe're very proud to say that a shortworkloads which is the mechanism throughwhich you would actually do thosecontrols is now available in nineregions today and is continuing toexpand this is the largest set ofRegulatory Compliance workloads that youcould actually deploy in any publicCloud today and the number nine is todayand like I said you know it continues toexpand as we go forwardthis provides you a view in terms of thevariety of compliance regulations thatwe invest into both in terms ofindustry-wide privacy and governmentaland Sovereign requirements that we dealwith you know across so you will see anumber of different Global ISO standardsthat we actually comply with today atthe infrastructure level and a number ofspecificcountry or jurisdiction specificstandards that we comply with as welland this list is something that willcontinue to growso from an operations Automation andsecurity standpoint we continue toinvest pretty heavily into ensuring thatyou could go ahead and then utilizeGoogle cloud in the most efficient andcost effective way as possible with thatI would love toinvite Mahmoud who is representing snaphe is the engineering manager at snapthat is responsible for theinfrastructure thank you so muchokay hi everyone my name is Mahmoud andI'm an engineering manager at snap andtoday I'll quickly give you anintroduction on how we at snap work withthe Google folks to try to figure outhow we use all those like machines andinnocence typesum so my team I lead the infrastructureteam in snap and my team uh worked witha lot of snap Engineers that rundifferent workloads uh some of them arelike reverse proxies some of them arestateless Services some of them are dataintensive or like machine learning uhworkloads that requires a lot ofcomputation and then I work with allthese teams to try to figure out what isthe right instance types for them to useum how we do this uh we usually try toexperiment and measure as much aspossible because every use case isdifferent so we try to work with themespecially when there's a new machinetype that comes out we try to run it onlike an A B tested and run on differentmachine types and see if the performanceis getting better or getting worse andso on and so forth and then there's somegeneral guidelines that we've learned byworking with Google for a long time forexample uh C types are very good forhigh computation use cases but also usecases that requires uh stableperformance if this makes sense versusmaybe a more General n-types that arealso high performance but does not havethis uh strong consistent performance uhmachine types like T machine types are agood for certain workloads that requirespecific CPU to memory ratio for exampleuh and then there's always like thatperformance versus cost trade-off rightsometimes you want to use like the bestmachines out there no matter how muchit's gonna cost you and then other casesyou would like try to save cost as muchas possible without compromisingperformanceuh and I want to talk about like two usecases here that looks similar but alsolike we have some differences and tellyou how we go about like picking theright instance types for them uh thefirst one is our API Gateway uh thoseare like front-end fleets uh that sitsaround the world and they talk to ourcustomers right away so all the Snapchatusers talk to those API gateways andthose are like reverse proxies theyreceive HTTP requests they do some maybeencryption some validation and thenroute the request to the right back-endservice and as you could imagine thoseare uh very compute intensive use casesbut also the important part is itrequires a very consistent performancebecause we don't want to providedifferent experience to different usersand in those cases uh machine type likethe C Machine type that has performanceconsistency is very important to usanother use case would be the machinelearning those are also like back-endServices they run feature extractiontraining models so also very very heavyon computation and requires a lot of CPUbut in this case we might be able tolike not really need this performanceconsistency and uh in order to be ableto save cost and for these use cases forexample as using something like the N uhinstance types would be very beneficialbecause this might be cheaperand the last thing I want to add is uhthis is a continuous process that wealways work with the Google Engineers asmore machines comes out for example whenthe C3 came out and we like tried totest that we sold as as high of aperformance Improvement as 20 percentlooking forward and I I want to tell youlike this is my last slide so I want totell you uh what my team do working withGoogle like on a regular basis right thefirst thing is capacity planningum as you mentioned about like futurereservation is like one thing that youcould use in Snapchat for example wehave like some like if there's like avery popular event usually like aroundNew Year's Eve we know everyone is goingto pull their phone and start takingpictures for fireworks for example rightso if you know ahead that there's goingto be a traffic surge you could try toestimate it and try to work with withGoogle or using future reservation to beable to make sure that you have enoughcapacity that you needum the other two things I think thoseare the things that I talked abouttrying to uhfind the right balance betweenperformance reliability and also cost soif you have like a background servicesor a service that would run in thebackground does not need a lot ofperformance so you'd have to use like acheaper instances types versus if youhave something that is maybe user facingyou want to provide consistentperformance as much as possible you wantit to be as fast as possible so youwould use things like C Machine typesthere's also things like the Plaidmaintenance if you have use cases thatdoes not cannot afford being interruptedfor example in this case you might lookat instance types that would providemore uh predictable maintenance scheduleuh the last thing uh fade over I thinkthis is also very important as much asthat I would like to think of the cloudas elastic and has infinite resources uhand practical this is actually not thecase and there's been a lot of caseswhere we try to scale using a certaininstance type and there's just we runout of them there is not more of themright so you also when you're designingthis you have to think about okay if I'musing S3 and there is no more S3 what amI going to fail over to right and thelast thing you want to do is to fillover to a machine type that isdrastically different from your mainmachine type because now you're havingtwo different Hardware running yourservice which might just completely likemake you making make you reason aboutlike things like latency very hard rightbecause some of them are going to beslow and some of them are going to befast it's going to be almost impossiblefor you to figure out that the problemis coming from having different Hardwareright so trying to figure out what kindof instance type you want to fall overto in case of your run out of your NSStype is also very importantuh that's it"
}