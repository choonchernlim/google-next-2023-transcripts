{
    "title": "Feeling isolated? Confidential computing to the rescue",
    "presentation_type": "Breakout",
    "categories": [
        "Security Professionals",
        "SEC304"
    ],
    "video_id": "HmFz_vWAMck",
    "time": "Aug 30 01:45 PM - 02:30 PM CDT",
    "transcript": "foreign[Music]hi good afternoon everyone thank you formaking the choice to see this sessiondespite it being a lunch hourwe're going to talk about a whole lot ofthings of course confidential Computingand we've moved through the encryptionTrifecta encryption at rest and thenmoving on to encryption and news whichis confidential Computing and then we'regoing to talk about some new productannouncements and subsequent to thatconfidential space and the Privacysandboxmy name is Sam lugani I look afterconfidential Computing in Google cloudand with me is Jenny who's the PM leadon confidential space and Christinawho's going to talk about the Privacysandbox she leads that spaceum great so privacy and security arecentered to how we design products andit's the same for our customers as wespeak to our customers often enoughthese things are top of mind for them aspart of this session today we're goingto present some scenarios that come upvery often in our conversations with ourcustomersand give you a blueprint on how toapproach these for your own organizationthis session is going to be a littledifferent there's a few slides butthere's a bunch of demos interspersed aswe look at those blueprintsso one of the first things that comes upin every customer conversation is theidea that they want the highest level ofprotection for their keysand that's especially true if you havedata that you can't anonymize ortokenize so what's the answer there it'sencryption at restand we have a few options when it comesto encryption addressed you can have acloud a cloud hosted key managementsystem or KMS where you can store keysin inner cloud service you can rotatedestroycreate new keys as part of that processyou can also have an HSM by your storeand do all cryptographic operationswithin a Hardware security module that'sespecially true if you have regulationsthat you have to work around or specificcompliance requirements so if you needan HSM that's fips 3.0 certified that'sthe way to go and then of course if youwant to create separation between whereyour keys are stored and where your datais that's where an ekm comes in wherethis is a third party system that'sdeployed up outside of Google'sboundariesso let's take a quick peek at a demo asto what this looks like in our consoleum can we skip can we yeah perfectgreat so I'm logged into Pantheon whichis a Google Cloud console within thisI'm going to create a new instance typeand as I'm creating this new instancetype there's a few options here and Isee boot disk now as I move over to thisboot disk I can look at the differentconfigurations I have and there's a fewencryption options there's of coursedefault on Google managed encryption keybut in this case we actually want tohave a key that's managed by thecustomer so I can click on CMAC I canlook at the keys that I have createdearlier that are available to me or Ican enter a key manually as well so inthis case I'm going to choose asymmetric key that I've added in alreadyand that's about it I can select thisand I can create a new instance typethat is associated with that key nowwhat happens though ifmultiple instances associated with thesame key and I as an admin want to havemore control over what happens withthose instances so I have a dashboardwhere I can look at all these differentkeys that I've created in this key inthis case there's a key called CC testand I've disabled that key for now whatthat would mean is that any instancethat's associated with that kind of keyshould not actually boot up and thatgives me more control as an admin solet's see if that works um I have thiscmec CC instance type and it isassociated with the key which we've justdisabled so I'm going to try and startthis instance typeand as I'm starting this instance cyberdoesn't get booted up and the reason isbecause as an admin I've disabled thatspecific key that's associated with thisinstance type and that gives me a lot ofcontrol to do specific things within myorganization can we move back to theslides pleaseall rightso now that you've figured out what youwant to do with data at rest encryptedbased on an encryption scheme that worksfor you what's the next step in thatJourney you've got to do somethinguseful with that data if it's sitting ina place and not doing anything it's notsort of making money for you so you'vegot to do something useful with it whichis that you want to bring it into aninstance type or a container and have anapplication work on that data but beforeyou bring it in you want to make surethat that container is hardened againsta bunch of things and that's where ashielded portfolio comes in we haveshielded VMS and shielded GK nodesenabled by default which is a big dealnow there's three key elements therethere's a vtpm a virtual trustedplatform module which looks at yourpre-boot sequence there is integritymonitoring which looks at your runtimeboot sequence and then there's a thirdelement called secure Boot and what thatmeans is that if anything is out oforder in your boot sequence yourinstance will not boot up and this iswhat would protect you against boot kitsrootkits and kernel level malware andit's enabled by defaultso you you had your encryption addressfigured out you have this hardened VMsystem what if you need moreahwhat if you need more confidentialityand more isolation around your datathat's where confidential Computingcomes in so confidential Computingprovides a verifiable way to guaranteeisolation within specific boundaries ina confidential environmentoftentimes we talk about whatconfidential Computing is you know wehave a small crowd so human be a bitwe'll try and sort of visualize whatthat could mean in specific situationsso imagine you know I'm at a bank in the60s That's My Monopoly manhat and I'mwalking into a bank there's teleservices available we all have a swimLanes that's my briefcase with that niceGoogle Cloud logo encryption at rest allboxed in and I have my keys in my walletso as I walk into the teller there'sdifferent swim Lanes there's multipletellers all around I'm opening this boxand I'm getting some gold coins outmaybe I'm exchanging some pii as wellnow although there are these swim Lanesif there is someone well inclined to seewhat I'm doing they could potentiallyPeak and figure out what I'm doing hereand we don't want that we want thatextra level of confidentiality so nowimagine the same bank and a world insidethat bank and I walk into that world anddo some of these transactionsso we don't have a world here but wehave this niceCloud umbrella so we're going to treatthis as our world right nowI'm walking in to this worlddoing my transactionstaking some chocolate out because youknow it's lonely here it's isolatedquite it's quite well isolated here andtaking out a few gold coins as wellbecause apparently coffee is prettyexpensive in San Franciscoso I'm doing all these transactions inclosing my box and walking out and asI'm doing these transactions mytransactions are protectedthere is a higher degree ofconfidentialityas as I'm going through this processthat is guaranteed isolation and there'sverifiability which is where attestationcomes in which gives you this assurancethat the environment is secure and hasnot been alteredand this is how this is how we look atconfidential Computing nowwhen we started this journey ofconfidential Computing about three yearsbackthere were a lot of options in front ofusto get rid of this head by the way butuh there were a lot of options in frontof usand as we spoke to customers one thingwas loud and clearthat customers don't want to compromisebetween having to make a lot of changesin their workloads or choosing moreconfidentiality so the way we'vedesigned this system is that if you'relooking at confidential Computing andadopting it there's no quote changesthat's required you can bring yourapplications as they are two VMS or twocontainers without any code changesbecause that was loud and clear threeyears backand we're maintaining that approach aswe move forwardthe other thing which customers broughtto us was that lookperformance is money we want to makesure that as we are sort of going theconfidential Computing route we're notyou know we're not compromising onperformanceand we spent a lot of time with ourpartners engineering how this would workreally well and seamlessly so theperformance impact for confidentialComputing on gcp is absolutely minimalwe have performance briefs we can happyto that we're happy to share with younow confidential VMS are very similar toregular VMS there's no code changesagain required and a question we getoften is where are the keys the keys arein that secure processor they'regenerated by the processor they handledby the processor and the memorycontroller gets access to themwherein it can decrypt data put it inthe cache and that with the CPU canexecute the instructions coming from theapplicationthese are ephemeral Keys generated byHardware Google or even any customerwould not have access to those keysso we've taken this baseconfidential VM concept and we'veextended to a lot of different productsso now we have confidential VMSwe have confidential GK nodes no codechanges lift and shift no performminimal performance impact ratherand we have confidential data proc anddata flowwhich means that if you havestreaming analytics requirements and youwant to do processing based on batchjobs you can do that within data flowall within dataproc if you're dealingwith Hadoop and Spark clusters that aremanaged now you can process a bunch ofthose things within a confidentialenvironmentand of course there's confidential spacethat Rene is going to talk about in abitso let's move over to the DemI I want to show you how easy really howtrivially easy it is to create aconfidential VM so again I'm logged intoa Pantheon I'm going to create aninstancethere's this magical enable box rightherenow the moment you click enable there'sa bunch of stuff which is happening inthe backgroundwith automatically picking a region thatsupports confidential Computing oh andby the way gcp supports confidentialComputing in more than 80 percent of itsregions globally which is more than anyother cloud providerwe're pickingum an image that is supported by aconfidential Computing and we support avast number of imagesand we're also picking the rightconfiguration that will support thisprocess so all you got to do is clickthis enable button within when you'recreating a new instance type now whenyou go to kubernetes the process is verysimilar you will create pick a standardclusterand go to security and then you got it asingle checkbox that can create aconfidential GK cluster so any nodeswithin this cluster going to beconfidential as well or you can havespecific nodes which are confidential inan existing cluster so we give you thatflexibilityand as a way to sort of checkI can execute this command I'm logged inand it should say that the confidentialnodes are enabled as part of thiscluster so it's pretty straightforwardback to the slides pleaseoh can we get back to the slides pleaseokay greatso what's the next step in this journeywe've spent a lot of time with ourpartners particularly Intel inevaluating different platformsas intel was working on TDX trusteddomain X extensions which supportsconfidential computingorange teams collaborated with them veryclosely to uncover areas where we couldfurther strengthen the security of theirplatformand this is not just a Google thing webelieve in confidential Computing to ahigh degree and we want to make surethat these benefits are available notjust for Google Cloud customers but foreveryone that's using confidentialcomputingand so we worked with Intel closely wepublished this audit at RSA where weevaluated the system's uncovered flowsand we jointly fixed those flawsand we continue to work with them ontheir next generation ofHardware that supports confidentialComputing so we've been working withanil's Team over the past few yearsto make sure that we expand ourconfidential computing portsfoliosuch that if you have workloads that areoptimized for Intel CPUs then you canget that benefit of confidentialcomputingso we are very excited to announce thatconfidential VMS will soon be availablein private preview on the C3 machinefamily that uses the 4th gen Intel Xeonprocessors which is uh which alsosupports TDX or trusted domainextensionsnowof this is remote attestation which isthat customers will be able to verifythat they're actually in that isolatedenvironmentso you can sign up for this privatepreview right away and this is a firstIntel based confidential VM offering thefirst of many steps will take along theway to make sure that confidentialComputing is available to a much wideraudience across the worldnow the next topic we want to talk aboutis how we securely collaborate withmultiple untrusted parties and to talkabout that I want to invite you any onstagethis is fine be carefulthanks Sam uh awesome demos and greatprops I didn't bring any props with meunfortunately so I'll have to try apantomime or something like that but umsuper excited about the Intel TDXpreview that's upcoming and overallabout our fantastic collaboration withsuch amazing Partners like Intel andmore to come there for surebut now I would like to talk aboutdata collaboration without data sharingand Sam you should be asking me nowRenee what are you talking about how canyou collaborate on data without actuallysharing it rightbut I'll repeat data collaborationwithout data sharing specificallyand also actually retaining full datayou utility that is often lost ordiminished when various privacyenhancing Technologies are applied andhashing tokenizationEtcspecifically I'm talking about unlockingsecure multi-party collaboration forteams and organizations something thatwas Impractical in the past especiallyif we're talking about that highlysensitive data regulated data Phi PCIEtc and this is where even the corecapabilities and benefits ofconfidential Computing may not besufficient like the memory encryptionand CSP isolationand that's why exactly we buildconfidential space this is the productthat we announced last year at lastyear's next conference it was a virtualevent so not nearly as exciting as thisone with us being in person and theconfidential space really helps unlockthese scenarios like a securemulti-party collaborationwhat's confidential space provides itcreates a secure environment calledoften trusted execution environment or ate or secure Enclave and that's whereonly a trusted workload can access yoursensitive data and no one else even theoperator of the environment cannotaccess your dataand that unlocks some really cool usecases and I'm gonna show a few of thoseto you nextokay so let's start simple we have adata owner and we have data consumer anda data consumer wants to gain someinsights from data owners data dataconsumer also plays the role of theprocessing owner or the operator of theenvironment kind of makes sense theywant the inside so hence they should payfor the processingthe data ownerkeeps control over their data theydecide when and which workload throughCo through code authorship should beable to access their sensitive data okayso what could be an example actually ofone of those scenarios well think of ahealthcare institution like a hospitaland they have tons of that supersensitive Phi data and a data consumercould be a research institution and theywant to gain the insights right and eventhough you can see data consumer our ourresearch institutions also a processingowner it doesn't mean that they canaccess data in the clear they can onlygain access to the insightsokay let's move to the second scenariohere even the data owner moved to theright side if you can see thatum it's about ml model protection rightwe're all excited about the AIML andllms right this is my obligatory AImention of the presentationum and um so and there's a there arevalid reasons for that right and some ofthese models really take tens ofmillions of dollars to develop and trainso obviously this is a very valuableintellectual property for all thesecompanies that develop modelsso they they want to make their modelsavailable to their customers while stillretaining control over theirintellectual propertywhile data owners may want to consumethe model but they don't want to sharetheir sensitive data with the modeldeveloper rightso this flexible architecture actuallyallows the data owner to be also theprocessor and hence control and keeptheir data private process the data gainthe insights pay for that while themodel owner the owner of theirintellectual property can keep controlover their model so it's a truewin-win-win scenario hereokay let's move to the next one the lastone a little bit more elaborate securemulti-party collaboration scenario hereas you can see in this case both partiesare adding data to this Mutualcollaboration and both are gaining theinsights right and this can becompetitors imagine multiple Bankslooking for fraudulent activity orinsurance companies looking for doubledipping fraud detection right can bealso Telco retail can be ad tax for thatmatterall uh adding their data their sensitivedata and at the same time gettingguarantees that their data is onlyaccessible by this verified approved andaudited reproducible code that they haveall agreed upon and of course thiscollaboration is not limited to just twoparties this scales to multiple multipleparties and finally you may notice thatthe data collaborators don't have to bethe processing owner or the author ofthe processing logic either they canOutsource those activities to otherorganizations that specialize in themand at the same time while retainingthrough remote attestation full controlover their data and knowing which codeis authorized to access their data okaysowhat is this magical product thatsupports all of these scenarios and morewell again this is why we buildconfidential spacethis is the product we call it ourtrusted execution environment gcp is TEit's built on our very robustconfidential VM offering that's been outfor a number of years as Sam mentionedalready it supports complete lift andshift no code modification is requiredwhatsoeverum we alsosee that most of our customers don'tnotice any performance impact whenrunning in confidential modeand finally we provide full TCP IPnetworking stack for this environmentout of the box finally this is all builton Open Standards and open source codeensuring easy product interopa little bit more details on theconfidential space and how it's builtanother tenant we had in mind whenbuilding confidential space is usabilityso it's very easy to use and set up weprovide at a station verify service forour customers out of the box as Imentioned we run on top of confidentialVMS and that's where we also provideespecially hardened image that removesthings like SSH and that's done toremove the operator the admin of theenvironment from the trust boundary sothat's how we achieve the operatorisolation and then you run your regularcontainerized workload on top of thatand we also um provide an interface forcustomers to create a very simple policyand that's how they specify theconditions under which they are willingfor their sensitive data to be processedin the secure environmentand so overall it's all about ease ofuse Open Standards and super easydeploymentyeahso last time at next when we announcedconfidential space I showed you a funnydemo where multiple people imaginecolleagues or classmates want to learnwho makes more money without actuallyrevealing their actual salaries right soa little bit funny example but it getsto the point you can still find thisdemo on YouTube as part of last year'snext announcement but let's um look at adifferent demo this covers one of thescenarios that I actually described inthe prior slides specifically ml modelprotectionokay let's get this startedso here imagine that we have a hospitaland they want to use a cancer detectionml model provided by another entity ontheir x-rays or or CT scansso on the screen we have kind of a frontend at our Hospital build for their useof ml modeland and the developer of the modelallows the hospital to be to use theirmodel but only if it's in a trustedexecution environment that's properlyconfigured you know only after gettingsuccessful attestation guarantees thattell them that it is indeed running in asecure environment and the operator ofthe environment cannot exfiltrate theirdata this wayumso now the hospital will select thatsuper sensitive Phi data they want toanalyzeand then they'll click the analyzebuttonit looks like actually the sensitivedata is me riding a bike in a supersecret Google office okay well let'sclick the analyze and what do we seewell we have an error failed to accessthe protected model please check your tedeployment configuration what happenedhere so it looks like there's some issuewith the te configuration itself let'sfirst look at what the model ownerrequired from the hospitalhow this T should be configured okay solet's look at the requirements lookslike our model owner wants the theirmodel to be used in Te confidentialspace with secure boot enabled onspecial type of confidential Computinghardware and even using this specificimage hash to be running in the te andwhere these conditions submit by ourhospital and their te let's look at thelive te measurements coming from thestressed execution environment and itlooks like the answer is nowe don't have confidential space comingfrom our software name secure boot seemto be disabledso what happened here well it looks likethe hospital misconfigured their te itlooks like they forgot to enable asecure boot which is one of the manyprerequisites for confidential spacebut now hospital will fix their issue wejust switch to another tab where thehospitals spun up another confidentialspace te hopefully it's configuredcorrectly now so let's look again at thelive te measurementsand now we have confidential space greatwe have secure boot enabled true perfectand now let's even look at the hashthat's running so a model owner requiredthis hash and it looks like it matchesexactly what we have in this teaso perfect now the hospital can retrythis model inference and inference ofthis super sensitive and secret image weclick analyze button and the inferencewill now runlet's see what it comes up withokay inference results are in it lookslike the model can use some tuningbecause I don't think it was a BicycleBuilt for Two or certainly not atricycle but that's besides the pointrightum so basically what we wanted todemonstrate here is the ability for amodel developer to secure share theirmodel with anybody but if and only ifit's running in a specific secureenvironment making sure that they keeptheir intellectual property intact whilethe users can keep their sensitive dataintact as wellOkay sohopefully that was clear if not don'tworry we have plenty of amazing codeLabs on our website that give youliterally step-by-step instructions onhow to reproduce this and many otherexamples with confidential spaceokay so let's summarizeconfidential spacepushes confidential Computing Beyond itscore value propositions and benefitssuch as memory encryption CSP isolationand unlocks these amazing multi-partycollaboration use cases across teams andorganizationslet's enabled through a number of thesekey attributes on the slide basicallyeverything is measured and attested tobefore customers share their data youkeep control over your data you knowwhat what code will access your data andwhen and you don't need to trust theoperator eithereither okay here we'll move to the lastpart of our presentation and I'll inviteChristina from the Privacy sandbox teamand that's the team that uses privacyenhancing Technologies like confidentialComputing powered trusted executionenvironments to make a web even moresafe and private Christina please takeit awaythanksthank you so muchum hi I'm Christina lavento I'm theproduct lead for measurement in thePrivacy sandbox which is a collaborativeeffort across Chrome and Android to keeppeople's activity private across a freeand open internetum I really don't think it's anysurprise to this audience that consumersregulators and businesses expectationsaround privacy are evolving and theserapid changes in the Privacy landscapehave prompted businesses to think aboutthe long-term durability and viabilityof their products and over the pastseveral years that we've been working onthe Privacy sandbox effort it's beengreat to see the level of Engagementfrom the ecosystem in privacy enhancingTechnologies the challenge of course isthat the digital ecosystem has evolvedover the past 20 plus years to rely onthird-party cookies and other persistentidentifiers to profile users and trackthem as they move across the weband mobile appsso for example today a third-partycookie might be used to identify aperson who has previously interactedwith a brand or Advertiser website tolater show them an ad for that Brand'snewest product or their newest releasewhen that person sees the ad this eventis sent back to the ad Tech with apersistent identifier possibly from athird party cookie and later on if thatuser makes a purchase or visits theBrand's website that purchase event orwebsite visit is again sent back to thead Tech with that same identifier whichallows the ad Tech to match up theseevents and and track the user so when wethink about tasks like measuring theperformance of an ad campaign this makesa lot of sense from a technicalperspective sending out events withpersistent identifiers as a key makes itvery easy to match and post-process thisinformation laterbut the problem is that all of aperson's activity across many differentsites or apps can be linked in this waywhich leads to many privacy challengesso given these risks it's our view thatthese persistent identifiers whetherit's third party cookie or some otheralternative identifier like an IPaddress present a privacy risk thatoutweighs their benefits to theecosystem now that being said justbluntly or removing or blocking theseTechnologies without providing areasonable alternative for ways todeliver relevant advertising and measureits performance could reduce access toinformation or disrupt the services thatwe all enjoy as part of the openinterneteven worse it could result in moreopaque tracking workarounds that areeven harder for consumers to observe orcontrolso our aim with a privacy sandboxinitiative is to work collaborativelywith the ecosystem to develop newprivacy centered Technologies to supportthe open web without relying on thesepersistent identifiers and we have awide range of proposals new technologiesand privacy focused changes that we'vedeveloped including ways of addressingcovert tracking creating clearcross-site boundaries and also tools fordelivering relevant ads and measuringtheir performancenow how do we do thisspoiler alert there's going to be someconfidential computingso before I talked about how an ad Techmight choose an ad based on a user'spast interactions with a brand orAdvertiser and then measure how that howwell that ad campaign is working using athird-party cookie to link up theirbehavior across the ad view all the wayto visiting the Brand's websiteand then finally perhaps making apurchase now with our privacy sandboxproposals we actually take a verydifferent approach so instead of relyingon sending a persistent identifieroutside of the browser with each one ofthese events to be matched and processedlater we Instead try to do as much ofthat matching and processing on thedevice as possible so for example tomeasure conversion so if someone sees anad and then later makes a purchase thebrowser can actually match those eventson the device and then before sendingthat match back to an ad Tech thebrowser adds noise May randomly suppressthe reports or create entirely new fakereports to protect the user's privacyhowever there are many instances wherebeing able to extend our computationbeyond the device actually enables us toimprove system health or actually allowsus to open up new options for differentprivacy properties and better efficiencyin our Solutionsnow the challenge here is of course wecan't just extend beyond the devicewithout having a way for the browser tobe confident that there's no outsideaccess to the data that we're processingand also for the browser to certify thatthe code being used to process that dataoutside of the device is really the codewe intend to be using that it's actuallydoing the Privacy preserving analyzesthat that we wantso to do this we naturally turn toTechnologies like trusted executionenvironments and in the next couple ofslides I'll walk through two examples ofhow our proposals leverage trustedexecution environmentsall right so the first place that we usetrusted execution environments in thePrivacy sandbox is for aggregatingconversion reports across users thisallows us to take advantage of thePrivacy benefits of aggregation so thatwe can add less noise to the resultswhile still protecting each individual'sbrowsing data the aggregation serviceallows an ad Tech to collect encryptedreports from many different usersbrowsers not just one at a time and thenprocess them to learn noisy aggregatedinsights about campaign levelperformancebecause the service runs within atrusted execution environment thebrowser is also able to validate thatthe correct aggregation and noiseaddition steps are performed tosafeguard users privacyso let's walk through a typicalaggregation workflow for conversionmeasure so let's imagine that a user sawan ad in their browser for a given adcampaign and then later made a purchasethe browser will handle matching the adview to the conversion event on thedevice and then creates an aggregatablereport containing the Matched conversiondata like the purchase category andpurchase dollar amount as well asperhaps the ad campaign from the ad thatthe original the user originally sawthis report is then encrypted before itsent back to the ad Technow the ad tag collects theseaggregatable reports and assembles theminto batches for example maybe all ofthe conversions for a given Advertiseron a given day and then sends them tothe aggregation serviceand the only way that the ad Tech canactually analyze the contexts of thoseencrypted reports is to use theaggregation service which runs Anapproved version of the aggregationlogic in a trusted execution environmentso decryption keys will only be releasedto trusted execution environments thatare running an approved version of thataggregation logicum and so what this does is it makessure that the browser is able to confirmthat the right privacy preserving stepsare applied before those results arereleased back to the ad Tech in adecrypted form now measuring adperformance is a key use case forsupporting the open Internet it'simportant to know if your ads worked ornot and the scale of the problem that wehave to tackle is immense theaggregation service can process hundredsof millions of aggregatable reports inone job and by leveraging this trustedexecution environment we're able toexpand the types of noise and privacypreserving mechanisms that we use beyondwhat can be applied on device aloneI now see that my problem advancing theslides was pressing the laser pointersorry about that okay uh so let's let'stalk about um a second way that we usetrusted execution environments in thePrivacy sandbox and that's as part ofour relevance proposals and at the coreof our relevance proposals or proposalsfor delivering relevant ads ismaintaining control of a user's interestand browsing history on the device butrunning ad auctions with particularlysophisticated bidding and scoring Logicon the device may present a challengefor system health and scale in somecases so expanding computation beyondthe device can allow ad Tech providersto take advantage of more compute powerto identify more relevant ads withoutimpacting the device's system Health ourbidding and Auction Services proposaloutlines a way for client devices tooffload ad auction computation byallowing sellers to run a seller frontend and auction services and a trustedexecution environment and likewiseallowing buyers to run buyer front-endsand bidding services in a trustedexecution environment so let's walkthrough an exampleso let's say a person is using anAndroid app and that app has anavailable spot that they want to showand add to the user the app will send anad request to uh with an encryptionauction input to the seller's ad servicenow this request this encrypted requestwill contain both contextual informationmaybe like the category of the app andinformation about the user's interestslike inference interest groupinformation that's normally collectedand stored on the deviceum so then once the seller ad servicereceives this encrypted request it thencalls a seller front-end service toconduct the auction and it passes alongthat encrypted auction input the sellerfront end is running within a trustedexecution environment and then callsbuyer front-end to get bidsthe buyer front end runs bidding serverto get bidding logic to run biddinglogic in a protected environment andsends real-time signals from a trustedkey value service to actually generatethese bidsnow once the seller received bids fromvarious buyers it calls the auctionservice within a trust and executionenvironment to score the bids and selectthe winning ad before returning it backto the client now the selected ad alongwith the other URLs may be needed forreporting or billing are encrypted andcan be inspected only by the clientserviceso the key thing here is that theauction input can only be decrypted inthe trusted execution environments runby buyers or sellers which allowslegitimate buyers and sellers to usethis input to determine their bids anddetermine the auction outcome butprevents it from being shared OutsideThe Trusted execution environment soeven though the user's interest signalsleft the user's device by limitingaccess to verified code running within atrusted execution environment the clientdevice is able to offload resourceintensive auction computation withoutactually leaking any of those usersignals directly to the Valor buyer orseller in the auctionokay and this is quite different frommost systems today that actually rely onan externally available persistentidentifier which is logged and sharedand matched across buyers and sellersokay so now that you've seen an overviewof the privy sandbox I'll hand it backto Renee thank you so much for having meamazing amazing worker Christina and theteam are really hard work reallyimportant work and really cool use oftees right so thanks uh thanks Christinaand and in factum confidential space is one of thePrivacy supported tees and we alreadyhave a number of AD techs today testingprivacy sandbox on gcp and we lookforward to collaborating with many manymore attacks as the ads world ispreparing for this change plan change ofuh deprecation of third-party cookies sotoday let's wrap it up we packed a lotin this session we had live demos we hadprops we had recorded demos lots of lotsof work and lots of content but let'ssummarize it first Sam gave us an updateand the State of the Union ofconfidential Computing at gcp uh all theservices including dataflow and dataprerogator supported and how super supereasy it is to enable confidentialComputing as easy as clicking thatenable button that you can see at thetop left corner of your screen so giveit a try for your VMS for your gke andother gcp servicesand thenSam also gave us an update about theupcoming Intel TDX preview the latestand greatest in confidential Computingfrom Intel so scan the QR code if you'reinterested in the middle of the screenand sign up for the previewthen we also discussedconfidential space that unlocks thesecool use cases like ml model protectionsecure multi-party collaboration and somuch more there are many code labs anddocumentation on our website so checkthose out as well and then we heard fromChristina about the work of the Privacysandbox team that leverages tees to makethe internet even more private andsecureso I hope you enjoy the presentationyou'll learn something new you got somecool links"
}