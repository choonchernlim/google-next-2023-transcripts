{
    "title": "Run impact-less ad hoc queries and data exports on Cloud Spanner",
    "presentation_type": "Breakout",
    "categories": [
        "Database Professionals",
        "DBS209"
    ],
    "video_id": "SjSF5p3tQrk",
    "time": "Aug 30 05:30 PM - 06:15 PM CDT",
    "transcript": "[Music]with that my name is Joe Young I'm aproduct manager in a cloud spanner teamand I have several other speakers withme uh NRA metal is our senior softwareengineering manager she's one of thepeople who work the magic behind whatspanner can do I also have Marcuslinebach our chief technologist and itlead for clout online banking fromDeutsche Bank and of course we have theillustrious MV Adrian founder andprincipal analyst from it Marketstrategy you may have known him fromanother very popular place that knows alot about itindustry now real quick this is ouragenda I'm not going through the bulletseverybody can read here but I do want toset the stage on how we're going to gothrough this by stating why we're heretoday this architecture diagram or thishighlight LEL architecture diagram hasspanner in the middle but this is verycommon for almost any databaseapplication out there where you haveyour key oltp application yourtransactional application that's yourmost important piece talking to yourdatabase it goes to a backend processingengine of some sort it goes to storageand gets data back for you and youprobably have a bunch of other workloadsthat could be analytical reports ETLpushing data out for compliance reasonsand whatnot you probably also want tofeed data to your wonderful AI models sothey actually have useful data andsensible uh relevant data as you trainthese models up so they can give yougreat answers so this is the stage wherewe're looking at most of you who arehere are probably quite familiar withthis layout you may have some variationsbut we're going to get started withlooking at how this works and Marcus isgoing to come up here and describe howDeutsche Bank has actually taken thisand modernize their environment and whatthey look forward to uh coming from dataBoos in the future Marcusthank you Joey so first of all let usget started and looking into what we aredoing in the German banking industry andhow we're present there right soDeutsche is present with two distinctBRS in the German market so we're havingpost bank first which is serving the wecall it daily banking activities rightso you're classical you're making atransaction you're going to an ATM oryou're doing basic investmentfunctionalities like buying a stockselling a stock on the other hand wehave Deutsche Bank which is focusingmore on the advisory part complexFinancial products to serve you withtogether they're present in over athousand branches within Germany what iscompared to the size of our country alot so but let's dive into the technicalhistory of those two PRS right and joinme in 2020 we sat down and looked intothe IT environment setup of both Brandsand they were completely separated theyhad separated environment no synergies Ithink a classical setup for many largecorporations and if I say environments Imean data centers so both operated theirown datacenters what is normally happening insuch a situation for large corporationsthose corporations go there and thinkokay which is the better system whichone do I want to migrate on to and thenyou go on a journey you focus on yourmigration to get rid of one and focus onthis on the second probably after twomaybe three years you will finish yourjourney you've done your migrationwhat's next oh you focused on migrationlet's start with the tech refresh rightso back in 2020 we had been in theluxury situation of kickstarting ourGoogle journey together the partnershipand what we said is let's do thisproperly let's build up a third platformfrom scratch Cloud native where we'llput our customer data on and that wewill serve our customers from we calledthat the customer interactionplatform and the fact that I'm heretoday shows that it has worked out andtoday we're serving postbank customersfrom a completely Cloud native platformleveraging over 50 Google Cloud nativeservices this is where we are today asyou can see there there's a road whatwe're following on but let's first ofall let's dive a little bit into onlinebanking as a productitselfso I said customer interaction platformplatform because it's the single pointof contact for the digital channelseither if you're coming from a mobileapplication of us if you're coming froma third party that is aggregating youraccount statements or classically goingto our web page all of those are beingserved over that one platform platformimportant to say that platform is notlimited for example to our retailcustomers it serves all kinds ofcustomers the small vaa customer ourprivate accounts but also corporateaccounts now I mentioned we have Mcreated postbank let's get a little bitinto numbers right and over thosepostbank customers more than fivemillion have activated online bankingthey're representing today more than 16million transactions aday and something I'm personally reallyproud about is if we're looking at onpremise system regulated Industries wehave a lot of applications who arerunning quarterly releaseCycles we have brought that down to abi-weekly align to our Sprint Cyclesrelease cycle as part of the migrationyou can imagine we had some morereleases going on so already we're above300 releases on that platform and thatis for the teams for us that's animportant number now let's dive a littlebit into the requirements such aplatform has and if you're looking atthis if you're looking at this the firstthing that comes to your mind as acustomer is your financial overviewright what are you using for your bankwhat is the most important topic for youdo I have money on my account how muchdo I have is to rent has to rent goneout stuff like that if you think aboutwhat it comes from a requirement perspperspective you're talking aboutavailability you're talking about rightaccurate data that you expect from abank this iskey on another example in Europe we havesomething called instant payment thatmeans we have milliseconds if you do atransaction that needs to arrive at theother bank get deposited there and getdeducted from your account we're talkingmilliseconds what is the first reactionyou do after such a transaction forexample you paid for your car you go toyour financial overview and you want tosee that those money left your bankaccount right looking at this we callthat a critical workload in our bank andfor this we paired up withspenner now let's look a little bit intothe requirements towards spenner and thegreat team behind what they did I'm notgoing through all of them no worries letme focus on two that are the mostimportant for us let's talk about theavailability I just mentioned we'reoperating spenner in a multi- regionsetup and that gives us five nin ofavailability if you're into availabilitydiscussion you mean you understand whatit means to have that Baseline ofavailability guaranteed by Google that'sa key feature for us to serve ourcustomers with the to meet theirexpectations on the second hand Imentioned performance right and Imentioned those 16 million transactionswhat I did not mention is that some someof those customers are handing in300,000 transaction in onego just imagine One customer having300,000 transactions processed and inthe same point in time you want to payyour car that you just bought would yoube willing to wait until thattransaction comes up you're probablystanding in front of the dealer like Imade that payment it better comes up sothis is what we're using spenner for andI'm actually quite happy with theperformance and everything we sawespecially with the great team behindspenner and the the product managementfrom Google and all the colleagues we'reworking on the ground with fromGoogle something I do like to talk aboutis Conantenhancements as a bank we're coming fromalegacy and probably all of you are awareof that product where you had versionsix and the project you upgrade wasdelayed and then you couldn't and youstick to that version or there was nomajor version coming and then you're inthe situation of being incompliant so weare really Keen to work with productswhere we see the owners of thoseproducts are actually pushing forwardand bringing enhancement and developmentin one topic I would like to talk nowabout is scaling exactly to say out toscaling so I mentioned that we M createdpost Bank onto our newplatform this was actually the biggestbanking mationever done in Europe inhistory so we're talking numbers andwe're talking requirements where weactually shut down the bank so forcustomers during that we call it cutover weekend they couldn't reach thebank they couldn't transfer money theycouldn't get access to the bankstatement and they couldn't come into abranch and make something because weliterally migrated everything fromFinance over the CRM we migratedeverythingand when you think about that fact youwant to have that as short as possiblefor your customers right so what comesto your mind first is let's scale ourinfrastructure right how can we increasethe processing time and I remember thatmoment when we did the analysis and lookwhat it mean so there were databaseswhere we thought okay we need to doublethem that's something we've seen in ouron premis state as well doublinginfrastructure we looked at some ofthose databases and we talked 13 timesthe scale we needed for a short periodof time now there's only a limitedamount of manual scaling you want todo and then we reached out to Google andsaid hey how do we do this and Googleactually came back to us and said oh oneengineer did something it's on GitHubit's open source let's look into thatjointly and one of our really passionatelead Engineers took that baby I wouldsay to him and run a PC together withGoogle and we do call this productionready if something can go to productionif we tested it through outly and knowthat it's suitable of running ourproduction load as part of thisproduction ready State there wereenhancements made and there was thatpoint when he came back to me and saidMarcus can I roll it out yourproduction and I waslike are you comfortable with it and hesaid I'm comfortable with it Google itlet's do it actually there will be ablog post about this published by Googleand deut pretty soon because we reallybelieve in this to be an importantpartnership piece and we're proud of itto show it and we gave it back to theopen source community so you can run onthe same out of scaling than we to runwith our whole environments death U andproduction so key point for us andshowing the partnership that Google isinterestedin now let me quickly touch Bas back onthe point point I gave to you from aroad mapperspective because obviously buildingup a platform means owning it anddevelopment it further right and you'veseen that we're with post Bank live nowwe're looking at our second stageDeutsche Bank you can imagine thosecustomers and wealth managementcustomers having 14 different accountsdifferent currencies they're demandingright so we want to do this right andthis is the journey we're on because webelieve in theplatform something we talked a lot onthis conference is AI right what is theBaseline for AI it's data now having allof that customer data online related ona data platform is key for us andenabling us for new products newfeatures every new feature developmentthat we do is done on that new platformfully Cloud featured by Google obviouslysomething I'm personally looking forwardto is talking about other Legacy systemsin the bank but this is the journey youembark on to and we're here after 3 and1/2years now let us look at one situationwe're here for data boost right so youunderstand that information inproduction is very interesting it's atransaction data of the people they'redoing in combination with somethingreally important for us the fraud databehind it because if you want to make atransaction in online banking you needto have a second Factor approval to letthat transaction go through right I haveboth that data in my productionenvironment on Google Cloud now I wouldlike to use that right what weclassically did is we copy over thatdata at night when not that much trafficis on to a data warehouse and then daysor even weeks later you analyze it rightthis is where we want to move away fromand for that case we're highlyinterested in using our production datato analyze it on the go and to performdecisions for fraud detection on thatbut without going further into that databoost topic I would actually hand itover to the right person to do that Joyback to you for the explanation of databoost thanksMarcus so going back to the slide thatwe started with so this is the contextwhether you followed the journey thatDeutsche Bank and Marcus let team didwhere they modernized by merging systemsfrom on Prem and moving them onto thecloud or you already have it sitting inthe cloud the the same scenario existsyou have your most CR latency sensitivetransactional systems and then you haveall of these other really interestingthings and again I I kind of joke alittle bit about the AI part but thereality is your AI models aren'tterribly useful if they're not trainedwith relevant data and those of you whoactually have deployed ml models inproduction today give me a show of handsthat you actually have a regularlyscheduled retraining of thosemodels how many of you donot okay a couple hon people here verygood so what happens when you need torun these kinds of workloads and whathappens when you need to run analyticswhat happens when some I don't knowcolleague attended a conference you knowlet's call it some other Tech conferenceand they learn how to write squel andthey learn how to write a join and theyhave access to two tables that are abouta trillion rows each and they decide I'mgoing to run that in your in myproduction system because I want to getsmarter decisions anybody experiencethat in your production environment onlya handful yall are lucky so I used tolive the DBA life and I I gave that upbecause I didn't like my payer going offat 3: in the morning anymore of coursenow we're all in devop so my payer goesback on again 3:00 in themorning we looked at that hard in Googleand we decided that you know whattraditional approaches help but theydon't really solve the problems you canmove data using ETL to a separate systembut eventually your ETL becomes anotherheavy load against your system you canalso create replicas but that hasadditional costs and guess what replicasrequire data movement and you pay a costyou can have resource Governors butthese things also have limitations thereyou have to make a decision when anexpensive query or high priority querycomes in which query that is lowerpriority will you kick out of the systemwhich one will you terminate those arenon-trivial decisions because kicking adatabase quy out doesn't mean that youcan run it back in the next second itmay actually take you hours of work toget it back to where it was so wefigured that's probably not a very goodapproach and that's where data boostcomes in where if you notice the colorsof the arrows have changed your transtransactional workloads continue to runagainst your original provision spannerinstance that just works nothing changesbut just by doing two things you grantan I am permission that's on thesecurity control site and you add oneconfiguration parameter to yourconnection string or to your connectionobject literally just these two thingsone security setting and one optionalparameter you add to your connectionstring spanner will know that thesequeries that have these two criteria metwill be automatically rerouted tocompletely isolated compute resources asyou can see in a diagram they'recompletely separate the computeresources are isolated and these aremanaged by Google you don't have toworry about provisioning sizing andwhatsoever they're always hot they arealways sitting there waiting for coriesthis is not scaling up or down this isalways sitting there waiting for coriesto come through as soon as they come inthere's no latency we service that Coryimmediately we go into Colossus storageand this is another advantage of spannerbecause our computer and storage isdisaggregated this is our architecturefrom day one we are able to look intothe actual physical blocks on dis thereare the exact same blocks as youroriginal spanner instance there's noreplicas here you don't pay for copiesof storage there's no latency involvedin terms of oh let me go create a blockof this so I can read off that all ofthis stuff hits you live no Cory latencywe process that get the data back thatwe need do a quick check with thespanner your provision spanner instanceto make sure nothing in memory needs tobe carried over and we send it back tothe client so that way you can literallygo run that big joint with these twotrillion row tables and nobody on thespanner side would even blink and thisis really really hard to do if you don'thave the same architecture and the sametechnology underlying spanner that wehave in today in Googlethe one and I should say this and I knowthis is engineering crowd but one thingis important here uh this is also a payfor the actual quy consumption in termsof Computer Resources so this is notsomething where you over provision andyou sit there it's 80% idle and you getreally busy 20% of the time so I knowEngineers are thinking well what do Icare about pay for you know consumptionit's budget somebody else manages thatbut hey imagine right if you save a lotof money for the company maybe it goesback into your bonus or at least thepartyfund now we talked about quite a few ofthe benefits here I'm not going to gothrough each of these in detail theyshould be quite obvious but one thing Ido want to call out the last Point hereit does reduce data sprawl because youneed to make fewer copies of your datadirect Federated queries against yourproduction instance becomes feasiblebecomes very practical your pagerdoesn't go up at 3:00 in the morninganymore just because somebody got off ofa conference party and decided to startrunning queries against a productioninstance that never happens to any ofyou I'm sure but that's happened to mein previous life literally people getout of a conference after the party anddecided that yeah I only had four drinksyou know at least that I remember let mego see what's going on in in ourfinancialsystems one of the things that's reallycool about this is we tested this youknow we went through in queries andfigured that oh let's go try that reallyexpensive queries that our friendlyanalyst run on the left side here youwill see that this is the actual queryrun on a production instance of spannerand you see the CPU Spike and it staysup there for quite a while those withreally good Vision you'll notice thatsome of the spikes actually stay upthere this is CPU running up there forover several minutes on the right sidethe only thing we did Grant permissionsenable that connection string parameterand you don't see the CPU jump anymoreno code change no schema change it justworks and of course because we arerunning on completely separate computewe are also able to make more aggressivedecisions about parallelization abouthow we want to execute and optimize thequery we don't have to worry aboutimpacting other workloads so this isanother Advantage this is a very modest8X performance gain we've seen as muchas 100x per gains of course sometimes wesee as little as no gains zero literallyso it really depends on your workloadand the kind of quaries that you'rerunning no amount of Hardware will solvereally really bad quaries we'll make itbetter but we can't really solve badqueries this is just an example of someof the workloads are supported on thebottom right right corner you see wealready have a bunch of isv supportingit today even though we literally justannounced the product they were soexcited they decided you know what we'regoing to get this working even before ugnow all this talk is easy I only haveslides so my colleague nerra is going tocome up here and show you live demo ofhow this actually works so this this islive so everybody you know just sendgood thoughts to her and make sure thedemo gods are working in her favor so nthank[Applause]you thank you Jill this is superexciting hi everybody I am NRA and Ihave the awesome job of presenting thepower of datab boost to you all so let'sgetstarted so in this ever evolving DigitalWorld gaming is an important experiencein which gamers are spread throughoutthe world yet connected an integral partof this experience is the game Tech thatFosters Innovation and transformation byenabling low latency experiences forgamers in irrespective of their locationirrespective of where they are connectedfrom so in this demonstration I'll beusing an online multiplayer gamingscenario in which the gamers are goingto exchange merchandise they're going toacquire items they're going to lootitems during a session they're going touse Virtual currency to buy items thegamers are super excited getting readyfor their next battle acquiring the nextweapon they're looking forward toacquiring the next Avatar customizingits appearance so we can see that thisrequires slow lencyexperiences with transactionalconsistency at horizontal scale so thisis where we use cloud spanner as abackend as the operationaldatabase now while all this is happeningwe have the gaming analysts who want toanalyze this data they want to slice anddice the transactions they want to seewhat's happening what merchandise isbeing exchanged in these weekend longlong gaming marathons so the way thishas been done typically in the past iseither by overpro visioning theoperational database to avoid impactingthe realtime transactional workload ormaybe by creating copies of data inreplicas read only replicas or maybe bymoving the data out from the operationaldatabase to analytical Warehouse therebycreating staleness in the pipeline andthis is where steps in data boost as mycolleague Joe explained data boostharnesses the power of cloud spannersdisaggregated compute and storagearchitecture to enable large scaleanalytics on operational data withisolation no impact to yourtransactional workloads so with thatlet's get started let's switch to thedemoand while we start against all s adviceI am feeling a little bit courageous andI'll try to do a live demo so let mekick off this query and I'll explainwhat it does as we go through thefloor so we can see that this is a gamedata boost enabled query this is on adata boost enabled connection I'll walkthrough the flow as we go through it sothis is my cloud spanner backenddatabase instance unicorn game instanceon on which I have a demo game databaseI will walk through the schema of thedatabase this is a typical online gamingsetup where we have the players who areparticipating in the online gamingsessions the player acquires item lootmerchandise we maintain their Ledger wemaintain the tradeorders so now with this let me try toanalyze this data as an analyst throughbigquery so to analyze this data from Bigquery I'll create Federated queryconnections from Big query to my cloudspanner backend instance this is thefirst connection data boost disabledconnection as we can see in this useddatab boost is set to FSE usedparallelism is set to true to harnessthe power of batch queries and this ison the same unicorn game instance anddemo game database that we just saw nowI'll create another inst anotherconnection which is exactly similar thisis again an external query connectionthis is a data boost enabled connectionwe can see that the used data boost isset to true in this one and usedparallelism is also set to true toharness the power of batch queries againit's on the same unicorn game instanceand demo game database so now with thislet me try to run some analyticalqueries and see the results basically sothis is a query as an analyst I'mrunning where I am trying to analyze theplayers who run High value transactionsget some statistics on their list pricethe number of transactions they took toachieve that so we can see that I ranthis query at around 2:45 p.m. it ranroughly for for a period of around 11minutes and ended at 256 p.m. so nowlet's look at the demo game databaseinstance CPU load at that point and wecan see that the CPU spiked to roughlyaround40% now imagine a scenario where youhave millions of Gamers spreadthroughout the world doing thesetransactions in real time you havehundreds of analysts analyzing this dataand the kind of load that's going to puton the operational database so now let'stry this query through a data boostenabled connection so this is the querythat I just ran at the beginning of thedemonstration this is the data boostenabled query and voila we have theresults here already this was a10-minute query on a data boo disabledconnection and out here we can see it'sthe same query that ran at 3:55 p.m. fora period of roughly around 1 minute andif I go to the same uh CPU Spike thereand trying to see if there's any CPUimpact there's nothing we can see ataround that point of time so there is noimpact on the operational database as Iran this query thereby proving the powerof isolation of data boost and anotherimportant thing to note here is thisquery ran in 1 minute whereas the databoost disabled query ran in 11 minutesso this query got a perf gain of 10x bymoving to databoost now I'll try to play the role ofan analyst who wants to do slightly morecomplexanalysis so for that I'll move on to myJupiter notebooks I want to do a cohortanalysis now so as we all know when wewant to do slightly more complexanalysisdoing that in declarative SQL is alittle bit painstaking so I will move onto imperative python in my Jupiternotebook and by moving to python alsocomes the power of using analyticalFrameworks we can use spark so for thisdemo I have used spark as we can see Ihave loaded the spark connector to mybackend database here and this is thesame unicorn game instance database thesame demo game and the enabled dat boostis set to true I'm also going to use ananalytical Frameworks like ppar andpandas to demonstrate the power of easeof using them in this demo so for that Ihave some utility functions and we cansee that basically for cohort analysisutility functions I have used pypar Ihave also used pandas for thisanalysis so movingfurther I load my data and this is alarge scale analytical query that I runbasically we can see that this query ranat around 126 p.m. today it ran roughlyfor around 8 minutes it scanned 4billionrecords moving to on to my metricsExplorer again on the same demo gamedatabase instance and when we can seethe when this large query ran the loadon my operational instance was only 0.6%thereby approving the power of databoost basically you can make large scaleanalytical queries and it will notimpact your transactional workloads andthese are the results of my cohortanalysis for this cohort analysis Idivided the players into group of threecohorts and measured their retentionalong the weeks as the gaming sessionprogressed so for the first week we see53% of the players remained in thesecond week 9% in the uh basically weekafter that and 9% uh further down 9% inthe last week and then we have theretention of players across the othertwo weeks so the nut nutshell in anutshell we can see with this demo thatusing data boost it's you get trueisolation for your transactionalworkloads you get the benefit ofperformance depending upon your queryshapes and how easy and simple it is touse data boost you can use it from Bigquery you can use it from analyticalFrameworks like spar you can use it fromdata processing applications like dataflow you can use it from clientapplications and it'll give the abilityto run large scale ad hoc analysis withtrue isolation so thank you all withthis I'll hand over to M who's going totalk to us about what data boost meansfor Next Generation datamanagement thank you am I on yeah okaysocan I have the slides all right so someof you have the luxury of being able togo to whoever writes the checks for thehardware and software you use and showthem a demo like that and have themunderstand of it most of us don't and sothey bring in people like me industryanalysts who say well what what does allthis mean to you um that's my theme hereit's the bigger picture how does thisstuff fit in we're talking about thenext generation of data managementpreparation meets opportunity andtransforms how you do what you do whatit costs you to get it done what kind ofresults youhave so consider the basics you know Joelaid this out very nicely it would benice to have unlimited data scale veryfew of us can assert that we have thatbut you know the way that managementsees this is I'm in the cloud rightisn't that why I went there I've gotunlimited data scale um yeah of coursecosts may be unlimited too and they'reless eager to hear that story so to thepoint of should I make multiple replicasof this in order to get the performanceI want um yeah that sounds great untilyou have to write thecheck similarly I have unlimited computescale don't I up in the cloud yes but doI have access to it and even if I haveit is the storage of this systemprepared to handle multiple differenthighlevel compute loads being thrown atit at the same time that's what we callworkload management most systems do notdo this gracefullytoday so if we turn people loose andonly drive our plans on the basis ofwhat we think we need and the assumptionthat we can do anything we want in thecloud we're going to have a rather largecurve of costsbut we're also going to have to dealwith securityissues and we're going to have a greatdeal of semantic confusion becausedifferent people looking at the samedata may think it means entirelydifferent things so we need to be ableto manage this in a uniform governedway in order to move to a a world that'sas happy as the one you justsaw we need to handle a number of thingsand all of these things need to behandled in the cont text of today'senvironments which have you can think ofit as a ceiling we can push this so farrightso whatever we deploy needs to beintelligent it needs to know how to usethe available resources it needs tobe observabilityenabled so that if I can put insomething that manages the operation ofthis system and doesn't require me towake Joe up at 3: in the morning byringing his pager I have to haveobservability on this system this systemhas to be self-reporting and it has tosend those reports to something that cando something about what it'slearning that's governance the systemhas to be governed and it doesn't justmean I know lineage it doesn't just meanI know the users and what they'reallowed to do means the operation of thesystem itself needs to beI have a ceiling if I've got 40% of myCPU being utilized and you need to payfor your car as Marcus described youdon't want to wait while those otherjobs run and so I'd like to have thatunlimited scale I want that scale to bethere when I need it and I don't want tohave to stop to make it available orPaige Joe to make it available for meright I want that to be autonomous Iwant the system to take what it it needsto meet my requirements when the systemneeds them and I need all of this to beintegrated I don't want this this tohappen in four different consoles Idon't want multiple players who have toset this up I'd like to set twoparameters and just have it run the wayyou saw earlier in fact you know in aperfect world I'd like not to have toset those parameters oh let the systemdo it but I know you're getting to thatum and finally what I want is for thatoperating system then to be optimizedfor me not just in terms of itsperformance but also in terms of how Ipay for it when I pay for it evenwhether I pay for it I don't want to payfor what I'm not using and that's whatoverr provisioning is all about right soI like to say to people if necessity isthe mother's of is the mother ofinvention choices are its children whenI build systems out of necessity I haveto make a lot of choices and some ofthem are very uncomfortable and until now the choice ofcan I scale the way we're talking aboutwas a simple one let's spend a wholebunch of money and buy a lot of capacitythat most of the time is going to gounused that's not an acceptable answerthat's not the choice we want to makewe've got a ceiling we don't want tohave to figure out how to live within itsotoday at the end of let's call it thefirst era of cloud data management as wemove into the next we have a lot ofthose choices to make how many of us howmany of you guys thought when we moveedto the cloud everything would be simplein terms of configuration and yeah thankyou Marcus you know better um ever seehow many instance types thereare I I you know I don't consider thatparticularly simple um it gives uschoices though and those choices areimportant when I need a certain thing Iwant an instance that'll do it for meideally though if I have the autonomyI'm talking about the system will dothat for me in fact it'll because it'sobservability enabled look at theworkload and it'll say well what thisthing needs is some tpus I'm running amodel let's give it the right kind ofprocessor to run that model on um whatother kinds of choices well what formatdo I want the data to bein do I accept the one it's already incan I operate against that format or doI need to make another copy of itsomewhere else in a more optimized formto run it that way I have a very simplerule for copies of data you should haveas many copies of the data as youneed and not onemore so the system will tell you howmany copies you need if it can handle itin the formats it it's already in butyou may have other reasons that drivethat choice it might be the languageyou're using the fact that it's a legacysystem that can easily be changed wellthere's more choices here but I don'tknow how much time we have left Joe I'mI'm I'm going to try to be I'm going tobe R tried oh I got six minutes I didn'tsee I had a clock there thank you allright so let's talk about one or twomore of them because they'reimportant what about the cost of movingdata around the system import exportokay duplication refresh in a systemthat has massive amounts of data like agaming system um how much do I careabout the behavior of the users 6 monthsago or the behavior of the users 3months ago or the behavior of the usersyesterday in the in the scenario thatyou saw demonstrated what I really wantto know is what users are doing rightnow and maybe what they've been doingfor the last 24 hours but most of thathistorical understanding is probablyembedded in some kind of a model thatI'm using to make decisions and choicesand then last and perhaps mostimportant yes we're in the cloud yes wehave capacity for data yes we havecapacity for compute but we also havemixed workloads we got transactionsgoing on at the same time as analyticsand is it really that simple we're inthe cloud so we can do it now no it'snot we need a system that caneffectivelyleverage the capabilities that the cloudprovides us to run mixedworkloads even if the ceiling isgoneso when I say we're moving from one earof the cloud we are in fact doing justthat because with this sort ofautonomous autonomous sorryintelligentself-configuring observability enabledkind of a system we can quote one of myfavorite Paul Simon songs one man'sceiling is another man'sfloor we can start wherever we want andwe can go as high as we need to gobecause the system will gracefully do doit for us um this isnew this is very new as an industryanalyst I've been following workloadmanagement enabled database systems fora very very long time they all work withceilings and they all work by swapping alittle bit of work out of this workloadfor that other workload in order to tryto do as graceful a job of degradingperformance when something else entersthe room as they can this is differentit's a floor now we can start whereverwe want and we can get to wherever wewant on the basis of a system that knowshow to do it for us automatically it'svery exciting and I'm very happy to behere to talk to you about it Joe back to[Applause]you thank you and you want uh no we'regood I think we you can hang on just forjust one minute we literally have ourlast slide and we get one our Q&A sofolks who have questions feel free to uhgather around the microphone but reallyjust a quick summary of what we'vecovered I know we walk through a lot ofdifferent concepts really quickly butthe whole idea is regardless of whereyou're at today or how you got to thecloud or you're just starting out in thecloud uh this is actually a provenapproach and there are a lot of folks inthe Google Cloud world that can help youthere and make sure you learn from ourexperiences make learn from folks likeMarcus experiences and don't have tostumble through on your own the otherthing really is and I'm not going to gothrough all of these details but the keytakeaway here is you don't have to worryabout sharing data broadly just becausesomebody might run a workload that willwake you up in the morning I joke aboutthe 3:00 a.m. pager calls but thosearen't the worst because I I get to do alot of things at 3:00 a.m. I'm usuallyup anyway the worst are the ones thathappen at 10:00 on a Monday morningbecause that's when things are reallyreally busy and somebody decides to gorun that trillin row table joint that'swhen you really don't want the page togo off so with data boo we believe we'vemade that possible but I invite you totry and either uh prove it for yourselfor if it didn't work for you let us knowwe want to know what it is and we willfix that thank you very much for hangingaround and listening to us if you havequestions we'll be hanging out rightoutside here thank[Applause][Music]you"
}