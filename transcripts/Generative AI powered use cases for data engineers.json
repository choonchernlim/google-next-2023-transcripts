{
    "title": "Generative AI powered use cases for data engineers",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA111"
    ],
    "video_id": "T0YoctXuSTw",
    "time": "Aug 29 03:30 PM - 04:15 PM CDT",
    "transcript": "foreign[Music]it's great to be everyone here my nameis Jason Davenport I am a developeradvocate so today we're going to cover afew things first off we will talk aboutgenerative AI all the cool things thatyou can do with it but more importantlyhow do we actually create those rubricsof things that we want to do and getthat value from from Ai and all thethings with it next to talk about someof the different tools that we'verecently announced here at Google Cloudfor doing different things in generativeAI and then last we'll actually pulltogether and we'll do a couple shortdemos using some of our AI products hereactually in the console and and see someof the cool things that you canhopefully go and unlock after we're donewith the session todayand I also leave plenty of time for a qa here for folks who are interested inthat as wellall rightAI it's really it's the thing that's TheFad that will disappear in six months nojust kiddingumwe could only hope right and we couldjust go back to ml and stats and all thethe fun things that are the foundationsnow if you think about you know wherewe've where we've come you knowespecially in 2023 with the Advent ofall these large language modelsyou know the thing here that we'realways trying to think about as weintroduce new technologies and changesis how do we get three things reallyreally accomplished first how do wethink about how we can do more with thesame or less you know everyone here hashas hundreds of things that we're tryingto do and we're always trying to unlockand figure out ways to do things moreefficiently do it better do it withhigher qualitynext how do we actually innovate so inthis case how do we do things that wehaven't done before you know whetherthat's novel to us novel to ourorganizations or maybe novel to societyand all those practicesand third and I think this is you knowone of the more interesting things withwith all this new technology is how dowe actually think about differentiationso you're doing things like what arewhat are different Industries to go intowhat are different things from my ownskill set that I wasn't able to dobefore how can I do those things and dothose those well and effectively inthose processeshowever we have this this this newpillar which is incredibly importantwith with olms and AI in general whichis how do we do this securely and atscale because what we don't want to seeis uh someone goes to Bard and plugs ina question and they understand thatJason Davenport lives in Denver Coloradoimmediately that would obviously be verybadyou know none of us here I think arealone in this journeyum we did a survey 91 of organizationsare are actually trying to increase allthese Investmentsum but really if we think about you knowtensions and things that are comingagainst thisyeah only 20 percent of organizationsare actually realizing use cases and andreally then the question isyou know as as analysts as scientists asEngineers how do we close this value Gapbecause if we have 91 percent of of ourcompanies trying to do these things butwe're only deploying 20well that's obviously a very lowrealized realized rate of of gettingvalue from all these different modelsinterestinglyum five years ago I think this wasalmost the same for base ML and so thequestion is really how do we unlock someof those Trends and really get thatvalue you know moving forwardI love these things because when westart talking about trillions of dollarsit becomes immediately immaterial to allof us in the roomumI know trillions right it's it's crazy Ithink here you know as we see more andmore of these statistics about new usecases and productivity and all thatthe question that comes to my mind ishow are we using generative AI for forthe powers of expansion anddifferentiation and we'll show someexamples of how we can do things usingyou know productivity enhancements butreally you know here here are the thegoals to grow and then how do we makesure that we're doing that with theright tools and that you know some ofthese value things like honest quitehonestly I think there was a slide likethis probably of data Lakes back in 2008or 2009 and you know the thing here isis the way that we will unlock thesethings and do more cool things with isnot by doing the same things that we'redoing today it's unlocking those new usecases that we never had the opportunityto even consider in the pastnopesorry I messed up the clicker all rightso why do large language models actuallymake these things more effective firstif we think about lom's as emergentTechnologies you know what this reallymeans is that you know as an engineer Ican also do things like ad marketingcopy you know that was not somethingthat we could do before the Advent ofthis without either you know a lot of mytime spent on doing something or mehaving the direct uh you know workerknowledge for thatsecond you know with llms we also youreally have this contextualunderstanding of language and where thisbecomes really important is if you thinkof the relationship between cats anddogsyou know as as humans you know we caninfer the middle part of that right youknow maybe the dog chases the cat youknow maybe the cat and the dog you knowthey they live in the same housebefore llms we knew that we had cats andwe had attributes of cats we knew thatwe had dogs and attributes of dogs butto fill that that kind of chasm in themiddle and understand the intents of thetwo entities was very difficult even inthings like you know bird models andthose things that came prior to thoseand so with that now that we canactually understand that context we canunlock new experiences for thisthen last and really coming to thatconnection piece is if we think aboutall the data that's available LM isreally kind of if we can direct themeffectively or how we can unlock allthat opportunity and understandrelationships that may not beimmediately apparent to us just becauseof the volume of data that we have tohave to get through I think here as wethink about you know now we're gettinginto the kind of the activation spaceand you know how do we get to jobs andand tasks that may be useful for for LMuse casesprobably the the main thing here I wouldcall out is that umyou know llms in the information economyare really the things that we're lookingto to say okay how do we take theinformation economy to to that nextiteration or that next generation andyou know as as I think we've all seenyou know changes changes never a linearfunction changes always step wise youknow what are the stepwise things thatfor example myself as a softwareengineer I will be able to unlock movingforward or what is my customerexperience going to be that really makesthe makes it more impactfulso if we think about that you know we'vestarted going from roles now let's talkabout how we're going to actually breakapart these things into maybe jobs theusers might perform and think about youknow from those jobs or tasks how we canthen actually get to do some sort ofscorecard for prioritization andactually using OMS for thisuh here and this is using a popularframework called jobs to be done forthose who are interested it's a it's areally great way of just breaking downthe activities that we do and and thevalue outcomes that we're trying todrive with thatbut thinking through here you know ifI'm a marketing you know user I'm amaybe a data engineer supportingmarketing you know what are the thingsthat might benefit from using an llm forbuilding something like marketing andsocial copy as a developer or engineeryou know one of the the things that wealways see right is it's you knowtesting is great testing is always thelast thing that I do and as a result ofit testing has never actually put intomy code you know documentation is alwayssomething where it's it's a nice to haveand I document it when it's painful butyou know everything else I don'tso what are those things right where youknow we we inherently May assign valueto that but we have not been able to dodo to date at scale that we may actuallywant to think about as those those firstthings to go through and then last butnot least you know coming to a knowledgeworker you know what are maybe thingsthat I can't do with my data you knowthat an llm may be able to help me doum things like anomaly detection whereyou know I can I understand whatanomalies are based on my currentunderstanding but what if I just gavethis to something else or this data andsaid hey what are what are the anomaliesthat you see you know having havingcontexts in these situations is veryimportant and once I can actually youknow use different contexts to myadvantage you know how do I build inthat that full Corpus of information andand really take action on thatso let's walk through you know some waysthat we can start thinking aboutprioritization of all these fun thingsand then we'll get into talking aboutsome of those tools and value pieceshere in a little bitfirst uh speaking to the last slide whatare the things that you as an individualor you as an organization want toprioritize as your use cases movingforward and hereyeah I think I think there's really kindof two ways that we've seen this go sofar right one is that we you picksomething that's you know crazysomething never never been able to bedone before you know let's try toactually do that and use this technologyas a bridge for that the other is let'spick something that's small but is youknow something that we can actuallymeasure and test and you know see thepotential benefits ofboth of them are completely valid it'salso good to understand like you knowwhat are what's the the level of effortI'm going to apply if it's a moon shotor if it's you know something where I'mlooking for for incremental gains onobviously thinking about the platform isis very important here so what are thetechnology pieces you know what are thebusiness processes and all those thingsthat go with itand then if we start to think about youknow moving into the middle this isreally where it's okay you know what arethose those models or the the actuallarge language things that I'm going touse in order to get the get this workdoneso first obviously is okay well what arethe models that exist you know based onmy problem is this a code problem isthis a language problem is this you knowunstructured generation what are thosethings with itnext is how do these models actuallyperform at the core tasks and then howare these models ultimately integratedso you take a a very very very largemodel with trillions of of parametersand notif my use case is sub 200 millisecondreal-time you know q a I probably have adisconnect in terms of what myrequirements for Value are in the modelis that I'm trying to actually use forgenerationand then really here where we start toget into is you know what are thetailoring things that we need to do forthis and you know first question like doI actually need something that's customor can I use things you know like likeprompt inputs or you know contextsetting to actually make the LMeffective without all the additionalcosts occurring with something likecustom Trainingand then ultimately andyou know I think this is where you knowwe've really seen a lot of momentum inin the past six months in terms oftrying to build a common understandingfor this technology is you know how do Iultimately keep my data safe and keep mydata safe within my organization safeand then keep my customers data withinmy organization safe safe for thatand so weyou know here here and I can't stressthis enough this is where we're reallytrying to think about how do we bringcompute or the AI compute to data versustaking data to the to the AR computebecause ultimately the data is the highvalue thing and what we want to makesure of is that we can we can keep itand say keep it safe keep it inresidency keep it in all those thingsthat matter for itand when we do all these things what weultimately can do is start to close thatthat gap between the data pieces and thebusiness questions that I have and thenthe actual value propositions or the orthe the opportunities that I see inorder to close that and here it's reallybuilt on again the premise of you knowlet's bring AI to datalet's unify those pieces together soit's it's a great experience and thenlet's bring the ecosystem partners andpieces into that so it's very easy andstraightforward to do for for our workall right fun things right a lot ofthings that we have to think about interms of prioritization but let's talkabout things as Engineers thatultimately we find super cool which aretools we get to use in order to do coolthings with lomssowhy do people first come to Google rightum if folks here I assume many peopleare working with with tools likebigquery really you know we are tryingto bring make a data and AI firstversion of cloud in order to do all thecool things that we believe the next 10to 20 years of of business problems willrequire to be solveduh next you know we really try to makesure that we're bringing that compute toyour data regardless of where of whereit is so using things like bigquery Omnito run in place in your data and anothercloud or doing something like a spark tobe able to run on an edge node uh whereyour data actually residesand obvi I think here you years ofresearch having gone into this both youknow for our work and then to benefitthe larger community in LOM piecesultimately yielding a highly secure dataplatform for for these things to do andnotand with that if we think about you knowthat for for doing this for any Userit's really a couple core products thatwe try to think of in terms of that thatinitial value story and the center hereis really you know using bigquery andvertex AI together in order to buildbuild use cases and build amazing thingsacross our different uh pieces andstacksso with that let's start to get intosome of the different attributes of ofthe data Cloud here and or sorry the AICloud not the data Cloud the dataCloud's the other thing that I do uh doon the side uh here for for the iCloudwhat we're working with uh or workingtoward with vertex AI is really havingthat end-to-end experience whetherthat's your initial kind of hypothesisbuilding or your actual productionmachine learning operations platformhave a single stop shot for doinganything that's required for AI in orderto make it more useful and moreeffective for your organizationall this is built on things that we callfoundational models so you know folkshere have probably heard about palm palmis obviously a set of foundationalmodels that we can use for things likecheck sorry text chat code even nowgetting into you know image gen forbuilding you know new and novel thingson top of thatand all this builds obviously on onthings like tpus and gpus where you'reyou're getting the the scale of Googlebut without the you know 10 milliondollar costs of infrastructure and buildout in those pieces of it and thenworking up is is the experiences that weget as developers using things likegenerative AI app builder so that way wecan do things like you know tests youare we going to get the right images arewe going to be able to actually build achat bot in this experience and thenultimately integrating these things intodifferent platforms so you know whetherit's you know something we may provideas Google for using something like duetAI or why this is actually a verticalsolution where you may take a componentof this and implement it in your ownplatform for customers than thatso I've said I think if we were playingbuzzword bingo I'd probably set securityfive or ten times I should probably sayit a couple times moreumit's very important to us in in all ofthese things that your data remains yourdata and if you think about you knoweven the the new rules you know inparticular for for the EU aroundcustomer privacy and digital privacy andall these thingsour intent here is that we we bring allthese data pieces into your parameter soyou can use them but everything alwaysremains secure and there's you knowthings like like using serviceparameters that way you know you you canprevent things like exfiltration andthese are all all things that we providejust out of the box in order to actuallymake your dataum highly secure in whatever region youneed in order to make sure that youryour work can be doneall right so we first talked about uhwhat are the what are kind of thefoundational components that we have thenext thing that we've we've beenlaunching and you've probably seen a lotof these things you know in in briefingsand new things is is duet AI so do Naiis essentially you know our chat bot foryou as developers or analysts to be ableto do different things uh and and havereally powerful AI driven experiencesfor thatand ultimately you know our job herewith this is to help you be more moreeffective and more productive and withthat what I'm going to do is I'll cutover we have about a two minute videobecause there's so many differentcomponents of this and and using theseare really effective in terms of justconveying you know what are all thethings and the personas that we can wecan actually work with with the way theyaround so I will cut over here to thatand dance[Music]thank you[Applause]foreign[Applause][Music]foreign[Music][Music]foreign[Music]here talk a little bit more about one ofthose areas in Duet which is uhobviously one that I I spend a goodamount of time with and that's you knowhow do we use dueta and bigquery and allthe things we just talked about so uhhere what we're we're seeing is just alittle a movie here on the side is howcan we actually use real-time completionin order to go through and to start youknow making essentially in this case api spark documentand here you know what what we're usingduet AI for is is kind of those inlinethings where you know if if I think ofmy own coding pattern you know quitefrankly what it usually resides with isis me having two screens open and onewith the thing that I'm writing and onewith the Internet is the search engineon there and trying to just make surethat I can get the right pieces in placeand here you know this is really whereif we think about you know theexperiences that we can power usingusing tools like duet AI is you knowultimately what we want is how can we doeverything in in one window do iteffectively and and do it in a way thatthat makes sense to create that valueand you're using here things like SQLcompletion and python completion arereally ways that we're trying to makethis easier for practitioners to do moreuhyou have had the pleasure of workingwith some large organizations likeL'Orealum and here you know I think that thethe key takeaway of all these things asmuch as we love to talk about tech isultimately what we are doing is usingTech to help engineers and to helpcompanies do better things uh with AIand always exciting to to haveorganizations that we can work with onon such fun use cases to to grow and andto build togetherso uh next thing here is is and I wouldencourage everyone to try it once we getout of here is is generative AI Studiowhich we just introducedand here uh using generative AI Studiothis really just gives us that authoringplace to start building you knowinteresting llm experiences and makesure that those prototypes make sense uhone of the things I always think aboutis you know if it's going to take me twomonths to build a thing well how can Ivalidate you know in 15 or 30 minutesthat this is something that that's worthmy time and I found you using this is iswell one it's it's kind of fun rightbecause I can start making images ofreally crazy things but it does help meto make sure that my value cases andthings that I'm building are are usefulin thatand all those foundational models so wetalked a little bit about Palm for textPalm for chat the other things here inthe bottom and and what we saw with duetis you how do we then bring things likecode completion and Kodi you know intoyour coding environmentso um if you think of all the surfacesthat we have is is interfaces to doinguh you know code and other developmentworkCody here is really how do we then makesure that you if you're working in ourconsole if you're working in VisualStudio code if you're working anotherIDE that again like we are bringing thecompute to where you are as thedeveloper we're bringing the to your IDto your data and ultimately helping youget more doneand what this will yield uh is is reallythe next generation of both vertex Aiand the bigquery platformso uh obviously there's a lot of funthings we could talk about and we couldprobably talk for hours about ml Ops andyou know how do we make things runproductionthe other thing is you know how do wemake it easy to serve all these modelsat scale and using things like modelGarden you know having better promptdesign and tuning support and generativeAI again it's it's really based on thelearnings that we've had so rapidly overthe past nine months and sharing thatwith everyone in order to to build greatthingsso with that uh what I'm going to do isI'm going to cut over to my my laptophere and we're going to do a couplequick demonstrations so the first onewill just be one of you how how is duetAi and the console work uh how do we getto see some of the things that we can doeven in terms of generalized questionand answer that we can give it and thenthe other one it will walk through beingable to actually use an llm in some ofour data analysis but for using it toactually do a an unstructured dataanalysis with some data to make somesense of it so with that I'm going tocut over hereall rightand my screen is up here so uh just forcontacts where we are I've started offhere I am in the the home page forGoogle Cloudand as we can see here I have a littlechat bot which is duet AI which I can goahead and open so I will do thatand so one of the most common things ifwe think about data analysis is you knowwhat are all the things that availableto me in order to actually perform dataanalysisand so you know something we may we mayconsider is okay well what are thegeneralized things that I may want to doand then what are the products that Imay want to do with that so I could dosomething likewhat should I do for data analysiswhat we can start doing is start just tobuild some some generalizedunderstanding for different things wecan do and you know here what we're whatwe're seeing is the response is hey wellwe can actually use bigquery but there'sa few other services that we startedtalking about you know maybe you know wetalk about Real Time with data flow youknow maybe we also we're we're an openprocessing shop and we want to do thingswith spark so I can see that I'mstarting to get some product Associationbased on the intent of the activity thatI'm looking to drivein this case you know you may want tolearn more about bigquery so what isbigquerycool it's a fully serverless datawarehouse awesome uh what what is thatwell how would I source thatyou hear we also try to do a lot ofinline hinting so umI think one of the really importantthings with with llms in this case nodifferent than any other one is how dowe actually provide citations forinformation because when we can providecitations that means that the olm isprobably not making things up I saidprobably to that because there aresometimes times when that happensum great so I know what bigquery is andin this case we want to do someunstructured data so how would I getunstructureddata and bigquerywhoa that's a lot all right let's breakthis apart because I just got a lot ofgreat information hereso essentially what this is telling meis that I can use bigquery I can usedata transfer service or I can use thestorage API to help upload a lot of datainto bigquery and then here are somedifferent ways I can do it and how I cananalyze it I could also obviously comethrough and I could start to lookthrough things like you know what is theactual unstructured documentation andthe goal here right is isn't necessarilythat we're going to give the the answerright we're not going to say hey what'stwo plus two well it's four like that'sa very deterministic thing inundeterministic things here is how arewe bettering the the practitionersunderstanding how are we giving you theright links to find things faster andthen ultimately create that value as apart of those statementsall right so we've started figuring outwhat are some different things that wewant to do with this you know let's sayI actually have some SQL now that I wantto go execute and what I'm going to dowith that is you know figure out heywhat is this actually going to do andthen how do we actually go implement itfor thoseso firstly we can pull upwe can see here I have a join table andhere you know what we're starting towork with is some sales data from ourorganizationfirst thing I want to do is understandyou know hey of all this data like whatwhat does this query actually representuh how many times here have we seen aquery uh someone else wrote it we pulledit up we looked at it or like I have noidea what that thing actually representswell let's break that aparthere I can click this little buttonand what we've actually done is is isuse some contacts so we've said to toduethere's the query now take this andactually explain it to me and and kindof practitioners terms of what'sactually happeningso here we can see what we're actuallydoing is we're finding in this casebecause we're using group buys and Orderbuys we're finding the top 10 users inthe space and and all the differentsales attributes that they have withthatso we can see here that it writes thisout and while sometimes this may looklonger than the query that we'rerepresenting what we're doing here is istrying to just make sure that we canbuild that that natural languageunderstanding of what the query isperforming and notso next yeah let's say then the you knowI have that sales data and I'm going togo build a what is a bigquery machinelearning model in this case an arimaforecasting model so what we're going todo is we're going to have this modelit's going to executeand then the thing that I actually wantto get from that is you know how do Iactually get a query that says okay youknow I want to iterate on this modelso if I were to run this and I ran itbecause it takes a minute or two and Ifigured you you don't want to have me uphere trying toum you know tell jokes or any of thatthat would be bad for everyoneum you know I'm not going to run thatbut maybe let's say here you know I wantto understand you know what is an arimaplus modelcool I have some information that'sdisplayed and so basically it's sayingyou hey what's a Remo why is this one alittle bit different gives me the linkto do that in this case what I want todo because I actually want to get aforecast off of thatwe can see here that just by typing inthis intent and think of this as kind oflike a chat turn as soon as I do this Ihit enter there's a little wheel thatspun and then I actually get my queryback here that I could execute in orderto get that forecastand here we can uh we can see theresultsas we pull it upall right pretty cool right so we'vestarted just taking some of thosedifferent engineering workflows we'vedone you know a little bit of dataanalysis uh we've used an llm to kind ofhelp help get these things through let'stalk about one more use case then whichis you know instead of having that llmhelp us drive productivity how do weactually use an llm to create some somemore value statements from fromdifferent things that I may havein this case what we'll doand here I just have again some simpleSQL on a script let me go ahead and makeit slightly largerthere we goso what we're going to do in this is weactually have some speech files and hereumyou're working with unstructured data isis kind of a hard activity right likeit's a bunch of wav files it's a bunchof MP4s MP3s you know things like maybeI get off of like a tech or maybe I getoff of a customer call or some othervideo that may come in well what I needto do is actually figure out how I cananalyze these better in a scale so thefirst thing that we have here which youcan execute is just building an externaltable that actually is an object linktable in order to pull all that datainto bigquery for analysisso when I create this all that I do thenis I have that object table and now Ican use all the cool things in bigqueryin order to actually bring computationto my unstructured data in thatso what we can do is if I were to dosomething like see what's in that speechfiles tablewe can see here you know here are somedifferent wav files that we haveand now what the cool thing is thatwe're going to do is we're going toactually run a statementwe're going to encode this using a chartmodel and that would be just using thisthis statement here and then what we'regoing to do is we're going to actuallyuse an LM against this data so we'regoing to help summarize all of this textinto a few things that we can displayso with thatum let's say I have that have it inthese thingshere I have my generate text statementso using a single SQL function we canactually go through and we can pass inwhat what our prompter our question isI can give it some text as an inputs sothis is the context that I'm going toapplyand then we can also do things like tunethe model so you know how much howcreative do I want the model to beversusum you know drier dryer fact based youknow what are some of the other thingsthat I want available and then what areyour output tokens so how much do I wantthe OM to come outand then when we have all those in whatwe can do if I run our last piece hereas we can see that I actually have oneof my resultsand here I have the content so what thellm summarizes is is the key things thathappen in the conversation and if we hadany categories for things like um youknow unsafe things like violence orsafety or something else we would havethose here with with scores alsodisplayed in terms of of that severityso here again making it easier as youstart to interact with these thingsunderstanding hey if this is a safething maybe it's okay that it goes outanything that's questionable and maybe Ihave a human in the loop to review andto get these things for itall right so what have we done todayum in this part we just summarized uphow we can use duet and we've alsostarted talking through some of the cooluse cases where you think about bringingthose those vertex a models to bigquerythat we can use in order to build buildreally interesting and valuable thingsfor organization"
}