{
    "title": "PostgreSQL the way only Google can deliver it: A deep dive into AlloyDB",
    "presentation_type": "Breakout",
    "categories": [
        "Database Professionals",
        "DBS210"
    ],
    "video_id": "J1_ClMwYdJk",
    "time": "Aug 29 03:30 PM - 04:15 PM CDT",
    "transcript": "[Music]my name is Sandy I am a product managerfor Google Cloud databases um and withme today I have rvy Mory uh seniordirector of engineering for databases atGoogle cloud and we're so excited to bejoined by Christopher executive directorhead of data stores and B engineering ofthe CME Group I want to kick us offtoday we're going to have a really greatsession for you guys starting with aquick introduction of alloy DB welaunched alloy DB at Google IO last yearand it's been a really awesome Journeysince going to GA last December and I'lltalk about it give you a quick introagaintoday then we're going to go see alloyDB in action talk to Christopher abouthis experience at CME Group using alloyDB and then rvy and I are going to diveunder the hood and then finally we'regoing to talk about getting there thingslike migrations our partner programs Etcand what's next how you can get startedand some great other sessions for you toattend there we go okay introducing allva postgress compatible database that wayonly Google can deliverit okay before we jump into what alloyDB is I want to talk really brieflyabout why alloy DB was was built byGoogle and that's because we've beenseeing customers as they migrate to thecloud uh approach their legacyproprietary databases differently fordatabases like Oracle SQL server db2 andmore we're not seeing as many customerswant to do like for like migrationsinstead they're using the excuse ofmoving to the cloud as an excuse to ummodernize their database estate and ummove to standardized open- SourceSolutions and there's one database inparticular that we see emerging Abovethe Rest and and that's postcross and so why are developers andEnterprises actually choosing postgresswe think there are a couple reasons whythis is a really great ecosystem it'sopen source you get all of theportability that you wouldn't didn'thave before really simple licensemanagement and it's super cost-effective it has Rich functionality thatcan compete with a lot of greatEnterprise databases on the marketincluding an extensible architecturethat amazing ecosystem of extensions andit's built to scale and of course it'sproven across millions of users inalmost every industry and has a reallygreat friendlycommunity at the same time what we hearfrom customers is that sometimes those Mmigrations can be hard hard especiallyif you're re-platforming from acommercial grade database but evensometimes if you're running open sourcepostgress at scale and so some of thepain points we've heard at gcp forcustomers running postr are reallyaround scale performance andavailability but as we talk to customersthey are also excited about newopportunities to as they move to thecloud opportunities to ease theirmanagement overhead and to access new tor to build new types of userexperiences like real-time operationalinsights or integrating moresophisticated AIML capabilities intotheirapplications and so to do that weintroduced alloy DB a new open-sourcecompatible database engine ready for toptier relational database workloads a lotof folks over the year I guess thatwe've been we've been live have asked mewhy did we name it alloy DB and it comesfrom the it comes from chemistry theidea that you take the these twoproducts and when you put them togetherwhen you take these two differentelements and put them together you makesomething stronger and I think that'swhat we've done here with alloy DB youtake postgress compatibility again adatabase and ecosystem that we reallylove and combine it with some of thebest of Google that infrastructure thathelps us scale offer better performanceand betteravailability some of the most excitingthings about allb are its performancenumbers it is four times faster thanstandard postc cross for transactionalworkloads and actually that's measuredon a 16 vcpu instance as you can seehere on a 64 we actually see even moreperformance benefit because alloy DB canreally take advantage of those largermachine shapes and this helps not justwith your Topline performance but it canhelp with things like price performanceas well because sometimes you can runworkloads using your alloy DB instanceon smaller amounts ofresources and it's up to a hundred timesfaster for analytical queries thanstandard postgress you know here's anexample of a query that on postgresstakes over a minute to run and on alloyDB takes less than a second so when wehave this type of huge performancebenefit on analytical queries thatdoesn't just change your applicationperformance it changes the types ofqueries you can run because the realityis you're never run running a query inyour application that takes a minute buthalf a second you can build experiencesonthat okay so just to recap allb wasmeant to deliver a commercial gradeexperience without the costs and withoutthe vendor lockin in addition to some ofthese performance benefits and I'm goingto talk about that last one the replicalag in a little bit it's also highlyavailable with a 49 SLA inclusive ofMaintenance highly scalable withscaleout storage horizontal scaling ofreads and vertical scaling of Rights andit's intelligent with autopilotcapabilities and embedded AIML to makemanagement easy but also with some toolsand capabilities that allowed you tobuild generative AI applications on topof it and of course it's fully postrestcompatible making it easy to move toeasy to run uh you can really trulytreat it like postr and it haspredictable transparentpricingand with that I'm going to transfer overto Christopher to talk about hisexperience at CME thank youSandy and thank you for inviting me tothis conversation today and thankeverybody for joining I know I I'velooked at this list of sessions here atnext and they're allfantastic and so you've chosen to spendyour time with us and uh thank you forthat um so just a quick introductionintroduction to to the Chicago mertileExchange um Chicago mertile Exchange orCME was formed in 1898 as the uh butterand egg board uh it expanded over thepreceding decades to include a number ofadditional agricultural products and umby the 1970s the CME had revolutionizedmarkets um by providing uh Futuresagainst interest rates other Financialelements and so with that let's talkabout our journey at CME to the cloudand in particular to gcp and theimportant role that alloy DB plays inourtransformationapologies okay so we have a clear visionof what we're trying to achieve andthat's really providing modern Analyticsuh and truly great data experiencesinternally into our customers but thatepresents a couple of differentchallenges for us um the CME over theyears has modernized its technologystack several times first starting witha legacy monolithic architecture andthen moving into more of a distributedsystems to take advantage of newcomponents and new architectures toenhance our systems well now we'remaking an equally significant um changehere at the CME which is adopting cloudand adopting Cloud specifically toprovide us the velocity that we'relooking for that we need that ourcustomers need to bring those reallygreat dataexperiences well there are somechallenges there and one of those is aspart of the transformation todistributed computing inside of the CMEthe CME has leveraged proprietaryvertically integrated databasetechnology in order to achieve theVelocity in our database subsystems thatthe marketsdemand and I'll just go ahead and say itthat that that proprietary integrateddatabase technology is Oracle exaddata um we also are working closely withour partners at Google to address someof the unique requirements that thefinancial services industry and ourmarkets have you know it's all great tomove to the cloud but we have to ensureand create the guard railsnecessary to keep our data and ourcustomers data confidential andsecure and then the finally there's oneother challenge that we have in thedatabase space and that's our people andourprocesses um you know our applicationdeveloper Community have been workingwith tools uh like pipelines continuousintegration continuous deploymentuh for a while now but our databaseengineering and our databaseAdministration teams because of thenature of the technology that we've beenworking with haven't always gotten intothat space and so as part of this we areupskilling our database engineeringteams to be more in line with acloud-based and uh devopscultureso one of these challenges that we haveis that the Oracle exit dat platformprovides a very high level ofperformance um and we need to understandbefore we start architecting theprocesses and actually migrating ourdatabase applications to the cloud wehave to understand fundamentally first Iis this going to accommodate our needsum will it be performant enough andsupport the latency requirements and thethroughput requirements that we havesupporting our applicationstoday and so in order to accomplish thatwe developed inhouse a database testingand benchmarking framework now it is uhI would say inspired by an oraclefeature called real application testingbut we've baked in the flexibility toenable us to run benchmarks to runfunctionality tests against variousother platforms and compare those backto our Legacy databaseinfrastructure and we've done thisagainst a number of key criticalworkloads within the firm the workloadthat I'd like to highlight for you todayin particular is a clearing system it'sa critical clearing system involved inthe clearing process and one of thereasons that I want to highlight thisfor you today is because it illustratesalso an impact of having leveraged theseproprietary database platforms likeexadata and that's that we have a hybridworkload here we're not just tuning forfast transactions and oltp usage we alsohave analytical queries that the userscan execute against the system throughthe user interface and so this particthis presents a particular uh challengewhen we're trying to find and leveragefit forp purpose uh database Platformsin thecloud and let me just let the cat out ofthe bag a little bit early here um thealloy DB tests were fantastic uh in ourparticular proof of concept that we didagainst this clear ing system alloy DBperformed very well against thetransactional queries our oldp use casein many cases uh it performedbetter and uh even with the analyticalqueries that we run against the systemwe found that many of them are keepingup with the demands of the applicationthere are a few exceptions and we'lltalk aboutthose all right now to kind of get intothe detailof the performance uh benchmarking thatwe've done for AlloyDB um so this represents one of ourreplays that we're using our in-housetool um to effectively simulate realproduction workload that we pulled offof uh one of the live productionsystems and in virtually every case wefound alloy DB is meeting thetransactionalrequirements of uh of of our applicationthere were a few exceptions those arethose 197 olop UI queries uh that didtake longer on Allo DB but I think thatthis just underscores the necessity ofgood design when you're working withrelationaldatabases um in in this particular casethe application would allow the user topick an arbitrary number of columns andapply an arbitrary number of filters toget the answer that they're looking forand you know I'm sure there are databaseadministrators out here in the crowd andas you may know that's a very verydifficult problem to solvefor and now let's talk about some of theoutcome some of the learnings that wehad um through these performance testsand stress tests against the alloy DBinstances um one of the first thingsthat I want to mention here this is justsomething that occurred to me a whileback I love Google's approach todatabase Engineering in the cloud asSandy mentioned postgress is emergingfor a number of reasons as theopen-source database of choice forGoogle Cloud for many Cloud providers umdue to its flexibility its licensestrategy uh feature parody with Oraclein many cases and so what Google's doinghere is they're engineering fit forpurpose uh uh services so you may startwith something like cloudsql postgressit's great for mid-range workloads it'svery cost effective and then you mayreach a point where you just simply needa higher level of performance a lowerlatency out of your database operationsor possibly a higher level of of of of aavailability and then Cloud spanner isthere to support your geod distributedworkloads but the point that I'm makinghere is that from the outside they alltaste like postgress and so that enablesyou to use a common set of drivers acommon SQL language and dialect and alsoa common set of tools against a verywide array of use cases alloy DB beingone ofthose another key finding that we havehere is we found 80% actually more than80% of our workloads don't actuallyrequire the level of response time theperformance that's offered by the Oracleexadataplatform um I think consolidation isnatural it makes sense and when you buyinto a technology like Oracle exadatafor a few of your workloads it's onlyvery natural to use the rest of yourcapacity to consolidate onto that andthat has an effect unto itself andthat's that it creates a very tightlycoup coupled data layer that we're nowworking to unravel here at theCME um a few other quick points becauseof the architecture of postgress andalloy by proxy uh you may be allocatingmore sessions in your application totake advantage of things like read poolswhere you can horizontally scale yourreads across a pool ofreplicas uh while isolating your readwrite primary so that may require someadditional sessions in your applicationlayer to accommodate that but generallyspeaking it's well worthit the other thing that I'll mention isthat if you're looking at your databasetransactions at an atomic level you mayneed a bit moreCPU um that's fine in mostcases and then finally we've all many ofus have worked on cloud-based databasesbefore and you know you're trying toachieve a particular level of iops inorder order to support your workloadwell with many Cloud providers that hasan effect and that effect is your overallocating storage you know on one handas a database administrator it's greatI'm never going to run out of storagebut there's a real cost associated withthat and so that's one of the patternsthat alloy DB here is working to breakis that no longer are we required toallocate orders of magnitude morestorage than we require for a particularworkload just to achieve our IOPTarget and then now I'm going to passthe mic over to Ravi here who's going toget into the guts of alloy DB and talkabout some of the features all rightthank you Christopher so now uh let'slook at a little bit behind the scenesof what is actually driving the kind ofperformance and the the amazing thingsthat Sandy spoke about so Sandy and Iwill uh do a little peek under the hoodyeah let's doit all right the fundamental principlethat ALB is built on is this notion ofdisaggregation of comput and storage soyou've got the database layer that's aset of compute nodes and they're alltalking to a storage layer that isdisaggregated completely so whatdisaggregation means is now you canscale the database layer completelyindependent of uh the storage nodes umand the storage nodes are able tobalance the load and give you a verycost effective and a very predictableperformance so the key Point here isthanks to this complete disaggregationarchitecture each of the layers canscale very independently based on yourworkload and so jumping into the storagelayer what's really cool about this isthat we have an intelligent databasestorage designed and optimized forpostrest as you can see here it's aregional storage service spanningmultiple zones and as Ry mentioned it'sdisaggregated itself so you have computeresources in the storage layercompletely separate from durable storagewhich is based on Google's distributedfile system Colossus when we talkedabout some of those performance benefitsat the beginning you know especiallythat 4X right throughput uh or sorry the4X transactional performance a lot ofthat is driven by this storagearchitecture because you have anarchitecture that powers fastpredictable performance eliminating IObottlenecks and offloading work from theprimary to the storageservice it can also help with thingslike availability and uh read replicalag which Ry is going to talk aboutright now all right so one of the thingsthat the storage engine architecturegives you is the ability for many readinstances to attach to the same exactstorage engine so this we alloy DBsupports the concept of read pools whichis the notion of a single readerendpoint behind which you can have evenup to 20 read uhinstances and what this endpoint givesyou is a very easy way to do horizontalscaling of your read connections so asChristopher was talking about based onthe workload you can add new readinstances very easily and very cheaplywithout doing any data copy so you'vegot the ability to dynamically adaptyour your cluster and the amount ofcompute based on your workload andthat's both up and down so you can forPrice spin it up yeah and when you don'tneed it very easy to spin it down theother thing that read pools give you isthis ability to handle your readworkloads without having any impact onthe primary so you get completeisolation between your read workloadsand your primary transactionworkload um also these replicas and readinstances are typically very low lagwhat it means is it's tracking almost inreal time what the view of the primaryinstance is and typically we look atsomething in the small single digitmillisecond lag uh and and this issomething that we've taken even furtherrecently with a bunch of innovationsthat we've done in the way the logs aretransported and applied on the replicathat results in a even lower lag and thepoint of this low lag replicas is now itreally opens up the door for a widevariety of reporting analytics use casesthat was much much harder to do beforethisdefinitely so let's actually look atsome numbers and here you've got uh twouh benchmarks that we're showing hereand it shows how alloy DB compares tostock postris so on the left we've got aworkload which is a high transactionthroughput workload running on theprimary but the read replica is idle andin this particular case the replica lagwith all DB is 25 times lower comparedto stock poston the right hand is uh even moreinteresting use case where in additionto the high throughput transactionworkload on the primary you also have aread workload happening on the replicain this particular case stock postgressuh many times ends up with unbounded lagjust simply because the replica is notable to keep up with the primary butwhat we've done in allb thanks to abunch of really uh clever Innovations isyou always have bounded lag and andthat's really awesome as you can seehere yeah I mean like the point of readreplicas right is to do reads on themand so what's really cool about this isit allows you to use all of yourresources to the max while still keepingyour replica lag in very manageablelevels one of my favorite features aboutalloy DB is the super fast failover wethought really hard about how to makealloy DB a highly available service andthat means a high availability for bothunplanned and planned types of downtimethat we take so in the unplanned casealloy DB has very fast bounded failoverthat's independent of database size andload and of course an RPO of zero thatmeans no datab no data loss on failoveryou can see a quick diagram of how itworks here with a primary and a failoverreplica and a single read write IP thatway you're not having to um managemultiple different IPS you'll use thesame endpoint to connect to the failoverin in the case where you haveto what I'm I'm really excited about isuh we recently launched actually thanksto feedback from CME uh a new faultinjection API for ha testing so uh youcan make sure through testing that yourapplication failover is as smooth asyour database failover is with that isreally coolyeah and then finally we wanted to makemaintenance easy again one of the mostcommon sources of downtime are isactually the downtime that we plan forboth us at Google when we do Googleinitiated maintenance and you guys whenyou do things like instance resizes orsometimes change flags that requirerestart with allb our goal is to makethese non-disruptive operations and sowe have in addition to our primary whenwe're doing maintenance we're going tospin up a replacement Primary in thesame Zone and coordinate maintain thereplacement primary and then coordinatea handoff from Storage after thereplacement primary becomes youroriginal your newprimary again a really new feature welaunched recently is now this happenswith less than one second of downtimefor most workloads on the primary andagain zero seconds of downtime on theread replicas that means you're able toreconnect right away a huge improvementfrom just a year ago when we were at 10seconds exactly so this really makesthis truly zero down time extremelyhighly available and you can use it forthe most Mission critical of yourapplications yeah all right um switchinga little bit from the database storagelayer up into the compute yeah um whenyou see the architecture here um whatyou see is that the database layer isreally an highly optimized postrisEngine with built-in tiers of cachingincluding RAM memory based caching aswell as uh an ultra fast cache that weuse for extremely low latency of uh dataaccess now in addition to the standardrow based uh caching that postris comeswith alloy DB has also introduced a newcolumn oriented format and I'll talk alittle bit about that in a second andthe point is both of these types offormats are automatically anddynamically handled by the database noneed for any application changes and thedatabase just figures out exactly what'sthe right format for the data based onyour workload and puts it into theappropriate tier of the cache soeverything is automatic and you get thetransparent benefits ofthis so what is columnar good for it itturns out it's actually really reallygood for certain classes of analyticalreporting type of queries that have toscan a lot of data so what we've done inalloy DB is introduced this new columnarengine that sits alongside the roadbased engine of postgress and does theright thing transparently So based onthe workload it converts the data intothe columnar format and the columnarengine works on it using a highlystate-of-the-art if I will uh type of anengine using things like vectorizedexecution Bloom filters and and a numberof other techniques to have the highestpossible performance that you can get uhwith that type of query processing uh sowe support vectorized execution ofthings like filters and Aggregates andnow recently we also added uh vectorizedjoints which now opens up to anotherlarge class of workloads that can behandled by the columnar engine um we'realso spilling it out into the ultra fastcache so you can handle much larger dataset sizes and uh last but not the leastwe're constantly adding support for moredata types in the columnar engine basedon a lot of feedback that we get fromour early customers and uh the result ofall of this is depending on yourworkload you can get one two orders ofmagnitude higher performance with thecolumnar engineawesome U Switching gears a little bit Iwant to very briefly touch on uh a setof features that we call the autopilotand this is based on our U thing of howdo we make alloy DB very very easy tomanage very easy to operate and sothere's a set of features under theautopilot umbrella and I'm just going totalk about three very briefly um so thefirst autopilot feature that I want totalk about is this thing called theindex advisor um so as the name suggestswhat it's doing is based on yourworkload it can give you a set ofrecommendations of what is the best setof indexes for your workload U it usesuh state-of-the-art AIML techniques todo this with very very low impact onyour system in terms of both storage andand CPU um and the result we've done alot of benchmarking on a wide variety ofworkloads obviously your mileage willvary depending on your workload but onon the thing that you see here which isa real world uh customer workload theindex advisor recommended indexes thatgive you a 4X better query performancenow of course with indexes you also haveto worry about the DML performance andthe cost of maintaining those indexesbut it's one of those things that canreally make your job of operating thislarge databases with a lot of tables lotof queries and things that keep changingall the time just let the machine tellyou how best to optimize it what'sreally cool about this one for me isthat it's columnar aware which meansthat it helps you leverage thesedifferent features for speeding upqueries in the way that's best for yourworkload and again in all cases you knowno schema changes no exactlyexactly another uh quick uh autopilotfeature that I want to talk about is onmemory management this is something thatall database administrators really knowuh that one of the things that youreally have to tune is how much memoryyou give to the buffer cache of thedatabaseand there's a problem that if you don'tget it exactly right either you end upwith out of memory errors which have torestart the database U or you end upleaving performance on the table so whatwe've done with alloy DB is to say okaylet the system figure it out so we'vegot this thing called the Adaptivememory management that based on theworkload Uh current workload at thatmoment in time it's dynamically able touse more memory or less memory but whatit guarantees is that you will not runinto outof memory errors so it's able tomonitor how much memory each of thebackends is taking and it'll make surethat one bad backend or misbehaving backend is not going to bring down yourentire database and that's a hugevaluable uh uh addition for folks whohave to operate this database and ensurethe highest level ofavailability and last but not the leastuh another autopilot feature that wehave worked on is this thing calledadaptive vacuum management um vacuumingis a very common problem that uh manypostgress folks are familiar are knowexactly what I'm talking about um andand not getting it right can have adisastrous Consequence the database canreally be down hard but what we've donewith alloy DB again in the spirit ofautopilot and Auto uh managing has donethis thing called adaptive and automaticvacuum management that guarantees thatyou just can like not stop worryingabout it and the database automaticallyfigures out how much resources to giveto vacuuming to ensure that you won'trun into transaction ID exhaustion umand if need be it adds more resourcesfor vacuuming and throttles back thetransaction ID consumption so lots moreuh will go into this autopilot umbrellabut this is on our path of just makingaidb completely automatic and completelyuh hands off driving if you will andlike again when we talk about theseautopilot Fe features it's really easyto focus oh oh it makes management easybut actually when we look at things thatcustomers really care about availabilityperformance it can have a huge impactyou know one of the largest sources ofdowntime for customers running postcross on gcp are out of disc errors andout of memory errors and so with theautomated memory management you're goingto avoid those even though we all hopethat we can do it ourselves S A littlebetter huge and then you know storagescales up automatically and drop a tablescales right backdown okay so we talked a little bitabout these autopilot features the waythat we use Ai and other adaptivealgorithms to make management of thedatabase easy for you but we know thatyou guys are also hoping to use AI tobuild more um interesting interactiveexperiences with your customers and sotoday in the keynote uh Brad announcedalloy DB aai it's an integratedcollection of features meant to help youas developers better integrate AI intoyour applications and leverage yourreal-time operational data to work withllms and build coolerexperiences that includes three partsthe first is um high performance highsscale Vector queries uh a couple monthsago we launched support for the PGVector extension and now we'reintroducing 10 times f faster Vectorqueries and support for four timeslarger Vector Dimensions um again tosupport a wider array of workloads butto also make sure that we can meet yourperformance needs that's due to tightIntegrations with alloy DB's queryprocessingengine we also offer easy embeddingsgeneration uh you know alloy DB allowsyou to bring your own embeddings if youwould like to and generate them whereveryou are but if you're just gettingstarted with Vector embeddings we alsohave a nice easy function for you tocreate embeddings in the database itselfbased on your operational data andfinally we offer integration with AItools that includes open source toolslike Lan chain via the postgressconnector it also includes Integrationswith uh vertex AI if you were here inthis last talk they just introducedvertex AI extensions we're super excitedabout that and looking forward tointegrating alloyDB and then finally this is a feature weactually launched um I think last yearbut the ability to call a Vertex a modeldirectly from the database uh superpowerful feature so you can call anymodel that's hosted in Vex aai rightfrom inside the database pre-trainedmodels or custom models yeah amazingcool okay I'm going to talk aboutgetting there so uh I'm going to zoomquickly so that we have time for Q&A butum thank you so much rvy uh I'm GNA talkabout getting there and um how how wecan help you get from wherever you areto alloyDB so again our investment in Googlecloud is to make database migrationseasier thanever and one of the ways we do that isvia our database migration service whichnow makes homogeneous migrations frompostgress wherever you're running it toalloy DB easier and fasterbut we've also introduced databasemigration service to support Oracle topostc cross migrations today that'savailable on cloud SQL but coming verysoon to alloy DB and again if you wereat the keynote this morning you saw oneof our really cool new features theability to leverage duet AI to do codeconversion to help with the last mile ofthatmigration and then finally we have uh anamazing program with partners for f ifyou're looking for folks to help helpyou along the way there are certifiedSolutions and certified partners thatknow how to work with alloy DB that canmake your journey easier and so we havea lot of the tools but I actually wantedto bring Christopher back on stage totalk about his experience and what heused uh actually I'll I'll I'll I'lldrive for you thank you s hello again umso earlier I talked about our firstproblem which is is there a cloud-baseddatabase that can keep up with ourtransactional throughput and latencyrequirements to support the exchange thesecond problem is how do we get there atscale and so what we have internally isa program we refer to as the DBrefactory and it's designed to solve acouple of problems one is our appdevcommunity they're very busy they havefull backlogs their engineering featuresthat the exchange needs and so workingour way into a backlog to say hey folkslet's pause for a second and refactoryour entire application for a newdatabase platform that's a tall orderand so with this DB refactory program wedo a couple of things uh we start withschema conversion and embedded databaseobject conversion we use a couple oftools"
}