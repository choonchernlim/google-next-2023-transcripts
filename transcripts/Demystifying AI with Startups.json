{
    "title": "Demystifying AI with Startups",
    "presentation_type": "Startup Lounge Session",
    "categories": [
        "Application Developers",
        "SU112"
    ],
    "video_id": "TWu6lE9XSe4",
    "time": "Aug 29 01:15 PM - 01:45 PM CDT",
    "transcript": "morning everyonecan we do that one more time morningeveryonethere we go thank you so much I reallyappreciate you spending a little bit oftime with us here in the startup Loungefor those of you that don't know thisexperience of this room and theexperience right outside is brand newfor us while we've done Google next anumber of times we've never donesomething with such a deliberate focuson startups and I'm thrilled that you'rehere and I hope you continue to seereally great results from theInvestments that we're making my name isDarren Mori and I want to kind of tee upwhat we're going to do in the short timethat we have together and then I hopeyou're going to walk away with a littlebit of more insight not only from myselfbut more importantly a really importantguest speaker that we have that's goingto shed some light on the actualapplication of AI to some reallyinteresting business problems but as Isaid my name is Darren Mori and I lead abusiness for Google Cloud here in NorthAmerica focused on providing startupslike yourselves what we hope is a reallyincredible experience all the way from avery human and dynamic experience atconferences like this all the way toonboarding to support to making surethat we're helping connect you into theecosystem and so I'd love to make sureto meet you throughout the day today andtomorrow and to get feedback from you asto what we can do to continue to ideallybe a great partner for you I also havethe opportunity in my evenings andweekends to lead the AI go to marketstrategy for North America that'soutside of startups that includes ourlargest Enterprises and so that's givenme a really and frankly incredibleopportunity to work closely with our AIleadership with Thomas and the team andas you heard this morning some reallyexciting announcements not only from achipset perspective but all the way upthe stack and we're going to talk alittle bit more about that today as wellso thank you againI want to give a little bit of a historylesson and many of you have heard thisand seen this but I just want to giveyou not only kind of my but also GoogleCloud's perspective when we lookbackwards and we Ponder really thegenerational shift that we're seeing inComputing at the moment now this ismeant to represent the level of what webelieve we're experiencing here atGoogle cloud and that you ideally areexperiencing with us which is this isnot a wave of just some new featuresthat are being added to a platform wetruly and fundamentally believe thatthis is a tectonic shift if you will inComputing you know we kind of talk aboutthe shift from Steam to electricity andelectricity to the information age intothe cloud into AI for those of you thathave as much or more gray hair than I doyou may know that my own experience wascoming out of undergraduate schoolworking on mainframes and trying to wrapcode around mainframes to extend thelife of that investment but try to makethem feel modern and then I took thepath into the client server world wherewe were convincing the world that wecould act actually have an underlyingoperating system with a database and anapplication some of you like Bonnie inthe room were working with me atMicrosoft back in the old days of doingthat I then had the opportunity to gointo the cloud with AWS early on in thecloud journey and got to see that movefrom client server to virtualization toinfrastructure as a service and we nowbelieve we're on that springboard thatwhole new launch pad into generative Aiand so I want to just Baseline us onwhat we think is again not a few bit offeatures but an entirely different shiftin the way that we're thinking about AInow many of you have heard and if youspend the next two days or three dayswith us here at Google Cloud next you'regoing to hear us talk a lot about thefact that while there is a lot ofattention on AI at the moment andfrankly I'll say this and the chip in myhead won't explode when I say it I'mthankful to our competitors for doingwhat they've done to move AI so quicklyinto the Limelight and frankly pop usacross the jaw a little bit and wake usup to really make sure that we are beingas bold and outspoken and aspirationalas we are currently but what's importantto point out and many of you that havebeen in this space as long as I havewill know is that AI itself is not newright many of us have been working on AIand machine learning for quite some timeI will say that the advancements thatwe're seeing and the more recent past ornew and Progressive and interesting butthe amount of energy and investment thatwe're putting into AI as a companyis expanding but also not completely newand I want to share with you thistimeline just to give you an idea ofwhen we think back just even in therecent past many of you may know thatthe Transformer the T and GPT if youwill was invented by Google right manyof you have actually probably read thatfamous what we call the Godfather ofpapers around artificial intelligenceand if you want links to these resourcesfind me in the team afterwards but whilewe've been deeply investing inunderstanding Transformers for examplewe didn't just stop there we'veobviously been spending a significantamount of time in the AI space that'swhy we have thousands of researcherscreating and Publishing thousands ofresearch projects code that we'resharing into the community and that isas many of you may know an importantelement of when we think about GoogleCloud not just with AI but in general iswe do believe that being an active partof the community of the open source andof the developer Community is criticalbecause not only will we contribute intothat Community we believe that we alsolearn a tremendous amount so we have amentality that developers and Architectsand data scientists and technologistsare almost an extension of our researchorganization because these people aredoing things that we inside Googlearen't doing and so that bi-directionalsharing of information is something thatwill continue to be a core part of ourDNAnow if we look ahead a little bit I wantin a very simplistic way give you animportant kind of Baseline view of whenwe think about generative AIspecifically now so we're kind of nowtalking about the more modern Conceptsaround AI what we're finding and I havethis incredible opportunity to meet withorganizations of all sizes and all typeson a daily basis is that there is adifference in generative AI meaning notall generative AI is a text prompt basedsearch experience where you're asking aquestion and getting a response back Iknow many of you are nodding and you getthat but what I will tell you is manyfolks even at this conference todayaren't necessarily at the same level ofunderstanding as you are they think thata search oriented generative AIexperience is generative AI theimportant thing for us is while we dothink that's interesting and compellingwe obviously do a little bit of searchyou may have you may have heard of thatside of our business I heard Thomas oncetell a customer that we worked fordecades to create the world's mosttrusted wind window into the internet sowe're going to be very responsible anddeliberate and thoughtful around how weapply generative AI to that experienceand we're going to double down on thegenerative AI opportunity that we seewith businesses with startups withuniversities and with governments and sothe intention of this slide is to justvisually show the types of conversationsthat we as a company are having there'sa commercial oriented search andconsumer oriented business and thenthere's a a startup an Enterprise agovernmental side of our organization aswell where we're asking more targetedquestions where the requirements arevery different and I want to give you aflavor now of what those kinds ofconversations are really resulting inmany of you in the room I would expecthave the same requirements forgenerative AI as you see on this slideand in fact many of you in the room arecreating capabilities to answer thesequestions for companies whether they beuniversities governments or Enterpriseswhen we think about the patterns of whatwe're hearing across the board these arethe the categories of requirements thatwe're hearing from businesses I want tobe clear this is down the business pathyou're not going to be surprised to hearthat the first thing that we hearconsistently the very first discussionI've been having is how do I leveragetechnology like generative AI but ensurethat I have controls and and parametersaround my IP many of us have beentalking about the writer strike thathappened right and that was very much anelement associated with the concernaround AI many of you may know the workthat Google and Google Cloud are doingcurrently with the music industry wherewe're actually proactively leaning in tosay how do we work together to ensurethat inventors and creators areprotected but we also inject all of thatwonderful art into Ai and working reallymore in a collaborative wayfrom a choice and value perspective ourbelief and you've heard this probablythis morning and you'll hear it a lotmore over the next few days is bigger isnot always better we don't believe thatone model is going to rule the world wedon't believe that our model is going torule the world but we do believe thatthe models we build will be one of amultitude of models that you or yourcustomers may end up choosing and sowhat we're doing is not only innovatingin our own model but we're also creatingthings like you may know of our modelGarden where we're going to also provideyou access to the plethora of our ownmodels and the hundreds of Open Sourcemodels that we plan on welcoming intoour platform as well so choice andbreadth and value is another elementthat we're hearing quickly as customersget out of the hype curve frankly andstart asking really really hardquestions the factuality element is keythat goes back to Thomas's point ofwe're creating the world's most trustedwindow into the internet now with AI andso we're working extremely hard onfactuality on toxicity on referenceability the fact that from the verybeginning our generative AI Solutionsboth from a consumer and a businessperspective had a global mindset in mindin fact the old friend of mine sittingin the audience and I were just talkingabout the fact that many of you knowthat building something for the U.Sguess what that may work for a subset ofthe us but we have to build forfactuality for data residency for datasecurity understanding that our customerbase is going to be Global in naturecustomers like yourself and Enterprisesand universities and governments theywant to move quickly so while this isnew and experimental they don't wantthis to feel heavy and burdensome sowe're trying to create on-board rampsrecommended guidance providing the rightpeople and human capital to make surethat we're able to move extremelyquickly and then obviously last but notleast the whole concept of this must besecureso obviously Google cloud has anunderlying core tenet of security at ourcore and the fact that we're able tothink about our platform and providethat security all the way up through thestack is a really important element ofwhy organizations of all sizes areleaning into Google cloud and I'm notgoing to go into extreme detail here butI wanted to just really portray the factthat generative AI for us is truly aplatform play meaning there's a coreelement of core infrastructure all theway down the chips and those of you whowatch the keynote saw we had a specialguest on stage to talk about those chipsthat's important but the the underlyinginfrastructure that's built with thosechips allow us to create a Vertex AIplatform level that allows underlyingdata scientists and Architects to workdown at the model level should they sowant to do so but we also believe backto choice that organizations likeyourself and your end customers willwant to be able to interact withgenerative AI not just that the modeland the llm level but also at theapplication layer and at an API level sothat we can Empower developers to createreally dazzling things really reallyquickly and again in a moment I'm goingto introduce a special guest to talk usthrough some of the real life scenariosof creating incredible developer andTechnology experiencesperfect timing as a matter of fact so Iwant to actually take a moment tointroduce Lin Chao Lin is our founderand CEO of fireworks AI she's going tocome on that's on stage and walk usthrough the problem they're solving andgive you some really great insights intothe actual outcomes they're generatingwith AI so Lynn come on upthank youthank you Darren and thanks Google forhaving me here and good morning everyoneI'm Lynn I'm CEO and co-founder offireworks before I start if I works witha group of brilliant Engineers uh I'vebeen at Mata for seven years mostlyfocused on building Pi torch and as youmay know pytorch is becoming thedominating programming language for AIas well as runtime when we talk aboutGeneral AI especially that's the focusof of everyone on top of everyone's mindhere most of gnm models in Uber Sourceare written in pi torch as a matter offact we flip open AI into fully usingpytorch about three to four years agoand I I guess it helped them acceleratetheir progress towards producing charityBT and gp4 and so on so um what I wantto talk about here isum what we think about the fireworksMission and our mission is to help allof you the product developers to stayahead of a curve in this January AIRevolutionso there's a profound technology shiftthat's happening right now before JaneAIa lot of companies they want to use airmodels they spend a lot of time curatingtheir data cleansing data preparinglydata and always train from scratchwith Gen AI the foundational shift hereis we have Foundation model it's there'sa reason it's called Foundation modelbecause those Foundation models absorbthe public information via internet andthen you can build on top of it forexample you can Infuse your domainknowledge and curate a customized modelspecially focused on Independent domainsfor example Healthcare legal and manyother domains and also in your companyyou may have your company proprietarydata you may have your company's specialslogan and then you can fine-tune themodel of in a specific domain towardsyour company's needs and the Casiocustomized model that way and buildtheir mode that way too and further youcan collect personal data and buildassistant or Avatar especially forindividuals so this is a profound shiftthat's jnai wave is pushing towards thatmeans you can customize air modelstowards your knee with much less datait's much more efficient for products toinnovate right nowso fireworks provide the jni platformespecially we have two functions one isserved where we provide the best servicefor the state of art open source modelsyou might have heard about llama comingfrom Mata there will be continuousstream of neural llama models we areactually able to enable those modelswithin a few hours of the releaseof course our API is very simple it'sopen air compatible if you're buildingon top of open AI or enthropic it's veryeasy for you to switch and use ourservicewe want to take away all your concernswhen it comes to cost and performanceso whether you're exploring your productidea try to disrupt certain landscape oryou are trying to scale product idea tofull production size scale to millionsof consumers you can use our platformeasily because it's I will literallyprovide the best performance becausethey are all python models and thelowest cost to serveand our pricing is very transparent it'sby per token if you don't use a GPUdon't pay for itthen we also offer a tune product uhwhere we actually open source our teamcookbook for you to easily customize useless data to tune your model towardsyour needs and then build your modearound you can easily upload yourcustomized model to our third platformand use the same API to access yourmodelyou can also open source it and haveother people access your model and buildexcellent product on top of itso I want to dive a little bit detailsgive you a little bit flavor of thespecifics of what we offer herefirst our API is very simple and it'sthe stable API it to solve the bestmodels we serve the Llama familiesllama2 families and the recent codellama as well as a stockholder Falconmodels and so onso you can easily access this superstraightforward super straightforwardAPIyou can also use our API to access yourfine-tuned models or other peoplefine-tune models so Wi-Fi tuning is sointeresting because it it givesspecificity of towards solving aparticular problem with a high Precisiona lot of time when you build product youneed that high position you don't wanthallucination you want the model to giveyou a specific Json stream you want themodel to give you specific diagrams thatyou want to actually extract fromproduct logs and so on so there's somany use cases that it's very targetedvery specific for you to build asuccessful product experience and that'swhy we provide very simple to use APIfor to access your fine-tune model otherpeople fine-tune modelsand we give you easy recipes Thecookbook and it's open sources free andyou can use that to fine-tune in Co-opat Google or in the favorite yourfavorite notebook or on your laptopanywhere you want to run it's superstraightforward to to use itBeyond Simplicity we want to reallylower the various of entrance when itcomes to cost so there are two kind ofcosts one is you want to do a lot ofexperimentation to make sure yourproduct experience building on top ofthe models are great and the way youwant to drive a massive amount ofvariance into test the productexperience we don't want you to break abank so that's why during yourexperimentation we actuallysignificantly reduce the cost to servewhen one of the 10 ideas becomeexcellent you hit the part Market fityou want to scale quickly and you don'tworry about scaling at all and again weprovide you the lowest cost to serve foryou to scalejust give it a flavor uh what does ourcustom soup look likeumwe this is just one example of a 7billion model and our four fine tunemodel we are 30 times cheaper than openAI fine tune the model price and the Gapis continue to increase and yeah I thinkthe recent number we compared is 100 20times cheaper so so keep that in mindyou're getting 100 times lower price touse our platformand also we really care aboutperformance right because your productexperience really you know built on topof uh really great performance we have alot of customers they are really drivingInteractiveum product experience for example uhit's a customer service chatbot or it'skind of a very interesting assistanttype of chatbot or it's a codecompletion single line multi-line orit's a diagram generation in real timeso over that's all of those productexperience require human interactionrequires criminal latencyso as as you can see from this diagramwe can provide more than 10 timeslatency reductionfor a model this is just one example ofOpen Source model we are able to drivedown latency across various differentbatch sizes by more than 10 timesbecause again this is a pytorch modeland we build pytorch we load python codewe know exactly how to optimize itthere's another kind of productexperience depending on really highlatency High throughput because you havea lot of job to finish within certaintime frame you want to pump up to put asmuch as possibleuh and we also have special technologyto hyper optimize for multiplierattention driving more than 11 timeshigher throughputso for you to Leverage The Benefitprovided byfireworks weather is very simple API todrive your product development or 10times High latency a low latency andhigh throughput or 100 times lower costyou can start right now usingapp.fireworks.aiand even better it's all free for you tostart your journey build on top of usand I'm super excited to see what youyou deliver and what kind of productexperience you disrupt based on gniand last but not least I wouldum really wholeheartedly think gcp forsupporting us ever since the Inceptionof fireworks gcp have been working veryclosely with with us starting frombootstrapping fireworks by giving usfree credit and give us a lot oftechnical support help us address a lotof technical problems across manydifferent the whole entire stackespecially call out to gke team becausethey have actively seeking our feedbackand address our request very veryclosely I look forward to grow flowerscontinuously on top of gcp and also helpyou scale your business much faster andbetter thank youforeigngreat example of a real worldapplication that ties right back to whatwe had said of choice controlling costsspeed all of those elements comingtogether from Len and the team and Iknow Lynn will be outside following thissession and would be very happy to chatwith you and answer even more questionsso as we round out our time together Iwant to make sure and call out again ther word that you're going to hear a lothere at Google Cloud next remember whatI said we've spent decades earning thetrust of people on the internet andwe're going to continue to deeply relyon the fact that AI requires a lot ofresponsibility I'm not going to readthis slide to you or drain the slide buthappy for you to take a picture or tojust process it on the left are GoogleCloud's values around AI these are notempty words we have mechanisms andprograms we have review committees wehave tooling to ensure that what we'rebuilding ourselves and providing you arethings that adhere to these values andeven more importantly because we believethat incredible outcomes will come fromAI plus humans not AI alone and nothumans alone we will work verycollaborated collaboratively with you inPartnership around these sorts ofmechanisms meaning we want to lean inwith technical migration Stories We wantto give you architectural assistance weactually have a lot of policy guardrails that are published and shared thatwe can share with you directly point youto these resources because again whatcomes with a lot of experience is a lotof landmines a lot of lessons and wewant to make sure that all of us aremaking high quality High responsibilitydecisions when it comes to AInow as you round out and head awaythere's a great code here you can scanthis goes to one of the ways that Lynnherself mentioned that we could help youget started is not only do we have aGoogle Cloud for startups program whichmany of you may know which is providingcredits and support and Architecturalassistance we've recently launched aspecific program around AI for startupslike yourselves that not only are goingto provide some credits to help offsetsome of the cost of using the technologywe're also going to swarm with Resourceswith people with architectural supportand partnership and go to marketassistance as well to ensure that we'rehelping you learn from all of ourexperience and move as quickly as youcan to ideally solve some of these greatproblems that we're all facingwe'd love to get your feedback on thissession as well as throughout the day soplease make sure you use the go the uhmobile app that I'm sure all of you havelet us know how we did let us know whatyou'd like us to improve on and as Isaid please use the startup Lounge outhere as your home base for thisconference one will keep it hydratedwith tons of caffeine and plenty ofwater we'll have some snacks every oncein a while but also we're just going tohave some really cool people likeyourselves talking about big problemstalking about technology and so considerthis your home over the next few daysand I look forward to seeing all of youthere so thanks so much and go have arest a great rest of your day and thanksfor your timethank youforeign"
}