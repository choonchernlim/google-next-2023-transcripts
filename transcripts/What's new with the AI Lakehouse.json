{
    "title": "What's new with the AI Lakehouse",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA105"
    ],
    "video_id": "Uje6T8dPC98",
    "time": "Aug 29 01:00 PM - 01:45 PM CDT",
    "transcript": "[Music]I'm Arena faruko I'm one of the productleaders for our smart analyticsportfolio and joining me today is SteveJared SVP of data and AI at Orange Stevehas been a product and Technologyinnovator across many stored SiliconValley companies like digital magicApple Facebook as well as a CEO of andfounder CEO of a technology startup andI'm really excited for Steve to sharethe journey that his team is on tryingto transform orange with data and AI ona globalscale but before we delve into thedeeper detail as you saw this morning inthe keynote generative AI represents agenerational opportunity to to rethinkhow we interact with the world whetherit's new customer experiences whetherit's um employee productivity on newcategory defining products that none ofus thought were even possible a fewmonths ago just like many of us can'teven imagine a world without theinternet I guess is that a very shortperiod of time we will not remember whatthe world was like without generativeAI every Enterprise in the world isthinking and putting plans on how dothey leverage generative AI for theirdata many are already way on the waytowards that Journey but for many othersit remains a tremendous challengebecause they are not they don't have theright dataFoundation instead their data isdistributed and silos where every singleInnovation project becomes a complexdata engineering project moving dataaround duplicating data and trying toconnect different systems with differentmetadata and Technologies together tomake the data available to their usersin their tools ofchoice Google has reinvented the waycustomers use data and information andour Google cloud data and AI cloud istrying to do the same for your data andyourAI with the same Simplicity securityintelligence and scale that you're usedto across our otherproducts it starts with getting you onthe right dataFoundation unifying all your datairrespective of where it is giv you theflexibility to use the best tools in theecosystem and infusing AI for allpersonas for the end to-end workflowsandsimplification so has anybody here heardof a lakehouse I'm justkidding lake house is a foundationalindustry term to describe theconvergence between data Leakes and datawarehousesthat convergence is foundational for theNext Generation Innovation around dataandAI it's less about the underlyingtechnology it's more around theproductivity gains and Innovation thatyou can achieve by getting onto thatunifiedarchitecture here at Google Cloud westrive to give you the best platform tobuild your AI Lakehouse that has fourkey componentsone unifying all your data structuredunstructured badge streaming here onGoogle cloud or beyond the boundaries ina cross Cloudfashion given you the openness andflexibility to store your data in anyopen format and use the best of Googletools as well as from the open-sourceecosystem to help youinnovate as you build your platformgovernance and especially data to AIgovernance plays a critical role to makesure that you can inovate in a fastsecure and responsiblefashion and last but definitely not theleast is activating your data with AIwhether it's making your data seamlesslyaccess accessible to your genapplications on making your us end usersmore productive with duet Ai and AIactivationthere this platform is allowingcustomers like dun and Brad street tounify data lakes and data warehouses andbring rapidly new generation ofself-service datadriven capabilitieswhile improving their performance theperformance of their analytics by5X let's take a look at some of theexciting new things we're announcinghere atnext one of the first foundationalcomponents of our lake housearchitecture is Big Lake a unifiedstorage layer for all of your structuredand unstructureddata today we're announcing Generalavailability of support for Iceberghoodie and Delta in Big Lake with finegrain security and performanceacceleration we are also announcingmanaged tables for a Pache Iceberggiving you high throughput streamingingestion storageoptimizations and DML all whilemaintaining full Iceberg Ritacompatibility as you can see big lake ispretty unique in the industry in thefact that it gives you full flexibilityin storing your data in the rightformats open formats that you choose bygiving you security and performance atGooglescale what we've done here is we'vetaken the learnings from running Planetscale systems with big qu and broughtthose learnings around securitygovernance data management two openformats so we remove the unglamoroustasks of data management M andengineering and let you focus simply onusing yourdata another capability that I'mparticularly excited about is thegeneral availability of object tablesfor all of your unstructured data likeimages filesaudio now you can seamlessly combine inyour analysis structured andunstructured data prepare your trainingCo Corpus for AIapplications and seamlessly integratewith document AI for an endtoend datatoaiworkflow many of our customers arealready seeing Big Lake astransformational to theirapplications take for example DeutscheBank who seen Big Lake astransformational for their risk systemone of the largest in the world andreally is one of the core technologiesthat will Define the impact that cloudcould have on um on theirapplications the other set ofcapabilities we're announcing aroundstreamlining your data to AIworkflow today we're making availablellms and specifically vertexfoundational models directly frombigquery while col an llm from mqu maynot be as big of a deal but doing thatin a full secure scalable and compliantfashion where your data remains withinthe boundaries of your securityperimeter is reallyimportant we also announcing the ga ofbqu inference engine so now you can runlarge scale inference of our Googlepre-train models or any of your ownmodels in tensor flow Onyx or XG boostformats all with familiar tools likeSQL embeddings moving on to embeddingsone of the most powerful Concepts inmachine learning we are now bringingthat capability to bigquery in scalableand securefashion now you can build nextgapplications like semantic search andrecommendation systems as well asseamlessly and at scale do llmfine-tuning and last but definitely notthe least in this set of capabilities isthe big query data frames for all thepython developers out there giving you apython API that's psychic learn and uhPanda compatible add big query scaleright parab scale all all from the sameenvironment as you unified your data andyou streamline your data to AI workflowwe're also helping your userscollaborate more seamlessly in bigquerystudio a unified workspace for your dataEngineers data analysts data scientiststo collaborate using their language ofchoice or framework of choice whetherit's SQL python JavaScript or evennatural language all integrated withyour SQL pipelines and umum uh sorry and uh data quality andlineage all embedded to help give youthe trust and the intelligence aboutyourdata and lastly as you saw on thekeynote stage we're bringing duet AI toall all the data analytics products bigquery and looker and datax and otherscoming soon across spark beam and airfflow what this allows you to do isreally making your users much moreproductive in the context of theirexisting workflows let's take forexample in bigquery now I get powerfulcapabilities around SQL generation autoccompletion as well as I cited assistantto help me understand the capabilitiesand help educate me on the best way touse thesystem as you leverage all thisintelligence across your data Suite oneof the most foundational things that youcan do is make sure you're operating onthe right data to AI governancefoundation so your users can innovatewith the right data in their tools ofchoice without compromising on yourpolicies and your governance guardLS with data Plex we have been leadingthe market around centralized managementand governance and in fact over 70% ofto analytics customers I using data Flexto simplify the management andgovernance of their integratedplatform it provides unified metadataacross your distributed data centralizedsecurity and policy management M anddata intelligence with automatic lifecycle management data lineage and dataquality and today we're excited toannounce that we extending data Plex tovertex AI models and data sets so nowyou have a single integrated always oncatalog that has all of the metadataaround your entire platform from data toAI that really serves as a foundationfor Providence for governance and forstreamlined workflows for all of yourusers across theirtools but governance doesn't stop at theboundaries of Google cloud and we'veintegrated datax with bigquery Omni andbig lake for multicloud governance wherein areas where you have bigquery uh Omniyou will now get a centralizedcatalog a centralized ability to applypolicies an endtoend lineage as yourdata moves across its lifecycle we're also excited to announce thegeneral availability of data plx dataquality andprofiling we've brought a lot ofintelligence in automation to reallysolve the age-old problem when you'resitting around the table conferencetable and somebody says I don't trustthat data point and the whole meetinggoes off therails it's one thing when there thereit's a bunch of humans sitting in themeeting and in other ways it's whenmachines have to make decisions andmaking sure that you can automate andthey're operating on the high qualitydata with data Flex data profiling inquality we will automatically profileyour data we automatically generaterecommended rules and we execute themand surface them to the users in theirtools of choice so let's say that I'm auser a data engineer working in bigquerystudio trying to perform some analysisof build a pipeline in context I can seethe quality of that data the informationabout that data and helps me gain trustand intelligence about thatdata another capab ability that we'reannouncing today is the extension of ourdata lineagecapabilities lineage Providence iscritically important to build trust inyour data but use it as a foundation forcompliance and perform impact and rootaroot causeanalysis we've had for a while thecapabilities for lineage and biter aswell as our pipelining tools likecomposer and now we're extending lineageto Apache Sparkso you can see endtoend lineagecapabilities across your entire datalife cycle but we also know that yourecosystem doesn't stop with Google Cloudproducts and so today we're announcingthe support for open lineage apis whereyou can integrate dataplex lineage withany open source system or any systemthat supports open lineage and see itwithin the same intelligent graph inyour current and existingworkflows but all of these capabilitiesare just beginning in thefoundation how do you then solve whatwe're focused on and especially with dAI is how do you solve the ageold coldstart problem how do I even know whichdata I should be looking for or whatquestions I can ask of mydata this is why I'm excited to announcethe AI capabilities in datax where wewill automatically surface the questionsyou can ask your data based on ourunderstanding of the metadata that youhave as well as usage patterns forpopular queries that you have uh thatother users are using within yourenvironment then we will use it as acontinuous feedback loop for your usersto provide feedback on how useful thiswas to them as a starting point and thenstart their analysis and use that as ajump off point there we're really hopingthat many of you will provide usfeedback on that capability to helpDrive the next level of innovation formetadata powered insights anddemocratizing yourdata I've talked a lot about the coolnew capabilities around our na productsbit query datax uh you heard aboutVortex aai but we also have alongstanding commitment to open sourceand from the analytics side that hasbeen a tremendous commitmentspecifically to aachispark we are committed to for GoogleCloud being the best place to run open-Source spark with the industry leadingpriceperformance over the past year we'veinnovated tremendously to improve theprice performance of Open Source parkwith many customers seeing 50 to 70%Improvement within their existingenvironments we've also innovated on thecustomer experience serverless sparkgives you a true serverless experiencefor aache spark across allworkloads today data engineers anddevelopers spend over only 40% of theirtime writing code and instead 60% of thetime managing infrastructure and all ofthe glue that comes around it we'vedramatically simplified that withservessspark and today I'm excited to announcethat we're extending servess spk fordata science with servus spark sessionswe're providing coste effective andrapid development for data scienceworkloads across vertexAI across your own Jupiter notebooks andas well as partner Integrations that arecoming soon with hex and deepnote as you heard in the keynote stageearlier this morning we're also deletingServo spark service to integrate withNvidia for both performance accelerationand costsavings everything we've talked abouttoday has been focused on analytics inthecloud but we also know there's a set ofLeading Edge use cases that span TheEdge and the cloud right those could bein retail manufacturing FinancialServices where the amount of data you'reprocessing in the edge sometimes is solarge that you you have to make adecision before you can make a roundtrip to the cloud or there are caseswhere you have data sovereigntyrequirements where you are not able tosend all of the data before youpre-process and anonymizeit this is where Google distributedCloud comes in Google think of Googledistributed Cloud as a true extension ofGoogle cloud in your own data centerwith a single unified control plane andmanagement plane letting you rundistributed applications across data andAI that makes sense for yourbusiness and today I'm incrediblyexcited to announce that we've extendedour spark offering to Google distributedCloud you can now run a fully manageApache spark on Google distributed Cloudyou can pre animize on anonymize dataaggregate data or truly run distributedworkloads across data and Ai and thatenvironment and with this I am delightedto welcome Steve to the stage to shwho's been a key launch partner for alot of these capabilities to share thejourney they've been on at Orange thankyou Steve thanks Serena and thanks somuch for the great partnership betweenour engineeringteams orange is one of the world'sleading Telecom providers we offerservices in 26 countries that you seehere on the map ranging from our hostcountry France to countries like Egyptand Morocco and and the DemocraticRepublic of Congo and so the breadth ofour challenges is really extreme andI'll talk more about how we're workingwith Google to solve some of those as acompany we're known for a lot of ourCutting Edge contributions to Telco infact a lot of the power saving modesthat are in 5G are there because Orangehas cared about those kinds of issuesfor many many years and we'recontributing to Future versions of thesefundamental Technologies like6G but we also have a longstandingfundamental commitment to Pure researchin fact in my own team we have 50 peoplethat are in the pure research teamworking on data in AItopics the way that we like to describeAI at Orange is that it gives us superpowers to our employees to our networksand to our customer interactions and wehave already many high impact use casesin those domains mostly where thebusiness has a lot of capex and Opextoday where we see data and being ableto bring a lot of efficiencies andimprovements in those domains so forexample in Reinventing the customerexperience we use AI today todramatically improve the the offers thatwe're providing to people the the theinterest of those offers we're alsoworking to improve our call centers byusing generative AI to live transcribethe call with the consumer and you canimagine across our 26 countries how manydifferent languages were're were wefaced with on a dailybasis and the idea that we can livetranscribe that call with AI and thenuse the AI to prompt the call centeragent with suggestions of what to how toresolve the customer's problem we canthen use AI to summarize that call forfor storage but also we can autogeneratea follow-up email that could be veryuseful you know helps the customer agentsave time to create that email that cancover the topics that they covered inthe call as well as suggested items forthem to solve their problem longterm in operating efficiency we're usingAI uh large language models as aninterface to a lot of the really complexdata we have today in the company and infact we we find that pairing a largelanguage model with a knowledge base isvery very powerful and then lastly interms of ournetworks across all 26 countries we'regenerating over a petabyte a day of justthe Telemetry data that's coming off ofthe equipment so being able to to workwith that data is is a reallysignificant problem but the idea that weuse AI to do not only predictive Networkmaintenance but also longterm toidentify the root cause of the problemso you can imagine how many cell siteswe have in the field so if we can use AIto determine an advance of the truckrolling to the cell site to identifywhat the problem is that can help sendthe right technician with the rightequipment and also save a lot oftime so we've been on thisjourney of trying to improve the waythat we work with data ni across all ofour businesses and we started with thesevery diverse requirements and in factinside of each country what we had ismany times the operating business unitwould create their own data stack and sowe would have a silo a data Silo fromthe marketing team or the finance teamand the networks team that reflectedthose organizational silos and so thecomplexity was extremely high and eachof those ecosystems had their ownprocess data model and so on and so theresult was that as Arena was saying theteams were spending all of their timejust managing the data infrastructure asopposed to focused on on generatingvalue for thebusiness then we attempted to build andintegrate our own infrastructure thatwas very kubernetes Centric and we foundthat it's not just another it workloadthere's lots of complexity aroundidentity and access managementcompliance security and and and and sowe learned very quickly that we neededto have a really strong partner and sowe choseGoogle we also found that because of thedynamic uh how fast the AIinfrastructure business was moving thefact that we were working with fairlymonolithic vendors was also a bigproblem so we needed to have a partnerthat was ow us to to use much more openTechnologies and move muchfaster so in terms of our ambition wewe're we're working towards this muchmore modular plug-and-play architectureand the idea that we can leverage bothopen source am AImodels open data Technologies but alsomanage services like the spark uhoffering that Arena mentioned is verypowerful for us and the fact that we canrun this now on GDC Edge gives us aninfrastructure on premise where we canmanage the data in a way that saves us alot of cost because the data that we'regenerating is so large that we need areally sophisticated way to filter thatdata before we would send it to publiccloud and the fact that with GDC Edgethis infrastructure isuniform and so we can have uniformmeasure management of these systemsbetween what we have for gcp in thepublic cloud and what we would have onPrem is verypowerful and also the fact that theseregulatory requirements we have fromcountry to Country they change over timeand so again having a fairly flexibleinfrastructure to respond to those isextremely useful forus so to give you a Peak at what thisarchitecture looks like on the left handside you have all of our on premisesystems that relate to these differentbusiness units and their datasources and then in the middle we havethe bridge of GDC Edge between our onpremise systems and and and the pubcloud and there you see our ability torun not only things like uh like thespark manage instance we can also run AImodels there we can do inference of AImodels there and manage it with airfflow the data comes from our onpressPrem systems into Google cloud and therein a very secure Zone that's where weoffer and build data products and thenthe data is consumed by the differentbusiness units in the sharing layer andwhen they generate data that they thinkis useful to be shared with other teamsit's written back to the secureZone and at the bottom you see the dataOperation Center so we work with calbrato provide business metadata across allof our systems not just the ones thatare residing on Google and also aMarketplace and for us this vision isreally fundamental to our strategy theidea that we have a marketplace whereyou can discover data and consume datais really really um it's we have todramatically open up the access to dataacross the business and the fact we havethese data protection um dashboards andalerts that are provided by dataplexincluding much improved dataobservation and this Federatedgovernance that can help us manage thedata whether it's on Prem or whe whetherit's in in GoogleCloud so we're on this journey towardsthis vision of a data democracy and forus a data democracy is not an anarchy ofdata it's a system where we have rulesby which are that are enforced usingpolicy ascode and within thatenvironment the user has a lot offreedom to get the job done with data sothe first point is this idea that Imentioned before about breaking downthese silos that we had that map theorganizational silos so now we can haveavailability of data across thesedifferent business teams andunits the second as I mentioned was thiselegant management between what's on PRand what's on public Cloud our existinginfrastructure that we inherited in manyof these countries the architecture isvery very inflexible especially betweenthese business units so having this bereally elegant between on Prem andpublic cloud and having uniformmanagement infrastructure is reallypowerful and this D this dynamism allowsus to respond to things that areunexpected so for example let's saywe're training a new AI model and wedon't know what data is predictive andso the idea that we can send a we cansend for a relatively short period oftime a large amount of that data topublic Cloud for modeltraining then we can deploy the modelsback down uh in country to be run oninference on this GDC Edgeinfrastructure is really reallyuseful but also let's say we encounteran unexpected event in the network wherewe have a a failure in the network andagain you know given that we'regenerating across the company over apetabyte of a day of just the Telemetrydata in a country where we have aproblem we can send a vast amount ofthat data to public Cloud for trainingwhen normally a lot of that data wouldbe aggregated or or even deleted overtime and the only way to do this reallyat massivescale is to use policy as code and sothe way that the fact that we can usethis this at a role based approach uhwhere we can ensure that users who haveaccess to certain data are are doing theright thing and also that we have theability to observe their operationsreally helps with compliance and alsodramatically reduces our security andprivacyrisks one of the things that I don'tthink has been mentioned yet at the showabout GDC Edge that's interesting isthat one of our concerns from a lot ofour Regulators was uh what data waspassing between the public cloud and thesuppliance on premise and so Googleprovided us with an open-source proxycalled The Boundary proxy that we canrun on Prem and inspect everythingthat's running over the management planeand so if we see something unexpected wecan sever the connection between theappliance and the and Google cloud andbecause the the control plane of GDCEdge is running locally the appliancecan continue to operate and it canoperate for as long as we need to tothen correct the problem uh and thenreestablish theconnection so the fact that we can havethis uniform architecture the fact thatwe can have this environment to run AImodel inference but also have our ownfirst-party or open- Source dataTechnologies we can Leverage The manageservices from Google and we expect tosee more and more of those over time andin fact we also believe that this willbecome a really thriving ecosystem wherewe'll have many more services comingfrom people like you and the audiencethat we can pick and choose from and sothe idea that our on premise data and AIinfrastructure becomes this reallyflexible relatively easy to manage uhenvironment is really a breakthrough forus in terms of Elegance and simplicityand it also dramatically reduces thecomplexity of the training that we needto provide to ourteams uh you know one of our challengesis that we have very very good dataengineering resources in all of thesecountries but with Antiquatedarchitectures they were spending all oftheir time just keeping the lights on onthe infrastructure as opposed to addingvalue and lastly the fact that we canuse this architecture to really rapidlyrespond to changing requirements thatare that come from our Regulators acrossall of our countries uh was reallyfundamental to us so Arena thanks againfor helping us towards this our journeytowards a data democracy and also togive superpowers to everybody at Orangeand uh what do you want to do next wellthan Steve and thank you for thepartnership I'll go with a fewunscripted questions maybe okayum you know it's so impressive with whatyou and your team have been able toaccomplish in such a short period oftime and we all know theseTransformations are like I would want totake credit for all the products I builtbut I know a lot is about people andprocesses sure internally and havingsuch a large distributed organizationand driving change at this rapid PaceI'd love I think all of us probably inthe audience would love to hear whathave been the true keys to drive thatchange armit technology that we havehere that's a great question so we did afew things the first is we chose atraining partner we chose corsera we usetheir tools widely across the wholecompany and we make those available toeverybody on an unlimited basis that wasreally fundamental the second was we'revery very transparent in the way that wework with one another so all of the workthat we do so for example all of thecloud foundation work we did with forgcp we share all of that work and we'revery transparent about our metrics sofor each of the projects that Imentioned we have really clear kpis thatwe've defined across the companies andwe share our successes and failuresopenly on a very regular basis so thatallows the teams that know that one teamfor example poer in the front row fromPoland they've done a particularly goodjob in a number of domains and the factthat we're so transparent about thatallows the different leaders across all26 countries to reach out for for helpum so I think it's really a balance ofbeingmeasurable uh and transparent at thesame time and that's enabled us to movea lot faster than we were in thepast"
}