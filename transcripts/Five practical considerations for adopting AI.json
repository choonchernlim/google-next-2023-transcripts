{
    "title": "Five practical considerations for adopting AI",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML108"
    ],
    "video_id": "UWSrGccNaFA",
    "time": "Aug 29 02:15 PM - 03:00 PM CDT",
    "transcript": "foreign[Music]hi everyone thank you for being herewe're living in a very exciting timewhere AI truly has the potential totransform all Industries and we not onlyget to be a part of it we get to driveitand this technology is being adopted atan unprecedented ratein my role I'm very fortunate to get totalk to a lot of customers and one ofthe key things that they ask is there'sa lot of hype around generative AI butwhat's truly going to add value to mybusiness and what should I consider informulating my AI roadmap and that'swhat Keelan and I will present on todayso first we'll touch on customerexamples of where they saw value from Aiand then we'll go into these fiveconsiderations which are how do youselect your use cases how do you createa culture of experimentationmeasurements and improvements securityprivacy and responsible Ai and thenfinally putting machine learning modelsin production at scaleI'm Donna I lead the Technical Solutionsmanagement team for generative Ai andlarge-scale machine learning and ourteam builds AI Solutions using GoogleCloud products and my co-presenter isKeelan hi everyone my name is KeelanMcDonald I'm a product manager on vertexgenerative Ai and I'll be returning injust a moment to talk a little bit aboutexperimentation measurement andresponsible AI but first Don is going totake us through some customer use casesall right so to start with the businessvalue that AI can createtypically companies look to improveeither an existing workflow this mightbe a rules-based engine for example orsolve a new problem that couldn't besolved before maybe just due to thesheer amount of dataso I'll give three examplesfirst a large consumer packaged goodcompany is using AI to get new insightsin the past the product composition ofvending machines was determined by theirsales representatives based off of theirexperience and intuitionbut the company wanted to take a moredata-driven approach so they built aplatform to predict the performance ofhundreds of thousands of vendingmachines and it led to new discoveriesthat couldn't be seen on a map aloneso for example the model predicted alocation which you know seems not to beuseful but then when they went therethey found out it's actually a GatheringSpot and it turned out to be a greatlocation for a vending machinesecond employee productivity so adigital native that creates personalizedexperiences for millions of buyersaround the world using state-of-the-artsearch recommendations and ads move tovertex our end-to-end machine learningplatform and in doing so they're datascientists and Engineers were able tocarry out twice as many experiments andthey can prototype new architectures ina matter of days instead of weeksand finally Innovation a largepharmaceutical company is exploring howalpha fold on vertex can help thecompany more accurately predict proteinstructure predictions minimizing thehigh ratio of failure from moretraditional methods and speeding up theability for researchers to conductexperiments on Google cloud and this inturn will accelerate the drug Discoveryprocessforeignso now I'm going to show you a prototypethat my team built in a matter of weeksusing Google Cloud products likebigquery looker vertex AI with an opensource UI framework and it demonstrateshow developers can use generative AI inEnterprise applications in this case tosupport a marketing teamand it was built with three personas inmindso let me try to use the pointer here itwas built for Mary the analystwho wants to get insights from thespirit data sourcesfor ciao a content creator who wants tocreate content for multiple digitalchannels and then Amani who is acampaign manager who is responsible forformulating building campaigns and thenalso optimizing campaigns and togetherthis team has been tasked with launchinga campaign for a new men's shoe line atsymbol retailall right so first they're going tocreate the campaign brief and campaignfolder for symbol retail the new men'sshoe linethey have their targeting inputs intothis case men between the ages of 30 and40 with the objective to drive awarenessand you can what you see here is thatvertex Palm 2 is actually generating thebriefand you can see the budget timeline callto action communication channelsand then this can then be exported forfurther collaboration and editing beforeit gets sent for Mary the analyst willshow how she can get analytics andinsights so first there's a variety ofways to build marketing data foundationson Google Cloud as she explores herlooker dashboards as a single source ofTruth across CRM data for exampleanalytics data and website data and shemight also have some predictive modelsfor example for her audiences in thiscase she wants to see the propensity topurchase predictions she can explorethemand here you can see you've write thecohorts that were generated usingbigquery machine learningnext you might have some more questionsabout our audiences and so she previewsthe data Within bigqueryand she has some questions that shewants to see so she's going to ask forthe customer emails ordered by some oftransactions and now you'll see thatCody is actually generating the codeexecuting it and also returning a resultand so this really assists her in herability to analyze data so next Trendspotting this is the public GoogleTrends data set you can seeand she wants to see what are the topSearch terms on the specific dates sohere she looks specificallyfor the 18th gets Eagles or she may wantto summarize news using large languagemodels in this case the keyword isfashion and you see the title andsummary returned and lastly she wantsconsumer insights in this case theretail trends for 2023and you can see the think with Googleresults returned it could also beconsumer reports and this is powered byvertex searchnext ciao wants to create content acrossa multitude of different channelshe starts with email copyand in this case it's based off of theinsights from Mary the analyst so he'sgoing to generate a few samples just toexperiment and seeand you'll see that the text again isbeing generated using vertex Palm 2. andthe images using imagine and their emailhas been generatedas well as translated to the preferredlanguage from the data that you sawearlierbut probably you don't want to do thisone by one and so you can also do thisin bulk either based off of cohortinformation or audience information andhere you can see the emails again beinggenerated using vertex foundationalmodelsand then it's submitted to the campaignfolder next child creates a website postagain the text generated using Palm 2and then different images using imaginechild selects the one that he likesand then adds it to the campaign foldernext he wants to create the social mediaposts so he's going to create a post forThreads again the same target audiencein this case he doesn't need an image sohe decides not to generate an imageforeignthread is created added to the campaignfoldernext child creates an Instagram post andmaybe in this case he doesn't want togenerate images he already has an imagethat he has at hand that he likes so hedecides to upload it instead the text isgenerated for Instagramand then he uploads an image of leathershoesbut sometimes you get different insightsright sometimes Consumer Reports show adifferent color works better and somaybe he wants black leather shoesinstead and so he can actually edit theimage for black leather shoes and itdoesn't have to be that the color of theshoes is changing the background couldchange or additional things could beadded to the image itself then you cansee here that the image was edited weaddedagain to the Instagram post and then tothe campaign folderand then Chow creates assets forperformance Max a Google ads AI poweredcampaignit's generating the headlinesdescription call to action images andthen added to the campaign folderand then all of this is shared withAmani who builds the campaigns and isoptimizing it and she can review it soshe looks at the campaign folder all ofthe available assets are shown she cansee the text edit the text double clickon the images to see if she's happybefore she activates it in this case toGoogle ads or across a variety ofchannels she can upload all of theassets generated to Google drive to beable to store and organize itand then also share and collaborateand also generate slidesas well as docs for furthercollaboration assisted by duet Ai andyou can see the presentation here aswell as the creative brief that wascreatedand then Amani wants to optimize acampaign performance so she actuallyseesthe same single source of Truthdashboards thatmarry the analystsshe wants to understand what are thebest practices for performance Max soshe asks the ads helperand this is powered by vertexconversationand here it returns an answer as well asa link with more information maybe shealso has some questions on Instagram andso she's asking how to optimize reachand again it returns a result and sowith this the team was able to launchthe campaign in a matter of days insteadof months and if you're a developer andyou're interested we actually releasedthe source code on GitHub for you to getstartedso how do you get started with your AIroadmap it starts with use caseprioritizationbased on our experience we'd recommendlooking at three things the first isbusiness impact and this very oftencomes down to the bottom line are thereincreasing revenue or decreasing costsit could be more indirect for examplelike boosting employee productivity soyou might want to look for a use casewhere there's a lot of manual overhead alot of repetitive tasks and then if yousolve that problem with AI then it'llmake the work for that employee moreinteresting for example more creativemore strategic and could help reduceattrition it should be a use case aswell that has enough business impact toshow value but also not so critical thatit becomes a really big riskease of implementation which impacts thetime to Market often depends on theavailability and Readiness of data aswell as the difficulty of themethodology used the new project or onethat's in a proof of concept stage mightbe easier than one that's already inproductionand then lastly the capabilities builtand this one often gets forgotten so wedidn't encourage you to look at a usecase which is maybe a repeatable patternacross the business so for example maybeyou have propensity models that youcould use within each region as well asthe technical capabilities that you'rebuilding so for example if you'recontinuous training or continuousmonitoring capabilities that would applyto multiple different use casesand in doing this it's very critical tobring together the business stakeholdersas well as the technical stakeholders todefine the use cases as well as whatsuccess looks likehowever you can't plan for everythingespecially in such a quickly movingfield and therefore it's critical toexperiment and iterate and with thatI'll hand over to Keelanall right so experimentationis hard it's probably not a stage thatanybody looks forward to but it isessentialso why do we need to experiment whenwe're building AI productstypically the reason is because it'shard to get right the first time and thereality is that with traditional AIproducts experimentation was reallydifficult you had really long timelinesyou needed a lot of data to get startedyou needed PhD level experts to iterateon the models you can see here there area lot of stages and each of those stagescould be many many months so you'relooking at a prettypretty long roadway until you're gettinginto productionthe good news that I bring to you todayis that generative AI has reallydisrupted the way that we experimentwith AIso you can see here on the chart thatthe great thing about generative AI isyou can get started with very smallamounts of data and very powerfulpre-trained modelswhat this means for you if you'regetting started on your AI Journey todayis that you don't need long preparationyou don't need large teams of expertsyou just need an idea about what youwant and the creativity to implement itwith some of the tools that we're goingto talk about todayall right so what does it mean toexperiment with a foundation modelthere's a few different paradigms thatyou can think about when it comes toexperimenting with Foundation models sothe first one is using fully fine-tunedmodels so experimenting with differenttuned models so these are models thatare designed to do a specific task likeimage generation translation chat someof the instances that Donna just showedyou the nice thing about thesepre-trained models is that if you have aspecific workload that you want to runyou can just try lots of differentmodels that are available on vertex soan example of this might be let's sayyou had a bunch of images and you wantedto detect whether a car was in the imageyou could browse through vertex find anumber of different Vision models runthose workloads against those Visionmodels and see which ones have the bestoutcome for your use casethe second way that you can experimentwith llms is through parameter efficientfine-tuning so when you hear the wordtuning you might thinkbig data sets to retune or fine-tune amodel but with parameter efficientfine-tuning you're actually just feedingit a couple hundred prompts to getstarted so this tuning has very lowoverhead you're just creating an adapterlayer in front of the model and it helpsyou to experiment very very quickly foryour use caseand then perhaps easiest of all is justsimply refining your prompts so Donnajust showed a great use case of aninstance where we were using prompts tocreate different types of content andyou could see that those prompts werejust simple sentences or requests to themodel if you're operating in thatParadigm just adjusting the languagethat you're using to prompt the modelcan often drive very very differentresultsall right so it rapid iteration ispossible with generative AI so this is areally new paradigm for the world ofAIMLand the best way to think about this isthat you can start by adaptingFoundation models with adapter tuning orfine tuning so these are easy ways foryou to tune the model for your specificuse caseof course if you're thinking more at theproduct level and you want to understandif the output of the model is resonatingwith your audienceyou can also Implement a b testing foryour products whether your users orcustomers or your own employeesand then finally you're going to want tocompare and measure the results againstyour traditional workflows and processesso as Donna pointed out earlier a lot oftimes AI use cases are either replacingexisting workflows or augmenting thoseworkflows so you want to you're going towant to make sure that whatever resultsthat you get from your experimentationhave comparable ideally better resultsfrom whatever traditional softwareparadigms that you're usingforeignso you've done some experimentation andnow you've got a lot of data hopefullythe next phase here is going to bemeasuring the output of your experimentsand actually driving improvement in yourmodels and your AI Solutionsso there's a few different uh steps tothink about in terms of measurementnumber one is accuracy curious and sothis is a tricky topic with generativeAI compared to traditional AI which wasmore deterministic but when you think ofaccuracy you really want to think aboutgrounding in the truth of what yourgoals are so obviously accuracy forCreative Marketing content might be alittle bit different than accuracy forobtaining facts or doing a certain typeof summarization of business stocks soyou're going to want to Define whataccuracy means for your use casenumber two is business impact so is thissolution impactful to your business doesit truly solve a problem improve aprocess add Revenue lower costs allthose kinds of things for every use casethose those goals might be verydifferent but you're going to want tomake sure that you have those defined sothat when you get that data from yourexperimentation you can compare thoseresultsand then finally efficiency so obviouslyone of the magical things about AI isthat it does things quickly and it umreally astronomical scale compared to alot of human processes but you want tomake sure that whatever your AI solutionis it makes sense for your business froma cost efficiency perspective soum all of these jobs uh you know requiredifferent types of scale you're going towant to make sure to understand thatyour solution fits into that frameworkfor youall right sothere is a path of measurement along AImodel development and I wanted to spenda minute to just take you through thispath it looks a little scary becausethere's several different stops alongthe way but the good news is that eachof these steps are pretty well definedand pretty easy to follow if you knowwhat you're looking forso the first thing obviously as wetalked about is picking a pre-trainedmodel and if you're experimenting you'reobviously probably going to pick a fewmodels to comparenumber two is going to be tuning so thatyou can compare the results of your basemodel with the results of your tunedmodelnumber three is going to be thatoptimization step so you see the datayou compare it to the benchmarks thatyou want and you continue to tune orswap out new models until you get theresults that your business use caseneedsvalidate so again going back to thataccuracy step making sure that you'regetting what you want based on themetrics that you've defined for yourparticular use caseand then finally you're ready to deployyour models now I want to say that itends at deployment but there is one morestep which is once a model is inproduction you want to have ongoingmaintenance and monitoring luckilyvertex makes that super easy but one ofthe things that's important aboutdeploying a machine learning modelwhether it's generative AI ortraditional AI is that you want to makesure that you have that monitoring inplace so that you don't getundiagnosed SKU or direct from yourresultsall right so I want to acknowledge thatgen AI evaluation can be challenging soas magical as some of these LMS arewe're still in a world where the metricsaround gen AI accuracy are being definedso I want to kind of recommend a couplesteps for you to be more successful withyour gen AI evaluationso number one is identify the data thatyou're actually testing with so Istarted this presentation by bringingyou the good news that you no longerneed you know massive data sets to trainmodels and that is absolutely true butyou do need some test data so that youcan compare the results in the modelseither compare base model results withfine-tuned results or compare theresults of other processes you've usedin the past with the results of the llmsand again you don't have to have thatmassive data set but you do want to havea data set to test with so that you knowyour results are in line with your appwith your outcome desirednumber two Define your metrics and againthis is one where there's a little bitmore onus on the user than on fromtraditional ML paradigms and that'sreally because as I mentioned earlierthe metrics are still being defined inthis space so generative AI is startingto kind of coalesce towards some commonmetrics such as Rouge for summarizationbut for many types of content thengenerative AI is going to produce thereare no particularindustry-leading paradigms forevaluation so a good example would behow do you know if a marketing blog isis good right there's a lot of humanevaluation and human judgment in thatand it's going to differ from use caseto user to company based off of theoutcomes the audience all sorts ofdifferent things so you're going to wantto make sure that you define that upfront as part of your experimentation sothat when you have that data you canreally measure it accuracy accuratelyand then finally narrow your decisionspaceum it can be very easy to be overwhelmedby just the sheer amount of things thatyou can measure uh things that you canuh you can Benchmark against with thesemodelsum as you probably are well aware thereare a lot of new models in the world andthey're doing very exciting things thatbeing said you want to be strict aboutdefining that decision space so that youdon't get kind of stuck in analysisparalysis you'll know your businessyou'll know your use case make sure tokeep that decision space tight and it'llhelp you iterate as quickly as you needtoall right and then finally we're goingto talk a little bit about securityprivacy and responsibility so this isnot unique to AI this is foundationalobviously to all software developmentbut with AI comes uh you know differentsorts of considerations when it comes toprivacy and responsibilityall right so you're you're on the fourthstep here you've identified an amazinguse case you've done yourexperimentation you've done yourmeasurement you're ready to deploy thisis fantasticbut you have to make sure that you havethe right security posture and the rightresponsible AI postureum for us at Google Cloud that spansfrom data governance to securitycompliance and support to reliabilityand sustainability and then of course toresponsible AI so the good news is thatas a Google Cloud customer you areinheriting those standards from us asyour infrastructure provider we arePartners in this journey to provide safeand secure AI that being said there aresome steps that you'll also need to takeand to implement Your solution and we'lltalk a little bit about what thatpartnership looks like in the next slidehereall right so as I mentioned the goodnews is that the responsibility in theAI space is a shared responsibilitybetween about and our customers and sowhen you build your Solutions on Googlecloud or you use Google Cloud AIServices we're going to share thatsecurity responsibility with you and soreally what that means is that we'regoing to be responsible for the securityand safety and responsible AIpositioning of the underlyinginfrastructure and what we're going toask you to do is be responsible forcreating secure configurationsmaking sure that you have dataprotection in place and of course makingsure that access access permissions andother access or other aspects ofmaintaining your environment are allproperly implemented and we do have alot of grenade and other enablementmaterials if you're working on onfiguring that out for your own projectsum but but you as the owner of yourprojects ultimately are the owner ofthose security policiesand so we call this a shared fate modeland we take it very seriously by reallytrying to be a full partner in thisprocessand so what that really means is thatwe've come up with a framework calledsecure AI framework AK safe which is aconceptual framework for securing AIsystems it's it's inspired bysecurity-led practices common to allsoftware development so things likereviewing testing and controlling thesupply chain and Google applies thisacross our software stack but it alsoincorporates some of the broader trendsthat are very specific to risks that areassociated with AI systems so aframework like safe ensures that when AImodels are implemented they're secure bydefault and so what that means is thatin order to make them unsecure you haveto undo settings that Google provides toyou so you can build secure private AIapplications without expending a ton ofresources knowing that these secure bydefault policies are in placebut of course I've just run you througha number of different policies andrecommended a number of differentpractices you're probably wondering howdo I do this at scale and that's whereml Ops come in comes in so with thatDonna is going to help us wrap up on thefifth step of ml Opsml Ops really enables you to increasevelocity reduce the cost and manage riskat scaleas most of you know it includesorchestrating and automating theexecution of continuous trainingpipelines model deployment andprediction serving data set and featuremanagementand then Model Management and governanceand a few years ago we published thepractitioner's guide to ml Ops whichoutlines the core processes andcapabilitiesbut what's new sincenow with generative AI organizationswill need to evolve their mlopscapabilities to address New Challengesit's still early days for generative AIbut we'll share a little bit about whatwe're seeing and some additionalconsiderations in this spaceso to customize models for their usecases organizations will need to adaptfoundational models to their task asKeelan showed earlier and they'll likelyuse prompt engineering this gives riseto a need for prompt evaluation promptmanagement processes as well as artifactmanagement for in-context learningcurrently we still see pretty much anexperimental approach being applied toother other methods of model adaptationlike model tuning or reinforcementlearning from Human feedback whichentails incorporating human feedback tocustomize and improve model performanceif you think back this is very similarto the early stages of traditionalmachine learning workflowimplementations before the introductionof Frameworks like tfx and kubeflow andwe expect mlops for generative AI toevolve in a similar wayas Keelan indicated earlier we'll needto evolve how we evaluate machinelearning models and manage AIinfrastructure given the computationallyIntensive nature of these workloads andthis is where our tpus and nvidia's gpuslike the a100s and h100s really shineand given the scale cost management willalso become more importantdistillation where a smaller modellearns from a larger model will likelybecome an important aspect of preparingmodels for efficient deployment andsurveying other areas of exploration arehow to get the same quality results froma smaller model and how to lower thecost of running themand then organizations are alsorecognizing that they need additionalguardrails on top of traditional modelmonitoring such as safety filters safetyscores recitation checks data lossprevention they need to monitor thegenerated output and connect toEnterprise data and as these Trendscontinue to advance and other Trendsemerge organizations will need to buildon their existing mlops Investments andtooling to better accommodate these newtechniques and I'd highly recommendwatching the session tomorrow buildingyour mlop strategy for generative AI bymikal and Arenaso now bringing it all togethera customer that's done these fiveconsiderations is Jasper so they built aSAS application on Google Cloud thataims to be the AI copilot for marketersthey fine-tune vertex Palm models formarketing content generation and enableusers to further customize outputs basedoff of their brand voicethey adjust output quality based off ofconstant user feedback and they benefitfrom the security of Google cloud andvertex and their SAS application is alsoEnterprise ready with sock 2 and gdprcompliancefurthermore their AI engine managesmodel fitting and training at scale andso their customers don't need to worryabout mlops Pipelinesand so their customers have seen valuethrough first of all increased velocityof content creation increased engagementon that content and then an overall costreductionluckily they're also one of ourgenerative AI Partners so if you don'twant to build all of this yourself youcan buy an off-the-shelf solution orwork with one of our many other great AIpartnersnow to get started you can take the AIReadiness Quick Check tool is based offof our AI adoption framework and enablesyou to assess your capabilities alongSix Dimensions lead learn access securescale and automate so if you scan the QRcode you can take the assessment it willtake probably only around 15 minutes andwill also give you some recommendationsfor next steps and to wrap up andconclude I'll hand over to Keelan formore resourcesthank youI think I might have lost it over herespeaking of warning I have a fewresources I'd like to point you to todayso number one is our Cloud skills boostpage this is a freely available learningplatformcreated by Google Cloud it has a numberof courses or you can take ad hoclearning sessions but it's a super waysuper helpful way to get started with AIspecifically or with generative AI morerecentlyand we also have published anothernumber of reference architectures andcode samples to help you as a developerget started as welltwo explore so anybody with a GoogleCloud account has access today togenerative AI Studio which is our UI forprototyping UI prototyping generative AISolutions so if you're interested inexperimenting with the Palm model thatDonna mentioned earlier if you'reinterested in experimenting with imagineyou can go there today and startprompting in the in the UIand then finally deploy if you're alittle bit farther along on your journeyand you you know what you want to buildwe have a few opportunities for you todo that todayum if you're ready to go fast we haveout-of-the-box Solutions around vertexsearch and conversation or if you'd liketo work with a partner as Donnamentioned we have a number of AIspecialized partners that can help youget going as quickly as you need tofinally obviously you're all here atnext so you're interested in learningmore about Google cloud and Google CloudAI so there's a number of solutions thatbuild on some of the content and themesthat Donna and I discussed today sothese are a few of the ones that we'drecommend common business use cases forgenerative AIS especially a good one tostep up from some of the more Generalwarnings that we covered in the slidestodayall right and then finally we'd loveyour feedback so um please do uh visitour session page in the mobile app andgive feedback um always trying toimprove for next 24 so I would love tohear what you thought of our session[Music]foreign"
}