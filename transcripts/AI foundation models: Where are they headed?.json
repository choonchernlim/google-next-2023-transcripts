{
    "title": "AI foundation models: Where are they headed?",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML212"
    ],
    "video_id": "qeOKXzdTzQo",
    "time": "Aug 30 11:15 AM - 12:00 PM CDT",
    "transcript": "foreign[Music]thanks for joining us for this panel onthe future of foundation models I'mCarolyn eugic I'm the director of AIservices within Google Cloud Consultingso I'm really excited here today we'vegot an awesome set of panelists here totalk about the future of foundationmodels so while people are stillfiltering in if you could find your seatjust so we can go ahead and get startedbut I'll start by having our panel hereintroduce themselves so starting withyou Eli hium Eli Collins VP product for Googledminemy name is Warren Barkley I run productfor vertex AImy name is Ori Goshen I'm the co-founderand co-ceo of air 21 labsall right well thank you very muchfor audience questions later on in thesession so as we're talking definitelybe thinking about what questions youhave for our panelists herebut we'll start out talking about theevolution of foundation models sothey're evolving at a very rapid Paceyou know we have billions of parametersand now trillions of parameters so arewe observing any sort of Moore's Lawhere or well things keep increasing soOri what are your thoughtsyeah I think the the size of the modeluh is important uh but it's noteverything uh there are other factorswhen uh when thinking about theperformance of these models and you knoweverything is is quite this this area ispretty nascent so we're still learningand experimenting this technology butum in fact what you're seeing is that ifyou just increase the size of the modelsyou start getting diminishing returns soother factors to to think about are thequality of the data which pre-trainingdata the quality of the data is actuallyhighly impact the performance of themodels the diversity of the data likewhat areas it covers also uh impacts thegeneralization capabilities of themodelsum and of course theum the length of training this issomething we've learned also highly asan as a great impact and there are otherconsiderations like the architecture uhdo you use dense or uh kind of mixtureof experts networksum uh of course the the whole notion ofinstruction tuning data this issomething that is is highly impactingthe uh zero shot capabilities of thesemodels and and of course there are otherfactors so I think we're still we'restill learningum what what does have uh impact on onthese models uh but we're I think we'renoticing two open opposing Trends hereon one hand we're kind of pushing theenvelope and and scaling things rightthe size of the models the size of thedataetc etc on the other hand the otherTrend we're seeing we're trying to takethese smaller models more efficientmodels trying to maximize theircapabilities and see what what can we dowith them having other considerations inmind like uh costs and and latencygreat thank you so much another areawhere I'm getting a lot of questionsfrom different companies is around taskspecific Foundation models so Oreo I'llstart with you and then love to hearWarren's thoughts as wellsure we're seeing especially in theEnterprise where these Foundation modelsare being used in specific contexts likefor specific use cases we're seeing alot of demand for task specific modelsit means models that are highlyoptimized for a specific tasks likesummarization or grounded questionanswering or paraphrasing or whateveryou sowhen you think about when you thinkabout that then you can actually usemuch more much smaller models which arecheaper to serve and and are faster andin in many cases are actually moreaccurate they tend less to hallucinateand then when you when you take thesetest specific models and apply them inin the Enterprise environment forspecific use cases you get a lot ofadvantages by using this uh thisapproachum yeah I think that the interestingthing is that you with Foundation modelsas you start with 90 of it done and soyou know you know in the old days ninemonths ago uh we would uh you know wewould start with a whole whack of dataand not much of anything from a modeland now if you start with these modelsthat are billions of parameters you canthen end up tuning them to be more taskspecific and then distill them down intosmaller models and so starting withslightly bigger almost done is wayfaster than trying to do it from theground up necessarily and so we've seena lot of customers doing stuff like thatwhere they're they have something theytest it out it works really well andthen they want to distill it down tosomething smaller that's cheaper andfasterright yeah it'sit's you know the past and as being ninemonths ago there's just been so muchchange in so much evolutionanother area where I often get questionsis around industry specific Foundationmodels so any additional thoughts onthat beyond what you've shared aroundthe task specific modelsI think it's uh I mean industry specificthings are there's certainly liketaxonomies that are specific to healthcare and things like that I think thething that is a little bit overdonesometimes is generic industry specificmodels in some cases uh do not captureall of the things you need for thatindustry and so if you take a model thatyou end up feeding a certain taxonomy toit it does really well at what your kindof instruction tuning and training itfor but it may not do the entire domainand so I think that we've seen thatoftenum in some of the testing andevaluations that you see like medpom itworks really well for summarization andthings like that of medical types ofstuff and it's there's certain otherthings that it's not going to do as wellbecause you know it's not trained ortuned for that piece but I don't knowyou've you've been in the middle of theindustry stuff soyeah so I mean Med palm and Zach Palmerbothum you know things that started asresearch projects and uh it's beeninteresting to see that um things thatwe designed to kind of push the frontierof say like well hey if you makesomething that's domain specific howgood can you get on the those benchmarkshas beenum you know has shown to be kind ofcompelling in a product context and asyou saw from the announcements yesterdayworking early in our our journey therebut they're already kind of beingproductively pursued in some clinicianapplicationsum but they are fundamentally I thinkcomplementary to more traditional taskspecific models and um it's uh you knowoften we talk about these approaches islike a it has to you know beats b orvice versa and I think in most of theseapplications It's A and B it's you needyou knew kind of both of theseum and I think what's often industryinteresting about kind of foundationmodels generally is um you know when youknew a task ahead of time summarizationclassification entity resolution Etcum task specific models are great asalready mentioned you can the the bestperforming models tend for those typesof tasks tend to be tasks Civic butsometimes you don't know the tasks inadvanceum and so that's where I think often thethe foundation models um highlight andthen actually as you as you start tolearn that task then you might go builda task specific model so it's um asWarren mentioned it's great to getstarted it lets you explore and then youcan always optimize lateryeah I just I just wanted to reinforcethat message I think a lot of customersare starting by using the generalpurpose Foundation models uhexperimenting better understanding theuse case actually in some cases buildingtheir data sets based on on theseFoundation models and then try todistill uh the models into more compactuh smaller models that are specializedtowards uh those specific tasksall right well this next question I'dlove to hear from from all of you butwhat's your perspective on whereFoundation models are headed forbusinesses in the Enterprise I'm sureyou're having a lot of greatconversations here with customers anddifferent organizations so where do yousee it headed from an Enterpriseperspectiveso I think key there are a lot ofdifferent aspects to be covered but onecommon theme we're noticing is aroundreliability how can we reliably deploythese models in productionand umand because these are kind of new kindsof beasts right these are statisticalmodels uh we can't uh they're notdeterministic by Nature so uh we we it'sit's I think it's it becomes verychallenging toum to start managing it's a kind of anew paradigm in in the Enterprise uhespecially when you cannot predict theoutput in advance soum it kind of it requires this shift inuh in the mindset of how do you interacthow do you work how do you deploy thesemodels in in production settings so Ithink reliability is just a key aspectthat is very important for uh forEnterprises soum it's being manifested in their needsto put a lot of guard rails in placeright there are many industries that thecost of doing mistake is high like ifyou're thinking about this vision ofhaving these you know financial advisoror or medical advisor or legal advisorwe can't have these systems makeridiculous mistakes so reliabilitybecomes a super important factor and uhand and there are various ways to toaddress this and I think this this isthis is going to be a key area forseeing more and more successfuldeployments in the Enterprise and infact in a21 that's that's the area wetook as a focus area for the comingyearsyeah I think so my son just startedengineering this year and uh he calledme last night and said why do I have tolearn differential equationsand I'm like because you do and he goesyou don't understand dad like I use Iuse Bard and do some pretty cool mathand I was able to do get answers out ofitum and so why do I have to I'm like wellyou know it's just write a passage sonbut I think that the reason I tell astory is because really you know in hisView and in the view of a lot of folkswhat this has done is allowed you to puta flashing cursor in front of businesspeople and giving them the power offoundation models and that's a big dealright and so I think one of the thingsthat we've seencertainly as this has grown is that youknow people who are customers andEnterprises who are really havingsuccess with this are going into thebusinesses and saying here's a flashingcursor and here are some guard rails forthat flashing cursor drive it and whatyou'll find is is that people whounderstand the business tend to getbetter responses and betterum kind of uh inference out of the modelthan people who don't and and so this isone of the things that we're seeing andI hate to say the word democratizationbut it does feel very much like thatwhere people are driving this into thebusiness and taking this super powerfultechnology that did require you to haveyou know significant math andunderstanding skills to be able to useinto people who are like I just want toget my business stuff doneum and I don't think it trivializes ittoo much and we've seen this happen withsome banking customers we have retailcustomers it's not always the digitalnatives who are doing this right nowthis is happening within lots ofdifferent Industriesas a son of a math teacher and co-leadfor Bard I'm happy to tell your son to Iwill send them to you differentialequationsum it's uh I meanI think one of the interesting thingsgoing on right now is there's somethingin one sense that's really kind of justa continuation of what we've done as anindustry before you know like Bert Ithink had 40 million downloads lastmonth it's been around for years youknow uh all of these traditionalum nlu tasks sentiment analysis entityresolution classification Etc like theseare well-known things businesses andcompanies have been adopting them for along timeum but there's also something differentgoing on and so I think Foundationmodels give us a little bit of alanguage to talk about what's differentso if you think of like what it is nowit's kind of a new type of buildingblock where you have the ability tocompute things and the data kind ofembedded into one unit it's a new it's anew LEGO brick to toum uh kind of use the term phrase thatwe didn't have before and I thinkthere's some aspects of that that arekind of new new and interesting thatkind of will drive some of theEnterprise use cases so if you think offor example code GenerationUm you know it's just started to workand if you think well what's Downstreamof code Generation Well tool use and APIuse and if you think about all theadvancements we've made on um you knowto ori's point that's just not about thenumber of parameters it's you know thereare these other components of the modelwhether it's like the fine tuning orgrounding in the case of you knowcompanies grounding on their internalproprietary databases or doing their ownfine tuning like these are all thingsthat are are more uh relatively newum and I think make the kind of modelsthat we see now much more interestingbuilding blocks for new types ofexperiences versus kind of better betterversions of things that we'veum always done before and I think you'restarting to see actually with some ofthe you know kind of the new companieslike Oris as well as uh some of thedemosum that you saw yesterdaypeople are figuring out how to applythose new capabilities to the productsthat we have people are figuring out howto build new new products with thatum and I think we're going to see moreof that that's really going to be if youthink about where where kind offoundation models are headed uh it'sgoing to be kind of less of what we usedto see before which is again still veryvaluable and and often the best way itdoesn't necessarily get a lot of pressbut often the best way to achievesomething and more of these new types ofthingsum that you know new experiences that wecouldn't do before primarily by usingFoundation models as building blocks aslarge larger systems versus justthinking of the model itself as as theproductall right next question is for Warren soone of the most common use cases andrequests we're hearing from customers isaround fine-tuning foundation modelsbased on a customer's data forcustomizationwhat's the future of this kind of finetuning especially as models areincreasing in sizeI think the fine tuning is becoming evenmore sophisticatedum you know Eli's team uh you know gaveus uh parameter efficient types tuninggave us Laura and so like the thetechniques that we're using for finetuning are getting just better andbetter and so you if you saw in thekeynote yesterday that style thing withimagine where you were dropping Stylesagainst pictures that's effectivelyfine-tuning and so the ability for youto take small small pieces of data andsay I want the stylistic I want thispicture to be stylistically this waythat's fine-tuning and so it doesn'thave to be you know epically complicatedfor it to be fine-tuning but we see agreat deal of that sort of thing even inthe code modelsvery interesting uh you know uh is Iwant to tune to my data and my styles ofmy code and the types of modules that Ido and the security practices and thingslike that and then you know it doesn'ttake a great deal of data for you tobasically fine-tune the model so itunderstands that and so we're seeingquite a bit of people doing that withvery small amounts of data being able tohave you know pretty large effects onthe behavior of the model and and doingthat and so you know we uh you know theresearch and deepmind teams uh helped usbuild adapter models which are thesesmall models that sit within yourcustomer tenant that you can actuallyuse as basically a mask to the parentmodel and that is how we do fine-tuningand that's how we kind of protect yourdata and your IPS to keep it within thecustomer tenant and there are techniqueslike that that allow you to do you knowand experiment and throw data at thingswithout you having to worry that somehowthat's going to leak into some otherplace and so we're seeing a lot ofpeople playing with that right now andthose tools are still evolving too so Ithink it's a good example we talkedabout Foundation models being buildingblocks for other things and one of agood example is foundation miles beingbuilding blocks for other models rightthat being like a prime example yeahwe've seen also one thing that people Ithink forget as well a little bit isthat you know you can get to a certainpoint with fine tuning but that you maynot want to actually spend more time andcontinue to push it it may be that youmight have a T5 model at the front enddoing some sort of filtering orpre-processing against the foundationmodel and you know it's the one modelthat rules them all I don't think is theway it's going to be as I think you'veheard from us today and so I thinkcontinuing to do those types of thingslayering models and stuff like that isgoing to be you know a way forwardcertainlyI just I just wanted to Echo that pointI think in the future we'll we'll seemore and more of these AI systems thatencapsulate multiple models and havethese more comprehensive pipelinesrather than one model that provides uh asolution for for everythinggreat I think another challenge that weoften have in this area too is justaddressing some common misconceptionsthat might be out there related toFoundation models so I'm curious whatare the biggest myths that you want tobust related to Foundation models thatmaybe you've heard questions around sotell me more about what you see as thebiggest mythsI would say one myth I would choose isthe ability to reason like reasoning Ithink that we're seeing you knowreasoning capabilities emerging in thesemodels but I would call this cellularreasoning I don't think that they canreason uh that deterministically as uhapplying more classical you knowprogrammable approach there are certainthings that if you want to have adeterministic solution you should uh youshould solve with code and there's acertain thing you want to solve kind ofuh neurally I would say soI think that the way moving forward withthat is actually a hybrid approach andum I think we're seeing more and more ofthat right now being being developed andunderstood by by the uh by the communitythere are certain things you want tosolve uh we've kind of more classicalapproach and there are other things thatyou may want to use the power of theseFoundation models to solve and the realquestion is how do you combine boththingsbut maybe one example you can just justto give you a taste for it and I like togo to any one of the assistive modelsout there and ask it a very commonsensical question like what weighs morea basketball or a seven-year-old childand it will give you this very elaborateanswer like basketball ways like thisand a seven-year-old child weighs likethat and then the conclusion would bethat basketball weighs much much morewhich of course is a it's it's nonsenseso just that's one of theum one of the things that I think thatthe one of the myths that people speakabout this large language was the secondreason that I think is actually isactually not trueforeignthat's a great example of I think um wetend to personify technology especiallytechnology where there's an input outputit's almost like a dialogue like we'reevolved to um kind of project in thosesettings so if you'd asked me maybe ayear ago I would have said sentience Ithink the kind of larger community nolonger thinks that we've created a bunchof sentient thingsum but generally I think you really havetoum and it's hard because we all have ourkind of implicit biases that we purchasestuff but you really have to notpersonify not you know if you if you'rea mental model for the models as a humanyou're going to miss the capabilitiesright because they do these amazingthingsum that you know uh they're kind ofsuperhuman and a lot of tasks but asalready mentioned they're you knowsub-human in in many obvious ones and sothat for us feels disconnectedcontinuous because you know we expect itwe're kind of normalized to the to thetask uh performance of humans butthere's nothing that says that modelsare going to be human-like in terms oftheir distribution of performancethey're going to be there's going to besome things they're amazing at somethings are uh they're not andum and I think kind of get starting tonormalize to that to the capability ofthis of the models versus like usepeople as a um as the kind of Benchmarkuh leads its historyyeah mine's kind of like the whole onemodel to rule them all saying I thinkthat that's like a huge mess and so youget a lot of people doing weird thingswith models like uh Hey I want to usethem for translation there's probably aplace for that but you know there arevery very very very good translationmodels out there that are much muchcheaper which is the other pieces that Ifeel uh I see you know I was talking toa customer and they're doing somethingwhere they're gonna have to touchbasically 300 million pieces of dataevery month to do this thing they wantto do with Foundation model and I'm likedo you if you guys looked at what that'sgoing to cost and they're like uh no andso we started I added it up for them andit's like 50 million a year and I waslike oh that's like 15 times our I.Tbudgetso I I think that people I think thatthere are like better cheaper fastermodels that exist out there and that youdon't need to use uh you know a hammerto put a screw inum in a lot of cases and so we see quitea bit of that uh yepso reasoning sentience and then onemodel to rule them all all myths youheard it here remember those no KillerRobots either no Killer Robotsall right from spacebut another question that I think mightbe really interesting for this audienceas wellum what has surprised you the most aboutFoundation models especially as we'veseen greater adoption and application inthe EnterpriseI was gonna say I'll start from a veryresearchy perspective and it's almostlike a you know it's umkind of in contrast to the previous uhdiscussion which is I've also beenreally surprised at how good llms canget at tasks that I would not havethought they would be good at so if youthink of you know code generation is agood oneum but also if you think of like imageGeneration all of those text imagemodels are fundamentally llms some ofthem even work by generating text tokensthat we then turn into images and so Ithink just theum uh the sheer applicability oflanguage and how much language isactually a part of so many tasksum you know was uh not not a not I thinkit's I'm still impressed at how muchroom there is left on pushing theboundaries on LMSyeah I I totally agree I think that'sthe at the breadth of use cases justkeeps surprising me day after day justheard yesterday aboutum uh Trend companies using llms forreplying to rfpsuh so it's just it it keeps on ongetting interesting as more and morepeople are thinking about these creativeuse casesumI think one of the things I I was uh Iwas surprised by uh it's just um it'sjust seeing how these are actually verygood for ideation it's more about thehuman and and models kind of interactionhow like a person would take him maybeand maybe even multiple people wouldtake themum you know a couple of hours to to kindof clarify or Chris christify a fewideas versus the person who works withthese models just in a few minutes getsreally good ideas so ideation is is aninteresting one that I I wasn'texpecting from Foundation modelsyeah I think it's the the rate ofinnovation it's just like I I a fewyears ago we're building a CV model anduh you know we got it to do uh a littlebit better with the predictionrecognition of something it was likepoint two percent or something and wehad a party like we were excited rightand it was like that was a huge deal ifwe made the Breakthrough we got slightlybetterum and what we're seeing you know withjust the rate of innovation is happeningwith these models right now it's justlike epically fast like it's just it'samazing how much better they're gettingand from every category whether it'sefficiency whether it's um their youknow their abilities to be moredeterministic and things like that we'reseeing just like the rate of innovationit's just enormous and I I don't see itslowing down it hasn't so yeahthank youforeign"
}