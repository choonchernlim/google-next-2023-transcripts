{
    "title": "Unlocking innovative generative AI use cases with text and multimodal embeddings",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML302"
    ],
    "video_id": "2M43pIOo77Y",
    "time": "Aug 30 01:45 PM - 02:30 PM CDT",
    "transcript": "foreign[Music]let's get startedthis isaiml302 unlocking Innovative AI usecases with text and multimodalembeddingsmy name is Anand I'm a group productmanager in the Google Cloud vertex AIplatform and I'm really glad to bejoined on stage by my colleague Fabianalso a product manager in the vertex AIplatformand Eric CTO of innovative companyvervin Verve is a Google Cloud customerlet's do a quick rundown of the agendabefore we dive in I'll start with aquick overview of what are embeddingsthen I'll pass things over to Fabian todo a cool demo with multimodalembeddings then Eric will talk aboutVerve and how they power Innovative anddifferentiated experiences for theircustomers with embeddings after thatwe'll do some architectural patternstalk about embedding tuning and thenit's q afor Q a we have a mic in the center ofthe room so if you have a question uhwe'd request you to walk over to the micso that everyone can listen to yourquestionall right so with that let's let's divein so what are embeddingsI call them The Unsung workhorses ofcontemporary AI you're not going to hearmuch about embeddings in the newsbut today some of the most widespreadand commercially important applicationsof AI are powered by embeddings you'reprobably thinking hey man enough withthe marketing Spiel what are embeddingsreallywell embeddings are a AI model generatedencoding of content as a vector or arrayof numerical floating Point valuestypically the content that is encoded asembeddings is unstructured contents youhave text or images and so forth but itcan actually be any type of contentnow a goodgood embedding generating model willencode Rich semantic information aboutthe content in the embedding vector solet's take as an example the vertex AItext embeddings API it takes text asinput and it will return an embeddingVector of dimensionality768. so what that means is the embeddingVector that you get back has 768numerical floating Point valuesnow 768 floating Point values may notsound like much it's just 768 numbersbut the breadth and depth of semanticinformation that is captured by thatembedding Vector nuanced semanticinformation is incredibleso embeddings are a very powerful andversatile tool and they're used in manycreative ways often they're used asinputs to other Downstream AI modelstoday I want to touch upon the propertythat is by far the most popularlyleveraged property of embeddingsso as I mentioned embeddings encode Richsemantic information about the contentright so if you have two pieces ofcontent that have that are semanticallysimilar then their embedding vectorsshould be similarso if I computed a distance measurebetween the embeddings then theembeddings of semantically similar itemsshould be close to each other and theembeddings of items that aresemantically dissimilar should be farapart and this property is by far themost popularly leveraged property ofembeddings so let's actually take a lookat this example image here so we haveembeddings created from books so we tookthe textual content of books producedembeddings and then the embeddings areprojected onto a two-dimensional spaceand that's the image you're looking atover there and what we find is theembeddings for books that belong to thesame genre they're typically clustertogetherof this property of embeddings powersmany many compelling applications andI'll pass things over to Fabian actuallydemo one such cool applicationright thank you Anandum thank you hi everyone and thank youfor joining us in person this year inSan Franciscoso as Anan mentions embeddings can beused to support a variety of use caseand today I'm delighted to show you howembeddings can be used to create ablazing fast multimodal product searchexperienceand for thatum we build a demo we've built a demo inpartnership with Mercury Mecca is aJapanese e-commerce company connectingmillions of people to shop and sell andsell items on their Marketplace so let'sDive Inokay we'll start with the text basedsemantic product search on the MercuryMarketplaceso one thing for this demo we only usedproduct image provided by Mercury asinput and nothing else no the emails arenot tagged there is no productdescription anything like thatokay so here I'm searching fora stylish deskmade out of metalso you can see here that product searchis happening on the Fly and returnsresults really quicklyso here we're matching the embeddings ofthe text querywith the embeddings of the all theindexed product image and I'm adding theproduct to my to my cartall right so now let's try a morecomplex queryso here I'm looking for a video gamethat I just can't remember the name ofit so here's the query a Nintendo switchokay as a console video gamewe're narrowing down a video game with ared climber as the main character youmay know who's that guyhere we go Super Mario 3D World that'sthe one I'm looking for soum here again we're only using productimage and and here that image embeddingsthe user query with relevant resultsand that kind ofum semantic search would be verydifficult to properly handle with aconventional approach with you knowkeyword bass for exampleokay third exampleum this is an image based product searchso here all I have is an image of aproduct that I would like to find on themacri marketplace think about you knowGoogle Lens rightso here all I need to do is take thephoto upload the photo I I I'm of theproduct I'm looking for in that case Isnapped the photo again it's a Nintendoswitch Cardinals game for Zelda breathof the wild great game by the wayand here I can see multiple optionsright so I'm picking that one as amaster Edition Perfect all right add tothe card so here we've been matching theembeddings of the input image with allthe embeddings of the of the productimage and now I think I've got hundredsof hours of fun gameplay in front of meokayso what makes the demo so unique wellit's fast rightum you get search results withinmilliseconds right in the backhandmilliseconds to do matching whileretaining a deep semantic understandingtwo it scales very well for this demo weused 5.7 million product image that's alot but that architecture thatarchitecture can scale out to billionsof products while maintaining the sameblazing fast response time andthroughput as welland third ah my favorite it's easy rightso here there is no data labelinginvolved model trainingum just bring in your data and thevertex CI embeddings API and Vectorsearch will do the work for youso before the Deep dive into thearchitectural patterns that we've beenusing behind with for that demo I wouldlike to introduce Eric puff Eric is veryCTO and Verve has been pioneering theuse of vertex imbeddings and Eric willtell us more about their Journey thankyou very muchexcited to be here my name is Eric Poffwith Verve we're a video poweredfeedback platform the name stands for acombination of video plus survey equalsVerveand our goal is to improve the world ofcustomer feedback becauseif you got there and lookumthere's uha lot if you go out there and look forContent reviews and ratings there's alot of problems out there with thatworld how can you trust the data a lotof it's Anonymous and if you're a brandor company how can you make decisionsbased on that information so with videofeedbackwe introduced the human element into theprocessafter all that information make itauthentic right and now as a brand youhave data you can trust so that you canmake improvements to your products orservicesour opportunity then at Verve is how dowe make sense of all this datathat's where embeddings come in we embedeverything and let me walk through aquick exampleuh let's say you're a shoe companyand you want to you have a new idea fora concept and you want to get feedbackon it test it outwe'll start with your customerswhat are their likes what are theirdislikesum what are they talked about in thepast well embed all of thatput that into a modelum and then cluster it and then we'llfind the segmentations so this examplewe have a segment down there in thebottom left we'll launch a Verve to themcollect their feedback embed all theinformation that they provided and thenwe can produce results from that so wecan tailor those results to if you're aproduct designer you're in research oryou're in marketingall that stuff is powered by embeddingsI won't spend a lot of time on this butI figured I'd show you how easy it is toget uh to get going so if if you haveideas on how do I get started and I wantto use embeddings here's what we did wehad an existing data flow where we hadour data we transcribed it from thevideos and then we introduced anembedding step where we'll embed thattextthen we'll index it into a vectordatabaseand then when we see we'll use thatdatabase to train our models as wellobserve uh serve all the insights intoour application as well so let me showyou some real world examplesum I kind of want to stress this outthat this is this stuff is live rightnow in our application uh we're superproud about it the first one is likeobject detectionso we've asked people to hey what's yourfavorite shoe uh tell us what you likeabout itwe can then take that video strip it outinto text take the video portion of itget the frames we can then identify theobjects in it and then do some some whatwe call Smart objects and smartdetection right this provides a lot ofvalue back to our customers so that Ican now pick out what people are talkingabout and do object identificationthe next one we call magic wheels so ifyou imagine we have hundreds andthousands of these campaigns out thereat any one time and we're collectinghundreds and hours of video no one wantsto sit and go through all that videouh but with the power of embeddings wecan take that information and find outwhat are the highlights so we have ahighlighting model all built onembeddings and we can tease all thatinformation out and create like a fourto five minute highlight meal and we canalso find the topics uh for each one aswell so topic modeling keywords topphrases and we can create highlightreels for all those as welland then last but not least is our uh wecan summarize the data we can dorecommendations we can also generate newideas right so drag the retrievalaugmented generation uh kind ofphilosophy and framework which I believewe'll be talking about a little bit weuse that as well it's all powered byembeddings so we can take thatinformation generate summaries we cancome up with recommendations where to goto next and then also generate ideas heythis to solve this problem or pain pointthat consumers talked about do this sowe feed all that into the llm and getthat information back and at the end ofit we have what we call our brand AIall powered by embeddings so I'll handit back to Fabian and talk about thearchitectural patternsthank you very much Ericum this is really exciting to see howverbe is using Ai and embeddings toextract novel insights from unstructureddataso now let's explore the architecturalpatterns that are commonly used to putembeddings to workokayto achieve embedding similarity inproduction at scale we rely on two keyenablers one the vertex CI embeddingsAPI to generate embeddings and to thevertex I Vector search to appear fromfast and scalable embedding similaritysearchokay let's have a closer look at thefirst key enabler generating embeddingsso to get an embedding all you need todo is take your content send yourcontenttext image both to an embedding APIendpointthe response will contain an embeddingwhich is a vector representation withwith a deep semantic information of theencoded content that you can use in yourDownstream tasksand today Google Cloud offers two typeof embeddingsand multimodal so which one to chooseokay if your goal is to create highquality text embeddings that you can usefor text classification questionanswering for example text embedding isthe right choice so this embeddingsupports long form document as an inputand generate embeddings in a 768dimensional vectorif your use case involves image or pairsof text image multi-model embedding isthe one you want to pick multi-modeltakes image or text or both as an inputand output a 1408 dimensional vectorokay the second key enabler is Vectorsearchso Vector search is used by Googleactually internally with a search playYouTubeand many more to provide fast andrelevant search results as well asrecommendationso the challenge or the problem withVector search is very simple it's how doI find similar embeddings really reallyfastI would have seen earlier embeddings andembedding is a vector right and andsimilarity search can be done bycalculating the distance between betweenthose those two vectors so smalldistance suggests High similarity and umand large distance suggest lowsimilarity so it's prettystraightforward it's pretty basic mathhere but it's not easy when you have todeal with millions or billions ofembeddings right so you can try to youknow just brute force it right but foran example with the macro demo fivelet's say five million product at youknow 1408 you know embedding Dimensionyou need to repeat the calculation sevenbillion times right so that's going towork right but it's going to take a verylong time to finish and not provide thebest user experience to say the leastso how can we solve for thatwell researchers have been studying atechnique called a-n-n approximatenearest neighbor and a n uses Vectorquantization to separate the embeddingspace into multiple clusters with a treestructure and that involves a fast andscalable search and a few years agoGoogle research published a new a nalgorithm called scan s-c-a-n-nscan is considered as one of the best an algorithm in the in the industry andtoday Google Cloud developers so all ofyou can take the full advantage of scanwith Vector vertex AI Vector searchso Vector search Okayumthat's been cool vertex a matchingengine we just changed the name so youmerely know that product so Vectorsearch is a fully managed Enterprisegrade Vector database that pretty doesone main thing is calculating Vectorsimilarity very fastso three key steps to use that thatproduct so one take your embeddings andimport your embeddings in Vector searchto create an index to Cluster theembeddings into embedding vectors intosimilar entities and three query a liveendpoint with your application to serveonline prediction and get search resultsso why using vertex AI Vector search allright so first it's Enterprise readywith you know scalability and loadlatency again you can perform search ofa billion of embeddings at highthroughoutput with super low latencyso it's a fully managed solution rightthat auto scales for example so that youdon't have to worry about managing uhthe infrastructure and you can focus onbuilding great products that Delightyour customersand third it's very efficient you knowand basically thanks to the underlyingalgorithm as a result it lowers yourtotal cost of ownership when compared toother approachesokay now let's recap everything and seehow we've used vertex AI multimodalembeddings API and Vector search topower the demo so the flow really lookslike the following so the first phase isembed an index so that happens offlineright so you here you pass all yourinput data in that case the 5.7 billionimage to the multi-model remitting APIto generate the embeddingthen you insert those embeddings in thevector search database and Trigger thecreation of an index to enablesimilarity search and then you go tolive endpoint that you can querythe second phase is online right it's atthe search time so here you pass yourtext query so here stylish desk or animage to the multi-modern emitting andyou get the embedding and you take theresulting embeddings and send them as aquery to the vector search live endpointand finally you get backed ranked resultso here in the form of image that sharessimilarities with the text search rightand they happen in different uh theyhappen so it's one side is emitting fortext and I'm adding for image but asthey are sharing the same editing spaceyou can you can you can make acomparison behind between themandum yeah that wraps up the architecturepattern overview and now Anand will tellus more about how embeddings are used inthe world of gen AIthanks Fabiansee at this point you're probablythinking yeah embeddings are awesomewe're sold but the title of this talkhad the term generative AI in it so wewant to hear more about generative AIall right let's talk about howembeddings are used in the world ofgenerative AI they'll be used in manycreative ways so today we'll just touchupon the two most popular ways in whichembeddings are used in the world ofgenerative AI by far the most popularusage of embeddings is to power thisParadigm or family of architecturescalled retrieval augmented generationand thank you Eric for teeing it up formeum retrieval augmented generationhonestly it's a fancy way of sayinglet's find and feed the llm pertinentcontext and information at query timethis Paradigm is also often referred toby the term grounding so you may haveheard the term grounding the elementso before we get into the architecturelet's look at what are the key problemswe're trying to solve the first problemwe're trying to solve is that llms don'tknow your business data or your domainspecific data LMS are typically trainedon public content from the internetbut they're not familiar with your dataand your data May matter the most foryour use casethe second problem we're trying toaddress is that llms don't havereal-time information they they doaccumulate and encode a lot ofinformation but that's information upuntil the point that they were trainedand they're not accumulating newinformation after they're trained sothey may not have information fromyesterday or last week or even lastmonththe third problem we're trying to solveis accurately citing sources ofinformationfor many Enterprise use cases you wantthe llm to give you the answer you'relooking for but also specify what is thesource the original source of thatinformationthe thing is llms they do encode a lotof information within their parametersor weights and that's called parametricknowledge but when they give reply isbased purely on parametric knowledgethey struggle to cite the source so whatis the solutionthe solution is to find and feed the llmpertinent knowledge or context at queryTime by using an information retrievalsystemso this is the high level architectureat a high level you start with the inputprompt and in the in the world ofgenerative AI the word prompt is oftenused to refer to the input of the querythat's passed to the model so you startwith the input prompt and before yougive it to the llm you actually call aninformation retrieval system that hasindexed the information you want the llmto use as context you call theinformation retrieval system you findthe most relevant matches you take thecontent of each match and you appendthat to the prompt and you take thataugmented prompt and pass it to the llmso now the llm has the original querybut also has a whole bunch of additionalinformation it can use this context toanswer the queryso let's actually take a look at a verya simple an example of a simplearchitecture a simple retrievalaugmented generation architecture thatcan be created with the tools we'vediscussed so far in this presentationso step one is to create the index soyou start with the document Corpus orthe knowledge base that you want toindexand you take the text of these documentsand you call an embeddings APIif the documents are large you may wantto chunk them up into slightly smallerpiecesnow you want to take these embeddingsand you want to put them in anembeddings plus content Index thisembeddings plus content index consistsof two things one is the vector searchsolution which Fabian described indetailbut here in addition to finding the themost similar vectors what we want to dois also return the content associatedwith each vector and for that you canjust use your favorite low latency keyValue StoreI do want to call out that the updatedvertex AI feature store now supportsembedding management and retrievalcapabilities so you may want to checkthat out please check out AI ml303 formore detailsall right so we have our index now sowhat happens at query time at query timethe user query comes in the user promptyou convert that to an embedding Vectoryou look up the embeddings plus contentindex you get the top K most relevantmatches you append the content of thosematches to the prompt you pass it to thellm and the llm response and there youhave it folks that's a simple retrievalaugmented generation architecturenow let's look at the second mostpopular use of embeddings in the worldof generative Ai and that is to empowerllms with the with the the capability ofmemoryso what is the problem here the problemis that llms don't have any memory oftheir own they get a query they processthe query they return the response eachquery is independent for the llm theydon't retain any information about thequery or the response beyond theduration of the query but there are manyapplications particularly assistive chatapplications chat agents and so forthwhere you actually want them to rememberwhat was discussed in you know a whileback in the conversation or evenremember what was discussed in Priorchat sessionsnow I do want to call out that whenyou're building a chat application themost recent turns of the conversationthey are passed back to the llm eachtime so the llm has the most recentcontext but they actually wanted toremember you know what was said a whileback or in previous sessions as wellrightso what is the solutiondoes anyone want to take a guessthe solution is to use embeddings andVector searchum so let's let's quickly take a look atan architecture so you have you haveyour long-term memory serviceum in the long-term memory service youuse an embeddings API and you use theembeddings plus content index that wesaw on the previous slidenow you're having a chat session foreach turn of the conversation you takethe prompt you convert it to embeddingsyou look up the long-term memory serviceto find the most relevant matches youappend it to the prompt you give it tothe model and the model response withthe relevant context now there's onething you have to remember here you haveto remember to put backthe most recent prompt and the mostrecent response of the model in thatlong-term memory service so you have itas context for Downstream conversationsand again there you have it folks nowbut you know it's it's that simple toempower your llms with long-term memoryall right moving along now let's look attuning embedding models and before wedive into this I'm actually very excitedto call out that the private previewrelease of tuning for the vertex AI textembeddings API is now availableso you know we'd love for you to checkit out now when we talk about embeddingtuning and embedding model let's startwith why you may even want to do that asyou've heard us say multiple times rightnow embeddings and code Rich semanticinformation and then you do semanticsimilarity matching but for your usecase what constitutes semanticsimilarity may be different in nuancedwaysor the the attributes that matter themost for your use case may be certainlydifferent from some other use case andI'll give you an example so when you'redoing semantic similarity matching theremay be a use case where uh all you careabout is the semantics or the meaning ofthe words in some piece of text or theobjects in some imagenow there may be another use case wheredefinitely the meaning of the words orthe objects in the image matter but whatalso matters perhaps more could be thestyle or tone of that content right solong story short there are different usecases where different attributes mattermore so how do you tell the model whatare the attributes that matter the mostwell you actually do that by giving awhole bunch of examples to the modeleach example and this is the input tothe tuning job each example is a pair ofitemsand each pair you specify if the if thatpair of items is a semantically similarpair for your use case or whether that'sa semantically dissimilar pair for youruse case and then the model learns fromthat so let's actually take a look athow the model learns I want to show asimple architecture for embedding modeltuning but what I want to call out isthe goal here is to give you anintuition of what is happening theactual implementation we use under thehood for the vertex tuning embeddingstuning API is actually far moresophisticated we won't have enough timeto dive into that so I'm just going togive you the intuition of what happenswhen you're doing embedding tuningso what happens when you use anembedding generating model you have yourcontent you pass it through an encoderyou get embeddings but now remember thatwhen you're doing tuning you provide awhole bunch of examples and each examplehas a pair of itemsso for each item in the pair you havethe encoder and you produce embeddingsrightnow let's take a similarity function andproduce a similarity score for thoseembeddings and a common similarityfunction is cosine similarity there areother similarity functions as well soyou're Computing a similarity score nowfor the items in your example that aresemantically similar for your use caseyou want that similarity score to be ashigh as possible and for the items thatare semantically dissimilar for your usecase you want that similarity score tobe low and that is essentially whatwe're doing when we're tuning the modelwe're updating the weights of theencoder the parameters of the encoderare updated so that the similarity scoreis high for the semantically similarexamples and the similarity score is lowfor the semantically dissimilar examplesand that's how embedding tuning worksum really cool stuff right and yeah wewould love for you to check it out andI'll pass things over to Fabian to talkabout how you can get startedum okay so here we are providing a fewpointers to Google Cloud product to helpyou createum use and tune embeddings and finallyif you're looking for more TurnKeysolution out of the out of the boxsolutionum that for embeddings based searchproduct you can check vertex CI VisionWarehouse which is a fully managedservice to cover your media contentum storage and search needs for examplevideos and image and vertex AI search toserve all your search needs withEnterprise content such as web pagetablet documents PDF and so onand for more information you can alwaysget in touch with us through your GoogleCloud contact[Applause]foreign"
}