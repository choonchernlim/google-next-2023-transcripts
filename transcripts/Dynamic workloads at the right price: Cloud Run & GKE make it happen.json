{
    "title": "Dynamic workloads at the right price: Cloud Run & GKE make it happen",
    "presentation_type": "Startup Lounge Session",
    "categories": [
        "AI and ML",
        "SU103"
    ],
    "video_id": "HhL5F9k99rc",
    "time": "Aug 30 06:30 PM - 07:00 PM CDT",
    "transcript": "foreign[Music]hello and welcome everyone to Dynamicworkloads at the right price we're goingto be talking today about Cloud run ingke and how they can help you scale yourbusinessI'm kazem fields and I'm a developerAdvocate at Google Cloud where I focuson Google kubernetes engine and opensource kubernetes and it's my birthdayso thank you for coming to my birthdayparty that Google's drawing for me[Applause]we also have today my teammate Lukeschlangen who is also a developerAdvocate on gke and we're very excitedto have Andrew Moreland from chalk andthey're going to tell you a little bithe's going to tell you a little bitabout Chalk's story of how they gottheir business going and scaled withCloud run and gkeso to start off today we're going totalk about scaling a little bit and whatwe mean by scaling then we're going tohear Chalk's story about how they'vebeen using Cloud run and gke then I'mgoing to go over the essentials of whatyou should know about Cloud run and gkeand kind of when to use them and we'regoing to talk a little bit about theGoogle for startups Cloud programto start off let's go over what we meanby scaling essentiallyscaling is all about making sure thatyour business has what it needs in orderto meet the demands that you're under soCloud run and gke are two tools thatGoogle Cloud provides that are meant forhandling scale they have reallyinteresting Auto scaling capabilities sothat as your demand shifts and changesyou're paying for the right amount ofresources to meet the demands of yourbusinessboth Cloud run and gke have a variety offeatures intended to make sure that yourworkloads are being run in a highlyavailable fashionthey're also again a lot about scale somaking sure that as your uh demand goesup you get more resources as it goesdown it also scales down so that you'renot paying for more than you needit's about enabling your workloads sowhatever business you may be runningwhatever programming languages whateverkinds of applications you may need torun Cloud run gke make use of containerstandards to make sure that you can runthem we'll talk a little bit more aboutthat later and I've been talking aboutresponding to demand both of these havea variety of features to help you dothatbut first let's hear Chalk's story fromAndrew to get give you a sense of howthis works in the real world[Applause]thank you cousin Mike I'm through okayall right so my name is Andrew Morelandand I'm one of the co-founders of chalkat chalk we help companies andindustries like banking Healthcare ande-commerce use machine learning to solveproblems like credit underwriting oremergency room triage or productrecommendationand the thread which ties all of theseuse cases together is the problem ofgetting the right data in the rightplace at the right time our customersneed to integrate and transform datafrom a variety of data sources so thingslike postgres databases or bigquery orPub sub or Kafka you name it all sortsof things they need to to tie togetherto deliver data to their modelsand today we're going to look at a quickdemo of how chalk uses Cloud run and gkein order to execute workloads withDynamic resource requirements in orderto serve these customerswe're going to focus on two of the keywork key two of the key workflows inmachine learning the first is theproblem of online inference so theproblem of getting a single Vector offeatures really fast to a model to makea prediction right nowand the second problem we're going totalk about is the problem of getting abig table of data to go ahead and traina modelso zooming out for a moment let'simagine that we're a bank I don't knowhow we would be a bank but let's pretendwe areand suppose we want to do a creditunderwriting model fundamentally what wewant to do is take a huge amount of dataabout individuals and their financialbehaviors and crunch that down distillit into some sort of machinewhich can predict the credit worthinessof a particular personso we want to understand can this personpay us back do they want to will theyand the way we're going to do that iswe're going to compute what machinelearning practitioners call features afeature is just a fancy word for a datapoint that goes into a machine learningmodelso a thing like a person's name or theirfavorite color their income how muchmoney they spend on burritos in the past30 days could all be a feature but todaywe're going to focus on features thatare derived from Financial transactionswhich is a rich source of data forunderwritingso zooming through this slidelet's take a look at some codeso on the screen right now is what wecall a feature schema so a featureschema basically just has the names anddata types of the features that we wantto computeum it's fairly straightforward but herewe're describing the features of atransaction object so a transaction hasan amount has a bunch of other data andit has a description so the thing thatshows up on your bank statementbutthe schema is not the interesting thingabout what we're doing todayhere's an example of what we call a SQLresolver a SQL resolver is one node anda big graph that we're building up acompute graph which we'll use to derivethe features that we're going to use forour modelsum that's SQL resolver which was therefor a moment and is now gone uh is notvery complicated it's basically justmapping data from an underlying SQLtable into the feature schema we justdefined but once we've defined this kindof foundation we can start to do thingsthat are more complicatedso what's on the screen right now iswhat we call a python resolver a pythonresolver is a more complicated constructwhich is also part of that same computegraph using the type signatures of itsargument list it can declaredependencies on features that we'vealready computed and it can tell us whatit's going to produceultimately what we're going to take inhere is the amount of a transaction andthe normalized description of atransaction which is produced by what wecall an upstream resolver resolver whichhas already gone through and cleaned upthat string that appears on your bankstatementand then it's going to tell us whetherthat transaction corresponds to atelecom vendor so maybe like a cellphone bill or something like thatand pausing for a moment what's why arewe doing this like intuitively why do wecare about this operationso if you look in the problem of fraudif you look at the transactions that arein a bank accountuh intuitively if the transactionscorrespond to normal everyday peopletype things like groceries gas Mortgagein the Bay Area probably rentum a cell phone bill it's more likelythat that bank account corresponds to anormal everyday person not someone who'strying to steal money from us and on thecontrary if we don't see those sorts ofpatterns in these accounts it's aprobably a big sign that this accountcould be made by someone with a falseidentity who's trying to construct asituation where they can steal moneyfrom us so it's a really powerful signalto feed into our predictive modelsand once we've defined this pythonresolverwe can go ahead and query itso on the right hand side you see theoutput of running a query commandso what happened basically is we sent anAPI request off to talk server ask fortwo features the is telecom feature onthe normalized subscription feature andchalk returned its output and inparticular we noticed that uh thisarbitrary transaction was just was uhclassified as not a telecom transactionwhich is a little odd because we see aVerizon bill payment in the descriptionso this raises kind of two points thefirst is that data quality is reallyimportantif you have you know bad data if you'retelling lies to your models they'regoing to tell lies back to youso one of the things we want to focus onis making sure that we have really highquality future pipelines to delivercorrect data to our models so that wecan make high quality predictionsand that's one of the problems thatchalk is really engineered to solve andthe second thing here is that you knowthings go wrong if feature pipelines arerigid and hard to change it's reallyhard to get that high quality of featureoutput that we ultimately want todeliver to our models so chalk is set upto make it really fast and easy toflexibly iterate on these featuredefinitionsso on the left we've jumped to thedefinition of one of those constantsthat was in that python resolverbasically a list of keywords that we'rechecking to see if they appear in thetransaction descriptionand we can do using Cloud run basicallyis add a new constant to this list ofconstants and the type chalk applyweighed about 100 milliseconds and thenthe new pipeline is liveand that leverages the ability of cloudrun to deploy tons and tons of pipelinesreally quicklyand as soon as it's deployed it's readyto be queried so we can see the changewe just made and see its impactimmediately so this gives us kind oflike a hot reload like modern webdevelopment experience but for dataengineering pipelines which additionallyhave been like fairly inflexible theytend to have lots of global statethey're slow to change and hard hard tounderstand what's going on in themso we think this is a really amazingdeveloper experience and it's madepossible by Cloud run because basicallyevery time that a user makes a codechange and we can set like a watchcommand up to do these automatically wecan ship off a new revision to Googleand it becomes immediately available forquerying but if it's not queried itdoesn't cost anythingit scales to entirely to zero and at thesame time if it is queried a lot it canscale basically instantly up to 10 000queries per secondso you have all these differentsnapshots of your feature engineeringpipeline all these different kind offorks and points in time which you canchoose to flexibly move between andpromote in order to have that modern webdevelopment experience for dataengineeringso this is the first workflow I wantedto talk about uh online inference butthe second workflow is also reallyinterestingthe second workflow is the problem ofgetting training data so instead oftalking about a single feature Vector wewant to talk about many many featurevectors so a big table of data which wecan use to go and train a modelso instead of running a query we'regoing to run an offline querymake sure the video goesall rightum so this offline query instead oftaking in a single transaction ID takesin a big Vector of transaction IDs andyou can pass in a bunch of features youwant to know about these transactions sonot just from one data source we canblend data from databases from computedfeatures from streaming sources frombatch sources like bigquery andsynthesize it into a unified table whichyou can then pass off to whatever youwant to use to train your model likescikit-learn or uh whatever you'd likewe're largely agnostic to thatum and what's going on under the hoodhere is when you submit that queryChalk's query planner sizes the queryunderstands how many resources you needin order to execute itand then spins up the right sizecontainers in Google cloud and Googlekubernetes engine automaticallyso we basically automatically understandhow many CPUs and how much RAM you'llneed in order to compute this trainingsetwe make sure we have the rightcontainers if we don't we spin them upwe Shard the work distributed out andget back the results all in a coupleseconds and gke makes it possible or gkeautopilot in particular makes itpossible for us to have this reallyamazing interactive query experienceacross data sets that have millions orbillions of rows while basically payingfor only a few seconds of computebecause we can step up and spin it backdownand without chalk without GK autopilotin order to get an experience like thiswe'd often have to leave a big sparkcluster laying around all day paying fortons of computers probably aren't doinganything in order to make sure that ourdata scientists have a really goodinteractive experienceso fundamentally the combination ofcloud run and of gke in particularautopilot gives us the ability to offera really incredible developer experiencekind of that modern web development hotreload experience for our dataengineering Pipelines uh all at a reallyaffordable price pointso thank you for having me up here Lukebut um I wanted to talk about one lastthing which was the transition fromcloud run to gke soyou might be thinking kubernetes uh hardtakes a lot of time to switch to butfundamentally uh Cloud run and gke haveapproximately the same configuration APIunder the hood so when we needed to makethat transition from cloud run to gke asour business scaled and our workloadsgrew larger than we can fit in a singleinstance we were able to make thattransition and just that transition injust about a single day so it reallyisn't so bad if you do need to make theswitchoh thank you[Applause]so in order to get our application outinto the world if that's what you'relooking for today if you're an a webapplication developer like me and youjust want to get your application intothe world this is the fastest way to doit it's a single command if you havegcloud installed if you have a containerimage already runningalready in existencethis is the fastest way to get out thereand maybe you don't have a containerimage already in existence you can usesource code to do this as well so youcan take your source code throw it toCloud run and if you have a Docker fileit can go through that if you don't havea Docker file it can guess it can make abest effort with webpacks and they canput that together for you which isreally phenomenal so Cloud run scalewith Cloud run there is a point whereyou'll move from cloud run to gkepotentially but I want to debunk areally common myth here and that is thatit doesn'tuh handle scale well because Cloud runcan handle any amount of scale so let'stalk about Cloud around here five bulletpoints that I want to run through beforeI get to that headline of why you mightactually be moving from cloud run to gkeso the first any language any binary anyLibrary this is true of both Cloud runand gke and that is because they're bothusing that containerization fundamentalsright we're taking our code we'reputting it into a container and now wecan run it a whole lot of differentplaces which leads to Andrew's pointabout how when and if you decide to movefrom cloud run to gke you already havethis fantastically containerizedapplication and you can move from one tothe other you just put the image in youryaml file for gke and say this is thesame image that we just talked about onthe previous slideso Cloud run uses containers leveragesthat power the reason I love it as a webapplication developer is it's fullymanaged after that line we ran it'sready to go it's up and running and itdoes Auto scaling for us so it's goingto automatically scale all the way up towhat we need and it's going to scale allthe way down to zero when we aren'trunning it so if you want you can setlimits to that so say at most you onlywant 10 instances and at a minimum youwill always want to have one ready andup and running whenever you need it youcan do that within Cloud run so there isa lot of potential within the bounds ofcloud run and thatincludes you only paying for what youuse to the nearest 100 milliseconds sothere's a fantastic demo we'd recommendyou check out innovators Hive you cansee Cloud Run in real time scaling upand down and you'll notice that whilepods are still ready at times you'reonly paying for the ones that arereceiving requests so you're not payingwhen the Pod is necessarily running inthe background we are scaling it for youup and down so this is a phenomenalplace to get started and doesn't preventyou from moving on to other things inthe end okay so I buried the lead hereand I promised that I would get to itwhy might you move from cloud run to gkelike Andrew said so again to hammer homethe point it's not based on scale it'snot the number of requests you receivebecause Cloud run can handle it whateveryou want however many requests you'resending Tori to our applicationCloud run can handle it so when do wemove so Andrew pointed out the firstexample that I'm going to use which isinstead of requests you want to Scalebased on something else so in his casein machine learning not every requestneeds the same amount of compute notevery request needs the same amount ofmemory and he wants to scale preciselybased on the query so he has a queryplanner he knows exactly how much memoryexactly how much CPU he needs in orderto run those queries that's what he'sscaling based on so he is looking atsomething like gke the other example wesee something very oftenwhere people don't have a singleapplication so so far we've talked aboutServices where it's just a singleservice a single back end and you'resending requests to that single back endand there Cloud run can scale up anddown to meet that demand but once yourapplication architecture starts to looklike this if your architecture ordiagram isn't a single box and you needa whole lot of interactivity betweenthose different containersyou can orchestrate that with kubernetesand that's another good sign that it'stime to move to kubernetes becausekubernetes can handle that well but ofcourse there's the old adagewith great powercomes greatoh come on with great power it comesgreatamounts of yaml yes we all said the samething at the same time fantastic thankyou so much and with that terrible dadjoke I'm going to hand it off to caslin[Applause]so now we're going to dive more into gkeand I love talking about kubernetes sothank you for letting me talk aboutkubernetes on my birthday[Laughter]so as Luke was saying gke has a lot ofpotential for helping you to manage morecomplex architectures it provides a wayfor you to have finer grained controlsit has a lot more buttons and knobs foryou to use when you have those morecomplex architectures or those workloadsthat have very specific requirementskubernetes and Cloud run and a lot ofcloud tools are really about distributedcomputing the cloud gave us the abilityto have a whole lot of computers at ourfingertips at any given timein Cloud run you're abstracting away alot of that complexity and just sayinghey what is the application that youneed to run we'll worry about theback-end stuff forkubernetes allows you more of thatcontrol to say here are the machinesthat are underlying my applicationshere's the things that my applicationsneed from those underlying machinesand a great thing about kubernetes is itallows you to tell it these things in adeclarative mannerso you tell kubernetes I have anapplication it needsgpus it needs ssds make sure that that'shappening for me and keep this manycopies of it up at any given time forexample you do all of this with yamlas Luke was saying so that's declarativeapplication management with kubernetesas we were saying another reason thatfolks move to gke is you do have morecontrol over the types of Hardware thatyou're using to run your applicationsand as we've been talking about itenables more complex architectureskubernetes has the ability to whenyou're running many differentmicroservices within kubernetes it hasspecial tools to make sure that they caninteract with each other and not thingsthat they're not supposed to beinteracting with so it's very good atenabling complex architecturebut we're here today to talk aboutscalingso there are four dimensions ofscalability that you should know aboutif you're considering using gke the toptwo on this diagram are about workloadsthe bottom two are about infrastructurethe two on the left are about creatingmore or fewer of somethingthat's called horizontal Auto scalingand it's usually what people think aboutwhen you think about scaling workloadsor scaling kubernetesthe two on the right are what we callvertical Auto scalingso the vertical pod Auto scaler is goingto be helping you to set the requestsand limitson your workloads so telling us how manyhow much CPU how much memory thatworkload actually needs node Autoprovisioning is about choosing the rightmachine sizes that can give you thoseresources that you needso horizontal pod Auto scaler is goingto be creating more copies of yourworkload or fewer and cluster Autoscaler is going to be creating moremachines or fewer machines so all ofthese work togetherand earlier in Chalk's story we heardabout GK autopilot specifically so in GKautopilot it's kind of a world betweenpure kubernetes and serverless which wewere talking about with Cloud runin the case of GK autopilot we set upyour cluster with enough Machineryenough resources to meet your workloadsneeds based on those resource requestsand limits and we essentially call itnodeless kubernetes what's happeningbehind the scenes in autopilot is we'veset up the cluster Auto scaler and thenode Auto provisioning for youso we're configuring all of theinfrastructure underlying your workloadsfor youbut you still have the ability toconfigure a lot of things about how yourworkload runs you could set up thehorizontal pod Auto scaler and thevertical pod Auto scaler you can tell usthat you need gpus you can tell us thatyou need ssds you have a variety oftools available to you to make sure thatyour workloads are running the way thatthey need to using kubernetes to havethe machines underlying it that you needand that's all I'm going to cover foryou today about gke itselfI hope that you learned something newand something interesting today in ourtalk these are the things that if youtook away anything I hope it'll be oneof thesefirst off as we heard in Chalk's storythat getting started with cloudrun andgke isn't so bad they can seem veryscary at first but once you startgetting into them they work very welltogether and Cloud run is often cited asbeing particularly easy to get startedwith soboth of them really are not so badCloud run in particular is great forsimpler architectures and Standaloneservices at any scale so it's not scalethat keeps you from running on cloud runbut perhaps a more complex architectureor specific Hardware needsgke provides greater configurability formore complex architecturesand whichever tool you choose we hopethat you've seen throughout next thatGoogle cloud has the tools to supportyour journey to scaleand we would like to bring Andrew backup to the stage to talk about wherethey're going with their business rightnowum yeah I'm very excited to announce therelease of some new functionality fortruck so we're releasing chalk brancheswhich is that functionality you saw backin the demo earlier where you can make anew deployment in about 100 millisecondsso it gives you that really fluiddeveloper experience and we've also aspart of this release built thecapability of defining features andresolvers in Jupiter notebooks so thedata scientists don't have to use an IDEif they don't want to they can just tryout new features and new pipelines rightthere and then deploy themI think uh one thing that our customersask us often when they're consideringusing generative AI is uh what should webe worrying about how should we bethinking about it and the thing that Ialways tell them is that these modelsare very powerful they're super fancybut ultimately if you give them bad datathey're still going to produce badoutput I think a lot of people haveshown that in a bunch of quantitativeways so the old Dodge garbage in garbageout is still trueand a last note we've been part of theGoogle for startups quad program forquite a while now and obviously thecredits are great but uh one of theother things which is maybe overlookedabout the program is the access totechnical experts so as we were usingCloud run and using gke we got a lot ofhelp from some fantastic Folks at Googleso I wanted to say thank you for thatforeign"
}