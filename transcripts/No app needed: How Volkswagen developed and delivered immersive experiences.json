{
    "title": "No app needed: How Volkswagen developed and delivered immersive experiences",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV207"
    ],
    "video_id": "qZjHV3-4wT0",
    "time": "Aug 29 04:45 PM - 05:30 PM CDT",
    "transcript": "foreign[Music]developed and delivered immersiveexperiences using a service in GoogleCloud called immersive stream for XRand my name is Bernard Reynard I am atech lead manager in Google Cloud forimmersive stream for XR and I'm joinedtoday by one of our partners whodeveloped the experience on immersivestreamflix are with us Pierre Greger whowill come on later to talk about some ofthe detailsnow we have some different sections thatwe're going to talk about and we'regoing to start with the state of themarketso why would you even develop these kindof experiences so in recent years we'veseen an increase in digital interactionsand these digital interactions led to analso increased importance of immersiveand extended reality experiencesbreaking this down to different sectorsin the shopping and e-commerce sector wesaw that several retailers and companieshad a search in e-commerce and some ofthem had their biggest retail years thisyear but we also see high return ratesso high the return rates are also at amaximum wider at a at an all-time highand online retailers are looking fordigital twin models to bring accuraterepresentations of their products totheir consumers so that they can get agood preview of what the product willlook like so that return rates will godownin the learning and education sector wesee an increased importance of remotelearning capabilities where educationcompanies want to bring immersiveexperiences to their students so thatthey can learn and experience these uhthese things from homeand finally in the entertainment andmedia sector we see a preference forDigital entertainment and companies arelooking for more engaging and immersivecontent that is interactive or moreinteractive than the streaming solutionsthat you see so farnow if we look at some of the numbershere we see there's uh yeah there'sseveral studies about this that show TheImportance as well 77 of consumers saythat they would shop more if they hadthe XR or extended reality experiencesconversion rates are also much higherwith extended reality experiences and wesee an 11 times increase and consumersare spending up to 2.7 times more ifthey have an extended reality experiencefor the productand finally there's already a hugemarket for this so 1.4 billion devicesare already capable of deliveringextended reality experiences to endusers and this is growing at a 30 30percent year-over-year ratenow this is not new and companies arealready looking at this so if we look atthe consumer sector Wayfair for exampleis using extended reality to createpreviews for furniture that they canplace in the Real Environment as we cansee herein the education sector for example thisSmithsonian channel is trying to bringthe Mars rover into your own garden asyou can see hereand in the entertainment sector Googleteamed up with title to bring or tocelebrate the 45th birthday of SpaceInvaders with a geospatial APIexperience for Space Invaders where youcan have Space Invaders In your ownenvironmentbut we also see that adoption of theseexperiences is still low and not at arate that we would like to havenow why is that from our perspective wesee a couple of experience a couple ofchallenges the first one is lackingphotorealism for immersive experiencesyou want to have photo real content andmany of these mobile devices that you'reusing to create or show these extendedreality experiences are limited in poweron their mobile gpusalso if you're stretching out the poweron these mobile gpus you're draining thebattery on these devices pretty quicklysecondly these devices are or theseexperiences in many cases are notseamless so end users first have todownload apps or huge digital twinmodels before they are able toexperience the immersive experiences ontheir end devicemaking it not suitable for ads use casesfor exampleand finally it takes a long time todevelop these experiences in many casesyou first need to optimize the digitaltwin models from CAD models that existto create the models that you can renderon these mobile devices and you need togo through lengthy steps ofacceptance criteria internally incompanies to get this signed off to tobe launched and you also need to developit for every single Target platform thatyou want to launch it on so you need todevelop it for IOS and Android andpossibly web as welland to overcome or address all of thesechallenges we developed immersive streamfor XRhere we use cloud gpus or Cloudrendering to create photorealisticimages that we then stream down aslightweight video frames to the deviceto illustrate the point aboutphotorealism here on the right side youcan see a 3D model that was renderedwith the desktop class GPU and on theleft side you can see a similar modelthat would be these days rendered onyeah mobile devices stillso the goal is to bring thephotorealistic image quality to mobiledevicesand we want to do this by still enablingimmersion and interactivityso thephone or the mobile device only sendsinput events to the cloud where we usepowerful Cloud gpus to render theseexperiences and stream them down aslightweight video frames so all thedevice needs to do is just send inputevents and decode a video frame so wecan create the same footer realisticexperience on any device whether it's anolder iPhone model or the newer a newerpixel model and here you can see avirtual car experience that we createdwith one of our early Partners Lexuswe do all of that while being seamlessfor the end user as you can see here ina digital or virtual kitchen experiencethat we created with Lowe's all the userneeds to do is just scan a QR code orclick a URL and the user is takenimmediately into the app and experiencesum yeah the first video framesimmediately there's no app downloadrequired because we are integrated intothe Google apps on Android and iOS andwe also have a web client that we canusealso there's no content downloadrequired this model that we arerendering here is roughly five gigabytesin size and we start rendering rightaway there's no need for preloading anyof the contentand all of that works on any devicewhether it's Android iOS or web we takecare of the end client and you don'tneed to worry about it developing orDistributing the client to any of theusers that you want to Targetwe support multiple platforms so youbuild the same experience once and youdeliver it everywhere and here you cansee like the experience that we willlater seeum appear present as well for Volkswagenthat runs on a mobile phone but alsoruns on a desktop and it just scales towhatever aspect ratio or end user deviceyou are usingfor the developer it's really easy toonboard so whether you have a 3D modelor an existing Unreal Engine project youcan just onboard with three simple stepsby adding a couple of files to yourexisting unreal projector you can start with a template projectthat already showcases a couple ofdifferent experiences that we have forexample for car configurator or afurniture configurator and all of thatis hosted on GitHub everybody candownload it and get started right awaylooking at the developer flow thedeveloper starts byum yeah First downloading Unreal Enginefrom epic and also either our GitHubdeveloper project or they start withtheir own Unreal Engine project and theydownload that to their developer machineor their workstation where they startiterating locallyonce they're happy with their contentthey upload it to Google cloud storageand then create two resources one is thecontent resource for immersive streamfor XR and the other one is the instanceresource the instance then tells uswhere we want to deploy that contentand from there we take all of thecomplexity away and we the all thedeveloper then gets is a URL or a QRcode that they then can share whereverthey want with their end users and theend users can then look at theseexperiences on their devices whetherit's mobile phones or desktops and justuse this one universal link foreverythingwe are at the moment we support theseCloud regions where we run cloud gpusand with these regions we can reachroughly the users in all of thesecircles that we show here and this isfor a typicalexperience that can tolerate up to 100milliseconds 150 milliseconds of motionto Photon latencynow latency is a common problem withCloud rendering solution we want to makeit as smooth as possible this is why wecreated a specialized latency correctionalgorithm for the XR modes that wesupporthere you can see what artifacts wouldlook like if we were to use the imagesthat we render in the cloud right awayand blend them with the camera image onthe client device and you can see thevirtual image starts swimming on top ofthe camera image breaking the immersionright awaythis is why we render more and try tocorrect the camera image or the virtualimage that we receive on the client sideso that it's the virtual image staysanchored on top of the camera image andkeeps the immersion alivenow we can deliver industry-leadinggraphics and we do that by using UnrealEngine 5 which is an industry leadinggame engine so we meet the developerswhere they areand Unreal Engine 5 is two great toolsthat help us with that the first one isnanite which allows us to create massiveextremely detailed worlds and streamthem downand the second one is Lumen which allowsus to create photorealistic Dynamiclightingon the hardware side we are using Nvidiagpus which are industry-leading graphicscards at the moment we support Tesla T4gpus but we are soon adding support forL4 gpusand these L4 gpus are great at renderingand encoding video but they're alsogreat for generative AI workloadsand this is why we are starting toexperiment with generative AI forvirtual backgrounds for example herehere you can see the Volkswagen ID busmodel in two different scenes that werecreated from text prompts and as you cansee not only does the background changebut also the reflections and thelighting changechanges depending on the text promptthat we useimmersive stream Forex art is integratedinto the Google ecosystem so it's reallyeasy to run ads with immersive streamfor XR where you can just use Google adsor the Google marketing platform tostart your adson YouTube you can create video ads withthe master stream for XR and also usethe QR code in your video contentand finally we have an integration withGoogle analytics where you can runcustom reporting for the experiencesthat you want to Launchhere you can report on any custommetrics such as visit account or mostpopular configurations or any ARinteraction that you want to trackwe can do all of this at world scale sofor one we can have a large number ofconcurrent usersand we can render massive 3D models orWorld catalogsand we show this by our Integrationswith Google Maps so there's a newfeature in Google maps called immersiveview for points of interest and soonthere's also immersive view for routesand this is all live in Google Mapsalready and here you can see that we canlike this is all running on immersivestream for XR and you can see that wecan render or that we can operate theplatform at Google scale or Google mapscale and we can render an entire modelof the real world or the 3D 3D model ofthe entire world on our platformnow there's a couple of customers whoare using this already kddi one of thelargest telecommunications providers inJapan is using immersive stream for XRto stream or render virtual concerts andthat you can see here on the left sidewhere they have a huge screen and thenrender these experiences down to thatdevicethe Singapore tourism board is usingimmersive stream for XR to render uhtourism experience or previews of whatit's like to to visit Singaporekdbi again is using immersive streamflixR for a virtual fashion showand then finally we have Volkswagenwho's using immersive stream for XR tocreate a virtual card configuratorand now we'll hand it off to Pierre totell us more about how universe createdthis configuratorthank you Bernardthank you for the introduction it'sgreat to be with you here all inbeautiful San Francisco my partner milcoand I established Universe X lab in 2020as an immersive studio and r d companyas a team with Hollywood visual effectsexperience and automotive and gamingwe're offering a unique blend ofservices from Real Time and webdevelopment to AI powered automationforeignmarketing team and you never sharemutual passion for new technologies suchas Ai and immersive Tech Forex flying isalways interested in using newtechnologies in innovative ways to showcustomers a Volkswagen before it ismanufactured our journey began withseveral exciting VR and AR showcases forthis our first Vision was actually quitesimple we wanted to allow customers tovisualize their personalized digital carright outside their own homes howeverour early projects were often driven bycomplex 3D data preparation rather thanfocusing on creating captivatingexperiencesto give you some context the digitalconstruction files of a digital twin canconsist of 30 or even 60 millionpolygons polygons are the digitalbuilding blocks of 3D worlds similar topixels on the screen this level ofdetail is a lot for most phones ortablets to handleusing standard polygon reduction methodswould result in something that looks alittle bit like a Swiss cheese so itwould be full of holes and looked maybeeven distorted therefore a lot of manualwork is necessary to make sure that thesimplified car model still looks likethe original designunfortunately these adjustments alsoinvolved acceptance procedurespotentially causing delays in Projecttimelines this procedure takes up a lotof time up to three months and sometimeseven more recognizing this as an r dcompany we decided to find a better wayto simplify this process we developedour own technology to reduce the numberof polygons from Cut files and thenumber of objects displayed in thereal-time enginewe combine these methods with AIalgorithms that learn and recognize the3D objects to know when to apply whichreduction optimization method thisallowed us to automate the process ofsimplifying digital twins over timewhile preserving the original shape andformwe called our AI geometry optimizationtechnology solid matter and used it forthe first time on the id4 which reportedfrom cut to the GLwhile we were quite happy with the 1million polygon model the final look wasstill not perfect as we'd liked it to bebecause webgl is unfortunately no UnrealEngine and it has still some quite somerender lookyeah limitations as you can see herefortunately for the ID bus AR projectGoogle isxr team collaborated with us inVW thanks to to the isxr technology wecould remain within the Unreal Engineand could benefit from its exceptionallighting engine and Automotive shaderswe also did not have to go down with thepolygon count so much we found thatkeeping the 63 million polygon modelbelow 50 million was actually theperfect range to complete thatcompletely implemented the need for anyremaining retopology taskall this allowed us to spend more timeon the overall experience in this regardGoogle provided us with the customizabletemplate that we effortly aligned withVolkswagen brand guidelinesthis streamlined the duration for such aproject from at least three months downto only four weeks thanks to the modelconversion power AI the ID bus wasaccurately represented eliminating theneed for further acceptance loopsmost of you probably know that userstoday just don't download apps as manymore as they used to be especially largeapps with lots of gigabytes thanks toisxr there is no need for an appdownload there was really that wasreally great for us as we did not haveto create publish and support two appson IOS and Android thanks to i6r assetpreloading even Large mobile models loadup in one or two seconds so that'salmost instantly right within yourmobile browser this streamlined deliveryensured the ID bus was displayeduniformly across all platforms anddevices eliminating extra acceptanceloops I still remember the moment when Iaugmented the ID bus in front of my ownhome in Germany that's the picture thatyou see as a stream and I could notbelieve how stable the tracking was itwas kind of like the first time that Iactually saw it this marked the realrealization of our vision we startedwith Volkswagen more than five years agotoday we're actively exploring thepossibilities of this technology weperceive the impact of immersive ads ashighly disruptive we found thatengagement rates of isxr ads on the IDbus were 11 times higher than rich mediaand three times higher than standard 3Dads in addition to that Google isxrtechnology when combined with thedigital twin powered by solid metagrants the automotive and otherIndustries with the possibility of asingle real-time model that can beutilized for streaming AR on mobilephones and 2D configurators on desktopdevices we are offering our solid metaAI geometry conversion technology as aservice in cooperation with Google andtoday if you're interested in usingsolid meta for your own i6r project youinvited to join our waitlist atsolidmeta.io thank you all right as Isaid you can start these experiences byscanning a QR code or you can also trythese experiences from our product webpage right away and on the product webpage we have a link to this experiencehere already and if you click it you'retaking into the Google app on iOS andyou start in 3D mode where you first areshown or presented with a 3D model thatyou can interact with you can move thecamera you can zoom in and out you canenable hotspots to interact with the carmodel and yeah look at all of thedynamic elements that we have but youcan also customize the model you canchange the paint to something that youlike maybe this orange looks nice andthe rims you can change as well and thenyou can look at the rims in in moreclose upyeah and then like we have we start withthis Studio background but we also allowthe user to change the background wehave in this experience we have fourdifferent backgrounds this one is aMountain Road background that we createdfor thisand you can also jump in side and lookat the yeah from the from the driver'sperspective what it would look like wehave a beach scene that we can loadand then as weseen before we have a generative AIbackground that we created here from atext prompt and then when you're happywith the car that you configurate thatyou configured maybe we take the yellowcolor you can then also start looking atit in augmented reality you quickly scanyour environment and then you can placeit here and look at all of the detailsthat you want to explore further andthis as Pierre mentioned this is areally detailed model so we can look atall of the different details here we canlook at the stitches on the steeringwheel which are all modeled out we canlook at the HUD here and see all of thedetails that we haveor yeah look at the different seats thatwe haveand we can still configure the car inaugmented reality as well we can bringup a configuration option here we canstill open the car doors and then we canalso look at the car in a virtualreality where we take over the entireseen and don't show the camera imageanymore but have a fully virtualbackground and here we can for examplelook at this beautiful beach scene fromthe driver's perspectiveyeah and yeah you can try all of thatyourself as wellby just going or navigating to ourwebsite to check out the differentexperiences that we have listed thereso we don't need that in conclusionimmersive stream for XRallows developers to createphotorealistic 3D and XR experiences andcreate seamless user experiences wherethe user doesn't need to download anyapp and for the developer it allows thedevelopers to have fast developmentiterations and a fast developmentprocess if you want to learn more youcan navigate to XR with google.com whichis our product page which has all of thedetails that you need to know and also acouple of links to the live demos thatyou can check out for yourselfnow with all of these sessions we arevery interested in feedback so if youhave the cloud next app installed pleaserate this session and tell us how we canimproveand we have a bigger presence here atCloud next so we had another talk at theinnovators Hive earlier today if youwant to learn more our colleagues Mikoand chingxa are here as well to tell ustell you more about developer specificdetails how you can can get started andwe have two demo stations where you cansee the demos for yourself we have theQR codes there and we are stuffing itthere as well and we also have some coolswag there we have these hats so if youcome talk to us at the demo stations youcan get one of these hats for yourselfum yeah and we are at the demo stationsfor the next few daysum so yeah please come byum that is our session thank youeveryoneforeign"
}