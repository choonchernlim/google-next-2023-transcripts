{
    "title": "Performance optimizations for Java applications",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV301"
    ],
    "video_id": "wNXMBi9g0uw",
    "time": "Aug 29 01:00 PM - 01:45 PM CDT",
    "transcript": "foreign[Music]optimizations for Java applicationsand my name is oops wrong wayAaron one Jolla and I am the Javadeveloper Advocate at Google Cloudprior to becoming the advocate here forthe Java Advocate I was you know aregular Java developerand when I was on a team in an org in aSprint it never really made sense for meto take time to look at what washappening with different jdk vendors orFrameworks as far as performanceoptimizations to hold that in mindbecause the problems didn't come up thatoftenand that led to me not having them onhand when I needed to apply them to aslow project or a workload or webserviceand so the idea of this talk is that Inow that I'm a Advocate have the time tosit back and keep up with where thesedifferent optimizations are on theirrelease strains with differentFrameworks and in terms of theirReadiness and usefulness and preparethat information for you in an easy kindof practitioner levelbite-sized package so that you don'thave to do the legwork and you can justhave it in mind when your problems arisesoto get started on this topic we're goingto start with the word optimizationsI got the wrong way it's a broad termyou can kind of land a plane on the wordoptimizations hence the iceberg therebut I just want to talk about what Imean in this context by optimizationand what we'll be focusing on todayum because there's a significantdifference in how I would approachoptimizing a slow call within an appversus a slow app that's starting up ingeneralversus an app that's building slowly andsoum in my experience there's alwaysthere's there's kind of three broadclasses of optimizations that are worthum keeping in mind when you're going toapproach how to address them and so I Isay I would say that there's a buildtime optimization where you are you havethe app code together you're looking toship an image or a jarum that's one class of of slownessanother class is run time when the appis up and running it may have beenrunning for a long time it may have runthe same operation tens of thousands oftimes and this is where things likejbm optimizations can come in and offerperformance boosts and then there arestart time optimizations which areclosely related to The Hot Topic of coldstarts where you may be in a serverlesscontext you may need a container tostart up very quickly and perform withina certain amount of time when a customeris waiting on the other endand I would say that within thosedifferent problem sets there aredifferent optimizations that should cometo mind andapproach the problems differently so Ithink they're useful categoriesI should also say that the format of thetalk is going to beme going over a few of my thoughts aboutthis type of work and then I invite youto come up afterwards there's gonna beplenty of time for Q a there's amicrophone in the middle and if you seevalue in this kind of Preparatory workplease let me know if you have anyquestions about these optimizationsum I'm happy to answer them or get backto you on themanother tool that I use to sort ofassess how I wouldapproach fixing a slow workloadis with this sort of flowchart so at thetop we have a slow workload that I'mbeing presented with and I ask myselfyou know when is the app slow is it inthe build time category start timecategory or runtimeif it's in the build time category thenmy firstapproach is toask myself within the org like say I'mworking at a bank are our dependencieschanging very often or are we tied tocertain verified artifacts that we'repulling the same way every time if sothere's an opportunity there to not haveto pull and build the same layers of thesame containers over and over again withtools likewith tools that offer layered buildswhich we'll get into in a minuteum if on the other hand there is a runtime in efficiency wherethere's a hot path in the app and it'sjust kind of algorithmically slow that'smore ambiguous class of problem to workwithmy first stop is always tracingand then you kind of have to apply acase-by-case optimizationsthat is a topic all in its own thatdeserves its own talk there's a lot tobe done with tools like cloudtrace tooffer performance gamesbut the bulk of the time we'll bespending here is in the start timeoptimizationsso a helpful question that I like to askwith the new and emerging optimizationsis is this a long-running workloadI feel like that helps me pick betweendifferent optimizationsbecause if it is a long running workloador if it is not a long-runner workloadthen an optimization like native imagecompilation may be a good fit it's greatfor optimizing short workloads there's aset of trade-offs involved which I havespoken and written about quite a bitespecially last yearum I can share my my blog posts on thatbut if you do have a long runningworkload and you want something like theoptimizations that the jvm can have forrunning over a long period of timeand running the same operation over andover again that you may not want toadopt the closed World conception andthrow out the gvm with Native imagecompilation instead you may want to takean approach one of two approachesbased on another question which is areyou running many instances of theworkloadif you are then you may be leaning moreto class data sharing and if you aren'tthen crack maybe a good option as wellnow for myself a lot of these terms werea lot of these projects were not top ofmind when I was working as a developermost of the time because they justdidn't come up that often but I'm goingto take you through my journey offamiliarizing myself with these tryingthem out seeing the situations wherethey offer good performance gains andwhere they offer fewer performance gainsand hopefully that will get you thinkingon how it could align your projectsso we're going to start with the buildtime optimizationsone alternate one option for a loweffort but high yield build timeoptimization is using a build tool thatwe published in 2018 called jibit's an alternative that is demon-lessproduces fast reproducible builds anddoes not need an installation to getstarted you can actually just run itfrom a maven coordinate if you don'twant to change your Project's Palmsoum it's open source project andin order to well there are there arelots of people talking about it in thecommunity and how it isan option on par withum containerization methods like springboots built-in build pack supportthere's a wonderful article attached tothat it's available in the slides fromthe spring teamtheir are also significant performancegains in the layered versus non-layeredimage concept that I touched on earlierso in the top left there you can see thenon-layeredtaking an Uber jar and putting it into aDocker file approach simple it works butyou will be building that entire app theentire container from scratch each timeyou change anything if you change asingle piece of app a single line of appcode you're re-pushing the entirecontainer with the entire jar rebundledand as you can see that in the bottomleft it is in one big layer of 321megabyteswhereas if you take a layered buildapproach with the jib coordinate thereshown in the top rightinstead jib automatically dices up yourapp in a dependency layeran app layer anda libraries error layerI believe and so that means that whenyou change your app code only thethinnest slice which is actually yourapp code is being rebuilt and pushedwhich if you apply it to a build serverrunning hundreds of builds for an entireengineering or engineering organizationyour savings are your time spent on eachcache layer times the number of buildswhich can add up quicklyespecially if you're paying for thatcomputeumso there's an overview onjib is an option for layered buildingnext we'll be moving on to crackwhich iscoordinatedrestore at checkpointthis is an emerging openjdk projectbeing developed by Azul that defines anAPI for making use of your apps referralto allow your apps to make use oftaking a running instance creating acheckpoint and restoring the same app inthe same state from that checkpoint soin a nutshell it is restoring a Java appfrom a warmed up image and the wordswarmed up are very important therethe performance results are compellingfrom crack Zone Publicationsthese are if you're familiar with themuhresults on par with Native imagecompilation or neuron neuron parwith a different set of trade-offs soa good option to keep in mindumnowthere are some considerations involvedit is still in a pre-generalavailability state it is gettingexcellent support from Frameworks but itinvolves certain kind of early adoptersteps like using a specific Tomcatversion that supports the coordinatedrestarts of a running image or a runningapplicationum which is a hurdlebut the experience of using it isactually relatively straightforwardyou're able to run your uh run your Javaapp normally with a flag to saythis is where I want to say that thatcrack checkpoint 2 flagdefining a path where you'll be savingyourum your checkpoint fileif you don't Define that I believe itstores at Java home by defaultandthen you run use the jcmd command torestore from that checkpoint later withthe crack restore from CR commandand so I'd say International limitationsof crack are that it is still very newvery promising but very new it hasimproving with limited supportum currently it only runs I've only beenable to get it to run on specific Linuxdistributions not on Mac not on Windowswhichis likely not a problem for build ordeployment servers but likely an issuefor developer machinesand then the third is of course theelephant in the room the dealing withthe snapshotand I'd like to take a minute to talkabout that becausefrom the jdk perspective the snapshot isbeing the snapshot handling is beingexposed as an API and Frameworks arepicking up that functionality at animpressive rate so soon soon enough andspring boot 3.1 which uses springframework 6.1 you'll be able to havespring life cycle hooks that can feedoff of these snapshots and allow you totell your app what to do when warming upfrom the one starting off from a warmedup image sothese things are coming soon importantto keep in mindumnowand that's I would like to I'd like tounderline thatum crack is a good option if you are notrunning several applications so asopposed to class data sharing whichbenefits frombeing applied to several runninginstancesof the same appso class data sharing is a feature wherea feature that has been around in thelanguage for a long timeumone of the many things I love about Javais the Java enhancement proposal processwhich provides like a great historicalrecord for the language its features andtheir improvements over timeand because of that we can seethat class data sharing as a baselinefeature was established in 2004. in jdk5.so concept is fairly old but essentiallyyou are taking an allowed set of classesand pre-processing it into a sharedarchivethat can then be loaded into memory atruntime to reduce the startup time ofother apps that use that shared archiveand of course that can also reduce thememory footprint because many apps canrefer to the same class files with oneshared archive many jvms can refer tothe same class files so that reducesmemory runtimeanda walkthrough of the experience usingBaseline CDs is pretty straightforwardyou use the share flag and you have fouroptions dump creates the archive offsays do not use CDs on says use CDsand fail if you don't like do not startif you can't use the archive Auto meansuse the archive if and only if it ispresent in the place you expect it to beso interesting straightforward prettysimple a few years down the line we getapplication application class datasharingin Jep 310.and so this is where the applicationclass data sharing implementers came inand saidwhat if we extend CDs to allow otherloaders rather than the built-in systemclass loader to do the same sharingtrick to save memory at runtime and tobe more performantthis means thatit's so it could amplify the benefits ofthe same class data sharing systemnow it added another step to using theclass data sharing feature so you had touse use app CDs to enable the featureand then you had you this is a helperfunction the listing it allows you tolist the files that it would be loadingat runtime to help direct you whenyou're trying to create your archive andmake sure that you're dumping theexpected list of files and then pickthem up as expected laterand then finally the using step is whenyou actually use the shared archive andget the performance bonuses that arepromisedfantasticbut as you can see it'sumit the performance benefits aresignificant in the Jep they quotereduction start time Productions of 30to 20 to 30 percent in some swing usecasesum but we'll get to my findings in aminute here when I try to myselfin Jep 341 thoughwhich was not that far apart and from2017 to 2018there was default app CVS became a goaland so the idea with this Improvementwas to improve the out of the boxstartup time for developers withouthaving them have to take on the hassleof having to run extra dump anddeliberately take all these other stepshence making it the defaultso I found this to be very promising uheven though as a first cut it onlytargeted a subset of builds it was onlynative 64-bit buildsbut it's a step in the right directionandvery promising for what comes next whichis dynamic CDs archives in 2018. again alot of movement in the last couple yearswith these last two improvementsand so the goal here is to dynamicallydetect which classes are loaded out of ajar and which ones aren't so that you'reonly loading the shared archive filesthat would that would actually be usedbetween runs and making the whole classdata sharing feature transparent andusable out of the box withoutneeding a whole bunch of steps and flagsfor you to take onor fewer at least and so this is thepart where I would normally tell youlike we're in the promised land and thisis uh fantastically easy and usable butit wasn't immediately clear to mehow to get the benefits because when Itried itI ended up getting Vanishing returns orin some cases negative returnsand that was despite the fact that I wasable to prove that it was using theloaded filesbut the issue was thatum I was really only running a singleinstance of a single application where Iwasn't running enough instances of thesame application and so this is whereThe Shining example of this is an app anapplication where you can put upmultiple instances and have many manyjvms benefit from the same sharedarchive files because otherwise it isreally just having one jvm pick up andput down the same shared archive filesnot much of a performance benefit so Iwould keep that in mindand then finally there's native imagecompilationsonative image compilation for those whoare not familiarisengaging in a trade-offwhere you adopt ahead of timecompilation and instead of taking theclassic Javause case of writing your applicationonce and running it everywhere where youwrite the Java code and it runs on a jvmon top of any architecture instead youtarget a specific architecture atcompile time and go directly down tobytecode to a native executablesorry not by codeum so you that means that you target aspecific machinewith a specific architecture but you getnear native performanceas a resultit involves a number of trade-offs whichwill be going off going into in a minuteand of course the themost prominent way to engage in thistrade-off is with growlvm which is ahigh performance jdk developed by Oracleand in recent news it's gotten afantastic uptake from Frameworks likequercus and spring and that's why Ithink it's important for developers onGoogle Cloud to keep in mind because itis no longer a hard to useumkind of Arcane optimization it is beingput in your hands by fantastic work inthe spring in the open source communitysothisall kind of came into Generalavailability last year with springframework three spring framework six andspring boot threeand the benefits as I would State themare smaller artifactsyou get faster startup times because youare no longer shipping with a fullrunning jvm You're simply shipping theresulting native codeand finally you have a smaller memoryfootprint because you're not shiftingthe jvm now there are a number of welllet me link over the benefits moreumtheirare significant reductions in startuptime and memory footprintthe graph on the right is from a blogpost that I wrote last year where in anaverage of 250 startup times the nativeimage compilation started up in 0.6 of amillisecond versus 132 for the same appinhonor jvmand the time to First request had asimilarly effective result so ratherthan just starting up and beingtechnically available that was a springboot container that was ready to serverequests at the endumand that was on an E2 standard machinewhich is roughly equivalent to a 16 gigMacBookbut there are a number of limitations tokeep in mind which are chiefly theclosed World conception meaning that youhave to accept that your app is taking asnapshot of what is available on theclass path when it compiles and sayingthat aside from a few exceptions nothingelse is coming in you're not loading innew uh classes you're not loading in theresources from the file system it ismostly a closable conception withoutspecific annotation to get around itI know the significant loss is that youare losing the hot spot optimizations sothe jvm is very good at optimizinglong-running workloads as many of youknowand so by giving up that jvmit is best it is it is advised that youdo this in use cases where you know thatthis is not going to be running for along timeum in some cases you may know that it'sgoing to run for shorter than a singlegarbage collection cycle and you canselect a garbage collector that eitherdoesn't run or make sure that it workswell with how your workload is going toencounter garbage collection Cyclesand the last trade-off is that yourbuild times are much longer becausethey're much longer and they requiremuch more resources because you're doinga lot more computationat build timethe interpretation step of taking yourJava byte code to the nativeinstructions for the machine is runningon are an expensive step and that's whataccounts for the difference between Javaperformance and native languageperformance and so you're taking on allof that cost right at the start for amuch more performant native executableat runtime thank you"
}