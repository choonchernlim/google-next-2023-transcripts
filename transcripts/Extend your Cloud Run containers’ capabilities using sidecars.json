{
    "title": "Extend your Cloud Run containers\u2019 capabilities using sidecars",
    "presentation_type": "Breakout",
    "categories": [
        "Application Developers",
        "DEV302"
    ],
    "video_id": "lTUVPIvLWUo",
    "time": "Aug 30 10:00 AM - 10:45 AM CDT",
    "transcript": "foreign[Music]welcome to today's session on how toextend your Cloud run containerscapabilities using sidecarsI am Sagar randhive I am a productmanager on Google Cloud working onserverlessand I'm Clayton Coleman long-termkubernetes contributor and I uh the teamlead for workloads on GK and I work withCloud run to make sure we have aconsistent platform for all of yourcontainerized workloadsbefore we dive into the topic ofsidecars let's talk a little bit aboutwhat is cloud runso Cloud run is Google Cloud's fullymanaged platform for running yourcontainerized applications in a fullyserverless mannerCloud run allows you to deploy and scaleapplications fast and securely in afully managed environmentit's simple and automatedyou just need to bring your containerand we do the do the rest includingscaling down to zerothere is no infrastructure to managewhich means there is no compute clustermanagement required or networkconnectivity management requiredand it allows you to go fastera developer is able to deploy a cloudrun application in a matter of secondsso what are the use cases of cloud runhosting public websites apis where userscan render server-side pagesrest or graphql apisbi-directional streaming with websocketsor hosting private Services internalonly services that can talk over privatenetwork with each otherwhich may include websites apis or HTTPor grpc based microservicesand lastly running data processingPipelineswhich include processing queues messagesfor example Pub sub messagesprocessing data for event drivenarchitecturescheduled scripts as well as backgroundand batch data processingso there are two types of cloud runresourcesservices and jobsa cloud run service follows purely arequest driven scalinginstances within a revision are scaledbehind Google managed load balancerit provides out of the box URLs and TLSterminationthe built-in traffic splitting andgradual rollouts let you reliably createnew revisionsandmanage you lets you manage yourrevisions without any disruptions toslosa cloud run service has multiple triggerpoints the trigger sources like HTTP 2grpc events and socketsand a Cloud9 service provides multiplepricing options like pay as you gopricing paper request pricing or payingfor the lifetime of an instancethen you have Cloud run jobsCloud run jobs are nothing but a set ofcontainers that run to completionthey are not triggered by any HTTPrequestsCloud run jobsare executed manually or on an automatedscheduleand you only pay while the cloud run jobis being executed you do not pay outsidethe cloud run job execution timeCloud run is available today in all 38regions and 115 zonesincluding over 200 plus countries andterritoriestoday I am excited to announce thatcloudrun supports sidecarsso what are Cloud run sidecarspreviously every instance in a cloud runservice ran only one containerwe are introducing Cloud run sidecarsallowing you to start independentcontainers that can run alongside yourmain serving containeryou can use sidecars to monitor yourapplications in real timerun client connection proxies to connectto Cloud SQL or alloy DB databasessecuring your application networking byrunning proxies like Envoy or nginxalongside your serving container andmuch moreand to dive deeper into these use casesI'll pass over to Claytonover to Euclidthanks and there's a number of featuresum in sidecar containers that we thinkare important so first it's not just onesidecar it's up to 10.um we think that sharing in memoryvolumes between multiple containersallows sidecars and their primaryapplication to work together for moreefficiency generally configuringkubernetes style health checks forindividual containers so that thecontainers can independently fail andthen be restarted specifying the startupordering of containers if somecontainers have dependencies on anotherand we'll talk about that in a minuteand finally if you're starting up in acertain order you often need to have aconsistent order when shutting downsosidecars in generalum you're complementing the maincontainer with a supporting workloadthat adds AIDS in ensuring consistencysometimes that may be between differentteams between different programminglanguages or Frameworks where you wantto ensure a consistent Behavior acrossthem and sometimes it's a more complexuse case that just wouldn't be possibleif all of the code was in a singleapplication many of these will befamiliar to kubernetes users in theaudience which already allows multiplecontainers to run side by side as partof the same application while developingCloud runside cars we looked at existingcontainer production use casesfor in addition to taking directfeedback from serverless container usersthis breath really gave us theconfidence that we could simplify andstreamline these scenarios which is partof the promise of cloud run as well asadd some new features which we'll talkabout how those might come to kubernetesin the futurea classic uh sidecar use case is addinga second container to observe the firstyou might deploy an open Telemetrysidecar to write metrics to the managedservice for Prometheus and get the samemetric across all of your runtimes inCloud monitoring it might also act as atemporary relay to help you migrate fromone monitoring service to another forinstance if you decided to switch frommanaging your own Prometheus to usingmanaged service for Prometheus someusers might also use a monitoringsidecar to perform local analysis oflogs that could look for unusualbehavior in the first container withoutnecessarily shipping every line to logservice which might save you cost orincrease the performance of thecontainer itself the sidecar allows aclean separation between the applicationcode and a common or temporary problemmanaged potentially by the same team orby another teamadapting existing workloads to run inCloud run was a second use case that wethink abouta lot of existing workloads grew up in aperiod where they had significantsignificant existing proxyinfrastructure to support theapplication that might have been in theearly days that would have been Apachewhich dates me when I say that but thesedays it might be nginx or even Envoywhere you're performing a significantamount of logic before the requestactually hits your custom applicationuh you might also have a need for acapability that's typically provided byone of these proxies like uh local HTTPcaching for expensive requestsin this case a sidecar acting as a frontproxy would allow you to integrate thoseexisting proxies and then potentiallyprovide a more complex Logic on the wayas requests pass through to your mainapplication and that could be permanentor that could be template temporary andeither way the sidecar is letting youcomplement an existing app withfunctionality that in this case proxiesalready do and it doesn't require you toduplicate that in a particularprogramming language so if you wanted tohave consistent cache Behavior acrossthree or four different microservicelanguages because your teams arerelatively diverse you can ensure thatthrough the Sidecargoing even further into networking usecases a more advanced use case thatwe're starting to see is the use of amicroservice as a proxy for otherservices and in this scenariothe envoy proxy can handle incomingrequestsand we've got a supporting applicationalongside and that supportingapplication actually is doing analysisor processing traffic as a filter or asa detecting proxy and then after adetermination is made by the mainapplication whether this request ismalicious or not it passes that on to aremote service and I mentioned EnvoyEnvoy has a lot of advanced networkingcapabilities the pattern could also beused to bring your own service mesh toCloud run or to use this as a serverlessgateway to bridge betweena set of applications outside ofkubernetes and some on kubernetesa lot of the cases before I've beentalking about incoming traffic anothersidecar use case that we think is a bigopportunity to really accelerate whilestill keeping the serverless propertiesof cloud run is to simplify connectivityto the dependencies of our applicationhere we're using a database client proxyto authenticate and Pool connections ina sidecar and that reduces load on ourbackend databasethe application also can be oblivious towhere the database actually lives as anice benefit your local test environmentcan use a local connection to a localdatabase for testing when you deployinto production for cloud run the sameconnection string is in place so youdon't have to change config between thetwo environments which is a nice littlebenefit it's an opportunity to enforcesecure connections from your front endsto your databases and to use moreadvanced features like I am basedauthentication we currently offer opensource proxies for cloud SQL and alloyDB that you can configure to your needsas a sidecarand this use case is also an example ofwhere startup and shutdown orderingbecomes importantwe don't want our main application tostart before the proxy hasbecause if it does we might have to adda significant retry logic that might adderror messages to the logs it might addfailures to the events by adding startupand shutdown ordering you can eliminatea source of operational friction thatyou're using this proxy that gives youaccelerated performance without the mainapplication having to be aware of itwhich is one of the key goals ofsidecarsand finally uh I've most of theseexamples have involved a single sidecarcontainer we wanted to cover one thathad two this is a more advanced usagepattern and it's similar to some of theprevious ones so in this case you mighthave Envoy acting as a front proxybefore requests hit the application butinstead of the application being the onethat's providing that filtering logic wewant to standardize how policy andaccess checks are handled across a largeset of microservices and so here we'reshowing an example of using an openpolicy agentsidecar which will make policy-baseddecisions on behalf of the applicationthese two sidecars working together getthe best of envoy the best of openpolicy agent and providing a standardway to represent request policy and theapplication itself remains agnostic andthis you can think about this asseparating the responsibility betweenteams as well the application team mightwant to specify the policies forthemselves using the open policy agentlanguage and the team that might providethis consistent Behavior wants to ensurethat all the applications perform wellthat if they find a bug in theintegration between the two they canroll that out to all of theirmicroservices at the same time and sosidecars also help bring teams togetherand uh we stopped we've added twosidecars here since we support up to tenthere's no reason you have to stop hereyou can imagine uh if you so choose uhcombining some of the previous patternsuh you might have a container to forwardmetrics two to apply policy to requestsand a fourth is a client proxy as adatabase I'm not saying that's a goodidea but it's something that we supportand as I mentioned earlier many of thesepatterns are in common use in kubernetesand we increasingly hear from customersusing Cloud run and gke together Cloudrun sidecars expands the set ofworkloads that can run on both Cloud runand gke and you can see from the exampleconfiguration how Cloud run requiresonly uh only superficial changes toadapt this multi-container kubernetesdeployment to a serverless cloud runservice with sidecars we often talkabout how Cloud run simplifieskubernetes sidecars are also an examplehopefully the first of many where Cloudrun helped influence the community keyfeedback from cloud run use cases andcustomers about sidecar helped us guideand accelerate a kubernetes enhancementproposal for sidecars that resolve thenumber of long-standing pain points withkubernetes sidecars and this sort ofcollaboration is part of our opencommitment to open standard or ourcommitment to Open Standards in theecosystem and interoperability betweenCloud run and gke I'll now hand it backto Cigar to cover some a customersuccess story with Cloud runthank you Clayton those are a lot of usecases for one featurelet's talk about a customer successstoryNASDAQ is a Google Cloud customerwho is committed to helping itscustomers efficiently Monitor and reporton their sustainability performancein 2022 NASDAQ acquired material aplatform that allows companies to reporton their environmental social andgovernance performancethis platform collects measures andanalyzes corporate sustainability datain real time and generates investorgrade reports designed to be sharedstrategically and cost effectively withstakeholders such as ESG ratersrankers Frameworks and regulatorsMetro follows a four-step approach toreport on ESG performancefirst it centralizes the qualitative andquantitative data this data can comefrom various sourcesincluding water consumption wastedisposal HR and electricity consumptionthen create customized kpis to measurethis datafollowed by generating investor gradereports designed to be sharedstrategically and cost effectively whichstakeholdersand finally publish that content onlinefor interact in an interactive way forconsumptionrecently material migrated to Googlecloud from another cloud serviceprovider let us see whyMetro migrated to Google cloud fromprevious stackthat ran Ruby on Rails on a VMon a different Cloud vendorthe old architecture was hard to scalebecause everything was collocated on thesame machinethey were looking for a reliable newcloud provider that would allow scalingin the long runthey also suffered outages whichmotivated migration to Google Cloud forits Global coverage scalability securityand high availabilityMetro chose Cloud runGoogle's serverless compute platform tofully power its sustainability reportingsoftwareCloud run allows material to runstateless containers that automaticallyscale Up and Down based on demandthis means that material only pays forthe resources that they consume whenthey are serving requests and do nothave to worry about Auto scalingpolicies or managing infrastructureas a team material wanted to operatewith a focus on developer productivityto avoid the burden of managingoperations whenever possibleCloud run is fully managedso it removes the burden of patchingkubernetes versions and operating systemversionsallowing customer to focus on deliveringvalue more rapidly to their customersit's ease of use and deployment speedalso enabled material to create newproducts as they migrated from their oldinfrastructure provider to Cloud runa few of materials team members have akubernetes backgroundand expressed interest in being able toleverage kubernetes features on cloudrun without having to manage nodes orclustersMetro has a startup mentality withambitious deadlines and product visionsthey really enjoy focusing ondevelopment rather than managingkubernetes resourcesCloud run made the ramp up extremelyeasy and made the customer feel secureknowing that if Cloud run isn't a fitfor a workload they can easily shift togke and still have the servicesinterpretablebefore cloud cloud run material wouldrelease codes few times a monthnow they can release multiple times aday making it a lot easier to spin upsandbox and demo instances for fastproduct iterationso what is materials visionmaterials vision for cloudtransformation was to separate databasesfrom compute so that the storageperformance and capacity can be scaledindependently from computethis database segregation also helpsthem achieve a sock 2 certificationmaterial leverages Cloud run as acompute layerand mongodb for legacy data while alsoleveraging Cloud SQL and alloy DB fornew servicesMetro uses six Cloud run Services percustomer and have over 800 Cloud runServices running in production todaymaterials data ingestion tools Powersover 120 businesses helping them keeptheir data clean and auditablewith an edit history and activity logthey allow a wide range of data onboarding options including templatesscripts and apisthis data can come from various sourcesincluding water consumption wastedisposal HR and electric electricityconsumptionas the application grewthe need to support download and uploadof large files became the biggestblocker for materials largest customerscustomers wanted the ability to uploadlarge data files without refactoringtheir client or server codenow I'll pass over to Clayton to explainhow they accomplished this using Cloudrun and the sidecars featurethank youso uh serverless platforms often have toimpose limits on the size of requests toguarantee a high level of service thiscomes obviously with a trade-off is thatyou can scale faster and that responsesare short-lived and often can quickly beresolvedin this case Cloud runsgenerous but not infinite 32 megabytelimit for the size of a request bodycreated a choice for Metro and how theywere adapting their upload applicationfor serverless should they update theserverless code or should they updatethe server code sorry to accept HTTP 2connections which have no limit on thesize of request body at the cost ofadditional development time and effortfortunatelyfor this talk as well as for Metro theaddition of multiple container supportin Cloud run opened up a simpler pathMetro was able to use Envoy as a frontproxy in the way of their existingserver code to accept HTTP 2 connectionsconvert the large HTTP two requests intoa large HD P1 request that happenedlocally inside of their Cloud runinstance and was then passed over thelocal network to the application sothere was no performance hit other thanthe latency involved in taking that bitsand the ability to leverage Envoy to dothis versus putting this in theirapplication code was also meant thatthey were able to take a pretty commonscenario that Envoy is tuned extremelywell to so this is another example oftakingcode that already works for a specificuse case such ashandling Network requests and they wereable to quickly integrate that intotheir Cloud run instance once thesidecar support was deliveredby deploying Envoy as a sidecarcontainer they were able to avoid coderefactoring and update the service butthey were also able to simplify themanagement of their microservices andthat use of envoy was really key forthem because their Journey started withmodernizing this application but itdidn't end there with over 800 Cloud runServices they increasingly anticipate aswe say for the long run the ability totie these applications together bringingEnvoy in in the near term as a frontproxy also opened the door to allow themto bring their own service mesh and toDefine their own rules for connectingthe front end and their uh their initialupload applications on the database tomore complex micro service scenariosthat they anticipated having in thefuture and overall they saw improveddeployment speeds a simplification ofthe management of the microservices andgreater scalabilitythank you Claytonso what holds for future of nasdaq's useof cloud runin future material intends to leveragesidecars to secure communication betweenGK workloads and Cloud run adhering tostrict compliance compliance standardsof financial servicesmaterial also plans to use openTelemetry collector sidecar toinstrument their Cloud run applicationsfor custom Telemetry for performanceanalysis troubleshooting and capacityplanninguse of open Telemetry will allow sendingthe tracing data to Cloud Trace directlywithout any hops in between thusoptimally implementing the SLO and SLIsupportMetro's adoption of cloud run for itssustainability reporting software hasresulted in numerous benefits includingimproved deployment speedsimplified management of microservicesand greater scalabilitythe use of cloud run has enabled them tofocus on delivering value to customersrather than managing infrastructurereducing the time it takes to create newproductswith its innovative roadmap Cloud runhas become a game changerfor customers like material to meettheir goals thank youforeign"
}