{
    "title": "Prompt engineering: Getting the skill your team needs next",
    "presentation_type": "Breakout",
    "categories": [
        "AI and ML",
        "AIML214"
    ],
    "video_id": "Mt5tLP-i5EU",
    "time": "Aug 31 12:15 PM - 01:00 PM CDT",
    "transcript": "foreign[Music]welcome to prompt engineering gettingthe skills your team needs next it's thelast day of next so thank you so muchfor bringing your energy to this finalday originally we actually had this talkreserved in a smaller room but it turnsout that this session was one of thefirst in the catalog to fill up so weactually have to move it to this roomand so I think it's safe to say thatprompt engineering has become top ofmind for teams and a little bit of abuzzword maybe uh in fact when we werepreparing for next talks this year itactually got a little confusing when werealized that teleprompter Engineers arealso called prompt Engineers so I thinkit's it's it's become a little bit of anoverloaded term but now in this newworld of generative AI promptengineering can often be misunderstoodas llms and models continue to change inbehavior and performance and so todayour goal is to demystify promptengineering and how you can think aboutit when building your own generative AItools for your teams hi everyone my nameis Stephanie Wong I am a product andproduct manager for duet AI at Googlecloud and today I am welcomed by anAll-Star cast today we have Ting Liu VPof cloud AI platform at Google Cloudwe also haveJustin Ferris who is the VP of productmonetization at git lab and Kevinschatzgamer who is the managing directorconversational AI at Google cloud andRachel Meyer who is the director ofmedia and knowledge engineering here atGoogle Cloud so welcome everyoneso let's just kick it off I also want toremind you all that we're going to have30 minutes of this discussion and wewill have time for audience questions sobring your questions at the end allright so why don't we just first startoff by having you all introduce yourselfand tell us about your background inthis space uh we'll start with you tingthank you Stephanie hello everyone I'mTing Liu I'm VP of engineering uhworking on the vertex AI so we basicallybuild the end-to-end platform uhincluding models tools andinfrastructures to make it available forcustomers to build your AI Solutions ontop of our platform I've been working atGoogle for 17 years actually I getmachine learning degree from CMU and Ijoined Google right after my graduationI've been working on a variety of Googleads products using machine learning andabout four years ago I joined GoogleCloud very excited about the new Janaiopportunities and have the opportunityto share with everyone here and discusswith everyone about the future of gen AIand Justin yeah I think Stephanie JustinFerris uh I work at gitlab and prior togitlab I worked for a very large RealEstate website where we were using Aiand ml to help recommend homes for usersat gitlab over the last 12 monthsobviously gender of AI has ramped updramatically so we're spending a lot oftime in prompt engineering leveragingGoogle modelsum to make developers experiences moreefficient more productive and moresecure so I've become an expert in thelast 12 months but dabbled not as longas uh Hing but but uh over the past fewyears yeahKevin uh yeah so uh so I've been atGoogle for three years uh since I'vebeen here I've been leading teams thathave done quite a bit in theconversational AI space largely aroundinitially contact center use cases interms of development of of virtualagents that can handle requests so thatthings don't hit live agents over thecourse of of that work most of the workwas originally spent with custom modeldevelopment Custom nlu Custom speech Etcbut with the rise of large languagemodels we've largely been transitioningto uh to be able to move away from verybespoke conversational design use largelanguage models to guide conversationsand only interject very bespoke dialoguedesign to an absolutely necessary andthen for the lastcall it eight months a lot of the workthat me and the team have been doing isuh demonstrating proof of concept andpiloting a number of different use casesthat leverage conversational AI to talkto data machines and systemsawesome Rachel hey everyone rayder MayaI've been at Google as well for about 18yearsum not all of that time in machinelearning that's relatively new for meI've been in Google Cloud for about thelast five or six I have a couple ofresponsibilities as an engineeringdirector I'm responsible for improvingthe quality of the models that we usefor duet Ai and Cloud working with a lotof the teams building Integrations ontop of those models I am alsoresponsible for developer relations teamwe're doing a lot of work in that areato explore how we can use some of theselarge language models and generative AIto drive some of the efficiencies in thework that we do creating media codesamples and other developer enablementmaterialand raida is my director so it's uh ourfirst foray into gen AI this year tootogether all right so let's set thestage and drill into a major theme of2023's next what kind of generative AIapplications are we starting to seeacross organizationsum Kevin why don't we start with youyeah sure I think you know just I Ithink every industry every company ishaving this conversation right now Ithink it's at the board of directorslevel I think every board is askingtheir leadership what are they doing inthis space and uh you know what we'vebeen working on ranges from how do wethink about a Travel Assistance productrecommendations we're seeing quite a bitcontinued growth within the contactcenter in terms of agent facingcapabilities in terms of uh customerfacing capabilities to be able to answerquestions everything from FAQ to morecomplex transactional type use cases Ithink we see quite a bit in thefinancial services industry todayeverything from retail banking to toresearch side I think healthcare hasbeen on the rise in terms of thinkingabout how do we go through uh reallycomplex documents and expose summarizedinformation out of those documents butif I kind of had to summarize right Ithink a lot of it is really orientedaround how do I make data conversationaland how do I do how do I extractvaluable insights out of really largecorpuses of text in a very Rapid Wayand what about you Justin what have youseen yeah I mean I see it touching everyfafs of an organization and as I thinkabout it it's you have all theseknowledge workers in a company andthey're tasked to bring value to yourorganization and so the board level Iagree everywhere every level down in theorganization they're asking how can youmake those knowledge workers moreproductive gitlab it's all aboutdeveloper experience and helpingdevelopers ship secure faster code toproduction but I'm using it in what Ifound expense report and I go back andforth with the model to you know getapproval or something like that right sowe're seeing it everywhere and it'sreally about optimizing efficiencybecause we've seen the power of it overthe past you know eight or ten monthsTing you've been involved in AI forquite some time so what have you seenmore recently in this generative AIworld yeah so I agree with everyone justsaid like it almost impact almost everyindustry every sectors but from maybetechnology perspective uh in the past Ithink AI has been dealing really wellwith structured data so we have a lot ofmodels uh if you already have astructured data and there's many manymodels that can be used and driveinsights and and everything I think theGen Air Model really get into theunstructured data space uh start fromthe language text and conversations andnow you also see many many of the visionmodels like image models and we're goingto the multimodal world that uh going toyou basically you can leverage thinkabout all the the audio data the imagedata text Data all become available andfor model to synthesize understand andhelp you make insights of those data andcreate a informations I think this isgoing to impact everyoneyeah in radioyeah I think my perspective has beenvery much on the developer side ofthings so obviously in Duet Ai and Cloudthere's a series of things whichactually we've been talking a lot aboutover the last few days to help Driveefficiency for developers operatorsreally technical practitioners acrossthe board so that's been really excitingto see I think my other perspective isfrom that developer relations side ofthings where we've been hearing for solong that there's this challenge aroundjust being able to discover all of theinformation that you need as a developerto be able to solve your problemssomething like Google cloud has such arange of products and services andfeatures it can be difficult for folksfor developers operators just to findthe right things that they need and sowe're seeing a lot of opportunitiesthere to create uh Services solutionsfor people to be able to find theinformation that they need and also onour side to be able to create thatcontent for folks to be able tounderstand what's available and and dothat from a perspective of covering somany products that we need to talk aboutso that's been really helpfulso llms are specifically the models thathave been in the Limelight recently andI think one of the things that we'venoticed is that they don't necessarilyhave an intuitive understanding ofcontext and in most cases users need tobe explicit in what they do want or whatthey do not want and so for example ifyou don't ask for thread safe code itmay not give that to you and so that'skind of where prompt engineering comesin so let's dive into what is promptengineering what are some myths thatyou've noticed let's start with ratothat's an interesting question I I thinkas you said the key to promptengineering is is really about providingas much context as you can so that themodel has that intuitive understandingbecause by default it doesn't it doesn'thave real intellect it doesn't have realunderstanding and so as much context youcan give to be able to provide thatknowledge that it's then able tohopefully give answers that are more inline with what you actually want is keyand so I think when it comes to to someof the myths I think people can gettricked into thinking that they'recommunicating with an internet with anintelligence right that when you'resetting up the context of the prompt itneeds to be in good human languageEnglish the same way that you would talkto a co-worker and often that's not thecase uh you know there's all kinds oflittle tricks that you can use and learnas you're communicating with these llmsto how you can influence the way that itprovides the sorts of responses that arehelpful for youTing what have you seen what is promptEngineering in your worldyeah so I see Chrome engineer because Ithink because Jenny I I thinkfundamentally changed the way humaninteract with computer and Technologiesnow with human language you canbasically extract the model or let modeldo things uh but I have to admit it'sstill at the early stage so that's whythe model is not really can easilyunderstand what human want the model todo and it's very sensitive to whatkeywords you put there and uh but to dothat dual analogy is more like uh you'retalking to a uh like four years old orfive years old and then adults needs toadapt your language to make the the kidsfollow instructions but I think as thetechnology become more mature we alreadysee that more like larger more capablemodels are less sensitive to how youprompt the model so I think with time itwill be maybe less important uh of likethe problem engineer is more about youjust give clear instruction to themodels and the model should follow but Ithink there's still a long way to goyeah I feel like it's kind of akin totraining a puppy which by the way we dohave a puppy petting zoo at next and Ithink it's still on for today until noonbut you know it's you have to really bepatient and experiment with prompts andsee what is working with the underlyingmodel what about you Justin what isprompt engineering any myths yeah youknow it reminds me of a course I took incollege interpersonal Communications andone of the core tenets of that course isunderstanding the Nuance the backgroundthe empathy the existing knowledge thatthe other human has when you'recommunicating with them teaches you tobe a better Communicator effectivelyprompt engineering is figuring out thatUnwritten stuff the non-verbalcommunication that you might have with ahuman and passing that to a model sothat you get all the better outputs incontext so that model maybe isn'tactually intelligent but it has all thatcontext to give you better results asyou work on your applicationyeah I'll add to that right I heardClarity I heard context I think thoseare the things that I would pick up onright is that you know at large languagemodels are really driven byunderstanding exactly what you're tryingto ask and the more explicit you can beand exactly what you're trying to askgive it as much context as you possiblycan and start to put guard rails in thein that prompt for what you do want tosee as an output and what you don'tright remember it's still a statisticalmodel at the end right so the moreinformation you can feed it to help itfigure out exactly how it should responduh you're spot on right it feels likeyou're talking to a real person it feelslike it understands exactly what you'reasking but all it's doing is usingstatistical models to understand thesequence of words and the intent thatyou're trying to drive so I think it'sreally important to be able to have thatClarity and context and feed it into themodels as well but I would add to thatas well uh is that when I think aboutprompt engineering it's software rightit happens to be written in naturallanguage language but it's largelysoftware and I think it needs softwareprinciples around it yeah I think one ofthe really interesting things aboutprompt engineering as well is it it endsup having two elements to it yeah if uhif you're Building Products that thenhave a chat interface there is a wholebunch of prompt engineering that goesinto it from the product side that theusers will never see when you're talkingto any of the chat models Bard or youknow anything like thatthere is a bunch of additional promptengineering that gets put in so that themodels have the right sort of contextfor the experience that they'reexpecting you to have and then thenusers themselves who are having thosechats are doing the same promptEngineering in order to be able tobecome more and more specific so youhave that sort of General context andspecificity and then very specific foreach use case so it ends up beingsomething where to your point it'sprogramming it's it's softwareengineering and it gets done both byproduct teams and then by the end usersof those products as well let me justquickly we quickly add one more of astartum because a lot of people say oh wejust do proper engineering normally it'szero shot but sometimes field shot canbe really powerful a few shot basicallyyou instead in addition to give you givemodel the instructions you also providea few examples uh and then with that fewexamples sometimes the model can quicklylearn and then get the results that youwantI'm going to dive into those techniquesin just a moment here but I want to talkabout the impact on knowledge workersum you know many leaders want to unleashthe power of generative AI which shiftsthe burden of becoming a prompt engineeronto their teams whether they'rebusiness users whether they'redevelopers data scientists copywritersand so how will prompt engineeringimpact knowledge workers success in thecurrent state and future we'll startwith tingyeah so I think it's going to impactalmost everybodyand just take a step back so I I thinkif you look at the the history of humanhuman histories like the development oftools always has big impact to thegrowth of the society so treats the fromengineer or general model as a superpowerful new Gadget new tools and theneverybody no matter what area you areyou are in learn the the prom engineerlearn to use the model will benefiteveryone and make everyone be moreproductive I think uh so the sooner youget to it the earlier you get thebenefithow about you Justin yeah I often thinkof I agree wholeheartedly I often thinkof like the marketer as a good analogy amarketer in the 1950s was asked toproduce content and and and writtenmessaging in print media and so theirtool was the newspaper or magazine orsomething like that many technologicaladvancements have come along the wayover the years like television theinternet social media digital mediumsand all of those marketers had to evolveand build new skills to be effective inthat new Dynamic we still have marketersand I think we'll still have marketers10 15 20 years from now but they'regoing to need to master these skills tobe really effective at driving the sameresults they've been used to driving forthe organizations to this pointI was also going to ask this follow-upto you all about whether we think thatthere will be jobs that will be createdby it or become obsolete Uh Kevin yeahso so I'll build on all this first offyes to your answer right it's we'regoing to see new jobs created as aresult of this we're also going to seejust about every job change as a resultof this right and I think we're seeing alot of the change happening in thecreative space and that's everythingfrom software engineering to to themedia space right I think we we'vehistorically learned that the bestsoftware Engineers are not the ones whojust code really well but it's the oneto understand system design and how whatthey're building feeds into uh into alarger a a larger systemfor lack of a better word and I thinkwhat we're learning here with promptengineering is is a few different thingsright first off I think if from aconsumer side what we're used to is Bardright that's kind of the way we'veexperienced prompt engineering and wehave it right poems and we have to dosome some creative things but I thinkthat's just really scratching thesurface on the power of what we'recapable of doing and I think acrossevery industry across every role we'llsee two things happen one everyone needsto understand how prompt engineering andhow their ability to prompt largelanguage models to be creative on theirbehalf is something they'll need tolearn and then secondarily fordevelopers and those who are buildingend products right it'll be hidden it'llbe there it'll be in the back end and Ithink learning as a creative how toharness the power and the capability ofthe products themselves to help you moveforward is going to be super importantbut I think you know what I've learnedfrom a skill set perspective from frombuilding out teams in this space is thatthere's a software and Engineeringmentality that needs to exist for peoplewho are who are prompt Engineers but theunderstanding of the context in thebusiness right kind of the Consultingaspect if you can find ways to fusethose together and iterate together witheither common teams or single people whohave common skill sets across those twothe outputs are super powerfulcan you read up yeah no I totally agreeand just to build on what what you allhave already said I I think right now wewe are really at the early stage of thisright and so we can already see peoplewho are experimenting with this start tobe inspired creatively by some of whatcomes back from these models I think forme one of the things which has beenreally interesting to see is the way inwhich you can really Drive efficiencysuddenly a lot of the the boilerplatetype of work that we have to dorepetitive copying pasting from otherthings using templates that we've usedbefore we're seeing that these sorts ofuh generative AI llm tools can helpdramatically reduce the toil associatedwith a lot of this work and let folkpeople focus on the more interestingexciting creative work the businesscritical stuff that's really the hardpart of most of what knowledge workersare doing it's not the repetitive workI I think that is step one and peopleare already being able to take advantageof that I think we're the most obviousopportunity for new roles and new workis is building tools on top of the basicinfrastructure uh a lifetime ago Iworked at an investment bank and therewas a joke that all of the the bigproduction systems started off as amacro and an Excel spreadsheet there's alot of Truth to that and and I feel likewe're in that same sort of stage forllms where it's like we're buildingthose macros those prompt engineeringthings which an individual can work outto be able to drive their own processthen the next stage is then buildingproducts and tooling and infrastructureso that everyone can take advantage ofthat so I think everyone's going to getbetter at prompt engineering it's goingto be a life skill but there are goingto be ways to harness that and be ableto drive that next level of efficiencyon top of it yeah and I'll even add tothat right I think one of the thingsthat's happened you know maybe maybeit's covid maybe it's been us being onvideo so much and not being face-to-facedays is the explosion of the amount ofemail you get and information inundationand it's not and this is a place wheregenerative AI is has been super usefulright just this week we can look atthings like not having to take meetingnotes right because it's transcribingfor you and making that transcriptsearchable not having to write tldrs andreally long documentation being able tosummarize actions right being able tosummarize across lots of differentdocuments and being able to extract themost valuable information and I thinkwhere where we're seeing the power ofgenerative AI especially in that lastpiece is that the longer the context thelonger the information the better AI isis at extracting the relevant datapoints than humans are right andsimplifying it down to the most relevantthingsI want to go back to YouTube for asecond because I know you've had someinteresting thoughts about job creationobsolescence and this prompt engineeringis that going to be as important in thefuturewell yeah so I thinkumeveryone already said like this Ibelieve they're saying we're going todramatic change uh improve uh everyone'sproductivities and make everyone have asuper power to do their job so imagine aworld thatum every patient or everybody can gettheir own personal doctor and everystudent can get a teacherum I think without AI it's not possibleuh and we say I uh this is going to be amuch better award that I think nobodywill doubt like whether we still need ahuman doctor or of course a human doctorwe need a human teacher but I this thisjust going to get a massive scale toimpact everybody's life yes agreed so Iwant to skip forward a little bit but Isaw a tweet that was saying that themost popular programming language of2023 is going to be Englishwhich I mean it's kind of true I thinkprogramming in llm is essentially usingnatural language it's English and so myquestion is do you think that it'simportant for these users to have a verygood understanding of the underlyingmodel to be a better prompt engineer howimportant is machine learning expertisein this case especially as if we treatit as softwareum Rachel it's a really interestingpointum I I think the the speed at whichmodels are improving and evolving meanshaving that deep underlyingunderstanding of the model itself isgoing to become less important over timeright there's a lot of different modelsto choose from even from one companyum and so it's really I think a matterof learning how to program in Englishright and I think you're going to startto see a lot of similarities and andpatterns that can be applied there'sgoing to be always trial and errorwhenever there's a new model wheneverthere's anything new to use but no so Idon't think that the underlyingunderstanding the underlying model beingan ml engineer is going to be criticalfor success I think communication skillsright a lot a lot of the ways in whichwe communicate with each other are goingto be directly transferable to this ifyou think about it from an engineeringperspective that's a core skill forsenior Engineers it's you learn how towrite good code there's a ceiling tothat how well do you collaborate howwell do you share knowledge andintention across teams so that otherpeople can collaborate and and build onthose ideas I think that becomes supercritical for this and unfortunately likeI said one of my roles is in developerrelations I like to think what wedescribe ourselves as Engineers withstrong communication skillsthat works out well in this in this eraand we're starting to see that alreadylike people who have those strongcommunication skills are able to takeadvantage and really explore what'spossible using these models yeah howabout you Justin yeah I honestly thinkthe context in the application you'rebuilding is more valuable than deepunderstanding of machine learning rightso we have a feature we call explainthis vulnerability in our product andthe team that's working on that arereally great deep Security Expertsthey're not ml AI Engineers necessarilythey've probably gained a lot ofknowledge like we all have over the past12 months but in the day they'reprompting and validating the outputsthey're getting and building a productaround that and that knowledge existingcontext and knowledge that they have ismore valuable than deeply understandingthe model itself as these models getmore sophisticated you know their jobgets easier but that that context andthat deep knowledge they have is stillreally valuable to build great productsand experiences for users so so I agreewith all that I would even add to that acouple of things right you see goodprogramming English right and I thinkthe implications of that areunderstanding how a programmer sinksright and if if we're treating a promptas software it means that that softwareneeds proper Dev test around it it needsregression testing it needs VersionControl it needs iter iterations on topof it and proper troubleshootingcapabilities but also the outputs ofwhat comes uh in response to to theprompts I think is where we're going tocontinue to see an increase in continuedgrowth around data science right how doI understand the accuracy andside-by-side comparison of results andhow consumers will respond to that Ithink a lot of the machine learningengineering gets hidden right Tingbuilds the teams that go and do this andthen we turn it into the hands of thebusiness users who don't who no longerneed to understand machine learningengineering but I do think you know mathand science and the structured way ofthinking that that happens through gradeschool all the way through collegeapplying it to structured way ofthinking through prompting is going tobe super important here yeah it's one ofthe things we learned working with someof the teams building the duet AIexperiences uhmodels give really good believableanswersnot necessarily the correct answers andand so when you're building theseexperiences so much of what you end upbuilding is exactly that infrastructurehow do you test so that you can feelconfident that as users are using thesemodels either explicitly or is at theback end of a system that they'regetting accurate useful results and it'sa lot of the same software engineeringskills that we've been doing for yearsunit testing output testing side-by-sideevaluations the deep subject matterexpertise that you're alluding to it'slike you need those people to buildthese tests and make sure that the theend users are getting what they want andthey add feedback loops to understandingwhat your users are doing and howthey're accepting those suggestions andusing those suggestions in their workwill also help you you know build betterapplications right yeah so if I put mydevelopers hat uh there is basicallyevery developer can become a machinelearning engineer uh with in the llmworld because I think Beyond a promptengineer many many Enterprise customersor developers they also want to bringtheir own data to customize this modelso in the past the way to train a modelis start from data and then you pick amodel and you really need to deeplyunderstand how this model Works toreally build a customized model but nowall the custom models will start fromthe base model and what you need to dois fine tune the model not start fromfrom scratch and then fun tuning themodel is super easy at this momentbasically a few lines of python code anduh and every developer every engineershould be able tofine-tune a model to adapt to their ownworld but I think maybe some people willask a question will that push machinelearning engineer out of job but I thinkthe answer is obvious no because there'sso much to do to advance the underlyingtechnology for the large models andthere's a lot to do for researchers andmachine learning Engineers right so Ithink we're going to cover one quickquestion and then we're going to haveyou all come up to ask your questions ifyou have any so while they're preparingtheir questions I just want to talkabout prompt engineering because I thinkwhen we think about prompt engineeringwe're often interacting with the modelas an end user but really when we'rebuilding generative AI products it canhappen at many layers of the softwaredevelopment life cycle like for exampledoing pre and post-processing on promptsso have you seen Effectiveness in doingthis how important is it to doing thingslike reducing bias controlling theoutputand I'm going to wrap the final questionin here which is how can teams uh howcan we better prepare teams to takeadvantage of all of this I'll start withKevin yeah I think look for first andforemost if you're not experimenting andplaying with large language models andunderstanding the power I think you'reprobably right probably already behindright I I think that's first andforemost is don't be afraid to get intothe weeds and start playing with withlarge language models doesn't matterwhich one obviously Google Palm ispreferred but start playing with itstart understanding what it's capable ofdoing and start applying it to some ofthe hypotheses that you have right Ithink experimentation right now iscertainly key there's a very wideaperture and funnel in terms of thepotential use cases and I think what wefind is that unless you're building youdon't know if you're running into a deadend or a brick wall and you don't knowwhen you should start pivoting orchanging directions so keep on buildingfinding an obstacle knock down thatobstacle and keep moving forward andwhat that means from an experimentationperspective is uh same as any otherexperiment you start with a hypothesisand you iterate on each of your resultsright I've seen cases where a customerwill come to me and they'll be likehere's our original prompt we like thisthis and this about the output here'sthe seven things we change changed inthe prompt and it's not doing anythinglike what we expected of course it isn'tright how do you iterate and how do youstart to really understand how theprompt reacts to small turns of the dialrather than big turns rightum and what about you Justin yeah I lovethat and andum you know my guidance to a lot ofpeople that started this is uh don'tstop experimenting I see a lot of timesthey'll try something and then they'llget a result and it's not what they wantand then they'll go off and do it adifferent way but at the end of the dayit's all about experimenting rapidly andlearning those those techniques thosecontexts and it could be very simpleright adding more specificity givingmore context pre-prompting so on and soforth to help you learn how these modelswork you can obviously get moresophisticated few shot adjustingtemperature adjusting size things likethat can can certainly help but you canlearn a lot even just by small changesand small tweaks and just constantexperimentation yeah well I do want tomake sure we have enough time forquestions so do we have any audiencequestions so far beforeall rightokay hi my name is Issa and I waswondering something that I've heard andum at least felt like I've experiencedto be true is the phrase that promptengineering is more of an art than ascience and I really like the lens oflooking at it as software engineeringand again I've at least personallynoticed there's definitely patterns andthings you can do to make it better butI was wondering do you think just atleast due to the nature of these modelslike them being probabilistic and all inus not really understanding exactly howthey work at like each point do youthink there is a ceiling to promptengineering and how it could how good ofan output we can get and if so do youthink that ceiling is at least right nowum barring us from experiencing the fullpotential of these modelsit's a great questionum I I think there islikely a natural ceiling at the thepower of whatever models are currentlyavailable I would argue that theultimate ceiling I don't know if thatexists as the models continue to getbigger and bigger more powerful largercontext windows that we're able to useto to impact the way our promptengineering is working and then howeffective that engineering is againstthe underlying models I think we're justseeing things evolve and improve sorapidly that it's hard to hard toforesee what that would be I think forme I like to approach it as a science Ithink it can feel like an art because wedon't already know what the solutions isbut if we approach it like a science ofyes we need creativity andexperimentation but evaluating what theimpact of all of that is and and reallytreating it in that scientific method ofmaking do an experiment see the resultsevaluate at an ongoing basis I think aswell it's it's tempting to over index onthe prompt engineering the wordsthemselves and ignore some of the otheropportunities like look at what what theuser prompt is and then apply Dynamicprompt engineering to that decide arethese the sorts of questions we want toanswer and what is the right kind ofcontext so rather than just the samehuge context for every user questionunderstand the questions betterdynamically apply prompt engineering tobe able to specifically answer thatquestion I think that raises the ceilinga little bit higher yeah I I think it'sboth actually right it's both an art anda science and I'll think back tosoftware engineering as well right howmany times have I heard over my careersoftware Engineers they look at howbeautiful my code isright which kind of puts an art aroundcoding as an example but I I think we'rewe'rewe have a good understanding right nowaround the art the science is stilldeveloping right we talked about howmany different tools there are and waysto optimize whether it be tuning aprompt whether it be tuning a modelwhether it be few shot Etc I think we'restill learning the best approaches andwhen to use each of these differenttechniques and I think the science willcome and even as we Master those if youthink about tools that humans havemastered over time they still come upwith new creative ways to use thosetools in different contexts right sowhen we get there I still see the bowEye Group both it's like Art and Scienceand then the creativity kind of has nobound yeah and don't explore by yourselfbecause there's a lot of communitieslike people sharing best practice bestlike use cases I think those will bereally helpful for us to get insights uhand uh yeah awesome thank you for thequestion do we have any othershellothanks for sharing your interestingperspective on this my name is Pratap sowe all mentioned about softwareengineering and as we all know the codeis valuable people copyrighted patentedhow do you see prompt in thatperspectiveso so I I think there's a loadedquestion right there right I I think thethe legal Community is still working onhow to exactly answer that right I thinktypically what we've heard is thatthings that can be protected have to bematerially human right I think there'sstill a lot of questions in the legalCommunity as to what that meanscertainly a prompt is materially humanso there's a fantastic question as towhether we should be thinking about theprompts themselves as intellectualpropertyyeah I mean we at lab we love Google'sapproach which is why we've chosen touse the Kodi model familyum but you know privacy is critical andmaking sure that prompts aren't storedand used to retrain models that's ourstrategy that's Google's vision andthat's how we're leveraging thattechnology and so that gives us someHeadway and protects against thoseconcerns as especially as the the otherside of it which is okay what about theoutputs what about where does this allgo and how do we know our customers askus a lot how do you identify what codein my repository was generated by amodel versus generated by a human rightand so this these conversations willcontinue over the coming years but theway we've approached I think togetherbetween GitHub and Google is the rightfirst step for these types ofTechnologies yeah I think it's aninteresting balance right because if youare creating a product and are able tofigure out the the perfect promptingthat is able to make your product superuseful it's competitive Advantage youdidn't necessarily want to publish thaton your front page at the same timewe're at that early stage where sharingand exploring what makes effectiveprompt engineering what is able to helpprovide these things is is super usefulso I think I think most companies aretrying to strive for that balance of howdo we share what we're learning theapproaches that work you know multi-shotthose sorts of things student teacherlike there's a bunch of these thingsthat work without giving away too muchof the secret sauce that makes theirspecific products super valuableright I think we have time for one ortwo more questions do we have anotheronehi guys hi sorry uh noise skates onquick uh hopefully a quick questionum I have a couple of children one ofthem is about to enter University sowhen I hear you talking about Art andScience and I've read things thatphilosophy Majors may be better atwriting prompt engineering than machinelearning Engineers so what would yourecommend for people of the younger ageand going into this because there'sgoing to be huge opportunities out thereand schools I don't think are up totrain on this yet so what do you tellpeople who are just entering into theircareer paths where do I go or what whatwould be the the path to being a promptengineer in this opportunist world thankyouum I I think you have to start by ifyou're going to University what are youpassionate about right maybe that'sphilosophy maybe that's a science maybethat's artum but then use these tools to do thatwork right and I know there's a lot ofattention my mother's a professor sothere's a lot of tension in am Ireviewing a paper that's been written bya model or I'm reviewing a paper that'sbeen written by a human but uh as astudent I would love that experience tochallenge that and challenge thoseconversations in the classroom with mypeers and with faculty to help uncoverhow do we expand learning how do we gainknowledge quicker and faster and moreefficiently in the field uh that they'rein right because any of these fieldsthat someone might study theseTechnologies benefit them right theydon't have to go into softwareengineering to leverage theseTechnologies to become betterphilosophers better you know physicalscientists better writers you knowbetter teachers themselvesand I'll add one thing to that it'sthere's a lot of degrees that that youcan come out of college with now thatyou wouldn't have typically sought applyto the technical world right Linguisticsis a great example of that speechunderstanding communication all of thesethings I think we're applying in inprompt engineering and large languagemodels and I think there's a technicalangle to just about every role rightit's not just always I'm going to studyspeech and I'm going to move into SpeechPathology or I'm going to studyLinguistics and I'm going to be ateacher I'm going to studyCommunications I'm going to be aprofessor I think the the need for someof those uh some of those skills in theworld of tech has has grown prettyrapidly yeah I think my my quicktakeaways I think communication skillshave always been an undervaluedopportunity to learn and nowadays evenmore so I think that was a piece ofadvice like I would have always said ifthere's opportunities to learn to be abetter Communicator that is time wellspent I think that is especially true inin the world of llms it'll beinteresting to see if uh those sorts ofcourses are required in technicaldegrees going forward right usuallythey're not or it's a it's an ancillaryyou know credit but it'll be interestingto see if they fold those sorts ofthings in I was going to say mycommunication studies degree is finallypaying off so this is great news for meuh okay we probably have time for onemore question very quick onehey I want to know if um if you haveopinions on what modalities are primedfor the next big foundational modelsuh so right now the um that we alreadyhave a text model we already have aspeech model we already have imagemodels uh I think next oneum like video will coming uh and thenagain as I mentioned it right now it'smore like individual models uh thetechnology is converging uh in thefuture the large model will be able tohandle multi-modalitiesso just watch out like there's newthings coming almost every month and Iwould add to that right it'smultimodality on input and output inputand off yeahall rightum well we are just about wrapping upnow I would say actually because I thinkwe only have a minute left so I justwant to thank everyone for coming earlyto this session on the last day of nextuh after the concert last night so Propsto you all for making it out here todayum please leave us some feedback I knowthat's a big ask sometime but we reallyappreciate any feedback you can provideus and if you see us around after thislike feel free to reach out and askquestions and thank you all thank youTang thank you Justin Kevin and rato forjoining us today and sharing yourself[Music]foreign"
}