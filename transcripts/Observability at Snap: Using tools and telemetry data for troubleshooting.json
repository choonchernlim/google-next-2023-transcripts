{
    "title": "Observability at Snap: Using tools and telemetry data for troubleshooting",
    "presentation_type": "Breakout",
    "categories": [
        "DevOps, IT Ops, Platform Engineers, SREs",
        "OPS207"
    ],
    "video_id": "-IFg-c-uUmE",
    "time": "Aug 30 03:00 PM - 03:45 PM CDT",
    "transcript": "foreign[Music]good afternoon everybodyit's 1pm on a Wednesday afternoon and abeautiful day in San Francisco andyou're here to talk about observabilityat snap using tools and Telemetry datafor troubleshooting isn't that excitingyou know troubleshooting is not excitingbut the fact that you are here isexciting so welcome welcome to Googlenext 2023 and welcome to this sessionso first off let's start with a quickintroduction my name is afrina and I'm aproduct manager here at Google Cloudessentially my role is to be the gapbetween you and the productso over the years of working in CloudI've spoken to many many customers rightI can put customers in three big bucketsnumber one customers that are in the appmodernization Journey right here in Techwe call it modernization meaning you'removing from your on-prem to a publiccloud or private cloudnumber two you've moved to cloud or youwere born in Cloud not you know you'llfigure out how do you sustain and scalenumber three you've kind of done withnumber one and number two and you'vefigured out how to scale you've gonefrom millions of users and you have adifferent set of problem to solve butthen from a troubleshooting andobservability angle you've kind ofreached the plateau of productivityso for today's session we have invitedone such customer that would fall intothe third bucketas far as the agenda goes we'll havesnap to talk about how do we start inGoogle Cloud how did the journey looklike and they would also be giving us asneak peek into how does day-to-daytroubleshooting look at snap and thenI'll be back on stage and I'll talkabout common pitfalls what stops therest of us from not being able to getthere what makes the journey complex andhard and we'll talk about what are wedoing here at Google Cloud to make it alot more easier for you towards the endI'll talk to you about what are webuilding next and we'll go from there sowithout any further Ado let's welcomeeven on the stagethank you thankshi hello everyone my name is Evan I'm atech leader from snap I hope you guyssnap for almost seven years now for thelast few years I have been mostlyfocused on building our obserabilitystacksuh for the first section I'll quicklytalk about a little bit of historybetween snap and Google Cloudlet's start with a quick poll threequestionsfirst one but silverhands who had heardabout Snapchat before this talkwow that's not actually it's much moresecond question who actually usedSnapchat maybe a few timeswas decentthird questionwho may have a kids or young siblingsthat I also use Snapchatgreat SD thank youall right oh I guess more thoughts hasalready been familiar with Snapchat butwhat you might not know is that snap isactually turning 12 in two weeks so thisis very exciting for us it has around400 million daily activity usersquarter and still continue to growwhen snap was initially launched thisbackend was built on top of a GoogleCloud app engine it's a fully managedserverless application platform itfollows a monolithic like architecturemeaning that all the service is runninga single backend it has been worked wellit's the part of the fast growth ofSnapchat from zero user to 100 milliondetective users it's been amazing but asyou can imagine right for a singlegigantic cluster and the group speakingof bigger manual problems.certainty likebig blast readers is very low costefficiency and Etcnow to solve those problems snap overthe last few years has spent a lot ofefforts trying to migrate over to amodern Cloud Model regionmicroservices architectures it worksquite wellnow with that there's new set ofproblems Services because now we have athousands of services right how can wemake sure each of the services arehealthy so we need a good observabilitysolution for thatnow that's my kind of a job comes in asTech leader for the team I want to makesure we build a platform that I canfirst improve reliability second improvedeveloper productivity and certainlyimprove quality efficiencywe have five principlesI first want user-centric this might notbe very upwards for internal tools rightbut if you have internet very intuitivevery easy to use it helps a lot withadoptionthe second and third principle a kind ofno-brainer here because to supportExcellence of Engineers and the southernServices you want to make sure yoursolution is highly scalable and alsorobustfirst one cost optimized right youalways want to pay a very closeattention to your cost because it caneasily exploderight especially for observabilityplatforms lastly model Cloud given nowmost of our services are run in acrossdifferent clouds clouds you always wantto match to thatso here's a high level architecturediagrammaybe let's you know spend a quick twoor three seconds take a lookso this is the very three former diagramright but there's the Hue there are thefew key decisions we made behind thesceneslike first of all we query we we providea unified set of tools for of servicesacross different clouds so that we canprovide a consistent troubleshootingexperiencessecond thing is for Medics we have beenevolving our Matrix back end to our siteoffering from chronosphere whichsupports the standard premises formatwith the parameter format we are able tocreate a unified data sourcesbasically for automatics right forMedics from within snap services ormetrics from cloud windows andautomatics from third-party software'schronosphere also provides a verypowerful control plane to help us takecontrol of our quota and cost spendingwe do also use cloud monitoring for someof our use casesexternally logginglike Cloud logging has been evolving alot for the last few years it added tonsof new features and also improved theirperformancewe had partnered with Cloud loggingwe're successfully trying to resolvesome issues and we are happy to stilluse cloud logging as well number onechoice for logginguh number four last oneall the tools we choose here can work atsnap scale just give you some some datahere to get a sense here informaticsright we ingest like billions of datapoints per minutes for logs we ingestmore than 1.5 petabyte of data each weekall right for the next section I'llquickly walk through two examples toShowcase you how we do troubleshootingat SnapchatSo Stories is one of our most likedfeatureson Snapchatlet's say suddenly the stump chatter isunable to load stories right from thephoneas engineer who is on call for thisstorage team was a typical incidenthandling life cycle looks like rightlet's say the uncle's name is Stellainstead will first receive alerts andshe acknowledged alerts she started totroubleshooting following some drum bookshe first saw that there is hugeincrease of 500 paracetic codes for theAPI that handles story quests this iswhat I mean right there is back-endinternet survivors but what exactly iserror right what caused itfor thatseller continue to investigate she firstchecked the department and configurationchain histories but I found nothingchanged now this becomes moreinteresting she wants to use logs tofind more informationsforeignso let's take a look kind of a zoom inlook let's see what's what's on Stellarscreen rightsothis is probably working yep on the leftside standard first uses the left fieldto try to narrow down to the logsto specifically to error logs from thestorage servicesthere's also one thing may not be veryobvious here but logs field Dynamicgroup of the logs for each of thoselabels this kind of system labels and soit can'tokay whether this error is coming from aspecific resource or notlet's say for this case it's not let'scontinueso for next probably is that I want toknow okay nowone exactly does the incidence that'shappening when exactly that's the firsterror starts showingthat's this histogram at the top helpsbecause it shows the very clear trendswhich are based on the number of errorsor number of logs for that period oftimeso Stella can click on the first part inthere and it takes to throw the firstset of our logs but sometimes this mightstill not working becausethere might be just too many duplicatelogs there's just too much noise how dowe solve that problemsoStellalook at the top of the results and seethere is a high dissimilar entrancefeature in thereif you click on the button trying topreview the suggestionsand if it makes sense she just appliedit remove that deeply logs and then shemaybe do this a few more times until shehas some clear signals so with thoseclear signals right so you may be ableto record the issues but I guess reallythe root clock here is not really thatimportant for this demo but it wasreally important that how can you gofrom there what is you know how can youdo better if this happens againright you always want to do thefollow-upsfollow-ups such as maybe just adding avery specific Medics right for thiswhich can better capture these specificissues you know add it to a dashboardsetup alarm and also make sure you alsoupdate your runbookas sure summary with all those nightfeatures from cloud login status wasable to resolve Vision much fasterright let me show you aanother example which are kind oftypical for platform ownerslet's see Sam is from our dataprocessing team she owns the ingestionpipeline which ingesting data from ofcourse a lot of different Servicesthrough Google Cloud Pub subduring a weekly review Sam founder thatokay suddenly the panel isexpect for one of the days and whocaused that right so you want to figureout thatSam first check the overalllike boundaries traffic Medics he fundslikeand he can confirm the start in timebut that's not enoughthere is indeed actually a breakdownmedicsbut there's a problem is that that thisMedics has around 300 000.now let me quickly post here and takeanother pollwho has again patchable hands who hasever tried to load a Medics with thismuch cardinalitywell at least there's a few it's goodnow what happensright someone's doubling it's likesomeone's doing thisright nothing happens exactly so thething is that for such cardinality rightthis probably matters become not verytrue because a lot of times the graph isvery it's maybe taking very long time toload or just not load at all even thoughit's loaded it may not be ready itbecomes super hard to interpret anythingfrom the graphs right there's just toomuch noisesso we have to think differently how dowe address this problem rightlet's try logsthis is very easy right you can easilyadd a One log line and contain thebreakdown information it's just doneright there but also there is one kindof a stream I want to call out here thatyou definitely don't want to log onlinefor each of the messages you processedyou always want to you know first dosome local applicationsand then you meet the log line in somesort of a reasonable frequencies andlet's say you know One log line per partper minute something like thatbecause if you don't do that thoseexecutive logs can potentially impactyour application performance or you knowalso uh cost a ton of money as wellall right now we have the logstime to do some analysis here it entersthe kind of the latest two which is bigbig query powered from cloud loggingit's called log Analyticsso it's very easy to enable actually uhwith no extra cost under normalconditions so at snap we have thisenabled for all of our servicesto do the analysis right you just needto do build requirements here the querybuilding experience is very much thesame like bigquery if you have a userbeforeyou can essentially just you know keepiterating on it and you get the resultsyou want and for every time you can alsotry to you know show the result in atable format for here at the bottom hereuh one helpful tips here is that you maywant to try to use one of these blacklarge language model based and tools tohelp you build queries if you are not aSQL expert it actually worksanother nice thing here is thatfor those aggregated data you canactually sourceas a graph in here like we have been wejust recently started using this uh it'sbeen amazing it has a similar dashboardexperiences like uh from cloudmonitoring highly recommend to check itoutas another source summary here is likewith those powerful tools right fromcloud logging we can now actually solvesome complex problems in one place youcan turn these unstructed data intostructured data and then into graphswhich is much easier to visualizethat concludes my two exampleshopefully it's useful for you with thatI'm gonna hand it over to afrina to talkabout some of the common troubleshootingpitifuls Enathank you[Applause]thank you so much you know what reallystood out with SNAP is it was an amazingpresentation where they talked about theguiding principles the architecture andhow they do troubleshooting rightthey're very agile they're super fastand and a lot of us have been trying toessentially do the same thing but wedon't realize the pitfalls that we mightfall intolet's talk a little bit about the commonpitfalls that we see in troubleshootingobservability is essential for Effectivetroubleshooting I mean it goes withouttelling but if you're closing a largenumber of tickets with root causeunknown as a resolution that you knowthat your observability is not correctlike you're not collecting the rightsignal you're not bringing them to theright place so let's talk about it alittle bit morewhat are the common pitfalls the numberone and essentially the biggestfragmented solutionthis means is if you're trying to DIY alot of things or you have too manysolutions in your ecosystem you have oneunderlying let's say for example youhave one underlying logs database rightyour devops team is using it to resolveissues in the local computer you'reexporting that logs and your securityteam is Now using another good lookingtool with different visualization toanalyze the same logs and now yourbusiness analyst team is taking the samelogs and Performing and creatingdifferent dashboards you see it's thesame underneath data why do we need somany applications right the overhead ofmanaging applications the avoid oftrying to scale which is number two hereand then trying to figure out how do youmanage cost which is number four likeOps is not cheap it is expensive and ifyou do not know how to control it thecost can get skyrocketingif I can throw a coin into my pocket forevery time a customer tells me that I donot know how to figure out my cost I'llI'll be a multi-millionaire by now Iwon't have to stand hereitselffragmented solution will lead to numbertwo number three and number four rightright you cannot figure out how to scalethat's going to be a bottleneckthen lack of cohesive experience if younotice when even was showing howtroubleshooting looks and snap they wereable to go flawlessly from metrics intologs so when you're thinking abouttroubleshooting it's essential that youthat you have signals that talk to eachother you should be able to go frommetrics to your logs metrics to yourtraces and then preserve that endcontext experience and if you don't havethat you're actually making it difficultfor your engineers to work ontroubleshooting it's going to be verychallenging soto summarize the common pitfalls that wesee fragmented solution complexity toscale lack of cohesive experience andskyrocketing costs so another thing toadd here in cost is we cannot tell youhow many petabytes of logs you're goingto generate right but what we can tellyou is if you generate this much this islikely the amount that you're going tobe paying predictability is importantand across industry we don't have astandardized way to chargelogs metrics or traces we all have somany different ways and I could probablywrite a book on how to figure out costsright it's that complexour recommendation is for you to pick asuite of tools essentially in oneecosystem and when you're doing thatthink about this right number oneoperate at scale right Google went fromzero to billion users on the sameplatform snap just went from zero to 400million users on the same platform soOps should never be a bottleneck whenyou're trying to grow your business youshould know that Ops should be able toscale right number two ability to meetyour reliability Target like if you havea well-established principle errorbudget you know your SLO then you shouldbe able to meet your reliability targetsnumber four is provide the versatilitywhat this means is you essentially havethe same signals across yourorganization so you should be able tobring in users to use that right it'sjust not your devops team your secopsteam your Biz Ops teams so manydifferent users should be able to makethe best out of the same underlying dataset and that would save you considerablyon cost and overhead and you'd be ableto reduce your toilnumber four remove fragmentation we justspoke about it number five is costeffectivein Google Cloud Google Cloud's Cloudoperation Suite is our observabilitysolution and what this does is we haveseveral tools within the ecosystemto collect all your signals metricslocks trays audit logs from both gcpservices and outside of gcp so what doesit mean you have on-prem hybrid Cloudstructured logs unstructured logsmetrics from other ecosystems you cancollect all of it and bring it intoGoogle Cloud and our goal is to give youthe same experience regardless of whereyour data was born if your data was bornin gcp yes you'd have a higherexperience but if your data was not bornin gcp you still need to have the sameexperienceSo within Google Cloud operation Suitewe have Cloud monitoring that collectstime series metrics for 60 plus gcpServices it would allow you to measureSLO you could create in contextdashboards across then we have Cloudlogging which is the home for logs youcan centrally collect yourorganization's logs route them toflexible locations where you wantperform analysis we saw several exampleswhich even just shared with us then wealso have Cloud trace alerting and muchmoreso let's talk about troubleshooting inGoogle Cloud what I want to do in thissection is essentially highlight some ofthe features that will help you in yourtroubleshooting Journeya typical troubleshooting journey isgoing to look like this right you'regetting your alerts and notificationthen you want to go explore what'shappening in your system and then you'resaying okay can I get to my root causethen you get to remediation where atsome point you get to auto remediationyou don't want you want to reduce yourtoil so just mapping that to the productdevelopment about how we think here atGoogle it's we want to help you do fourimportant things number one collectcollect signals from everywhere becauseobservability and troubleshooting is alot more faster thing to do if you havea single pane of glassnumber two configure that's whatmonitoring is for you need to knowwhat's happening in your ecosystemnumber three detect so when we arethinking about detecting of course youcan configure certain things but heylife always throws up with random randomnew things right you cannot alwayspredict things that's going to happen sowe think about okay if you can detectthe nouns what can we do to help youdetect the unknowns then lastlytroubleshoot and make it easier for youto get to the root causenow what I'm going to do is essentiallygrouptwo sections into one so I'm going tofirst talk about features that you coulduse for collect and configure then I'lltalk about features that you can use fordetecting and troubleshootingall right so Step One is collectbringing data into Google Cloud so ifyour data is already in Google Cloudbut if it's not the step the first stepin troubleshooting is centralizing yourdata collection right soStep One is Ops agent so if we have totalk about Ops agent I'll just put it intwo categories it's automatic comespre-installed if you're in gke or Cloudrun you do not have to do anything it'sday Zero observabilityif you have GCE VMS your virtualmachines then you would have to installyour Ops agents it's our opinionated wayto collect metrics logs and tracesnumber two and number three would helpyou if you want to collect signals fromyour multi-cloud or on-prem environmentnumber number two is our open Telemetrycollector we support that and we and weenable you to use an open Telemetrycollectornumber three is bind plane observabilitythis is our third party vendor and theycan help you remotely manage all yourconfigurationsonce you've collected all your signalsthis is a number one recommendation whenit comes to logs we want to I mean werecommend that you collect your logs ina single bucket sorrylike centrally stopsokay so we want you to centrally collectyour logs in one single bucket and youcan applied guard rails by managingaccess using something called log viewssee you so when you do this you'reessentially creating that single pane ofglass that's going to maketroubleshooting a lot more easier andthis is exactly what snap just sharedwith us in the architecture right theywere able to troubleshoot issues fasterbecause all their logs as in onecentralized location this is going tomake it easy let's say you work for afinancial services your security team isalways going to ask you hey are youcollecting all the logs are all yourlogs in one place they're going to bealways behind you and centrally storingyour logs is essentially the key to itthatyou could configure something called anwhat uptime check does is if you have abusiness critical application and beforeyour users report that hey some anapplication is down we can configure itwe can ping it periodically to see ifits responds to our HTTP https or TCPrequest and let you know that hey yourrequest is probably done somewherethat configure alerts and notificationof course we all know about alerts but Ijust wanted to highlight new featuresthat you could add to yourtroubleshooting or start so you couldforecast an alert what this means islet's say your CPU utilization isclimbing up and before some thingsbecome an actual fire drill you want toget notified two or three days inadvance you could configure somethingcalled forecast alerts and you will getnotified so you know there's adifference between a page and a ticketthis is where you can create a ticketthen you could configure a log SpaceAlert again there are two ways you canalert right you could alert on a log oryou could alert on a metric so whenwould you use a log base alert let's saya very very high priority securityincident happened and you want to knowimmediately right if something happensonce and if something shows up once inyour logs database and you want to getalerted on it logspace alert is the bestway to do itof course we have log space metric wehave been using this for many yearsmetric absence are secops friends lovethis because if you're not collectingmetrics from some place how would youknow like if you configure an alert formetric absence you would know thatthere's something as broken in yourpipeline and you should go take a lookat itand Google Cloud mobile is anothereasier application to have in your phoneand if you have a log Space Alert thefastest way to find out if is by gettinga notification on your phoneand I believe about 29 30 of our usersstart acknowledging and troubleshootingfrom their phone because they haveaccess to the consolenext through our gcp you should be ableto create an end context dashboard thiscreates a single pane of glass view thatwe were talking about right when youcreate an end context dashboard youcould pull in your metrics logs andtraces all in one view for your team tolook at now they're not scramblingthey're not looking into 20 differentWindows to go find the same informationeverything is available in context insingle paircloudtrace when troubleshooting gainingsufficient proof to support yourhypothesis is critical Cloud Trace newUI helps visualizing your request flowsfrom distributed traces it includes amore responsive and interactive detailsectionnext let's talk about detect andtroubleshootsoerror reporting is another amazingamazing tool and it comes in free withCloud logging so what error reportingdoes is it will keep combing throughyour logs and try to look for errors inyour logs database and when it sees anerror it would automatically send you anotification let's say here I'veconfigured a slack channel so you get anautomatic notification nextwhen you click on that notification thatyou got in your slack Channel you're notgoing into the error reporting page whatI love about this it consolidates givesyou that single pane of blast foreverything that you need to know withrespect to one error right sohere you can see the description of theservice a clear description of the errora histogram and then it also tells youthe root cause of where it found thetrace and the logs from here you can gointo logs toonow we recently integrated duet AI agenerative AI capability into errorreporting sonext time you don't know what totroubleshoot where do I go from nextthat's often the biggest problem introubleshooting Journey you were likehey what can I do to troubleshootso it will give you three to five waysfor you to go explore furthermorenowfrom error reporting you can go intologs Explorer by clicking on view logsnow what this does is it gives you astarting point to go explore your logfurthermore you don't have to reducenoise you don't have to figure outfilter all that right so error reportinggives you a starting point to exploreyour log and even just showed us all theamazing features that he uses in logsExplorer to make troubleshooting easiermy idea of fun is coming through logssays no one ever somebody going todisagreeokay I get paid to love logs per livingand I don't do that myselfso we recently integrated duet AI inlogs Explorer so this has been a hugeAdvantage like if you go in and say canyou explain this log entry to mein simple language natural languageterms it will tell you what happenedthis is amazing I don't have to strainthrough combing through logs and try tounderstand and summarize myself versusduet AI can do this for you okay thispart was deleted in this service at thistime in this cluster isn't thateverything that you need to know at thatpoint rightsonow logs Explorer can help youtroubleshoot when your cardinality isnot so high versus if your cardinalityis high and you want to bring in moreusers into your ecosystem then loganalytics comes in playlog analytics okay so to explain loganalytics in very simple wordsyou send us your log data unstructuredsemi-structured whatever format you haveand we in the back end will figure outhow to store it in a SQL database youdon't have to create an ETL pipeline youdon't have to figure out how to store itwe will do it for you in the back endthen it's schema on read so there is nopre-processing your team is not spendinghours and hours trying to figure out howto build a database you don't have toDIY we will do it in the back endand put scheme on read and it allows youto use C Corp right SQL is I guess thethird most popular language in the wholeworld and generative AI can help youwrite SQL queriessoschema and read and SQL and with instantcharting and dashboarding capabilitiesbigquery lets you come to petabytes ofdata in seconds right an excellent usecase of this would be say for exampleyou want to find out devops Trend helpme understand my API performance bylooking at the top count of requestGroup by response type and severity itwould take you three to five steps to dothis in another tool with SQL it's justone query and you're able to get to rootcause this fasterlikewise if you have sec Ops help mefind all the audit logs associated witha specific user over past month when yougenerate your compliance report this isjust one query that you need to run andyou have your answers instantlywith networking troubleshootinghelp me troubleshoot network issues forGK instance using VP VPC flows andfirewall okaySQL makes it easy it brings in moreusers into the ecosystem if you thinkfrom a long-term perspective it savesyou on costs it makes it easy it reducesa steep learning curve that you usuallyget with any observability solutionwe also have something called Communitysecurity analytics it's a GitHubrepository let's say you want to getanswers to all these questions andyou're already already ingesting a tonof security securityum logs you could go into SQL just copypaste the SQL query from there andexecute it it makes life so much easiernolog analytics is the first step I wantto talk to you about what do we think isgoing to come next and Ops and what arewe building here in Google Cloudour vision is to bring in logs metricstraces metadata and a managed data Lakeand enable you to create use cases suchas log analytics which is the step onethat we just saw and build more on itsuch as gcp utilization phenops and muchmorean example of how the data Lake wouldlook like say for example you couldbuild a report like this which prettymuch combines a metrics from your Cloudmonitoring and you're buildinginformation from cloud billing andgenerates insights into cost andutilizationwhen knobs has been a problem for manymany years this data Lake and bringingall your signals into one ecosystem isgoing to make troubleshooting a lot moreeasierthat being saidyou know it's truly an exciting time tobe in cloud and a furthermore excitingtime to be in apps right with building adata Lake and having generative AI ontop of it troubleshooting is going toget a lot more easier and fasterso for the final wrap-up I'd like toinvite Evan for this stageif we have to give you three suggestionsadvice or recommendation I'd say numberone is think about scale right Googlewas able to go from zero to billionusers on the same platform snap was ableto go from zero to 400 million users onthe same platform and Ops was never abottleneck we never stopped the businessgrowth we enabled the business to growfaster so when you're thinking about Opsdecisions think about okay will thisstop us from scaling the only time youshouldn't be thinking about scale is ifyou don't want your business to grow oryou're going to deprecate your solutionI hope that's not the case rightnumber two remove fragmentationif you're going to add a step in yourOps Journey think about what would ittake for me to do it 10 times more or 20times more if you feel like it's complexthen you're adding a fragmentation layerfor your Absolution so removingfragmentation will greatly greatly helpyou with observability andtroubleshootingand lastly partnership goes a long waylike Google has been helping snapyou know help with their operationsystem for a very long time at snap hasbeen helping Google develop a productlife cycle for the op solution so withPartnerships we can go a very long waythat being said thank you so much forbeing here today and we truly appreciateif you can take a quick minute to giveyour feedbackand the learning does not have to endhere these are the other sessions whereyou can learn much more aboutobservability Solutions if they're notlive it'll be recorded on YouTube andI'll be stopping the booth at theinnovators Hive down if you have anyquestions I'm happy to take it therebeing said thank you so much for beinghere this afternoon truly appreciate itthank youforeign"
}