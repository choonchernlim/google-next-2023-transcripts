{
    "title": "How to optimize Kubernetes for reliability and cost-efficiency",
    "presentation_type": "Breakout",
    "categories": [
        "DevOps, IT Ops, Platform Engineers, SREs",
        "OPS300"
    ],
    "video_id": "fJp_IWoNmrc",
    "time": "Aug 29 03:30 PM - 04:15 PM CDT",
    "transcript": "foreign[Music]thank you very much for joining us in asessionof optimizing kubernetes particularlynot just optimizing it for costefficiency but for reliability which isone of the key pieces that we want totalk about through this sessionjoining me myself I am Ken Hua I am aglobal solution manager focused on gkeand app modernization for optimizationand joining me is Chris mear fromPriceline as well as Thomas Evans fromcubecastso they will come on and talk about someof their pieces and we'll kind of runthrough that we will take some questionsat the end and possibly some postsession as well if you have anyquestions afterwardsso I will get right to it from a topicperspective I mentioned the presentersChris and both Thomas but I'll cover theresearch so for those of us that are mayor may not be familiar some of us mayhave caught it late June from a Googleperspective we released a report to kindof focus on optimization of kubernetesin the context of cost efficiency aswell as reliability and one of the keypieces when we talk about the report isfocusing on cloud agnostic so albeithere I'm speaking from a Google Cloudperspective the report itself is cloudagnostic so albeit from this perspectiveas I mentioned I'll cover some Googlekubernetes engine aspects as wellso with that in mind is as part of thereport we went through a methodology ofhow do we classify for those of us thatmay have been familiar with the state ofdevops report in the previous years theyhad some level of classification of howthey segmented some of theirparticipants in this case ourparticipants were anonymized gkeclusters and this fleet was less than orequal to three nodes we didn't want thesmaller ones we wanted some of thelarger ones as well to kind of mix andmatch the overall construct of how wesegmentedwe used the construct of classificationtree to help us segment this as well asgive us some little semblance ofopinionation which you'll notice on thebottom right hand corner is the at-risksection and that's when we talk aboutthat reliability element of it is wheredoes that play into all of this we did aquasi interval as I mentioned earlier wehave segments of elite high medium lowas well as the at-risk potion and funnyenough so we actually took this datagrouping for January 2023. one wouldthink that oh we actually first tookthis of November 2022 and for those ofus in certain sectors November of 2022is very critical to our business and wekind of use that as a measuring solooking through it we noticed that thedata didn't actually change very muchoverall the story kind of told itselfequally overall so we chose Johnny 2023as the data setI mean kind of walk through that if welook at the report as a whole some of usmay have caught the blog post one of thekey things outside of the report thatwe're talking about is to have a minimumset of reliability for workloads thatrequire not all workloads require asense of reliability but if workloads dohave that minimum sense of reliabilitythe least thing we can do out of thisentire session at least for my part isset resource requests on your workloadsso for those of us familiar withkubernetes we know this is a constructthat we can use in order to reservecertain resources within a node of aclusterthe reason why we want to set resourcerequests albeit reserving is that it hasa lot of critical things that itcontrols or augments with it excuse mewithin our clusterwhen we think about standard resourcerequests we think about I'm justreserving resources but in reality wecan see here a list of different thingsthat can be augmented tweaked impactedas a result of not setting requests onour workloads so that's a very criticalthing we think about if we're looking atAuto scaling for our nodes becausethat's how kubernetes usually triggersit I schedule more pods they're inpending mode if my cluster Auto scaleris enabled and I have more resourcesavailable to me it will scale up but ifI don't set request it will just keepthrowing it on similar nodes withoutunderstanding because that's howkubernetes schedules by using requestsand this is sort of that criticalelement if we look at it from thisparticular use case I said throw a bunchof pods in a particular nodethis would actually potentially scale upif I hit my 110 pod limit if that's mymaximum pods per node if I set that upso that is one mechanism I can use tohelp me drive that behavior but all Ihave to do really is set requests andwe'll talk about that a little furtheras wellas part of the report I mentioned someopinionation a lot of that opinionationis driven across what we've discussedwith customers as yourselves as well asorganizations to say what is importantbecause we know kubernetes can emit alot of metrics but how do we get somesemblance of understanding and these arewhat we see as the golden signals fromleft to right is workload right sizingam I asking for enough and of what I'mactually meeting within my workloadam I using too little am I using toomuch how do I right size thatHow about if at non-peak depending onthe industries that we represent or workthrough we have different off-peak timesand if there are off big times we'd liketo scale down to reduce our consumptionof resources because there's no demandso how do we set that and how do wemeasure thatthe next piece is a lot of what we seein this room we talk about cluster binpacking this room is fairly been packedand what happened was essentially wecan't vertically scale this room anymoreso we scaled horizontally we have asession on Thursday so that's anotherway of viewing it from a bin packingperspective we're fairly packed in thisroom right now and how do we measurethat because I want to make the use ofthe machines that I provisionthe last piece is how I adopt Clouddiscounts and Cloud discounts come inthe form of spot type of VMS ordiscounts that are available in thiscase through Google Cloud committed usediscounts that I can apply and this issomething where Chris will actually comeon and tell how Priceline did it fromtheir perspective because I havemultiple strategies that I can applywhen I talk through discounting and gothrough that but these are the signalsthat we're measuring we added one moremetric which was essentially whichworkloads are not sending requests inhow we segmented our clustersso as a result if you hadn't had achance to catch the report there areseven findings that we kind of alludedto or ran through and the first piece issetting requestsby not I unders by understanding settingthe amount of report resource requestsfor the workloads that have a minimumreliability notice that I said minimumreliability because there are someworkloads that qualify that I want to bebest effort but there are also someimpacts if they are best effort sothat's something that's the mostcritical thing as I mentioned that wasthat third slide that I had in thepresentationthe second piece I showed four signalsacross workload right sizing down scalebin packing discounts workload rightsizing is actually the most critical onebecause if you think about it if myworkloads are not right size properlyI can impact how I scale potentially howIbin pack because I might not pick theright machine because kubernetes isgoing to say what machines do I need andif my applications say I lean a lot morethan I actually need from anapplication's perspective I may looklike I've been packing very well but inreality I may not be contacting as wellas I'd wantand and the fourth one is you send thirdone is essentially being able to if Iover exert an index on cost efficiency Ican impact my reliabilityfor instance I start bringing downcertain resources I can impact thereliability of my workloads because I'mgetting too aggressive in how I teardown particular pods or tear downparticular nodesthe fourth one is I just spoke to youabout pods and nodes and all thistechnical stuff from a kubernetesperspective but when we are performingthese actions within our clusters thereis real life potential end userexperience that may be impacted as aresult because we think about itworkloads are coming through if I needto scale up it takes time before I canactually serve a request that comesthrough if I'm bringing down a workloadwhat about that transaction that's inflight so those are things that canimpact my end user experience so that'sthe fourth key findingwhen we look at the fifth one is allabout yes I mentioned demand-based downscaling is a metric but how about theimpact of it we want it to be automatedwe don't want to be involved as part ofthis downscaling mechanism so we need touse constructs that are available to usWithin kuberneteshorizontal pod Auto scalar which helpsus go wider is one mechanism toelastically grow as well as shrinkwithout us being involved otherwise weon the operations side developer sidehave to determine what are my Max myminimums and I'm going out through mypipeline to adjust these sizes that maynot be the most quickest reaction wewant the let's cluster perform for us ifour workloads allow us to do suchthe sixth one is about Elite and highperformance they do take advantage ofcloud discounts and what we usually seewhen we talk about these clusters andthe segments usually the Clusters thatare larger we pay a lot of attention tothese clusters and they we have morevisibility as again Crystal kind of runthrough being aware of what ourworkloads require gives us a more senseof confidence when we want to say I cancommit to these certain amount ofresources for my one year to three yearperspective depending on our level ofconfidencethe last one it depends on the toolingwe use because a lot of tools that areout there very much focused onallocation of cost is based on or equalto the request that I setso on that third slide when I said setrequests if I'm not sending requestspotentially those costs are notaccounted for and that's something thatwe need to address KU class does alittle differently they take Max use orand or respect requests so that's oneway to look at it as well but we justneed to be cognizant if we're usingthird-party tools or other tools what isbeing factored in as far as what is anactual requestit's very interesting we see I can readnumbers but in reality when we look atitfor elite and performers over lowperformers they get more value they getmore for what they pay for and theyheavily utilize discounts becausethey're aware of what's happening when Icontacts or construct when I said theythese are clusters we don't have anygroupings of these segments or anythingthese are just clusters that seem toexhibit these behaviors but in realitywhen we look at it they are getting moreuse of what they have which typicallymeans that utilization is probablyhigher right sizing is a little bitbetter or better awareness of the rightsizing and if my right sizing is justrightbecause there is no magic to it I justdon't apply a number I need tounderstand these on a per workload basisthat I can then confidently determinewhat should my discounts be as a resultof thatgoing back to this last segment that Isaid we carved out for not only is itthat if I my cost allocations impactedthe reliability could be impacted isthat negative user experience that couldpotentially happen because we thinkabout it is when a node gets to itslimitif it's a best effort workload which isa workload does not set request it'sunfortunately the first to go when thekublet needs to protect itselfso it has a starvation mechanism thatsaysI have no more resources who's the firstto go best effort then burstableguaranteed is that one that I reserveresources but things can still happenbut we can see a tier of how the kubletreacts as a result of thisand we see this a lot for instance someof our workloads exhibit that 1.6 xtimes moreso this is something from a best everperspective what is that impact to myworkload and the last one we talk aboutis best effort is sending requests butwhat about the burstable ones so this isunder provisioned memory memory issomething that with CPU I can throttlealbeit can impact user experience memoryis fairly static once that memory isconsumed or allocated for I can't reallyreallocate it unless that pod goes downso that's something that can impact ourend user experience as a result of thatthe at-risk segment also has some senseof I want to optimize so potentiallywhen we look at the address segmentcould potentially be over indexing onthat low hanging fruit we think of clouddiscounts because I can think about itfrom the perspective of I want to savemoney I should just commit to a certainamount of resources which could behelpful but remember remember that isthe last part if I resize and actuallyproperly workload right size I may nowbe heavily over provisioned for what Icommitted for but that's something tothink about when we talk about theaddress segmentthis kind of gets into that construct ofdo I have enough data for what I want towork with and that's that insufficientdata I saw how much my current clusteris using I'm going to commit to that andthen I actually perform some rightsizing activities and maybe I possiblycould have over committed so those arethings where we talk about workloadright sizing key finding number twobecomes that very critical element whenI drive towards thatthis kind of all we also look at thisfrom a utilization perspective if Idon't send requests my bin packing islow so think about this if my binpacking shows that I'm 50 bin packed Igo I could probably do less with 25 ofmy nodesso I bring down those 25 of nodes butbecause my requests I didn't ask for itall of those are now consuming moreresources I actually don't have roomit's almost like at 50 bin packing I ammasking what's happening within myenvironment I'm throwing more nodes atit in order to prevent the reliabilitything I'm trying to preventso that's something we think about aswell if we over provision our nodes thatcan kind of hide some things that we'relacking within our environment and Ibring it down I tear it down I bring iton 25 I don't want to go too crazy bydoing 50 let's do 25 but what happens tothat overhead I no longer have thatwiggle room so I think I'm doing and allof a sudden I think I'm doing better inbin packing but in reality my workloadsare at risk as a result of itso from a Google Cloud perspective sothose of us may be familiar with thatoptimization tab that's made Availableto You metrics that are made availableto recommendations so from a GoogleCloud perspective even if I have vparecommendation or I don't deploy vpawithin my cluster we're actuallyGathering some of those metrics for usbehind the scenes as a metric so that'ssomething that you can leverage thatwe've kind of utilized in our dashboardsto help you understandat a high levelnow we don't understand from anoptimization tap perspective that issomething that we see per cluster whichfirst if I have three clusters and ahandful of clusters that's really easyto seebut we've also released dashboards tohelp you see at a higher level at anorganizational level so there are toolsthat we applied and can we deploy thatand be able to maximize how we look atthose resourceswe also have workshops andrecommendations that are providedworkshops that Priceline went through sothese are things that we kind of gothrough to say proactively in adata-driven way how is my environmentwhat is my current health so this issomething if you're currently usingkubernetes engine today you can ask ofyour account team that we want to assessthe health of our workloads and ourclusters and go through that processthe other pieces I talked about sendingrequests I talk about all thesemechanisms to protect my workload whatare ways to potentially enforce that soif we're not familiar with autopilotautopilot automatically sets requestsfor us whether we like it or not and weactually are forced to go back andre-evaluate what my requests are becauseit will set its minimum and either myworkload is not going to work or I needto adjust that minimum because it's overprovisioned so we kind of set forth thatparticular element another thing thatwe've just launched in preview is aconstant policy bundle for reliabilityand being able to use this along withpolicycontroller Opa gatekeeper from anopen source perspective but also abundle to help you enforce settingrequestssetting labels on our workloads I didn'tspeak any about this but labels are veryhelpful for our workloads in order forus to categorizebut also setting pod disruption budgetsstanding requests enforcing that UponOur workloads and within our pipeline sothere's a lot of things that from aGoogle Cloud perspective we can kind ofhelp you with if you're taking advantageof it and those are availableso that's at a high level for the reportas well as gke and kind of runningthrough that and with that I will handit over to Chris and he'll cover whatPriceline did for the workshop as wellas what they've taken further so thanksChrisawesome thanks Kent appreciate thathey everybody hope everybody's having agreat nextall right let's jump right into itso Priceline is uh online travel agencyunderneath of booking HoldingsIncorporated we've been an industryleader for about 25 years and over thelast few years we've embarked on a cloudJourney that cloud Journey has beendriven mainly by a cultural shift andyou've probably heard this story beforehow do we shift our our teams fromthinking around the data center tothinking around cloudso in supporting that we had thismassive shift within a few short yearswhat supported that was ourinfrastructure is code and terraformingand you'll see the foundations insidethe triangle hereour fin Ops approach our modernizationof our self-service approach for ourdevelopment teams through an updatedmodern pipeline that allowed us to shipthose workloads into kubernetes andwe'll talk more about that but prior tothat being able to ship your workloadrequired us to have a 12 factor forthose applications to make themresilient and and really be able to bemanaged by kubernetesso here's a few topics we're going todive intoumwe'll talk about requests which Kenttalked about extremely important thediscounts we leveraged to try and makethis efficient and cost effective thebin packing we use to reduce those idlecosts and the right sizing the importantright sizing of those applications totailor them to what the applicationrequired and make it efficient in termsof what it's consuming inside of cloudlastly I'll talk about traffic egresstraffic and scale down how do we scalethese things down as well as scale themup and scale them down effectivelyall right so requests right Cannon plussize this enough the reservation ofresource for your container how do Imake sure my containers are effective inserving the applications that arerunning on them is by setting thatminimum request what is the minimumrequired amount of resource for thatapplication to serve effectively to myend usersum those resources now are available foryour container and gke will manage thosecontainers as well as the pods theyreside on those pods will movethroughout gke by process of it'screating an efficient use of theconsumption of those nodes so those podscan be fluid right and the key pointthere is as those things move you wantto make sure that request is there toguarantee to Ken's point that thatminimum amount of resources availablefor your app to keep that app performantso for Priceline we needed to make surethat those CPU and member quests weregated in our pipelines to ensure that asteams are onboarding and migrating intokubernetes that they would have thosedata requests already definednext thing I want to talk about isdiscounts so standard use discount orsud is a discount that you really get byproxy of consuming a resource for aperiod of a month so it's kind ofalready there for you you don't reallyneed to do anything other than consumethose resources and that's for on-demandresources committed use discounts theseare things that need to be strategicallyinvested with them right so forpriceline's approach what we did was weteamed up across teams communicatingwith our SRE teams our programmanagement teams our application teamsabout what's happening in ourenvironment what applications are beingmigrated what applications are expectedto growwhat do we see as different computetypes that we want to consume what'shappening across regions so all of theseelements are key elements to considerwhen you're thinking about how to investwhy is that well I'll do a little segueabout committed use discounts standardversus Flex standard committed usediscounts are Regional compute baseddiscounts so if you invest on aparticular compute type within aparticular region that's where thatinvestment will reside it cannot beported to another region or a differentcompute type so that's why you need tobe specific about thatthat team up about what's happening inthe environment would then generate areport for us to say here's what wethink is happening over the next six to12 and 36 months and how do we plan oninvesting to support that our investmentstrategy has been Target 80 percentcoverage that'll give us flexibility foreventualities in that period of timebecause this is a commitment in acommitted use discount for one or threeyearswe also staggered our investments so aswe consume expirations happen over thecourse of the year which also providesadditional flexibility so when youconsume in thousands of cores when youhave a significant shift you can pivotwith thatthere's discounts all right next slideall right let's talk about uh Binpacking right so cluster Auto scalerum is a fantastic feature in kubernetesright which allows as Ken said the nodeto expand with consumption or scale downso scaling up and scaling down thisessentially packs those pods in based onwhat the requests are for yourcontainers so the key here for us was toget a communication across ourorganization to trust in the process incluster Auto scalar based on the factthat your apps have been 12 factored saywe'll be resilient and based on the factthat you've set requests for a minimumperformance on your applications sotrust in the process we engagedinitially in the balanced profile whichis essentially the default profile andit's a safer profile it does not it'snot as aggressive as the optimizedutilization profile the optimizeutilization profile was what we laterfollowed on with and as that's moreaggressive it's going to give you a muchmore larger reduction in your idle costsbut it will also create this situationwhere it takes a little longer to spinup your pods right so because it's soaggressively downsized there's no extraidle resource for you to spin up quicklyso how do we deal with that well we usewhat was called pod pause pods to setadditional reservations to allow us tospin those things up quickerright so all of those efforts reallywe've seen up to 60 percent reduction inthose idle costs which was amazing forusall right so right sizing there's acouple slides on this one and I broke itup into two sections because I think theorganizational piece of this is reallyimportant how should our teams tune whatis required safely and efficientlycommunication is the most valuable toolyou're going to have in your tool belthere so you want to identify and agreeon what the high value targets are sohigh yield low effort is the keyyou also want to set up guidelines andguard rails in documentation reviewsthat's easily consumed and easilyactionableadditionally what we also did was weleveraged what we call our architectureGuild where teams participate in openCommunications about how to considerwhat their app consumes how to considerwhat happens in zones or regions thisopen conversation allowed teams to airout their concerns whether they couldconsume what guard rails or guidelineswere there and allowed us to Pivot onmaking those more efficient as welllastly program managed to be able tohave TPMS across teams participate withthe team in moving that ball from lessefficient to more efficient in rightsizing application and testing throughthat sdlcall right so execution of that rightsizing here's some of the actual toolswe leveraged the first piece was adedicated performance operations staffso our embedded devops team was createdfor focus on things like performance andconsumption so how performant is myapplication and how do I consider howefficient my application is so thoseteams help focus with our SRE teams toget those applications fast tracked intoa right sizing process additionally inour emission controller we use mutatingweb hooks to gate what can be deployedin our non-production environments so asan application team may have sets ofrequests that they want to run at acertain level and move that through thesdlc it may not be necessary and the webhook Gates that so that we're notdeploying in non-production resourcesthat aren't being consumedadditionally workload aware ofvisualization how do we show developmentteams what their app is consuming inPriceline we are an active activemulti-region deployment so I need toknow what my aggregate of consumption isat any point in time and over a courseof time so that I have a reliable set ofmetrics to base my decisions uponokay into traffic so as a multi-regionaldeployment for our runtime we also havemulti-zone right so lots of layers ofresiliency and redundancy there which isfantastic but it also generates aconcern around egress trafficit's very easy to consider Regionalegress traffic is the first thing youthink about it's very expensive to havetraffic egress across regions butadditionally interzone traffic is a verysignificant expense and needs to beexamined58 was the the amount that we were ableto hit in reducing our interest Zone andegress cost which is tremendous weleveraged uh istio we have as ourservice mesh and we leveraged localityload balancing to keep those trafficpatterns within zonesum topology awareness is anothercomponent we leveraged on top of that sotopology spread constraints how do mypods deploy inside of my zones setspread amounts so that you have thoseacross the zones that you have deployedlastly reporting how do I see things arehappening with the traffic from atraffic perspective from a billingperspective you can go to the billingconsole look at skus filter based onthat and see what the interzone egresscosts are what may be spiking acrosswhat projects or what particularnamespaceslastly you can investigate into thatthrough things like networkingIntelligence Center and the topologycooler it's another fantastic toolall right so uh scalinga couple slides left before I'll beturning it over to Thomas to talk aboutsome of the cube costs and visualizesome of these things but scaling up asKent mentioned is very key to a lot oforganizations especially those that areretail and go through things like CyberMonday right so how do I scale up HPA isa fantastic solution for that it alsoscales back down for you so how do wemake sure that we're scaling up and downsafely what metrics do we target is aneffort per application team to look attheir apps and figure out how to Targetwhich particular metricsso Target your high value applicationsagain you want to look for high yieldlow effort to get you the quickestreturn on your investment of effortrightadditionally partnership with teams sopulling in your site reliabilityEngineers your infrastructure teams andprogram management to think about howwe're going to move this from one levelof a static to an HPAlastly as I mentioned multiple Regionalresiliency we had to think about okay soif we have Regional maintenance how dowe warm up a site that's running an HPAbecause HPA will balance those trafficloads so that the less hot site I'llcall it that way the warm site has lesstraffic than the hot site how do we warmthat up or heat it up so that it's readyto take traffic so we had to approachthis within the strategy ofpre-warming those pods launching them inand that's where our SRE teamarchitecture team were able to create aLoosely coupled architecture and whenthat Google Cloud devops awardall right so we talked a lot aboutscaling there with HPA scaling down isthe big trick here though for multiplezonesscaling down requires effort to optimizeremember that cluster Auto scaler doesscale your nodes up and down but it doesnot have topology spread constraint whenit scales downso we use things like kubernetes 6Dscheduler which reviews how the spreadis existing and it evicts pods and thenthe cluster Auto scaler will thenredeploy them according to the topologyspread constraintsso essentially it's evicting what'soverloaded and allows the auto scaler tobring it back up to parityall right lastly to sum this all upfolksCommunity Based right I mentioned anumber of times teaming up havingmultiple teams talking across each otherCommunications is the most valuable toolso that's a key Point high value loweffort another key consideration andeasily consumed actionable guidance goesright along with communication as a keyall right with that I'll turn it over toThomas thanks everybodyyesgood afternoon everyone can you hear meall right there we go right on so myname is Thomas Evans I'm the director ofengineering for Cube cost and Chris andKent just give you a very technical Deepdive into something that our productsare going to make really easy for youreally really quickly but before I getinto that let's talk about how Coop costcame to bevery simply we are a cost optimizationtool that is solely focused onoptimizing your kubernetes spend sowe're going to give you great visibilitywe're going to grave you great actionitems that you can use to go exerciseyour your phenops muscle against yourcurrent kubernetes offering soour product was built by two formerformer googlers Webb Brown and a jtrippa thing who came out of here ohgosh four or five years ago now and theyquickly realized on the old boardproject kubernetes or what was going tobe kubernetes was a very complex problemright really really good at giving youflexibility in your workloads giving youa whole lot of configurability and awhole lot of opportunity it was reallyreally bad at letting you see any of themagic under the hood right particularlywhen it came to cost really good atthrowing things in the pool racking upyour bill every single month and youhaving no idea where your money wentright really coolso that's where Kube cost comes intoplay we're going to give you a reallyclear Solution on how to identify yourcosts we're going to allocate them backdo the chargebacks we'll do all sorts ofactionable insights that let you reallygo in and exercise your muscles againstthese golden signals that Kent and Chrisjust talked about so let's talk aboutjust three right so I think we offer 12to 15 in the product depending on yourconfiguration but to start off let'stalk about the resource requests rightthe obvious low hanging fruit in theroomumCube costs will provide a page thatallows you to dive in and see whichwhich workloadseither do not have any sort of resourcerequests set to them or which ones areunder or over provisioned right so we'vegot a couple of different algorithms andyou've got some options on how youactually want to calculate those butwe're going to provide recommendationsthat say hey you're 40 over provisionaryyou really need to go adjust this toreally help your bin packing and yourother side effects from thislooking at leverage demand based downscaling again Kube cost provides acouple of items here that lets you go inand automatically down scale your uhyour workloads as need be based upondifferent components throughout itand then finally discount coverage sadto say Coupe cost AI can't quite callGoogle and negotiate your bill downwe're working on it but for now we'llstick with reserved instance sizing uhand spot instances as well and we'regoing to go in and be able to identifysome of those workloads that are readyfor you and provide recommendationsbased on thatso the fun part about today for anybodywho's familiar with our product it hasto be installed in your kubernetescluster in your own cloud however thatis no longer the case Kube cost cloud isnow available it is in generalavailability and it's a simple agentinstall and we're going to give youthese golden signals in a little underfive minutes so all of that said wouldlove to bring Canton Chris back upwe'll talk through a couple othercomponents here so I canreport as far as the couple first coupleslides so this is an opportunity if youhaven't had a chance to download thereport these slides will be availabletomorrow as well in PDF form but the QRcode if you want to download the reportand see in detail what I was able andthe team everyone was able to summarizeand then work through kind of thatprocess to kind of understand what Italked through but also what else isthere available for the team to kind ofrealize within your organizationand as a part of that are other sessionsthat are available related to cost Chrisgets to tell us not today was about gkehe has other sessions to talk aboutoverall gcp so if you're on gcp theopportunity how you can look at it froma cost perspective for all of your gcpenvironment but also some other areasaround what's new with kubernetes and inthe Showcase with our demo Booth there'salso some pieces that I believe broadcomalso goes to remember optimizationperspective so other sessions for you tokeep in mind as well beyond the reportand then I believe Coupe cost hassomething we do yeah so two things soplease come see us we're at Booth 1650downstairs we'd love to talk to you andwalk you through some of the finerdetails of Kube cost Cloud but todaywe're also partnering with thoughtworksso today at six o'clock over inthoughtworks is headquarters just acrossthe street uh we are going to have ahappy hour with them would love to seeyou over there would love to talkthrough some of these details that weprovide[Music]foreign"
}