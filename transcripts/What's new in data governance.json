{
    "title": "What's new in data governance",
    "presentation_type": "Breakout",
    "categories": [
        "Data Analysts, Data Scientists, Data Engineers",
        "ANA106"
    ],
    "video_id": "zvCdrNJsxBo",
    "time": "Aug 30 05:30 PM - 06:15 PM CDT",
    "transcript": "foreign[Music]welcome before we get started I justwant to say how great it is to be ableto do this in person so thank you forbeing heremy name is and I lead the product teamsfor data governance at gcpand with me today I have two guestspeakers Sebastian rozanis from careforhe leads their data and analytics teamand is the chief data and analyticsofficerFung Lee who is the big data engineeringmanager at snap and they are here todayto share a little bit about their dataJourneys and how they are helping theirstakeholders realize value from dataso with that let's get startednow all of you are well aware that thedemands on data today are ever growingand increasingand this is especially true in this genAI first worldand you as cdos owners of data platformdata owners are increasingly tasked withmaking sure that your data platform isscaling to meet your business needsas more users and more tools need accessto data you're able to give them accessin a secure and easy mannerand as a result of this it's gettingextremely challenging to realize valueon many of your data initiativesacross our customer base we see thatthere are some key reasons why customersare unable to realize value from theirdatathe first one is dealing with dark datanot knowing what data exists in yourorganization what data is duplicate andwhere to even start looking for datathat you need does this resonate withyou are there people here strugglingwithout dataumwell once you find data that you'relooking for the next challenge is reallyto know whether you can trust that datawhether you're dealing with data that'scomplete that's accuratesure all of us have been in a situationat some point of time where you've useda data set that's incomplete orinaccurate only to realize it a littletoo lateand now with data footprint being moreand more distributed with data beingstored in multiple formats in differentstorage products and in differentlocations maintaining a consistentgovernance and compliance stature isbecoming even more challengingohI think I skipped some slides sorrytherestill learning how to use the clicker uhwe launched dataplex to help you reducesome of these impediments and be moredata driven and be able to realize morevalue from your dataFlex is a data first opinionated datagovernance and data management productit integrates with a number of ourexisting gcp products and capabilitiesto provide you the ability to govern andmanage your data at scalewith dataplex you can catalog all yourdataunify and organize that data leveragingmetadata and then centrally secure andmanage that dataand map that back to your businesscontext dataplex has built-incapabilities such as profiling lineageclassification and more that will helpyou manage data at skewand we are seeing dataplex used today bycustomers in a variety of Industryverticals geographies customers ofvarying scale in fact over 70 percent oftop Google cloud data analyticscustomers use dataplex today to manageand govern their dataand we are also collaborating andintegrating with a number of Partnerssuch as Culebra and others to buildend-to-end data fabric that you canleverage to manage your distributed datalandscapenow we launched dataplex last year inFebruary and since then we have beenbusy listening to all of you workingback from your needs and innovating andadding capabilities across the Spectrumto really enable you to discover yourdata with business context centrallysecure and manage your data and buildtrust in your data at scaleand I have a few more things to add tothis list today but before I do that Ido want to invite Sebastian on stage andshare a little bit more about how histeam at kev4 is delivering value fromdata thank you thank you projector forthe introduction uh I'm really honoredto be with you today so I'm Sebastian II am the global studio for careful andone of the major customers of Google onthe Google platform and I I will tellyou a bit about our story how we gotaccelerated on data governance datamanagement we leverage dataplex and Iwill tell you that a bit more at the endbut before that I wanted to tell you abit about the story that enabled usenable me to Embark our executivecommittee our Business Leaders into thedata governance Journey because let metell you one thingthere's very fewvery senior Business Leaders who areinterested about data governanceintuitively seen as a bit of a boringtopic as a as a requiredactivity to make things running but it'snot something that naturally will excitepeople people are more excited aboutgenerative pvi or I'm actually learningthen by data governance however it'sprobably the most important topic I haveto tackle as a chief data officerso I will tell you how we how westoryline it to unbox these peoplebefore I do that I wanted to share withyou a few numbers to for you tounderstand uh what's the asset we aretalking about to care for for those ofyou who are not very familiar withcareful we are a global retailer orparenting in 44 countries not operatingin North America by the way so probablyhence why most North Americans don'tknow carefulum uh it's based based on theheadquartered in France but it has inour Global footprint with that comes ahuge machine behind uh we have as youcan see here eight more than 80 millioncustomers globally uh and 50 million ofanother Loyalty cards we are veryradical you know data on themum we have nine core countries in whichwe operate and 35 more where we havefranchises that are operating under thecar for brand and we processed 10billion tickets uh and uh and uhmore than 85 million monthly orders inour supply chain just to give you a fewnumbers about them the massiveorganization that it is with 400 000employees globallyand all of that comes to to the Googlecloud and we we operate a global dataplatform and local data platformconsolidating 10 billion transactionsover three years so which makes it thelargestumdata Lake data platform for retailer inEuropeso starting with with this number as youmight ask yourself how do I make surethat I create a wonderful asset toautomata make sure that I increase thequality of the data that is here becauseby the way all the algorithm all thedashboards and all the decision makingtools that are built on top of it aredependent on the quality of what'sinside here so my goal was toum in a way if I use one of themotor that work very well here in NorthAmerica is how do I make data governancegreat againand cool for the organizationand which we find a way uh and we setout for our self-efficient behind it sobecause we operate Supermarket we usedwith our entire teams and also ourexternal partners that are purchasingour data because we also have a DataBusiness where we sell our data toBrands we want to make data shopping aseasyas a trip to the supermarket and wechose this analogy because it worked forus as a retailer and my advice for allof you guys is find the analogy thatworks for your businessit's very very well with the with thewith the teams with the business teamwhich how the kernel behind datagovernancewhat did you try to solve so he's kindof a real life example of what happensevery day at Cafe we have a businessperson who has a relatively simplequestion I want to have tons of erosionin v80 whatever you know data I want andthen I start having a loop of peopleembedded you know it goes to the managerit goes to somebody in in the tech teamand goes back to to somebody who'sgoverning data and at the end we figureout that the the data is actually in theend of somebody in the analytics team soit's a mess because you have all thesepeople involved and and it's verydifficult for the business user to findits way to find the person who can getthe data outand hence why the vision that we'vedefined and I will try to show you whathow it works concretely was to puteverything Under One Roof makeI have three principles applysystematically to all our data data mustbe accessible must be understandable andmust be reliable and behind all of thatyou can imagine all of the designprinciples for data governance that youcan apply to it on the criteria that weapply to our data to make sure thatthese three criterias are always metand the idea is also to bypass a numberof the stakeholders that are frankly notadding much value in the processso here is a vision so umit's like you know the corn in the fieldand it comes from different systems atcareful and then there are a number ofprocessing plants that are like the etlstransforming all of our data to make itusable and then this data is dumped intoa warehousefor us it's called a data warehouse butin a way it's a it's like a warehousefor in the supply chain and it's waitinghere to be consumedwhat typically happens is that we haveanalytics team so what's called theanalytics Factory it's our it's my teamit's consisting of a number of datascientists data Engineersthat areanalysts and Experts of datavisualizations were in a way operatinglike a restaurantum and uh this restaurant is nicebecause it serves the business usershere uh and all the videos they love togo to the restaurant why because it'svery comfortable you don't have to youhave to to take care with the mass ofthe warehouse so I go I go directly tothe team and I always have these guys inthe middle of my decision making processhowever what happens my team is totallyunder the water the the there arebottlenecks herebecause there are too many requests andof course people get frustrated the theshares here they are frustrated becausethey get too many requests and theydon't know how to prioritize and come toMedia how do I manage my workload andthe guys here in the business arefrustrated because they say why do Ineed to wait two weeks to get the dataout of this companyand so some people because they are fedup they go directly to the warehouse butguess what the warehouse so it's hereit's bigquery for us it has never beenbuilt to be used and usable by abusiness user it has been built for thatscientists so people get lost and theydon't know which box to open and theydon't even have a driving permit for theforklift to get the data out on thefifth level because they've neverlearned a sequel so they are totallylost and and many people are having youon access it's congested because all thetech people who are here they are noidea how to manage businessrelationships and and in the end uhguess what most people who are going tohere they don't get the right data theydon't get the right product out of thebox so they think they get this thisturnover but actually if you take aturnover without the Vats they wanted tohave it with vat but they have no ideawhy it's because here all the data arelabeled in a technical way it's notready for businessso that's why we we came up with withthis concept of the data Supermarket thesupermarket is this extra layer thatorganizes all this data and we builtthat over the data text layer that wasintroduced to you by contact area it's aplace where all the users can easilydiscover the data so because why becausedata are displayed organized in LA'swith with specific labels on each of theproducts and by the way all the labelsshould be interpretable by human atleast this is a vision of a when youenter a supermarket you want to knowwhat you're buyingyeahso if you double click in this conceptof data Supermarket against this analogyis critical because it's how are we atcareful I am back in our business tomake sure they understand that how itoperates how data Works in suchcompanies you have music history thingsit's like a store that we operate wehave an assortmentstuff we put on shelves an organizationwith people to operate the store andoperate to make it to make things workso now and as you might imagine this isthe the playing field of uh of um datapacksso if you go to talk about theassortments it's basically where we weput all the company data on shelves withsimple understandable shared definitionswith business holes and calculationrules that are transparent andunderstandable by everyone you don'tneed to have a data engineer badge tounderstand the how the kpi wascalculated and we we have clear a clearplan to improve the assortment tounderstand which assessment we need toput first on the Shelf and some qualityimprovement measures that we want tomake sure that the products are alwaysfresh when they are on the shelves if wedouble click on this here's what itlooked like and here's how again thebusiness can really understand what is aproduct rrk what is a data product in away because these are data products weare working on shelves uh so we westructured our data governance in 21data domains which are representing theexhaustive view of the data 4 and wedecompose that into Data families andultimately what we care about the coreof the problem is how do we make surethat we put uh here and so yes just seethat there are some friends and stillnot translated here but I guess you canimagine what it is tomatoes salads Etcum so the data the data product here isexactly what we want to put on theshelves and what we want to control andwhich we want to put quality measuresand which we want to to uh to have uhexhaustivity Clarity transparency of allof this data and of course it goes downthen to attributes at the end which areall the all the data related to our dataproductin a way the data product also like in astore there are different natural dataproducts some data products can be verysimple very raw like you can buytomatoes but you can also buy thetransform products in a way kpi thetransform product uh like tomato saucewill be that and maybe you can buy inthe fresh array Pizza which will becomposed of multiple kpis multipleConsolidated indicators so this is theway also to Embark the business is to sothey understand that in the endeverything that we produce as datawhether they are very raw or verytransformed these are all products thatwe are putting on shelves and hopefullywe make them a accessible understandableand reusable because we don't wantpeople to reinvent all the time therecipe to make a pizza and guess whatthis is what happens at careful like inmany big organizations people areReinventing the will Reinventing therecipe every time which is both achallenging because later you need toreconnect the data together and and ofcourse that it doesn't work and two theyspend a lot of time on this versuscreating value for the organizationso then comes the organization behind itso I will be very brief on this this isthe part where I had personally toconvince the most my senior managementteam that they need to invest because asa data officerI am not operating the data supermarketthe data Supermarket is operated by thebusiness I'm I am in a way I'm kind ofthe supply chain manager I'm providingthe data to the door of the supermarketand then you're managing your store eachLa is managed by the business just likein a store like the headquarters Where IBelong we never operate the storeso here's where we put in place atcareful holds the data owners of thebusiness the Committees thedecision-making process to prioritizeour software we put on shelves becauseguess what we'd love to put 100 of ourdata in 100 weight levels everywhere butit's costly we need to prioritize weneed to be use case driven value drivenwho is the best position to Define whichdata is of value it is a business not meso again I'm providing them with theskills uh training them to to be gooddata managers good shop managers I'mproviding them with a Playbook but thenthey operate they run the show and andultimately they run the data Supermarketthey have an LA or a set of shells andtheir friends run another set of shelvesand when they want to do crossfunctional analysis they trust eachother on the way because they operatethe same wayand finally comes to true and the toolis as an aspen for us essential to makesure that these data stored in in ourdata Lake for years is actually usableand efficient for for our business usersso we need a simple intuitive andPowerful tool to do that and before wewent for database we actually scannedthe marketfor a number of Tours who are doing thisand you mentioned earlier they were partof the of the RFP the request forproposal that we made a number of peoplelet me know uh things like that theGalaxy are Informatica so if some of youare from these companies close your earsbecause we scanned everything and wecouldn't find any of the session on themarketwho were was simple enoughbusiness oriented enoughto meet the requirements the very simplerequirements of putting data availableto everyonethe all of the players we looked atlike a rich sets of activity you coulddo that but it would way too complex forour business users to engage when weshow this product to the business wowI'm lost too many options too many menustoo many things I can do I just want tohave data availableand I want it to be simple and I don'twant you to have two two day training tobe able to access the supermarketso what and then that's when we met withuh with the Google team and we figuredout there was that great solution builtnatively on top of of Google Cloudcalled dataplex and that is in a waycataloging structuring all the data uhas it is today the interface is yetstill for me very well built for for ourdata teams uh what we decided to do isto build a custom layerwith web Technologies on top of dataplexdata packs doing all of the heavylifting for us structuring and doing thedata lineage all these difficult stuffthat are difficult to replicate it'sdone natively totally integrated withwith the entire Google stack enablingfor example natively to to Grant accessto people went to the supermarket andsay I want access to this data productcan you give me access yes very easilybecause it's naturally nativelyintegrated so it's by coupling thetechnical propositiondataplex with a very simple uh solutionso this is what it looks like today it'sa it's a very simple Portola to put abit like Google you know we can navigatein also through the the dataarchitecture here like the digital youknow the parameter show URL here youhave different Notions of turnover sohere's the v18 turnover you can see hereyou have the data on Earth you have a arule to manage the how it is calculatedall the synonyms the sensitivity youhave a link to to the data product islinked to an advanced product which isthe way the tomato sauce is linked tothe pizza in a way with all the reportsthat are being uh produced using thisdata that are certified you can even gowith dataplex to the table so if you aremore technical more for data analyst youcan link back to the table and evenunderstand how to what SQL code you canreuse to access the data platform so ina way it speaks to the business becauseas you can see the the first interfaceis really built for business resources Iwant to understand how this kpi iscalculated in a very simple fashion andhopefully I want to have access to heresome linked data products which arecalculation based on this turnover ordashboards that are certified by dataowner that are reporting the the salesBuy store and it's the one dashboardthat I want you to access and not theone of your friend or in the in theother division so we make all the datawhere's our row transform or finishGoods available through a singleplatform uh with with dataplex and webuilt this simple interface with veryfew options on top of it to make itaccessibleand here by the way we can add that tothe basket what it means is that if youadd it to the basket you can requestaccess with this data so so the bigchange this does for our teams is thatby default all the data data productsdashboard become visible to everyonejust like when you go to the storeeverybody can see the alcohol Departmentbut if you're in France for example ifyou're 17 years old you know I'm not 18you can see the product as you can seethe whiskey you're not getting out withthe whiskey because the request is theID card so the same idea here that wewant to make everything visible but itdoesn't mean that you have access somaking all of this dataaccessible by Design is the game changerfor the organization to make sure thatwe don't reinvent the wheel and we makeall the basic stuff simply availablewithout any human intervention with allthe complex process I showed you in theintroductiongood that concludes myPub we arecareful this and how we connect that toto the databaseso let methank youlet me introduce you to Fong who willtell you about is Gionee at snapthank you guyshi all wow I've never seen my photo likethat this bigso a little bit about myself my name isFong I am a manager at Snapchat I'vebeen in the data space for 20 years butthe last eight years I've been at Samand I want to talk to you about our ownour own Journey towards data governanceso snap is a technology company Snapchatis an app that empowers our users uh thepowers our people to express themselveslive in the moment learn about the worldjust and have fun with each otherum our community is about 397 dailyactive users on average and we use datain all sorts of ways right so we haveanalytics data we have machine learningwe have experimentation featuredevelopment right so these are all thethings that you knowso before I kind of get into deep um Iwant to talk a little bit about our oura bit of our snaps architectureso being data driven is really importantto us right and the key principle thatwe have is we want to be able to enableour each individual teams to build theirown pipelinesum to solve for their own needs at theirown pace so super critical to all thisis that teams aren't able to do thethings that in which you know to solvethe problems so what we have is we'llhave systems service produce thousandsof data sets right these are loggingdata that you guys all know about but asteams build their data pipelines intheir own way in their own you knowlittle silos the results of all this isthat you have teams producing multipledata in multiple formats with multipleschemas across millions of partitionsacross many many gcp projects rightso so to make this even more interestingas as teams these schemas will evolveover time as teams continue to innovatethe schemes will change all the timeso what's the problem with all thisright how does how does your datascientists know what data is out therehow does your mle knows what data is outthere how do you ensure that datagovernance is implemented uniformlyWithin These individual teamssoso the first problem that we have is wehave dark datawith millions of partitions spreadacross different storage Technologiesdata Discovery is the key to answersimple questions like what data doesSNAP havewhat is this field used forwhat is this data used for is this databeing trustworthy Who currently hasaccess to it who should have access toitand Adoption of new technology news usecases makes this a continued problemrighta second problem that we have is as younotice the individual teams are unableto build their own pipelines what youhave is you have these what I call datapuddles right just localized data Lakesso becauseum because with Zero Entry opportunityinteroperability between teams becauseblob storage you're not required toconsistently have because it's late towrite defined schemas on right thisleads to inefficiencies in dataengineering efforts and duplicate datayou're not able to read it how mostteams will just reproduce the data fromscratch it increases the risk of datacompliance compromises and systemsdisruption diminishes our ability tooptimize resources you're not able toget economy of scales if you're not ableto kind of get everybody to do the rightthing right and then hinders our abilityto drive complianceso with these two problems what to dowith assessour vision is to embrace uh embrace thedecoupled execution principle but wewant to convert from a data messinto a data mesh are you able to seethat yesso with data Plexit's not built a unified management andgovernance layer on top of ourdistributed data so that team is so thatindividual teams are able to continue tobe powered to develop on their own lifecycle at their own pace while at thesame time putting the guard rails inplace to ensure standardized dataquality and complianceso what we've done is introduce threethingsfirst is that logical data like thatspans across multiple physicalboundaries enables interoperabilitybetween teams that were once silentas the thing at the bottom second thingis them as a centralized metadatacatalog that's tightly integrated withour infrastructure so as as teams arereading from one data set right foranother set we're able to establish in alineage graph with that lineage graphwe're able to enrich that with how oftenhow much does this data set cost howmuch does it cost to produce this dataset how often is this data set red whatis the cost of that readand secondly and lastly is we're able totie it all together by building a UniFito buy a centralized data governancetooling framework to do theundifferentiated heavy lifting ofkeeping data safe compliant and drivingbest practicesso we're able to answer simple questionslike where is the data now rightum with the with the data mesh ourvision is to drive maximum is to drivemaximum potential of analytics data byproviding the tools to discover queryprotect and clean data at scale so withthat we have four goals cost andperformance optimization through manageand efficient storage and wastesecure and compliance throughcentralized and tight integration ofdata governance frameworkease of use you know making it easy toread from make it really make it easy towrite to and lastly is adoption of OpenSource especially to unlock our nmlinitiativesso what capabilities do we leveragedataplex for three things one is aunified metadata catalog what we wereable to do is with a unified metadatacatalog we're able to merge our littledata puddles into a single data Lakeorganized by a logical business groupingum we can we started off with dataDiscovery and compliance but we ended upsaving tens of millions of dollars everyyear for the past couple of years justbecause now we're able to identify datawaste we're able to identify inefficientstorage format so it's been so I wouldsay cost savings is definitely up therein terms of impact and lastly is they'reable to accelerate development velocityso now teams are able to share with eachother what you get here is now teams arethinking if my data set is being used bymultiple ways maybe I should partitionmy data in a ways where it's able to beused across multiple use cases right sonow we have a now we have a lot moreinteroperability between teams nowa second capabilities that we had wasAuto Discovery GCS so dataplex does thisthing where it scans GCS files and as itdetects new data sets in there I'llregister in your catalog what that'sdone for us is enables continuous dataclassification so when it detects whenthere's a new data set out there withpii we're able to apply the rightpolicies on itsecondly is we're able to lower doreduce operation loads so data packstakes care of the schema freshness foruslastly is we're able to adopt opensource Technologies so what happens isnow we're able to query data directlyfrom GCS without the pro without theloading into the structured datawarehouse so it bypasses this entirestep for us unlocks unlocks analyticscapability via notebook integrationunlocks and model capabilities viavertex Ai and Spark support for us sowhich is a huge which is a which is ahuge use case for usour journey doesn't end I mean which Ifeel like we're still really early inour journey and looking forward weactually have four areas of uh we havefour areas that we're looking to improvewe want to double down on an efficientml by leveraging open source technologywe want to be able to unify our dataAccess Control policies based on thesensitivity data so what happens is youknow with further Investments and dataclassification we're able to justidentify more types of data pii phonenumbers birth dateswe want to be able to host this policyin a single place and then Leverage Theenforcement of it through nativeintegration throughout our ecosystemsum data lineage is something that wewant to learn more and build more of sodeeper integration with the rest of ourtool sets and um and then with that onewe're looking to get more cost savingswe want to be able to better prioritizeour data cell you can imagine if you taga CEO dashboard as being high prioritiesyou imagine all the jobs that feeds itto also be high priority as well rightlastly it's data transmission deskknowing that your data is used by theCEO dashboard chances are that theentire lineage is probably trustworthyenoughlastly is improved data qualityautomated rules to alert anomalies issuper critical for ML initiatives thesemodel chain these models are chained ontens of thousands of features rightthere's no way that you were able toum write jobs manually so automation ofthese anomaly detections is key to usand with that I want to hand it back toprojecta[Applause]well first and foremost I want to thankboth Sebastian and Fung for sharing suchreally valuable insights sharing thechallenges that your team faced and alsohow you are able to let your businessteams operate autonomously while stillputting guard rails to really make surethat you have governed access governedoversight over your dataso it's hard to kind of Follow That andfollow those stories but I'm going totry with some new announcements that weuh we want to make available today indataplexso first one is actually our ourintegration and extension to vertex AIwe believe that data governance and AIgovernance shouldn't be two separatethings shouldn't be siled and with thatin mind we are actually makingcataloging of vertex AI metadata readilyavailable in dataplex so now as youcreate new models and data sets invertexthose the metadata for those would beautomatically cataloged in dataplex innear real time so that your data assetsand AI assets are searchable in one andthe same interfacedatablikes already supports a variety ofsources as you can see here where weautomatically catalog and index metadatafrom for Google data sources in yourreal time and give you the ability tobring in third-party metadata into asingle comprehensive metadata graph thatdescribes your datarelationships as well as your businesscontext and this really forms thefoundation of your governanceso finding and knowing what data existsis just the first step once you find thedata that you own and have access to youoften need to know the shape of yourdata and that's where the profilingfeature in dataplex is super handyand this is now generally available itwas in preview for some time and wereally appreciate all the feedback thatwe got from youwith profiling you can track thestatistical characteristics of your datayou can run this over a period of timeto track things like change in your dataor data drivesyou can also make this profilinginformation available alongside the restof your metadata in catalog and dataplexas well as directly in bigquery so yourdata scientists analysts have thisinformation handy as they are startingto work with their datadata profiling information is alsouseful in the next capability ofdataplexdata quality where we are able to Autogenerate and recommend rules based onthe profile of your data you are alwaysable to add custom rules where you cancall a UDF in bigquery or a pqml modelas part of your custom rules and theserules run on a completely managedserverless platform with built-inalerting dashboarding reporting toreally help you measure things likecompleteness validity a curious accuracyand freshness of your dataand just like profiling you can make thedata quality results or relevant dataquality results available both in thedata catalog part of dataplex asadditional metadata as well as directlyWithin bigqueryand we give you the flexibility toconfigure your alerts to configureactions based on granular rules on agiven table as well as monitor theoverall health of your data by providingyou built-in dashboards and reportsnow once you find that a certain tablehas a issue has a data quality issue youoften need to know it's upstream anddownstream dependencies and that's wherelineage comes in handy now we launchedlineage earlier this year and we havebeen rapidly expanding the support oflineagewe are able to automatically tracklineage for bigquery bigquery Omni forcross cross Cloud lineage as well as forBig Leagueum and then we've also added support fordata fusion and composer along withextensive extendable third apis that youcan create events for third-party datasourcesbut today we are announcing Generalavailability of data lineage for spotjobsum or running on data proc so regardlessof the language that your spark jobs arewritten in or whether they are spark SQLjobs or rdds we are able toautomatically track lineage for thesejobs and show them in the same lineagegraph in dataplexbut you knowjobs on dataprocopen lineage so any system thatintegrates with open lineage can nowsubmit events that get reported intodataplex and tracked as part of itslineageand last but not the leastwe are announcing the upcomingavailability of duet AI in dataplexnow as I mentioned dataplex provides abuilt-in Global search where weautomatically index your metadata andmake that available for you for yoursearch queries but you might havebusiness users as Sebastian wasmentioning who might want to ask aquestion of their dataand for them we are enabling a naturallanguage interface or over our searchthat will make it easyfor business users to ask questions oftheir datanow what happens when you don't knowwhere to start or what questions to askso the next capability that we'reenablingproviding you not only access to databut insights and what do I mean by thatwe want to give you a highly curatedlist of questions that you can startasking of your data as a starting pointto start exploring your dataand to really solve that cold startproblem now these questions willcertainly be available on a table levelbut the interesting part is that we areable to give you these questions acrosstables at a data set level as well asacross projects so you can really startasking these questions and reallyunderstanding data as well as therelationships between your datanow dataplex leverages metadata togenerate these list of questions andthen we use usage data to actually rankthem so that we give you a highly highlycurated and relevant list of questionsthat you can use and you can click onthese questions as you can see here andrun the SQL directly within bigquery andbigquery Studio to get results and startand jump start your Analyticsthat's all we have todayum unfortunately we probably don't havetime for live q a but all three of uswill be available after this session forany questions that you might have or anycomments discussions that you'd like tohave and I want to thank everybody forattending thanks Sebastian and fun formaking time to share their stories todaythank you very much everybody[Applause]foreign"
}