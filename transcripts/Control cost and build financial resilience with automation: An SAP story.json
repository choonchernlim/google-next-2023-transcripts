{
    "title": "Control cost and build financial resilience with automation: An SAP story",
    "presentation_type": "Breakout",
    "categories": [
        "DevOps, IT Ops, Platform Engineers, SREs",
        "OPS204"
    ],
    "video_id": "hPweWa6vEvI",
    "time": "Aug 30 04:15 PM - 05:00 PM CDT",
    "transcript": "foreign[Music]it's great to finally be back at Googlenext in personI'm actually very excited today becausewe have one of the largest fit-upsshowing ever at the largest conferencein the worldmatter of fact[Applause]one of the six spin-off sessionsthat we are having this year with manycustomer stories to shares lessonslearns product launch announcements sokeep in you know look look forward tomanual sessions tomorrow as well andI'll share some of that insights as wego forwardthis is an example of Google'scommitment to help our customers ontheir coffin-offs Journeyand with thatI'm gonna talk about how some of ourcustomers such as SSP get started ontheir Finance Journey however before weget started I'd like to take a quickpollthere are three stagesof Finance maturity craw Walk and Runwe will show handshow many of you here today are in theearlycross stageokay a fewhow about walk stagewow okayand how many of you consider yourself ina run stagewowI'm impressed matter of factaccording to the state of fan offFoundation report less than 20 percentof the organization's report themselvesare in the Run material stage of Financeand that's why today's session is soimportantwe're going to hear from what our Googlecustomer sapwho's the leader in class enough on howthey Leveragekey Google native capability andservices to dry automations within theirCloud Finance organizations so withoutfurther Ado let's get us started withsome quick introductionsmy name is Erica lamb and I lead I'll gohalf in US practiceso my name's Sarah McMullen I'm theproduct lead for Google Cloud billing myteam's responsible for building all thephenops tools and the automationFrameworks that customers like sap usehello I'm Wallace Suleiman from sapI lead the global Finance practice atsap and my team specifically we buildand provide finop services to make sapworkload run more cost efficiently onthe cloudthanks Sarah and Wallace now in caseyou are new to Carlton Ops let's juststart with some foundational Concepts atGoogle we Define Cloud Finance as anoperational framework that bringsTechnologies finance and business teamstogetherreally focus on drawing that culturalshiftenabling organizations to make financialdecisions in a more cost consciousmanner driving that Financialaccountability to the edge and helporganizations accelerate and realizetheir business valueand this is achieved through peopleprocess and toolingteam has been working with hundreds ofcustomers in the past yearswe see there's a five key criticalbuilding block of success in Enterpriseadopting cloud finopslet's start with the accountability andenablementthat is afunction of a cross-functional teamcomprised of IG Financeengineering architecture operationsindividuals coming togetherto set standards and best practices forthe rest of the Enterpriseonce you have that coffin of Team stoodoutmeasuring success measurementrealization focus on what are thesuccess metrics the kpis that you needto help Drive the progress of yourfinoff disciplinemany organizations that they think aboutgoing to the Run stage Cloud uniteconomics become relatively importantthe third aspect of this iscustomizationsthis is a continued disciplineit is not one time and done eventas we think about customizations thereare three key aspects to thisresources optimizations pricingoptimizations and Architecturaloptimizationsthe fourth pillar is planningforecasting as you think about how youmove from your workload from on-prem tocloud or as you manage your ongoingworkload on the cloud Financialforecasting become very important as youdemand and your month-to-month variancecan shift drastically managing thatFinancial forecastthinking about how you're using thatfrom the trend-based historical dataconsumption model to a drive-based modelis a key Focus area for manyorganizationsfinally bring that all togetherwith tools accelerator focusing on nearreal time Data Insights driven enablingbusiness and product leaders to makethose decisionsand that often includes automationtooling which we'll be talking aboutwith sap todayso now I'm gonna hand it over tocherish's uh Sarah to share some of thefin Ops tools the the apis that makeavailable where customers like sap hasbeen able to Leverageawesome thanks Ericwhat an exciting time to be a part ofFinn Ops and evolving cultural Evolutionit's interesting to see all the folks inthis room this practice really didn'texist until a couple years ago and Ihave the exciting opportunity to sharewith you building blocks for kind of ournext generation of phenops automationbut first just to set the stage of youknow why we built the way we didwe need to recognize a foundationaltruth and that truth is whether you aredoing cost allocationforecasting or optimization all of thoseactivities need to be grounded in goodsolid cost dataand within Cloud billingour data strategyhas three pillars the first pillar isfoundational data cost data seemsdeceptively simple right cost is afunction of price times quantity plus orminus some allocationshowever when you dig into the details ofthese foundational data you realizequite quickly that that also includesusage it can it can also includegranular costs that give you insightinto how those resources are being usedand it can also includecredits promotional credits things thathappen after your contractual discountsand before taxesso now we have these foundationalcore data we also need to look at oursecond pillar which is enriching thatdata to make sense of it and this iswhere Scopes such as the resourcehierarchyfolders organization projects come intoplay as well as your billing accountScopes in addition to Scopes that youprovide via layer labels or tagsand then once you have established thisfoundational data layer you've enricheditthe third and final step within our datastrategy is democratizing ithow you access the data is really afunction of how you want to use itand for example if you are looking atyou know a historical analysis overseveral months a data pipeline probablymakes sense for that use casemaybe you're looking to make sense ofsomething in a specific moment of timeand make a mission-critical decisionbased on the price of something well inthat case an API probably makes the mostsense to get that data and say you justwant to you know do a couple of simplecost calculations we'll CSV downloadsprobably make sense for that type offunctionso againthree foundational data pillars that wehaveand now let's look atwhat we are actually putting out theresowithin the foundational layer we havethree billing bigquery exportsinterestingly enough you can actuallyenable this within the billing consolein one click so that's not new we've hadthis alwaysbut some interesting facts about ourbilling bigquery exportswe actually update these up to eighttimes a day depending on the serviceand we also know that cost data isreally big data bigquery enables thepipeline and the storage all in oneand fun fact within Cloud billing weactually use bigquery to process all ofour Cloud billing data and it acts asour analysis storeso we actually use this to processbillions of rows of data every daynow our three pipelines The Standardbigquery Exportincludes your basic cost informationincluding usage skus project labelslocations Etc so there's a there's amultitude ofdata in the standard billing bigqueryexport now we have the detailed billingbigquery export the detailed billingbigquery export is where we put all ofthe granular cost information intonow what's exciting is throughout thisyear if you've been watching we'veactually been including a lot ofdifferent servicesgranular costs in the detailed billingbigquery export for example we includedapp engine at the instance level spannerat the instance level firestore at theinstance level and just this month we'venow included bigquery at the jobs anddata sets levelwe also have a pricing bigquery exportand that can that includes your contractpricing as well as your uh list pricingand it also includes any uh currencyskus and Geographic taxonomy informationokay so there's your foundational datalet's get into how we're enriching thisdataso we've now included in the detailedbigquery export the ability for you tojoin it with the pricing bigquery exportwe now have additional pricing fieldsfor you to be able to join those twodata sets together very easilyspecifically we've added the effectiveprice tier start amount and unit andpricing unit quantity columnswe also have included additionalinformation for our customers toidentify whether their purchases weremade from Google or third-partyMarketplacewith the addition of data such as legalname of the partner and the transactiontype of the selleradditionally what goes without saying isthat we also put in support for tagslast year now tags is an interestingconstruct because we have labels and wehave tags and I'd be remiss to say thatif you haven't looked at tags I wouldadvise you to do soright now we only support compute andspanner instance within the taggingecosphere for cost data but this isgoing to be our next generation oflabels and why are tags so special wellthey support inheritance they supportsecurity via IM policy so you canactually start to control who can createtags and also they support specialcharacters like the ad symbols so nowyou can have email addresses potentiallyadhere to your tags sotake a look at tags this is going to bea very interestingenrichment tool that we are going tocontinue to build on within cloud dataand I'd advise you to take a look atthatall right so now let's get intoapis sofirst off I want to walk us through somenew tools we have to understand costsprogrammaticallywe just recently put out the pricing APIpreview and I should note that there'sQR codes on all of these slides so ifyou want to scan them it'll take you tothe information for you to quickly seewhat the product's all about you canbookmark it as we goso for those that are familiar we have acatalog API so what's this pricing APIwell this is our next generation of thecatalog API specifically it now includescontractual pricingand additional metadata includingcategorization of the product servicefamilyregion discount type and SKU groups whatdoes this mean this means that now withthe new pricing API you can compare SKUprices and discounts across resourcesregions and SKU groups to understand howsavings compareso sometimes we get the question fromcustomers which is okay why are youputting out a public preview why isn'tthis going straight to gawell let me tell you we take ourcontracts through our apis veryseriously at Google we know that youbuild Mission critical applications onour apis when they ga now this is goodand bad for us from a productdevelopment standpoint that also meansthat we cannot introduce breakingchanges into a ga product because you'reusing those so for us to be able toquickly iterate and learn and evolve ourpricing API we want you to use it wewant you to tell us feedback we want tobe able to take your direct feedback andmake this product awesome for when we GAthis next year and I'll tell you thatwe're going to include batch querybatching of querying of all the skusuh by the end of the year so that's onething that's going to go into this APIbefore we GA it as well as we're goingto include visibility on skew pricinghistory so those are two features thatwe want to put in before we GA but wealso want to get feedback from ourcommunity and our ecosystem on usingthis APIand we also realized that customersdon't launch a SKU that's the thing wemonetize within Cloud billingthey don't even really sometimes launcha service like compute they launch acollection of these services to form aworkload this is where the costestimation API comes into playthe cost estimation API eliminates thegap between services and skusso what you can do is you can use thisAPIto Define your workloadyou give it your expected usage yourregion your resource type and then it'llreturn one or more skus and theassociated contracted prices with thatestimation now currently we only supportcompute and Storagebut we plan to evolve the services asthis API gets used so again takeadvantage of it it's there and provideus feedbackso now I'm going to get a little bitmore into how you can automate GCEoptimizations through committed usediscounts so committed use discounts orsometimes we refer to them as cuts forshort they're a great way to optimizeyour rates we allow customers discountsoff list pricing or negotiated contractpricingin exchange for a commitment of one orthree yearswith varying commitment by term or byregionand the commitments API this has been inin market for quite a while allows youto view create and manage yourresource-based commitmentsnow there's some additional featuresthat have actually been added in thisyear those include the ability to mergeyour commitmentsso now you can extend the lifetime ofyour commitment to co-term with yourbilling contractnow a couple of fine points on mergingmerge commitments will inherit thelatest end date from your mergedcommitmentand merge commitments obviously need tobe of the same term so one year canmerge with one year every year can mergewith three year and they have to be inthe same region and machine familythe other thing that this API nowsupports is upgrading so you can upgradefrom one to three year and it also andit also involves splitting so now youcan split your cuts to get to the rightlevel of granularity to managesome restrictions apply around splittingspecifically uh splitting cuts areapplicable not to license Cuts or cutsthat are attached to reservations so youcan't split those ones but it also doesnot extend to upgrading so you can'tshorten your cut by splitting itandany prioritized attribution on thosecuts that you split that resets so ifyou're familiar with prioritizedattribution just just be aware of thatbut it's pretty exciting I think thatnow we're starting to include more andmore functionality within this API foryou to essentially manage cud'sprogrammatically and I know that a lotof our customers especially if you buycuts and tranches you may have a longlong list you can tidy that up prettynicely in an automated fashion with thisAPIand I already kind of mentioned cutallocation so cut allocation is a reallyinteresting feature that we have withinGoogle that's pretty unique we allow ourcustomers to allocate their standardresource Cuts proportionally or byproject now this what we are nowofferingis the ability via a new procurement APIthat is still in private preview so thisis one of the only QR codes that youyou'll need to sign up for this privatepreviewbut you will be able to now attributeyour committed U.S discountsby folder so why is this kind ofinteresting well if you organize yourresources by folder it certainly makescost allocation using committed usediscounts a lot easiernow also note that discount sharing mustbe turned on for you to be able to takeadvantage of this featureall right so I just kind of ran throughsome foundational data we'veyou know but where are we kind of goingwith thisthe amount of foundational data is isonly going to increaseas we deliver more and more capabilitieswithin the cloud that's a givenand you know we're always going to behere to continually support that journeythrough additional granular data andthrough tools to automate this processbut I think we're still in the earlydays of automation for fin Ops and infactwhat I think is surprising is a lot offolks here were in The Run stage but Iwonder if that is the majority of thephenops practitioners out there wherewe're seeing kind of a mixed bag ofautomation not being adopted as much andso why is that is it because the toolsaren't in place is it the processes isit the peopleso we have a theory in Google and wethink that obviously some of these newannouncements that were made thismorningand in the previous days within nextAI is is really going to accelerateautomation it's very clear to uswhere others may have struggled withapplying some of these tools and datathat bridge is only going to be less andless and less closed through Ai andwe're already thinking about working onour next round of automationcapabilities using this technology so Iwant to leave kind of with that teaserof where we're goingand I want to introduce our next speakerwhich is Wallace Solomon from SCP who isgoing to talk to us about how he's led aphenops practice that I would categorizeas in in the running stage actuallysap is a very large Enterprise and Ithink that Wallace has grown a phenopspractice and has some really interestingautomation use cases at large Enterprisescale so I'm super excited to introducehim and we'll walk through kind of howthey've set up theirusingthe using all of the foundationalbuilding blocks that I just talked aboutWillisthank you Sarahwell I hope every one of you areenjoying this fantastic conferencewhat about gen AI[Laughter]now I want toum really thank you everyone forumlistening to what sap is doing in thefin lab spaceuh maybe a little bit of a history ofwhere sap is with Google Cloud platformwe started about five years ago a littlemore than five years ago in 2018 westarted adopting our workload moving ourworkload to Google Cloud platformso it's been a reallydecent five-year journey to where we aretodayand we are running today one of the mostcomplex and largest scale wise rightworkload application workloads on GoogleCloud platform so we're really proud ofthatif you look at how we came to todayyou know the journey that we've comethroughwe have reallyumyou know come to the point wherewe spent a lot of time looking at how wemigrate our existing workload or deploya new workloads on Google Cloud platformum and this is reallyum you know very interesting experiencethat we've had I want to share with youtodayback sorry okayall right I'm trying to uh yeah I'mtrying to go off script a little bit[Laughter]um sap uh of course some of you know uhwe're one of the largest applicationcompanies application software companiesout therewe've beenoperating in the multi-cloud environmentso needless to say we're running bothhyperscalers more than just ahyperscaler platforms we're alsooperating in our own data centers andso for us one of the complexities is toreally look at how we run how we run ourworkloads in a way that we can reallymanage our workload at scaleoperationally and also cost efficientlyas you start spending more money anddeploy more workloads at our scale we'retalking aboutyou know north of a billion dollars ofspendingany one of these platforms you know youreally need to look at the coffeeefficiency rightum you know but just like a lot of youguys I see a lot of handsum you know you're either already doingthis today or you are doing uh at apretty good degree of maturityum and one of the things you'll belooking at is how you wanted toum how you wanted to scale youroperations in a cost-effective way okayumso I want to share some of the learningswe're doing on the fin Ops Journey weare just like anybody we are alsolearning every day from our friends atGoogle from our friends from the finalFoundation there's a lot of newpractices best practices that have beencreated in the last number of years andI think we've benefited a lot of thatbut historically when we started doingour migrations and our deployment intothe public Cloud we've we've taken maybeconsciously we've taken a hybridapproach what I mean by that is we'vestarted by looking at as many vendorSolutions as possibleto accelerate our journey but at thesame time we're looking at ways that wecan customize our specific needs byleveraging as much Native capabilitiesfrom the cloud providers as possible aswell you heard a lot of the uh you knowservice new features API capabilitiesSarah just mentionedand we're also working very closely withEric's team to look at the opportunitiesto build up new services to power ourproductive workload So today we'rerunningboth our customer facing productworkload like sap business technologyplatform or as for Hana software as aservice our Ariba procurement Servicesjust name a few as well as many internalworkloads on Google Cloud platformandtoday I want to show you just by namingtwo examples if you like because youknow we've we've been doing thismultiple years on Google Cloud we'relooking at how to run cost efficientlyone of the two things Eric mentionedearlier uh in the finance best practicesis to optimize your resources and alsooptimize your rate or commitment rightso by committing your resources toGoogle Cloud platform you got a verysteep discountbut how do you work both side of thecoin if you will efficiently if one ofthe problems we wanted to look at is asyou start to optimize your workloadyou also may be cannibalizing yourcommitment a little bit so how do youbalance that you know two side of thecoin if you willI want to show you today two examples ofwhat we're doing in the costoptimization hereso I'm showing youuma right size example and this is whatwe're doing to customize some of theworkloads on Google Cloudso specifically what we're doing here isto looking at how we can downsize someof the VMS because this is probably thebiggest opportunity we're looking atwhen we can achieve resource efficiencyin Google Cloudin order to look at what opportunitieswe have first of all we wanted to lookat what are the underutilized resourcesin terms of virtual machines in theGoogle Cloud platformso we scan any particular projects andwe look at how wehow we can collect those performancemetrics data because in any right sizein excise the last thing you wanted todo is to impact your applicationperformance right so we look at theperformance metrics data over time weuse Google run to scan our environmentyou know every hour and we collect a lotof those performance metrics datayou know CPU utilization memory disk IOwhat have you into bigquery and weperform the analysis you know of courseall these data are mapped to our assetsand cost objects and we look at uhthe analytics and then we put that intoour right sizing engineto perform the downsizingrecommendations where applicable uh toour lives of businesses some of theexecutions are done outside of the rightsizing engine some of them areintegrated with our applications ICDpipeline so a lot of those actions arebeing performed either you knowseamlessly integrated or you know weprovide a recommendation to ourapplication team they would be you knowtaking those executionsonce those right signs and actions arecompleted we track them and we inputthose results into our commitment enginecommitment management engine we build ain-house system called plutusum I'm going to show you what we've beendoing include us to manage committedusage discountsum a lot of the apis Sarah discussedearlier are being leveraged in theBluetooth engine we're using thecommitment API to manage a lot of thecuts and flex Cuts we're also using theinventory API to list and to discoverwhat's the current status is of ourresources we're also doing that forbigquery additions right now and lastbut not least we use thecloud building apis and priceinformations we're actually updating allof the new pricing apis based on thelatest release in all of our toolsso a lot of those automations are builtinto this product or this service thatwe're essentially managing all of thecars and flex cards across the entirecompanyso without further Ado I wanted toreally show you a demo because thesesystems are running behind sap firewallso I have to record them into this demohopefully it playsand playdo I have to press againall right my name is Serene and I'm adevops engineer from saptoday I'm going to show you how weleverage gcp capabilities to optimizesap workload running on Google Cloud webuilt an in-house tool called costoptimization platform or copit integrates with gcp Native servicesto help sap applications run costefficientlyon the landing page I can track thesavings for my organization includingachieved savings year-to-date projectedsavings on track for fiscal year 2023and the max potential savings identifiedby the cop tool below I can also findthe max potential savings for myorganizationwhen I click on right sizing savingopportunity cop directs me to theoptimization detail pagecop can analyze the CPU and memoryutilizations over a chosen time frame weuse mql to query Google Cloud monitoringAPI to collect via metrics every hourthis is managed by cloudrun additionallywe will use the Google asset inventoryAPI to gather resource detailseverything will be stored in bigquerywhich will be analyzed by cop to provideprecise scaling recommendationslet's check this instancehere you can see you can save 540 permonth by switching N2 standard 32 to N2custom 1250176if we look at the metrics the CPUutilization during the past 30 days isvery lowit suggests reducing vcpus from 32 to 12and memory from 128 gigabytes to 49gigabytesonce you're ready to optimize simplyapply the recommended configuration inyour Cloud environmentafterward you'll be directed to theoptimization progress view to track thestatus of the instancecop uses statistical analysis to makethe best suitable recommendations oncethis VM is downsized the unused CPU andmemory can be viewed in our in-houseCentral RI and cud management toolcalled plutusnow I am on the plutus inventory screenI can check all the cuts my projectfiltered by region and machine type sothat I can see if there are enough cutsto cover the landscapethe inventory table also displays anoverview of cut performance and detailedinformation for each commitment made theVMS from downsizing are already here andI can use other tools included tomaximize cut return on investment plutusleverages Google's commitment apis suchas commitment resource commitmentcommitment scope list and more to buildup the cuts inventory reportI reach a point where I have sufficientvcpu and RAM usage for my VMS howeverplutus identified low cut coverage formy project landscape from the inventorypageI can use the recommendation page wherethe plutus engine proposesrecommendations to bring more netsavings and increase cut coveragein the recommendation report bluedispatches usage data through bigqueryquery job configuration and providesrecommendations to increase my cutcoverageplutus will suggest bcpu and RAMpurchase amounts for my projectonce I decide on the best fitrecommendation I can select one or moreprojects and purchase their recommendedamountsplutus facilitates this transaction andmakes the purchase with its executionengine using the commitment operationAPInote that everything I showed here canbe automated as wellonce the purchase has been made I can goback to the inventory page and check myproject coverage againthanks to Google's Rich set of serviceapis and automation capabilities sap isable to officially manage and optimizeits application workload running onGoogle Cloudthank you so what's next as you lookforward to enhance the uh you know coptool if you will yeah so I think uh justlike what you showed in the finaps theflywheel one of the next pain points orchallenges were tackling is toreally how to accurately forecast ourdemands because the demand management isreally critical todoing the right commencement managementand the optimization effort itself alsoimpacts how we you know how we are goingto be fluctuating our demand situationover timeso a lot of those demand signals doesn'tcome from one location I mean typicallywe collect them from our sales pipelineswhat have you that in reality you needto look at a lot of the other impactingfactors and this is the area where weare you know hopefullynot just by looking at aggregatingdifferent demand signals but alsolooking at the power of machine learningto help us do more accurate forecastsand demand managementthank you for thatum so as you just heard from Wallaceright no matter where you are in yourFinance journey is it is there a processcertainly you know your journey mightstart in the early cross stage and inorder to do what he was just showingthrough that demoif you're early on cost and labelingstrategy become very importantthen if you're in a walk stage the nextstep is that getting that cost ofdisability through a cost Insightdashboard so with the sap use casethey'll build their own dashboard usinga number of cloud building apis andservices natively and then as he sharedthe next step of that is once you havethe visibility in place Financialforecasting get into that unit economicsand actually realize the business valueis the essential step in your finalsJourneyand I think one of the key aspects ofthis is that you know many of you raiseyour hand you either you know crawl walkor run stage You Are Not Alone on thisright you know you have your peers youhave the thinner foundation and also youhave our Google Cloud Consulting teamhere to partner with you on this journeyso with that I want to show you and andannounce one of our latest offeringright you know you can't leave thisconference without talking about gen AIso we actually launched our coffin offfor General offering which help ourcustomers ensure that they are able tomaximize their generic investment byfollowing the fin off principles andprocessesthe service offering included frameworkfor assessing your generic Readinessfrom finite perspective agendaonboarding process a cost-benefitmodeling to help customers as they thinkabout how you should think aboutprioritizing your general use casesfurthermore I'm very excited to announceand Now launch our new assessment toolthat you can actually access today byscanning the QR code on the screen sothe first one is a lightweight versionabout coughing up assessment toolum and the other one is a assessing yourgeneral Readinessum definitely go take a test run todayand share your feedback with us both ofthe tools are pretty self-served veryquick short uh50 minutes questionnaires that you cancomplete and we'll share with you allthe recommendations and the next step onhow you can take actions on itforeign"
}